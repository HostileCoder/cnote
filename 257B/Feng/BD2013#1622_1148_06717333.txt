Learning Bayesian network from event logs using 
mutual information test 
Riska Asriana Sutrisnowati 
Department of Big Data 
Pusan National University 
Busan, South Korea 
riska@pusan.ac.kr 
 
Hyerim Bae*,  
Department of Industrial 
Engineering 
Pusan National University 
Busan, South Korea 
hrbae*@pusan.ac.kr 
 
 
Jaehun Park 
Department of Industrial 
Engineering 
Pusan National University 
Busan, South Korea 
pjh3479@pusan.ac.kr 
 
 
 
Byung-Hyun Ha 
Department of Industrial 
Engineering 
Pusan National University 
Busan, South Korea 
bhha@pusan.ac.kr 
 
Abstract— A Bayesian network can be considered to be a 
powerful tool for various analyses (e.g. inference analysis, 
sensitivity analysis, evidence propagation, etc.); however, it is 
first necessary to obtain the Bayesian network structure of a 
given dataset, and this, an NP hard problem, is not an easy 
task. Among the available scoring metrics, the present study 
employed Mutual Information Test (MIT) to construct a 
Bayesian network from the event logs of port logistics data 
covering six days of observations. Additionally, dynamic 
programming was used to shorten the combinatorial 
calculation of the metrics and, later, to minimize the 
computation time. To validate our method, we conducted a 
case study of port processes using actual event logs from an 
Asian port. 
Keywords— Learning Bayesian network, mutual 
information, event logs 
I.  INTRODUCTION  
Currently many businesses are supported by information 
systems that provide insight into what actually happens in 
business process execution. This abundant data has been 
studied mainly in the growing research area of process 
mining [1-4]. One of the important performance-monitoring 
concerns is the execution pattern. Suppose that a process 
contains an OR, according to which, it can follow one 
course or another course: Which is it more likely to follow? 
Any different flows can differentiate the final result (e.g. 
total execution time; required resources, etc.) of that 
process. It should be clear, then, that an event of a process 
might contain many other attributes, which, in the cases of 
some complex business processes [9-10], may have tens or 
even hundreds of attributes. Thus, determining which 
attributes influence a given pattern is not straightforward. 
To accommodate this process pattern uncertainty, in the 
present study, we employed a Bayesian network to 
determine which attributes cause a particular kind of process 
flow.  
In our previous work [5], we used a dependency graph, 
retrieved by Heuristic Miner [6], and decomposed any 
cycles found into a non-cycle structure. This methodology, 
though enabling quick retrieval of the constructed Bayesian 
network, has drawbacks relating to the fact that its non-
 cycle structure is dependent solely on the structure of the 
dependency graph. In other words, we have to take due note 
of the fact that the structure is supported only by the 
successive occurrences between activities and not by the 
common information shared. To remedy this shortcoming, 
in the present study we refine our previous work by 
developing a dynamic programming procedure of mutual 
information score using Mutual Information Test (MIT) [7]. 
The data used to calculate MIT score was originally not in a 
form of event logs, and, indeed, MIT was not designed for 
the business process management field. Therefore, the 
formula was modified to accommodate the problem at hand. 
We, also, took account the computational complexity both 
of the recursive procedure, proposed in [7], and our 
proposed dynamic programming. 
This paper is organized as follows: section 2 discusses 
the background; sections 3 and 4 introduce the proposed 
method and a case study, respectively, and finally, section 5 
draws conclusions. 
II. BACKGROUND 
A. Bayesian network 
A Bayesian network is defined as a directed acyclic 
graph (DAG) G of tuple (V, A, P), with  
• { |1 1,..., }iV v n= = :  a set vertices of the graph, and 
• { ( , ) | , }ij i j i jA a v v v v V? = ?  : a set of arcs representing 
dependencies. 
Let 1 2{ , ,..., }nX X X X=  be a set of random variables such 
that iX  is a random variable for each vertex iv  in the graph. 
For each random variable iX , there exists a parent set of
  
iX , denoted 1 2( ) { , ,..., }ii i i isPa X X X X= . Using the chain 
rule, the joint probability density 1 2{ , ,..., }Ix x x x= can be 
written   
1 2
 1
 ( , ,..., ) ( | ( ))
 n
 n i i
 i
 P X X X P X Pa X
 =
 =∏ .(1) 
2013 IEEE 6th International Conference on Service-Oriented Computing and Applications
 978-1-4799-2701-2/13 $31.00 © 2013 IEEE
 DOI 10.1109/SOCA.2013.38
 356
The Bayesian networks’ powerful utility in inference 
analysis notwithstanding, learning a Bayesian network from 
a given dataset is an NP hard problem [13]. Such learning is 
time-consuming, especially where the data is unordered and 
there is no reference structure.  
B. Mutual information 
De Campos [7] proposed the use of mutual information 
and conditional independence tests as a scoring metric 
applicable to the learning of a Bayesian network structure. 
The metric balances the degree of interaction between each 
random variable and its parent(s) with the correlation in 
terms of the independence of an 2?  distribution. Since the 
MIT score comprises the local scores for each iX  over its 
parent ( )iPa X , a higher MIT score indicates a higher 
dependency of each iX  on its parent ( )iPa X . The MIT 
score of a DAG, denoted as G, over an event log, denoted as 
L, is formalized as 
 
( ),
 1; ( ) 0
 ( : ) 2 . ( , ( ))
 i
 i ji
 sn
 MI T L i i l
 i Pa Xi j
 S G L N MI X Pa X
 ??
 ?
 = ≠
  
 = ?    ,(2) 
where 1 2{ , ,..., }nX X X X=  is the set of n variables 
corresponding to 1 2{ , ,..., }nr r r discrete states, N is the number 
of observations of event logs L , 
1 2( ) { , ,..., }ii i i isPa X X X X= is the parent of iX
  
in G with 
corresponding 1 2{ , ,..., }ii i isr r r  discrete states, wherein 
 | ( ) |i is Pa X=  is the number of parents of iX , ?  is a fixed 
value of 0.9, 0.95 or 0.99 confidence interval, 
( , ( ))L i iMI X Pa X  is the mutual information of iX
  
and its 
respective parents, ( )iPa X , ( ), i jil??? is the value such that 
( )( )2 ,( ) i jiij lp l ??? ? ?≤ =  (the Chi-square distribution at 
significance level 1 ?? ), and ( )ii jl?
  
is the degree of 
freedom of: 
1
 ( ) ( )
 1( )
 ( )
 ( 1)( 1) , 2,...,
 ( 1)( 1), 1
 i i
 i
 i
 j
 i i j i k i
 ki j
 i i j
 r r r j s
 l
 r r j
 ? ?
 ?
 ?
 ?
 =
 	 

 ? ? = 
 =   
 ? ? = 
 ∏
 ,(3) 
where { (1),..., ( )}i i i is? ? ?=  is any permutation of the index 
set {1,..., }is  of ( )iPa X , which lists the corresponding states 
in descending order.  
De Campos [7] also provided, for construction of a 
Bayesian network, the recursive procedure, represented by 
equation (4) (which procedure, because the data set 
considered is not in the form of event logs, can be costly).  
( )
 ,
 ( , ( ) : )
 ( , ( ) \{ }: )
 min 2 . ( , | ( ) \{ })ij i r
 ij
 r i i
 r i i ij
 X Pa X L i ij i ij l
 g X Pa X L
 g X Pa X X L
 N MI X X Pa X X
 ?
 ??
 	 
 
 =  + ?  
 ,(4) 
where ??  is the value such that ( )2 ,( ) rijrij lp l ?? ? ?≤ =  and 
the number of degrees of freedom is 
1;
 ( 1)( 1)
 is
 r
 ij i ik ik
 k k j
 l r r r
 = ≠
 = ? ? ∏ . The base case of the recursive 
procedure is ( , : ) 0
 r ig X L? = . Accordingly, the MIT score 
defined in equation (2) can also be expressed 
1; ( ) 0
 ( : ) ( , ( ) : )
 n
 MIT r i i
 i Pa Xi
 g G L g X Pa X L
 = ≠
 =  .(5) 
C. Process structure 
The dataset used in the present study was in the form of 
an event log, denoted L. Van der Aalst [12] proposed a 
hierarchical structure of process execution event logs. In his 
work, a process consists of cases, denoted c, and each case 
consists of events, denoted e, such that an event is always 
related to one case. For instance, suppose a tuple 
, , ,A B C D< > , which represents a case in the event logs in 
which an event A is followed by an event B and then an 
event C and, eventually, an event D.  
For convenience, we assume that each event in the event 
log is represented by one random variable X , so that AX  
represents the random variable of an event A. ( )iPa X
 
  is a 
set of candidate parent(s) of an event in the event logs. Since 
a case c in the event logs contains a sequential process 
execution, we can assume that the data in the event logs is 
ordered. For example, an event A has an empty candidate 
parent since event A is the start event, denoted ( ) {}APa X =
 
 , 
while an event B has event A as its candidate parent, denoted 
as ( ) { }B APa X X=
 
 . We should take note 
that ( ) ( )i iPa X Pa X?
 
 , due to the fact that a candidate parent 
makes no higher contribution in the iterative calculation of 
( , ( ))L i iMI X Pa X cannot actually be considered as the actual 
parent. 
III. LEARNING BAYESIAN NETWORK 
Suppose that we have four random variables, 
1 2 3, , ,X X X or 4X : each random variable has two states, 
2r = ; the candidate parents of 1X  and 2X  are 
1 2 3 4( ) { , , }Pa X X X X=
 
 and  2 3 4( ) { , }Pa X X X=
 
 ; and there 
are no candidate parents for 3X  or 4X . Using the recursive 
procedure in equation (4), the calculation finds the parents of 
1X . The calculation starts from the top and, incrementally, 
calculates to its bottom layer to find the base case. The 
procedure has a computational complexity of 
( )2( 2 !)mO n m m? +  for n  random variables and 3m ≥  
candidate parents for each random variable. The idea, then, is 
to reduce the complexity of the recursive procedure by 
transforming it into dynamic programming.   
357
 
Fig.  1 Bayesian network resulting from given example 
Let us assume that for each MIT local score we need to 
find the minimum score such that the (i)-th local score is 
from the minimum (i-1)-th local score. Unlike the recursive 
procedure, we would like to start our procedure from the 
bottom up and move incrementally to the (i)-th step from the 
minimum (i-1)-th step. The formal definition of the 
recurrence is 
1
 1 2
 1 2
 ( )\ ( )
 1
 ( , ( ) : )
 ( , ( ) : ),
 ( , ( ) : )min
 2 ( , | ( ) )ij i i r
 ij
 k k
 d i i ij
 k k
 d i i ij
 k k
 d i i ij
 X Pa X Pa X
 k
 L i ij i ij l
 g X Pa X X L
 g X Pa X X L
 g X Pa X X L
 NMI X X Pa X X
 ?
 ?
 ?
 ? ?
 ? ?
 ?
 ?
 ?
 	 
?  ?=   + ? ?  
 
  , (6) 
where 1( , ( ) : )k kd i i ijg X Pa X X L?? is the minimum k-th local 
score that has parents 1kijX
 ?
  that yield the minimum local 
score for the (k-1)-th steps, and 
12 ( , | ( ) ) r
 ij
 k
 L i ij i ij lNMI X X Pa X X ??
 ?? ? calculates the mutual 
information score by adding ( ) \ ( )ij i iX Pa X Pa X?
 
 . The 
mutual information score for finding each parent of a 
random variable is similar to that in equation (5).  
Suppose that our recurrence for 
1( , ( ) : )k kd i i ijg X Pa X X L?? , for the k-th step, is correct. 
Accordingly, we consider two options for calculation of the 
(k-1)-th step: 1) the calculation of 
1 2( , ( ) : )k kd i i ijg X Pa X X L? ?? , where there is no contribution 
from the addition of the remaining random variables as the 
parents of iX ; 2) the addition of 
1 2( , ( ) : )k kd i i ijg X Pa X X L? ??  and the remaining random 
variable(s), denoted ( ) \ ( )ij i iX Pa X Pa X?
 
 , if by adding 
it(them) a better mutual information score of iX  in (k-1)-th 
step is made. The minimization of the (k-1)-th step will lead 
to the minimization of the k-th step. Thereby, our algorithm 
will find the optimal mutual information score. The base case 
is obviously 0 ( , ( ) : ) 0d i ig X Pa X L = , where ( )iPa X = ? . 
Our algorithm has the computational complexity of ( 2 )mO n  
for n  random variables and m  candidate parents for each 
random variable. 
The procedure for finding the parent(s) of 1X , using the 
same example from the beginning of this section. The 
process starts from the bottom and gradually inserts, in 
sequence, the remaining parents of 1X . The last iteration 
shows the optimal mutual information score for 1X , denoted 
3
 1 1 3( , ( ) { } : )dg X Pa X X L? . The complete Bayesian network 
for the example is shown in Fig. 1. 
IV. CASE STUDY 
A. Port process overview 
One hundred and eighty (180) of the 500 port logistics 
operations in the world are required to serve more than one-
 half million TEU (Twenty-foot Equivalent Unit) [8] 
annually; this fact has compelled the adoption of more 
efficient operations. Most port logistics operations currently 
are supported by information systems that store actual 
operation records. Employing this data, and using the 
process mining technique, port managers can obtain useful 
insights into what actually happens in the port logistics 
process execution. Moreover, since port logistics are prone 
not only to complexity but also uncertainty, in this study we 
employed the Bayesian network to investigate port logistics 
performance. 
Fig. 2 shows port logistics process in BPMN 2.0 
notation. Port logistics event logs obtained consists of 395 
process instances and 1009 events. It covers six days of 
observation, and includes the discharging and transshipment 
processes. The discharging process discharges a container 
from a vessel for stacking in the yard, after which it is either 
brought out of the port as an outbound container, or loaded 
onto another vessel. Due to privacy issues, some of the 
contents have been masked; this did not affect the study 
results. The events (activities) include yard operations for 
container discharge (YD), quay operations for container 
discharge (QD), yard operations for container loading (YL), 
pluggings for reefer container (RP), container shuffling 
(SF), quay operations for container loading (QL) and yard 
operations for container gate out (YO). Each event is 
represented as a random variable, the state(s) of which is 
(are) an attribute(s) value in the event logs, (i.e. the value of 
the originator or of another data attributes). 
B.
  Data preparation 
Each event in the same process instance is ordered based 
on its timestamp. This facilitates construction of a Bayesian 
network, since the parent of a given event is actually an 
event that previously occurred. To that end, first, we list the 
random variables, and their respective candidate parents and 
states from the event logs. For convenience, each random 
variable is represented as its 
abbreviation: , , , , ,YD QD SF RP YL YOX X X X X X  and QLX . For 
instance, a variable YDX  has its candidate parent(s) 
( ) { }YD QDPa X X= , whereas QDX  has an empty set of 
candidate parents, since we cannot find any predecessor of 
event QD in the event logs. The following is a complete list 
of events and their respective candidate parents and states. 
358
TABLE I. LIST OF RANDOM VARIABLE WITH RESPECTIVE STATES AND 
CANDIDATE PARENT( S) 
Variable Number of States Candidate Parent(s) 
Originator(s) Attribute(s) 
YDX  8 14  ( ) { } YD QDPa X X=  
QDX  6 14  ( ) { } QDPa X =  
SFX  8 20 ( ) { } ,SF YD RPPa X X X=  
RPX  2 0  ( ) { } ,RP YD SFPa X X X=  
YLX  8 10  ( ) { } YL YDPa X X=  
YOX  8 10  ( ) { } , ,YO YD RP SFPa X X X X=  
QLX  7 10  ( ) { } QL YLPa X X=  
 
Fig.  2 Port logistics process in BPMN 2.0 notation 
The states are those of the originators, which in this case are 
quay cranes and yard cranes. 
C. Generation of Bayesian network 
To learn the Bayesian network from event logs, we apply 
our proposed calculation steps to our case study. First, the 
variable with an empty set of candidate parents is left as it is. 
Afterwards, starting from the first variable, we calculate the 
local score according to equation (5). Since YDX  has only 
one parent (as do YLX  and QLX ), the calculation will be 
straightforward. For SFX  and RPX , each having two parents. 
The results indicate that between the two candidate parents, 
there is only one parent YDX , for both SFX  and RPX . This is 
due to the fact that 1 ( ,{ }: )d SF YDg X X L  and 
1 ( ,{ }: )d RP YDg X X L are smaller than 1 ( ,{ , } : )d SF YD RPg X X X L  
and 1 ( ,{ , } : )d RP YD SFg X X X L , respectively. 
The local score calculation of YOX , denoted as 
( , ( ) : )d YO YOg X Pa X L ; on this basis, we also gain the actual 
parents of YOX , which are ( ) { , , }YO YD SF RPPa X X X X= . The 
complete Bayesian network in our case study is illustrated in 
Fig. 3 (a); Fig. 3(b) includes the attributes from the event 
logs, and also shows the observation of originator YC61 in 
YD
  
 and the flow traversing through YL that affects the 
posterior probability of QL being late in the container 
loading process of VESSEL01, which also can be expressed 
as 
( ’  01’ | ’ 61’, ’ ’) 0.0002QL YD YLP X Late V X YC X Traverse= = = =
 ; meanwhile Fig. 3(c) shows the posterior probability 
distribution of each possible state in the random variables. 
D. Analysis Scenario 
After the Bayesian network is retrieved, the network 
analysis, which includes inference analysis, sensitivity 
analysis, and others, can be performed.  
• Causal inference 
Causal inference can also be used to investigate the 
cause of working delays. In [5], we noted the lateness 
inference of an overall process given one delay in an event. 
For example, if the container placement in the yard for 
loading preparation (YL) is certain, then the probability of 
the container loading process become late for Vessel V01 is 
0.0211 and, eventually, the probability of container loading 
process being on time is 97.88. 
• Backward inference 
Backward inference is used to find the probability of the 
opposite direction of causal inference, that is, the probability 
of the caused random variable where the affected random 
variable is known. For instance, the probability that a 
container going off port through the container gate out (YO), 
is a reefer plugging container, is denoted 
( ' ' | ' ')RF YOP X traverse X traverse= = , and is 0.017.  It 
should be noted that only reefer containers go through reefer 
plugging event RFX . In this study, using the same means of 
retrieving the reefer plugging container probability, we could 
determine that the probability of those containers having 
been through a shuffling event (SF) was 0.015. 
• Explaining-away inference 
Suppose that a port manager wants to know which event has 
a higher chance of triggering a gate-out process: YD, SF, 
RP or a combination thereof. Using explaining-away 
inference this time, the port manager can predict this. A 
more interesting analysis that can be employed using 
explaining-away inference is the ability to infer any possible 
patterns influenced by each random variable state(s). As an 
example, assume YD and QD as an event with yard cranes 
and container-bound remarks as its states, respectively. It 
can be inferred that any yard cranes carrying a container 
with “transshipment” as its remark is more likely, with the 
probability of 0.09, to execute YL than another process. 
This way, if YD and QD are certain, we can obtain a clearer 
understanding of the probability of transshipment occurring.  
359
 
 
Fig.  3 Bayesian network of the port logistics case study 
V. CONCLUSIONS 
This study refined our previous investigation into 
Bayesian network generation. In that earlier study, we 
decomposed any cycles found in a dependency graph into a 
Bayesian network. However, in such a case, the non-cycles 
structure remains as the original dependency graph structure. 
Moreover, the dependency graph is derived from the 
Heuristic miner algorithm, which derivation does not follow 
the principle of Bayesian network construction, namely, 
dependency (independency) among vertices. To remedy this 
shortcoming, in the present investigation, we employed 
mutual information test (MIT) to construct the Bayesian 
network. MIT was not originally designed for the field of 
business process management, and so the data set used to 
calculate MIT is not in the form of event logs. Thus, we 
propose dynamic programming for MIT calculation. Our 
proposed method was proved to entail less computational 
complexity than the recursive procedure for the original MIT 
calculation. Moreover, we validated our method using real 
port process analysis. The case study reported in these pages 
covered six days of observation and involved almost four 
hundred process instances. Considering that event logs 
contain time-series data, we would like to enhance this 
method in a more applicative direction, specifically with 
respect to the n-order Markov chain in a dynamic Bayesian 
network. 
ACKNOWLEDGMENT  
This research was supported by Basic Science Research 
Program through the National Research Foundation of Korea 
(NRF) funded by the Ministry of Education (2013013143) 
and the National Research Foundation of Korea (NRF) grant 
funded by the Korean government (MEST) (No. 
2012R1A1A2008335). 
REFERENCES 
[1]. M. Song, C.W. Gunther, W.M.P. van der Aalst, “Trace clustering in 
process mining,” Business Process Management Workshops in 
Lecture Notes in Business Information Processing vol. 17, pp. 109-
 120, 2009. 
[2]. C.W. Gunther, W.M.P. van der Aalst, “Fuzzy mining: adaptive 
process simplification based on multi-perspective metrics,” In: 
Proceedings of the 5th International Conference on Business Process 
Management (BPM’07), pp. 328-343, 2007. 
[3]. J. De Weerdt, S.K.L.M. vanden Broucke, J. Vanthienen, B. Baesens, 
“Leveraging process discovery with trace clustering and text mining 
for intelligent analysis of incident management processes,” IEEE 
CEC, pp. 1-8, 2012. 
[4]. S. Goedertier, D. Martens, B. Baesens, R. Haesen, J. Vanthienen, 
“Process mining as first-order classification learning on logs with 
negative events,” In: Proceedings of the 5th International Conference 
on Business Process Management (BPM’07), pp. 42-53, 2007. 
[5]. R.A. Sutrisnowati, D. Jeon, H. Bae, M. Song, H. Lee, J. Bae, 
“Identification of lateness factors in container handling process using 
Bayesian network from event log,” In: Proceeding of The 2012 
International Conference on Logistics and Maritime Systems 
(LOGMS), pp. 97-106, 2012. 
[6]. A.J. Weijters, W.M.P. van der Aalst, and A.K. Medeiros, “Process 
mining with the heuristics miner algorithm,” Technology, vol. 166, 
pp. 1-34, 2006. 
[7]. L.M. de Campos, “A scoring function for learning Bayesian networks 
based on mutual information and conditional independence tests,” 
Journal of Machine Learning Research, vol. 7, pp. 2149-2187, 2006. 
[8]. J.P. Rodrigue, “The geography of transport systems,” 3rd ed., New 
York: Routledge, ISBN: 978-0-415-82254-1, 2013. 
[9]. Lee, D., Bae, H., “Analysis framework using process mining for 
block movement process in shipyards,” ICIC Express Letters, vol. 7, 
pp. 1913-1917, 2013. 
[10]. B.N. Yahya, M. Song, H. Bae, D. Jeon, S. Sul, R.A. Sutrisnowati, 
“Port logistics data analysis using process mining,” In: Proceedings of 
Korean Operations Research and Management Science, 2012. 
[11]. J.P. Rodrigue, “The geography of transport systems,” 3rd ed., New 
York: Routledge ISBN: 978-0-415-82254-1, 2013. 
[12]. W.M.P. van der Aalst, “Process mining discovery, conformance and 
enhancement of business process,” Springer-Verlag Berlin 
Heidelberg, 2011. 
[13]. D. Chickering, D. Geiger, D. Heckerman, “Learning Bayesian 
Networks is NP-Hard”,  
 
360
