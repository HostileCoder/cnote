Secure Decoupled Linkage (SDLink) System for Building a Social Genome
 Hye-Chung Kum1,2, Ashok Krishnamurthy2,3, Darshana Pathak2, Michael K. Reiter2, Stanley Ahalt2,3 
1Department of Health Policy and Management, Texas A&M University Health Science Center 
2Department of Computer Science, 3RENCI, The University of North Carolina at Chapel Hill  
kum@srph.tamhsc.edu; {dpathak, reiter}@cs.unc.edu; {ahalt, ashok}@renci.org 
 
Abstract — Population informatics is the systematic study of 
populations via secondary analysis of massive data collections 
about people, called the social genome.  A major challenge in 
building the social genome is the difficulty in data integration 
of heterogeneous and uncoordinated data while protecting the 
confidentiality of the data subjects.  Here, we present our work 
in designing a flexible computerized third party linkage 
platform, Secure Decoupled Linkage (SDLink), which can 
provide both privacy protection and accurate high quality 
integrated data using a hybrid human-machine data integration 
system.  Our evaluation results show that chaffing used in 
combination with universe manipulation is very effective in 
blocking inferences during the clerical review process. 
Keywords- privacy preserving record linkage; decoupled data;  
I.  INTRODUCTION 
Today, nearly all of our activities from birth until death 
leave digital traces in large databases that continuously 
collect, store, and process huge amounts of data about us. 
Together, these massive data collections (termed “Big Data”) 
about people collectively capture our social genome, the 
footprints of our society.  If properly integrated, analyzed, 
and interpreted, this social genome could offer crucial 
insights into many of the most challenging problems facing 
our society such as healthcare, education, and economics.  
The field of population informatics is the systematic study of 
populations via secondary analysis of this social genome.  In 
particular, health informatics analyzes electronic health 
records to improve health outcomes for a population.   
II. RELATED WORK: RECORD LINKAGE & PRIVACY 
Digital data about people often ends up in heterogeneous 
and uncoordinated systems.  Without effective methods to 
integrate such information in coherent, usable ways, the data 
holds little value, introducing the need for record linkage – 
the process of identifying record pairs which belong to the 
same real-world entity. However, the process of record 
linkage is complicated by the inherent nature of real data that 
are inconsistent, missing, erroneous, and continuously 
updated.  Absence of a common, error-free, unique identifier 
makes exact matching solutions inadequate (i.e. too many 
true links are missed), leading to approximate record linkage 
methods which require manual resolution of ambiguous links 
[1].  Most recently, for high quality linkages, there is more 
interest in interactive record linkage that uses a hybrid 
human-machine system which can take advantage of human 
interaction to manage errors in real data [2]. 
The goal of privacy preserving record linkage (PPRL) is 
to identify the records in one or more datasets that represent 
the same person, without compromising the confidentiality 
of subjects involved [3]. Private record linkage is the most 
researched form of PPRL.  It is defined as computing the set 
of linked records given as input a matching function and then 
outputting them to the two private parties without revealing 
anything about the non-linked records. The goal is to apply 
the known matching function in a secure manner. 
Consequently, the major challenges in private record linkage 
remaining for real applications is the lack of discussion on 
how to find the matching function that give high quality links 
and how the ambiguous links will be resolved without 
human interaction [4, 5]. Although relevant, private record 
linkage is a different use case than what we see in practice 
for population informatics where one trusted research entity 
(e.g. linkage center, health statistics division) obtains proper 
access to all data that need to be integrated while protecting 
the confidentiality of the subjects.     
III. SECURE DECOUPLED LINKAGE (SDLINK) 
In this paper, we present the Secure Decoupled Linkage 
(SDLink) platform that is based on the decoupled data 
access model presented in [6] and supports the trusted third 
party use case for population informatics. SDLink is a 
flexible computerized third party linkage platform that 
focuses on protection against attribute disclosure (i.e. does 
this person have cancer), rather than identity disclosure (i.e. 
who is this person).   
A. Shuffling and Encrypting The Connection Information  
The first step to building a computerized third party is to 
decouple the identifying information (PII) from the sensitive 
information to block sensitive attribute disclosure [6].  The 
decoupling occurs in three steps.  First the full table is split 
into two tables, one for PII and another for the remaining 
sensitive data, denoted as T1= T1(PII)+T1(SD).  Second, the 
rows in the PII table are shuffled randomly so that the row 
association between T1(PII) to the T1(SD) cannot be easily 
derived.  Finally, asymmetric encryption is used to lock the 
row association information from the T1(PII) to the T1(SD). 
Each private key, K(Ri), for row association of particular 
tables are given out to the custodians of each table who have 
the authority to grant access.  In SDLink, which has multiple 
decoupled tables, there is also a master key, K(T), that is 
used to lock the table association information for matching 
up Ti(PII) to Ti(SD).  In order for two tables to be linked, a 
user will have to obtain keys for row association to both 
tables from the custodians and present it to SDLink.  Then 
SDLink will use these keys and the master key it holds to 
link the tables using the identifying information, interacting 
with the user as needed to determine the mapping function 
and resolve ambiguous links, and then return the linked de-
 identified table, which include confidence levels of linkages.   
2013 IEEE International Conference on Big Data
 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 7
B. Information Supression During Clerical Review 
What information is disclosed during clerical review has 
much impact on the risk of disclosure during record linkage. 
The goal is to only display the meaningful differences 
between the variables needed for record linkage and suppress 
other information (Fig. 1).  For example, difference between 
IDs (e.g. SSN) are recoded into number of different digits 
and transposes.  DOB comparisons are made on an element-
 to-element basis for month, day, and year taking into account 
transposes both within one element and between elements.  
Conveying meaningful similarity information in names 
without fully disclosing it is the most difficult.  More 
research on meaningful differences for record linkage is 
needed. In our evaluation, we start with understanding the 
risk of fully disclosing names.  We show in the next section 
that even when names are fully disclosed, privacy can still be 
maintained due to the non-uniqueness of names, chaffing, 
and uncertainty in the universe around the data. Recoding 
can have an important side benefit of resulting in more 
consistent linkage decisions, both between different matches 
by one person as well as different people because it will 
help people use the same information for linkage decisions.   
 
 
Figure 1.  Review Screen ([D]iff, [M]issing, [TX]=Transpose, [—]=Same)  
C. Universe Manipulation and Chaffing 
Even when identifying information is separated from the 
sensitive information, users can still infer attributes by using 
background knowledge.  For example, if someone you know 
(background knowledge) is on the cancer registry (group 
disclosure), they must have cancer (attribute disclosure).  
Thus, strict decoupling via encryption along cannot 
guarantee no attribute disclosure. We employ additional 
methods to interfere with such possible inferences by 
manipulating the universe around the data that is displayed 
during review and adding fake data.  In the previous example, 
consider if you knew that the list being linked had people 
who did not have cancer (i.e. fake data).  Or if you did not 
know this was a cancer registry.  Furthermore, there is no 
way to know how many people named ‘John Smith’ exist in 
the universe of the data, especially when the universe is 
unknown.  Our experiments confirm that even with rare 
names fully disclosed, when the universe is effectively 
manipulated people are not able to confidently infer identity.      
The probability of attribute disclosure through group 
membership is dependent on a variety of factors including 
any pre-existing information that is known by the observer, 
the knowledge on the nature of the list, and the uniqueness of 
the PII in the universe of the data. The threat model where 
Alice is the researcher doing the review and Bob has bribed 
Alice to find out the disease status of Ian is described 
formally in Fig. 2.  In this example, Alice could memorize 
the name for the target subject, Ian, and could spot the same 
name during clerical review. It is important to note that, 
identifying the person is not a confidentiality violation yet.  
Rather, the violation occurs when an identified person’s 
disease status becomes known.  Whether spotting the same 
name during clerical review can lead to confirmation that the 
real person of interest (IanBob) has cancer depends on two 
factors.  First, does the list represent everyone with cancer? 
And second, how likely is it that the viewed name (IanPII) 
represents the actual real world entity (IanBob), which 
depends on factors such as the rarity of the name.  Here we 
discuss methods to further introduce uncertainty in inferring 
that IanBob has cancer by intentionally manipulating the 
universe around the displayed data point (IanPII) with little 
impact on the matching decision.  There are three methods of 
modification: (1) chaffing: literally change the nature of the 
universe by adding fake data, (2) fabrication: change the 
label/name of the universe presented to the researcher to 
obscure inference, and (3) nondisclosure: hide the identity of 
the universe from the researcher to reduce confidence. 
Chaffing is the process of adding fake data to a dataset 
to enlarge the universe to such an extent where group 
membership no longer reveals sensitive information. It is 
comparable to a person concealing themself by becoming 
part of a large crowd.  In particular, by adding a certain type 
of fake data, we can fundamentally block attribute disclosure  
1. Alice is a researcher who is responsible for resolving ambiguous links 
via clerical review for a study on linking Cancer Registry data from two 
hospitals, LA and LB, located in NC.  During the process, she will be 
shown a partial list of PIIs from LA and LB to resolve the ambiguous 
links, denoted as LA(PII) (Alice) and LB(PII) (Alice).  The expected size of 
the partial list is a tiny fraction of the full lists. 
2. The tables are decoupled as LA = LA(PII) + LA(SD), LB = LB(PII) + LB(SD), 
where LA(PII) is the PII from the hospital records in LA and LA(SD) is all 
columns except PII including all the sensitive data.  Alice has no access 
to LA(SD)  and LB(SD) which specify the type of cancer diagnosis in the 
registry along with other information. 
3. Bob, who works for a health insurance company, bribes Alice to find out 
if Ian has cancer and gives Alice Ian’s full PII denoted as Ian(PII)  Note 
that there is no guarantee that Ian(PII) is unique in the universe of real 
world entities, denoted as RA, from which the data is collected.  We 
denote the unique real world entity that Bob is interested in as IanBob. 
4. We assume that Alice knows that LA(PII) and LB(PII) are cancer registries. 
5. During her clerical review process, Alice can combine her prior 
knowledge of IanPII with the partial lists of PIIs given to her, LA(PII) 
(Alice) and LB(PII) (Alice), to make inferences. 
 
Under simple uniform models and assuming IanBob has cancer, 
Risk (Bob finding out that IanBob. has cancer  
          | IanPII. is on either LA(PII) or LB(PII)) 
=[Pr(IanPII ?LA(PII) (Alice))+Pr(IanPII ? LB(PII) (Alice))]*Pr(IanPII.==IanBob.) 
= very small since clerical review should occur in only a tiny percent of 
the full lists 
 
Thus the main threat of inferring that IanBob has cancer results from  
• having seen his PII in one of the partial lists during review 
• knowing that LA(PII) and LB(PII) are cancer registries 
• AND the uniqueness of IanPII  in the universe RA 
Figure 2.  Formal Threat Model  
8
through group membership.  Disclosure through group 
membership can only occur when the list disclosed for 
review represents a homogenous group, such as cancer 
registry.  By adding real names to the list that do not have 
cancer, and letting the researcher know that the chaffing has 
occurred, the list is no longer homogenous and membership 
on the list has no meaning.  In sum, the researcher can no 
longer be certain of sensitive information based on group 
membership even if the identity has been disclosed.  The key 
to chaffing is to add the appropriate fake data so as to 
introduce uncertainty to attribute disclosure, but not to 
interfere with the matching decision.  The most effective 
method is to incorporate short refresher training covering 
how the list is chaffed, that a chaffed list effectively has an 
intractable universe, and thus inferences cannot be made 
with any reasonable certainty. Adding PIIs that the researcher 
is familiar with, such as their family and friends, into the list 
can be an effective method for subtle mental reminders that 
the list includes fake data obtained from the user. 
An orthogonal method to changing the nature of the list 
through chaffing is to confuse the identity inference.  One 
method to block identity inference is to falsify the universe 
by presenting the list as if it came from a different data 
space. In our threat model, we might present the list to be 
from a hospital located across the country, say CA.  Such a 
false presentation of the list LNC as LCA would make it 
probabilistically impossible for them to infer that the viewed 
name (IanPII) represents the real person (IanBob) of interest 
who lives in NC.  In other words, by presenting the list as if 
it came from a different data space (LCA?DCA), the 
Pr(IanPII==IanBob)=0 because IanBob?DNC & IanPII?LCA?DCA 
& DNC?DCA=?.  Thus, if Alice believes IanPII? LCA, we 
effectively block any possible correct inferences on identity.   
Sometimes it can be difficult to totally falsify the 
universe to a research team member responsible for clerical 
review.  In such situations, not specifying the universe until 
after the clerical review can also be useful.  When we 
provide Alice with records from an undefined universe, she 
can be led to similar uncertain conclusions about the identity 
of a person because they are led to assume the whole world 
as their universe.  In order for Alice to make a reasonably 
accurate inference from prior knowledge of the subject’s 
name, they need two pieces of information: the existence of 
the same name on the list and the number of real people with 
the same name in the universe where the list came from, R.  
The probability that the spotted name on the list is the same 
real world entity of interest is 1 in n(same name in R). The 
rate of confidence is inversely correlated with the size of n.  
When the universe is undefined and the researcher must 
assume a huge universe of anyone living in the US, even for 
rare names it is difficult to assume n=1 with certainty. Thus, 
even if the researcher is able to recognize a particular name, 
there will be a constant degree of uncertainty in their 
judgment.  Nondisclosure is quite similar to chaffing in that 
the universe becomes enlarged.  This allows for an increase 
in probability of comparable real world entities to exist, 
resulting in an increase in n(same name in R), which in turn 
reduces the confidence of the researcher about the identity.   
IV. EVALUATION RESULTS 
To better understand what kinds of PII should be 
disclosed to the researcher during clerical review, we did an 
experiment by conducting an online survey. The survey 
simulated the situation that the insider, Alice, would be in 
while performing the clerical review.  Our goal was to test 
how well the different methods worked to reduce identity 
disclosure and attribute disclosure.  In this experiment, we 
measured (1) the effect of chaffing, (2) the impact of the 
modification of the universe, both falsifying and non-
 specification, on identity inference, (3) the disclosure risk of 
different identifying information attributes; namely, the 
common name, the common name and DOB pair, and the 
rare name, (4) how these attributes interact with each other 
when used in combination, and (5) the effects of missing and 
erroneous data on the different methods using variations on 
the common name and DOB pair.  
Meet George Brown, a student at Meadowgreen HS  
Using only the information provided here, how likely 
is it that the George Brown introduced above is the 
same person listed on the honor roll provided here?  
A. Highly likely to be the same person 
B. Moderately likely to be the same person 
C. Slightly likely to be the same person 
D. I don’t know if they are the same person or not 
E. Slightly likely to be two different people 
F. Moderately likely to be different people 
G. Highly likely to be two different people 
Meadowgreen HS  
Honor Roll 
Amanda Ward 
Edward Jones 
Hilary Ford 
George Brown 
Susan Miller 
David Green 
Alexander Parker 
Brian Richards 
Daniel Parker 
Alex Parker 
 
Figure 3.  Sample Survey Question for Common Name Scenario 
Fig. 3 is the basic question set up.  The respondents are 
given different identifying data about a target student and an 
Honor Roll list with the same identifying data. Then we ask 
them to select their confidence level about the likelihood that 
the information given in the question and the honor roll 
refers to the same person (identity disclosure) on a seven-
 point Likert scale (i.e. three levels of yes, three levels of no, 
or I Don’t Know). The survey had in total 18 questions; six 
scenarios, each with three questions.  The six scenarios were 
ordered so that questions would build on each other. We 
started with the simple common name scenario, and then 
moved onto to common name and DOB.  The next two 
scenarios were common name and missing DOB followed by 
common name and transposed DOB.  The transpose was 
created by swapping month and date numbers in DOB (2/5 
and 5/2).    The survey questions for these cases had the 
missing or transposed DOB in the honor roll for the target 
student.  We left rare name and chaffing to the last two 
sections because we wanted the respondents to get used to 
inferring identity before giving them the chaffed list 
experiment for attribute inference.  In the fifth scenario for 
rare name, the target student had a rare name (Rahul Ghosh) 
and the honor rolls included other rare names such as 
Viswanath Sastry, Jie Lee, and Michelle Pham. In addition, 
we changed the question slightly to ask how likely it is that 
the target student had made the honor roll (attribute 
disclosure) at his school.  The scale wording was also 
adjusted to indicate the confidence of having made the honor 
roll. We changed the question slightly so that we could ask 
9
the respondents to answer the same question one more time, 
knowing that the honor roll included some fake data of 
students who did not make the honor roll. This is the sixth 
scenario, wherein we tested a given rare name as the 
identifying information on a chaffed list. For the three 
questions in each of the six scenarios, respondents were 
given the honor roll from the same high school (Same HS: 
‘Meadowgreen HS’), an honor roll from a different high 
school (Diff HS: ‘Valley Mountain HS’, falsified), and 
finally an honor roll from an unknown high school (No 
HS:‘A HS’, undefined).  We constructed the three honor 
rolls so that they shared some names including the target 
student but were sufficiently different from each other.   
The full results are shown as 18 stacked bar charts in Fig. 
4. Each of the questions corresponds to one stacked bar.  We 
tested the change in the confidence level of identity or 
attribute by comparing responses to different questions using 
the Wilcoxon signed rank test, a non-parametric T-test.  We 
mainly recruited from graduate students in various 
departments including public health and computer science, 
who we anticipate will be doing the clerical reviews.  We 
had 59 respondents.  Although we made no attempt to recruit 
from students with experience in data analysis, we obtained a 
good mix of respondents with various experiences in data. A 
previous paper [6] reported the demographics and data 
experiences of the respondents from this study with selected 
findings(8 of 18 questions). Here we present complete results 
on the effects of manipulating the universe and the impact of 
missing and erroneous data on the different methods. A 
summary of the impact of chaffing from [6] is also included. 
A. Impact of Chaffing  
T-Test results between common name scenario and rare 
name + chaffing scenario was surprising.  There was 
sufficient evidence (p-value < 0.005) to conclude that 
respondents were significantly less confident in the identity 
of rare names on a chaffed list compared to common names 
on an accurate list (Bar 1 vs. Bar 16).  Chaffing was very 
effective in preventing attribute disclosure of rare names 
during clerical review [6].   
B. Impact of Falsifying or Undefining the Universe   
We found that manipulating the label of the displayed 
list was quite effective in reducing confidence in identity in 
all cases.  In the base case for common names (George 
Brown from Meadowgreen HS), when a list was presented as 
being from the same high school, all but 11 answered Highly 
or Moderately Likely the Same Person indicating fairly high 
confidence in identity.  There was a dramatic shift in 
responses to the second question when a list was presented 
under a different universe (Valley Mountain HS) and even 
went on to assert that the person on the list was a different 
person.  Only 6 answered Highly Likely the Same Person 
while the number of respondents answering Highly Likely 
Different People shot up from 0 to 29. The median for the 
falsified universe is on the other end of the spectrum at 
Moderately Likely Different People.  The results from the 
third question, the list with no high school defined (A HS), 
were quite different from the first two questions. The vast 
majority of the respondents fell in the middle of the spectrum 
with both the mode and median response being I Don’t 
Know. The combined response to Slightly Likely Same or 
Different People and I Don’t Know was 56%.  We conclude 
that the respondents were confused and could not confidently 
assert a response on whether the presented person was the 
same person or not.  The finding supports the hypothesis that 
an undefined universe will effectively introduce uncertainty 
such that people will not be able to make an affirmative 
conclusion about a name they find on the list.   
Although not as strong an effect, we see a similar trend 
in the impact of falsified universe and undefined universe for 
scenarios where we presented the common name and DOB 
pair and a rare name.  Given a common name and DOB pair, 
the median response increased to Slightly Likely the Same 
Person for a different universe and Moderately Likely the 
Same Person for an undefined universe. In comparison, 
given a rare name, the median response was I Don’t Know 
for a different universe but again Moderately Likely the Same 
Person for an undefined universe.  Not surprisingly, the 
DOB and the rarity of a name serve to increase the 
confidence of the respondent compared to only a common 
name.  Nonetheless the modification of the universe still had 
the impact of reducing the confidence levels as indicated by 
the T-tests which confirmed statistically different medians in 
all cases when the universe was manipulated.  Most 
importantly, when used in combination with chaffing, the 
impact of manipulating the universe seems to have an 
additive effect (Bars 17 and 18).  The median response for 
rare names with the universe undefined dropped further to 
the ideal level of I Don't Know when using the chaffed list 
(Bar 18).  This is an important finding because it confirms 
that using a combination of chaffing and nondisclosure of the 
universe, names, including rare names, can be fully disclosed 
with minimum risk of attribute disclosure during the review. 
It is quite interesting to note that given a list from a 
different high school, in all questions, there were some 
respondents who selected either Highly or Moderately Likely 
the Same Person as the target student.  The Pr (target 
studentA ? LX)=0 given that target studentA ? DA and  
DA?DX=? regardless of how rare the identity might be.  
Logically it would be highly unlikely that a George Brown at 
Meadowgreen HS is the same George Brown at the Valley 
Mountain HS.  However, 15% still answered that they were 
Highly or Moderately Likely the Same Person.  For common 
name and DOB pair it was as high as 42% and for rare name 
it was 19%.  In the pretest of the survey, we asked informally 
about such responses.  Some respondents thought that the 
student may have transferred from one high school to the 
other or that the student was simultaneously enrolled in both 
schools.  The respondents were unconsciously adding new 
dimensions, such as time, into the situation to accommodate 
their personal belief that two people with the same name and 
DOB are highly likely to be the same person (Susan Miller, 
DOB=4/17/1994).  Given that Susan Miller is a fairly 
common name, we believe such responses strongly suggest 
the possibility of researchers making incorrect inferences and 
jumping to wrong conclusions.  It could in fact be true that 
10
IanPII Œ IanBob, but when researchers make incorrect 
assumptions that IanPII==IanBob, harm can still occur.  
Thus, it seems that this result points to the need for good 
training before researchers are allowed to do clerical review.  
C. Missing and Erroneous Data   
Of all six scenarios, respondents were most confident 
about the identity of the target student when presented with 
the common name and DOB pair where 50 out of 59 
respondents answered Highly Likely the Same Person, with 7 
more respondents answering Moderately Likely the Same 
Person. These results indicate that people are highly 
confident about a person’s identity given a pair of name and 
DOB.  This finding is supported empirically by Weber et al. 
who show that the name and DOB pair was surprisingly 
effective for record linkage under certain circumstances [7]. 
Thus, we recommend that the raw DOB should not be 
disclosed in the PII list during the clerical review process. 
Instead, information related to DOB should be displayed as 
differences as shown in Fig. 1.  However, this strong 
confidence in identity is quickly diminished in the scenarios 
with missing DOB and transposed DOB (Bar 4 vs Bars 7 & 
10).  In this experiment, we tested the effectiveness of the 
different methods in the presence of missing and erroneous 
data, because such data is common in real-world big data. 
V. CONCULSION 
We are planning a second study to focus on the different 
methods for recoding names to understand its impact on both 
linkage decisions and disclosure.  Identity disclosure without 
sensitive attribute disclosure has little potential for harm [8]. 
Recognizing that the desire for privacy protection is for the 
sensitive data rather than the identifying data, we introduce 
SDLink, a simple but powerful data integration system that 
supports safe interactive record linkage so that errors from 
linkage can be managed throughout the full workflow.  
Errors that are not properly managed in machine only data 
integration systems propagate to subsequence data analyses 
[9] leading to potential problems with incorrect analyses, 
which can ultimately result in incorrect decisions. Harm from 
inaccurate data and information can be as devastating as our 
concerns about privacy violations.   
ACKNOWLEDGMENT 
This research was supported by funding from the NC-
 DHHS and NSF awards CNS-0915364 and OCI-1247652.  
REFERENCES 
[1] K. Elmagarmid, G. Panagiotis, S. Verykios. Duplicate record 
detection: A survey. IEEE Trans. Knowl. Data Eng. 2007;19(1):1-16. 
[2] H. Kang, L. Getoor, B. Shneiderman, M. Bilgic, L. Licamele. 
Interactive Entity Resolution in Relational Data: A Visual Analytic 
Tool and Its Evaluation. IEEE TVCG 2008;14(5):999-1014.  
[3] C. Clifton, M. Kantarcioglu, A. Doan, G. Schadow, J. Vaidya, A. 
Elmagarmid, D. Suciu. Privacy-preserving data integration and 
sharing. In ACM SIGMOD  workshop DMKD '04.  2004. 19-26. 
[4] R. Hall and S. Fienberg: Privacy-Preserving Record Linkage. Privacy 
in Statistical Databases 2010: Lecture Notes in Computer Science, 
2011, Volume 6344/2011, pp 269-283 
[5] D. Vatsalan, P. Christen, V. Verykios. A taxonomy of privacy-
 preserving record linkage techniques, Info Sys.  2013;38(6):946-969. 
[6] H. Kum., S. Ahalt, D. Pathak. Privacy Preserving Data Integration 
Using Decoupled Data. In SPSN , Springer 2013; 225-253 
[7] S. Weber, H. Lowe H, A. Das et al. A simple heuristic for blindfolded 
record linkage. J Am Med Inform Assoc. 2012; 19:157-161. 
[8] S. Fienberg. Confidentiality, privacy and disclosure limitation, 
Encyclopedia of Social Measurement, Academic Press 2005;1:463-9 
[9] P. Lahiri and M. Larsen. Regression analysis with linked data. Journal 
of the American Statistical Association, 2005;100(469):222-230. 
 
Figure 4.  Results 
 
11
