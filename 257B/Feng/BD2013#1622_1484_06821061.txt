Privacy-Preserving Two-Party Distributed
 Association Rules Mining on Horizontally
 Partitioned Data
 Feng Zhang?, Chunming Rong†, Gansen Zhao‡, Jinxia Wu?, and Xiangning Wu?
 ? School of Computer Science, China University of Geosciences, Wuhan, Hubei, 430074 China
 Email: jeff.f.zhang@gmail.com
 †Faculty of Science and Technology, University of Stavanger, Stavanger, 4036 Norway
 Email: chunming.rong@uis.no
 ‡ School of Computer Science, South China Normal University, Guangzhou, Guangdong, 510631 China
 Email: zhaogansen@gmail.com
 Abstract—In many applications, data mining has to be done
 in distributed data scenarios. In such situations, data owners may
 be concerned with the misuse of data; hence, they do not want
 their data to be mined, especially when these contain sensitive
 information. Privacy-preserving Data Mining (PPDM) aims to
 protect data privacy in the course of data mining. Privacy-
 preserving distributed association rules mining protocols have
 been developed for horizontally partitioned data scenarios with
 more than two participating parties. However, they depend on
 a secure multi-party summary and union computation, which
 cannot guarantee security while the number of participating
 parties is two. We use commutative encryption and design a
 secure division computation protocol as the core techniques to
 implement the protocols for the privacy-preserving two-party
 distributed mining of association rule mining. The protocols’
 security and performance are analyzed.
 I. INTRODUCTION
 Data mining has gradually become the core technology
 in decision-making tasks in recent years. While widely used,
 however, it is faced with many challenges [1]. Privacy preser-
 vation is one of these key challenges [2]. In many applications,
 data owners are concerned with the misuse of their data, and
 they do not want sensitive information to be mined. With such
 concerns in mind, they are not willing to provide their data for
 any data mining-related activities.
 Significant privacy concerns in data mining also prevent
 the legitimate use of data. For example, the Data-Mining
 Moratorium Act of 2003, enacted by the Senate and House
 of Representatives of the United States of America, forbids
 the carrying out of data mini ng activities within the U.S.
 Department of Defense unless it is for the purpose of searching
 public information or owing to particularized suspicion of
 an individual [3]. Data mining, however, may provide more
 insights from data, thus bringing huge economic and social
 interests. PPDM makes tradeoffs between data mining con-
 tributions and data privacy. It aims to carry out data mining
 precisely and efficiently while ensuring data privacy.
 A. Related Work
 PPDM research was initiated by two independent research
 papers [4], [5]. [4] addresses the PPDM task in the centralized
 data storage scenario. It builds a decision-tree classifier from
 the training data in the values of individual records that have
 been perturbed. The main idea is to employ a novel recon-
 struction procedure to accurately estimate the distribution of
 original data values. By using these reconstructed distributions,
 it is possible to build a classifier whose accuracy is comparable
 to the accuracy of classifiers built with original data. Mean-
 while, [5] addresses the PPDM task in the distributed data
 storage scenario. It focuses on the issue of ID3 decision tree
 learning by building efficient cryptographic protocols based on
 secure multi-party computation. These two studies represent
 two different research directions in PPDM: One is based on
 the Randomized Perturbation Technique (RPT), and the other
 is based on the Cryptography-Based Technique. The former is
 mostly applied to centralized data storage scenarios, while the
 latter is generally used in distributed data storage scenarios.
 PPDM has developed to be a major research direction
 in the field of data mining research in recent years. It has
 achieved significant results in many data mining areas, such as
 association rules [6], decision trees [5], clustering [7], outlier
 detection [8], bayesian networks [9], recommender systems
 [10], stream mining [11] and social network [12].
 Besides, there is another PPDM technique called k-
 anonymity [23], which belongs to the privacy-preserving data
 publishing techniques. Its purpose is to prevent indirect identi-
 fication of records from public databases because combinations
 of record attributes can be used to exactly identify individual
 records. But k-anonymity is believed to be vulnerable. When
 there is little diversity in those sensitive attributes or attackers
 have additional background knowledge about the victim, k-
 anonymity encounters severe privacy problems [24]. -diversity
 [24] and t-closeness [25] are two subsequent techniques
 closely relative to k-anonymity and to relieve the problems.
 However, all of them haven’t yet resolved the privacy chal-
 lenges. Many research results have indicated that the three
 closed relative privacy models are vulnerable to various privacy
 attacks and pride insufficient privacy protection [26], [27].
 In recent years, differential privacy [28], [29], [30] has
 received considerable attention for PPDM. Differential privacy
 is a model aiming to provide privacy to statistical queries
 and pattern mining. It aims to provide means to maximize
 2013 International Conference on Cloud Computing and Big Data
 978-1-4799-2829-3/13 $26.00 © 2013 IEEE
 DOI 10.1109/CLOUDCOM-ASIA.2013.87
 6363978-1-4799-2830-9/14 $31.00 © 2014 IEE
the accuracy of queries or data mining while minimizing the
 chances of identifying its records. Laplace mechanism [29] and
 exponential mechanism [30] are two methods to implementing
 differential privacy under the scenarios of numeric outputs
 and discrete outputs. There have been considerable studies on
 applying differential privacy to PPDM so far [33], [34], [35],
 [36].
 Our study has little relevance to these above papers, except
 that it is closely related to [13]. It can be seen as a subsequent
 work of [13]. In comparison with [36], it addresses a different
 problem with a different techniques, which is a encrypted one
 but not a differential privacy.
 B. Motivations
 [13] presented a method to perform privacy-preserving dis-
 tributed association rules mining protocols with the assumption
 of three or more parties at a horizontally partitioned data
 scenario. However, the method depends on a secure multi-party
 summary and union computation, which cannot guarantee
 security while the number of participating parties is two.
 In [13], all final globally frequent itemsets (rules) are
 disclosed to all participating parties. In a two-party case, it
 may be argued that knowing an (a) itemset (rule) is supported
 globally but is not supported at one’s site reveals that the
 other site supports that itemset (rule). This leakage cannot be
 avoided.
 However, we noticed in many cases that knowing whether
 or not a locally frequent itemset (rule) at one site is globally
 supported but not revealing this knowledge to the other site
 is worthy of investigation. For example, Walmart may want to
 know if the rule beer? diaper is strong when putting it under
 consideration for a transaction union of Walmart and Target,
 but is not willing to reveal to Target that whether the rule
 beer ? diaper is a strong rule of itself or not; an owner may
 want to know if the frequent gene patterns in its gene database
 are still frequent under the combined database with another
 one, but is not willing to reveal to the other gene database
 its private data, such as the size of the gene database, and
 the frequent gene patterns themselves; such motivation does
 exist in a hospital where its president wants to know whether
 a nosogenesis generalized from large of patients still works
 on the combined two patients databases but with some privacy
 concerns.
 Some researches are devoted to two-party security com-
 putation, such as [20] and [21]. [20] initiates the secure two-
 party computation and [21] gives its security proof. But they
 are all about the protocols for the general secure two-party
 computations, which are limited by their time complexity and
 are not applicable to concrete applications, such as data mining
 tasks [22]. Our study can be seen as a complement to [13], as
 well as a concrete application of the general secure two-party
 computation protocol in [20].
 C. Contributions
 To our knowledge, no studies have been conducted to
 address this gap in knowledge so far. In this study, therefore,
 we propose a secure division computation protocol based on
 commutative encryption. The proposed protocol works as the
 core technique to build up protocols that perform privacy-
 preserving two-party distributed mining of association rule
 mining for the first time so far as we know, which constitute
 the major contributions of this paper. Since in the two-party
 case, knowing an itemset is supported globally but is not
 supported at one’s own site reveals that the other site supports
 the itemset, this work only needs to examine the problem by
 way of disclosing the global itemsets to the site at which they
 are frequent locally but hiding them from the other site.
 D. Structure
 The rest of the paper is organized as follows. Section
 II presents the problem definitions, basic preliminaries, and
 security infrastructures. Section III discusses secure multi-
 party association rule mining protocols and our proposed
 two-party protocol. The analysis of the proposed protocols’
 soundness and security is presented in Sections IV and V.
 In Section VI, the performance analysis is shown. Finally, in
 Section VII, we conclude our paper and identify future work.
 II. DEFINITIONS
 In this section, we will give some basic definitions of As-
 sociation Rules Mining, Distributed Association Rules Mining,
 and Secure Distributed Association Rules Mining; and the
 security infrastructures, Commutative Encryption System on
 the mining problems.
 A. Association Rules Mining
 Let I = {i1, i2, · · · , im} be a set of items. Let DB be a
 database of transactions, where each transaction T consists of
 a set of items such that T ? I .
 The association rules mining problem can be defined as
 follows [14]: Let I = {i1, i2, · · · , im} be a set of items. Let
 DB be a set of transactions, where each transaction T is an
 itemset such that T ? I . Given an itemset X ? I , a transaction
 T contains X if and only if X ? T . An association rule is
 an implication of the form X ? Y , where X ? I , Y ? I
 and X ? Y = ?. The rule X ? Y has support s in the
 transaction database DB if the probability of a transaction
 in DB containing both X and Y is s. The association rule
 holds in the transaction database DB with confidence c if the
 probability of a transaction in DB containing X and thus
 Y is c. An itemset X with k items is called a k-itemset.
 The problem of mining association rules is that one must
 necessarily mind all rules whose support is greater than a
 minimum support threshold and whose confidence is above
 a minimum confidence threshold.
 For an itemset X , its support is the percentage of trans-
 actions in a DB which contains X , and its support count,
 denoted by X.sup, is the number of transactions in DB
 containing X . An itemset X is frequent (or more precisely,
 frequently occurring) if its support is no less than the minimum
 support threshold. It has been shown that the problem of
 mining association rules can be reduced to two subproblems
 [14]: (1) Find all frequent itemsets for a given minimum
 support threshold, and (2) generate the association rules from
 the frequent itemsets found. Since (1) dominates the overall
 cost of the mining association rule, association rules mining
 research has focused on the development of efficient methods
 to solve the first subproblem.
 6374
TABLE I: Notation Table [15]
 D Number of transaction in DB
 S Support threshold minsup
 L(k) Globally frequent k-itemset
 CA(k) Candidate sets generated from L(k)
 X.sup Global support count of X
 Di Number of transactions in DBi
 GLi(k) globally frequent k-itemsets at Si
 CGi(k) Candidate sets generated from GLi(k?1)
 LLi(k) Locally frequent k-itemsets in CGi(k)
 X.supi Local support count of X at Si
 B. Distributed Association Rules Mining
 This paper investigates the mining of association rules in
 a distributed environment. Let DB be a database with D
 transactions. Assume that there are n sites, S1, S2, · · · , Sn,
 in a distributed system, and the database DB is partitioned
 over the n sites into {DB1, DB2, · · · , DBn}, respectively.
 Let the size of the partitions DBi be Di, for i = 1, · · · , n.
 Let X.sup be the global support count, and X.supi be the local
 support count of X at site Si. For a given minimum support
 threshold s, X is globally frequent if X.sup ≥ s?D; corre-
 spondingly, X is locally frequent at site Si, if X.supi ≥ s?Di.
 In the following, L denotes the globally frequent itemsets
 in DB, and L(k) the globally frequent k-itemsets in L. The
 essential task of a distributed association rule mining algorithm
 is to find the globally frequent itemsets L.
 A fast algorithm for distributed association rule mining is
 given in [15]. The procedure for the fast distributed mining of
 association rules (FDM) can be summarized below:
 1. Candidate Sets Generation: Generate candidate sets
 CGi(k) based on GLi(k?1), itemsets that are supported by Si
 at the (k ? 1)th iteration, using the classic Apriori candidate
 generation algorithm. Each site generates candidates based
 on the intersection of globally frequent (k ? 1)-itemsets and
 locally frequent (k ? 1)-itemsets.
 2. Local Pruning: For each X ? CGi(k), scan the database
 DBi at Si to compute X.supi. If X is not locally frequent
 at site Si, it is excluded from candidate sets LLi(k). (This
 pruning only removes X from the candidate set at site Si. X
 could still be a candidate set at some other site.)
 3. Support Count Exchange: Broadcast the candidate set in
 LLi(k) to other sites in order to collect support count. Compute
 their global support counts and find all globally frequent k-
 itemsets in site Si.
 4. Broadcast Mining Results: Broadcast the computed
 globally frequent k-itemsets to all the other sites. Some basic
 notations on distributed association rules mining are listed in
 Table 1.
 C. Secure Distributed Association Rules Mining
 Let n > 2 be the number of sites. Each site i has a private
 transaction database DBi. We are given support threshold s
 and confidence c as the percentages. The goal is to discover all
 itemsets (association rules) satisfying the thresholds, as defined
 in Section 2.2. We further desire that disclosure be limited: No
 site should learn the contents of a transaction at any other site,
 what itemsets (rules) are supported by any other site, or the
 specific value of support/confidence for any itemset (rule) at
 any other site unless that information is revealed by knowledge
 of one’s own data and the final result.
 The above is the definition in [13]. However, in the case of
 i = 2, we have stated in section 1 that knowing an (a) itemset
 (rule) is supported globally but is not supported at one’s site
 reveals that the other site supports that itemset (rule). This
 leakage cannot be avoided. So the definition for the two-party
 case is a little different; the purpose of our study is to design
 secure two-party association rules mining protocols to preserve
 the following data privacy:
 1. the support and database size of each site are preserved
 not to be disclosed to the other site,
 2. each site knows whether or not a locally frequent itemset
 (rule) at the own site is globally supported but not revealing
 this knowledge to the other site.
 D. Commutative Encryption System
 To implement the security of multi-party computation, a
 commutative encryption system is necessary. We define a
 commutative encryption system as follows [16]:
 Definition 1 - Commutative Encryption System. An en-
 cryption system F = (M, K, f, g) (where M is the domain
 of plain and encrypted messages, K = (E, D), E, D are
 sets of encryption keys and decryption keys, respectively) is
 commutative if both the encryption function f : E?M ? M
 and the decryption function g : D?M ? M are computable
 functions in polynomial time, defined on finite computable
 domains, that satisfy all properties listed below. We denote
 fe(x) ? f(e, x), gd(x) ? g(d, x), and use ?r to signify is
 chosen uniformly at random from.
 1. For all e1,e2,,en ? E, d1, d2, · · · , dn ? D, each m ? M ,
 we have
 fei1 (fei2 (· · · (fein (m)) · · · )) = fej1 (fej2 (· · · (fejn (m)) · · · )) ? T
 and
 gds1 (gds2 (· · · (gdsn (T )) · · · )) = gdt1 (gdt2 (· · · (gdtn (T )) · · · )),
 where (i1, i2, · · · , in),(j1, j2, · · · , jn),(s1, s2, · · · , sn) and(t1, t2, · · · , tn) are four permutations of (1, 2, · · · , n).
 2. For all e1,e2,· · · ,en ? E, all m1,m2 ? M such that
 m1 
= m2 and big enough k, we have
 pr(fe1(fe2(· · · (fen(m1)) · · · )) = fe1(fe2(· · · (fen(m2)) · · · ))) < 12k .
 3. For x, y, z ?r M , e ?r E, the distribution of <
 x, fe(x), y, fe(y) > is indistinguishable from the distribution
 of < x, fe(x), y, z >.
 Informally, Property 1 denotes that the ciphertext of com-
 positely commutative encryption is identical regardless of the
 encryption order. Property 2 signifies that two different plain
 messages will never have the same encrypted messages. Prop-
 erty 3 guarantees that the encryption is secure. Specifically, it
 states that given a plain message x and its randomly chosen
 encryption way fe(x), for a new plain message y, an adversary
 6385
cannot distinguish in polynomial time between fe(y) and
 a randomly chosen value z from the domain of encrypted
 messages. The adversary cannot identify in polynomial time
 which of the two plain messages has been encrypted as well.
 Thus, the adversary can neither encrypt y nor decrypt fe(y)
 in polynomial time.
 Some encryption systems satisfy these properties, such
 as DDH [17]. Interested readers can refer to [16] for more
 detailed applications.
 E. Security in Semi-honest Model
 In the following we give the definition of Secure Two-party
 Computation [22].
 Definition 2 - (Privacy with respect to semi-honest be-
 havior): Let f : {0, 1}? ? {0, 1}? ? {0, 1}? ? {0, 1}?
 be a functionality, and f1(x, y) (resp., f2(x, y)) denotes the
 first (resp., second) element of f(x, y). Let ∏ be a two-
 party protocol for computing f . The view of the first (resp.,
 second) party during and execution of ∏ on (x, y), denoted
 V IEW
 ∏
 1 (x, y) (resp. V IEW
 ∏
 2 (x, y)), is (x, r, m1, · · · , mt)(resp., (y, r, m1, · · · , mt)), where r represents the outcome
 of the first (resp., second) party’s internal coin tosses, and
 mi represents the i-th message it has received. The output
 of the first (resp., second) party after and execution of ∏ on
 (x, y), denoted OUT P UT
 ∏
 1 (x, y) (resp. OUT P UT
 ∏
 2 (x, y)),
 is implicit in the party’s own view of the execution, and
 OUT P UT
 ∏(x, y) = (OUT P UT
 ∏
 1 (x, y), OUT P UT
 ∏
 2 (x, y)) .
 We say that
 ∏
 privately computes f if there exist proba-
 bilistic polynomial-time algorithms, denoted S1 and S2, such
 that
 {(S1(x, f1(x, y)), f2(x, y))}x,y?{0,1}? C?
 {(V IEW
 ∏
 1 (x, y), OUT P UT
 ∏
 2 (x, y))}x,y?{0,1}?
 {(S2(x, f2(x, y)), f1(x, y))}x,y?{0,1}? C?
 {(V IEW
 ∏
 2 (x, y), OUT P UT
 ∏
 1 (x, y))}x,y?{0,1}? .
 where C? denotes computational indistinguishability.
 Definition 2 says that under semi-honest model, a protocol
 is said to securely (privately) compute f if the information
 obtained by every participated party after carrying out the pro-
 tocol, can be polynomially simulated through the participated
 party’s input and output.
 This method is based on an assumption that the involved
 parties are semi-honest, i.e. they follow the rules of the
 protocol using its correct input, but is free to later use what
 it sees during execution of the protocol to deduce private
 information. In such model, a proof is secure if the view
 of each party during the execution of the protocol can be
 effectively simulated by the input and the output of the party,
 which is called simulation paradigm (mechanism) of security
 proof.
 In our later proofs, we use a key theorem in the secure
 multiparty computation, the composition theorem. We state it
 here for the semi-honest model. A detailed discussion of this
 theorem, as well as the proof, can be found in [22].
 Fig. 1: Determining global candidate itemsets [13]
 Theorem 1 (Composition theorem for the semi-honest
 model) Suppose that g is privately reducible to f and that
 there exists a protocol for privately computing f . Then there
 exists a protocol for privately computing g.
 In the theorem, “g is privately reducible to f”implies that
 we can come up with a private protocol for evaluating function
 g given a black box access to function f . This allows us to
 use existing secure protocols as components, worrying only
 that their results do not reveal anything and ignoring the
 communications carried on by those components.
 III. SECURE ASSOCIATION RULE MINING PROTOCOLS
 In section 3.1, we will illustrate the major idea used in
 [13] and its weaknesses. In section 3.2, we will introduce our
 idea on how to securely conduct frequent itemsets mining in
 two-party case.
 A. Existing Protocols
 [13] follows the general approach of the FDM algorithm
 [15], with special protocols replacing the broadcasts of LLi(k)
 and the support count of items in LLk. It first gives a
 method for finding the union of locally supported itemsets
 without revealing the originator of the particular itemset. It
 then provides a method for securely testing if the support count
 exceeds the threshold.
 The idea in [13] follows the two-phase approach, but
 combining locally generated rules and support counts is done
 by passing the encrypted values between sites. The two phases
 discover candidate itemsets (those that are frequent on one or
 more sites) and determine which of these meets the global
 support confidence thresholds.
 The first phase (Fig. 1) uses commutative encryption. Each
 party encrypts its own frequent itemsets (for example, site 1
 encrypts itemset C). The encrypted itemsets are then passed
 to other parties until all parties have encrypted all itemsets.
 These are passed to a common party to eliminate duplicates
 and to begin decryption. (In the figure, the full set of itemsets
 is shown to the left of site 1, after site 1 decrypts.) This set
 is then passed to each party, and each party decrypts each
 itemset. The final result is comprised of the distinct itemsets
 (C and D in the figure).
 In the second phase (Fig. 2), each of the locally supported
 itemsets is tested to see if it is supported globally. Fig. 2 shows
 6396
Fig. 2: Determining if itemset support exceeds the 5 percent
 threshold [13]
 that the itemset ABC is known to be supported at one or
 more sites, and each computes its local support. The first site
 chooses a random value R and adds to R the amount by which
 its support for ABC exceeds the minimum support threshold.
 This value is passed to site 2, which adds the amount by
 which its support exceeds the threshold (note that this may
 be negative, as shown in the figure.) This is passed to Site 3,
 which again adds its excess support. The resulting value (18)
 is tested using a secure comparison to see if it exceeds the
 random value (17). If so, itemset ABC is supported globally.
 This gives a brief, oversimplified illustration of how the
 idea in [13] works. However, as the authors stated in their
 paper, the methods were not secure while the number of
 participating parties is exactly two. It is apparent in a two-
 party case that (1) when one party knows the final itemset
 union, it will also know that the itemsets in the union definitely
 belong to the other site, and (2) when one party knows the final
 summary of the supports, it will also know the support of the
 other site. One party can easily deduce the other party’s data
 from the global results and its own input.
 B. The Two-Party Case
 In this section, we will illustrate how to find globally fre-
 quent k-itemsets as the foundation to preserve the participating
 parties’ data privacy.
 We will need to adjust our expectations since the following
 leakage cannot be avoided: One party can easily deduce the
 other party’s data from the global results and its own input.
 We lower our expectations of knowing whether or not
 a locally frequent itemset (rule) at the own site is globally
 supported but not revealing this knowledge to the other site.
 The following is a concrete application of this expectation. For
 example, Walmart may want to know if the rule beer? diaper
 is strong when putting it under consideration for a transaction
 union of Walmart and Target, but is not willing to reveal to
 Target that the rule beer ? diaper is a strong rule of itself.
 This process is completed in two steps.
 The first step is to encrypt CGi(k) through both sites,
 which is conducted by Protocol 1. At step 2 in the protocol,
 each site encrypts CGi(k) with its Commutative Encryption
 System, then via step 3 sends the ciphertexts to the other
 party, which again encrypts the ciphertexts received by its
 own Commutative Encryption System (step 6) and sends the
 results back (step 7). The purpose is to conduct secure equality
 comparison in Protocol 2, making use of the fact that the
 encryption results of Commutative Encryption System have
 nothing to do with the encryption order.
 The second step is to find GLi(k), which is conducted
 by Protocol 2. In the protocol, one site sends its two-time-
 encryption ciphertexts one-by-one to the other site (step 2 and
 3), thus locating its support count at the other sites (step 6,
 7 and 8). Step 11, 14 and 15 generate random numbers for
 the purpose of conducting secure scalar product computation.
 At step 17-27, the two sites conduct a secure scalar product
 sub-protocol to securely compute the global support of the
 ciphertext (its corresponding plaintext, the itemset); if the
 support is not less than the threshold, the itemset is a globally
 frequent k-itemset and will be added to GLi(k).
 Protocol 1: Encrypt the candidate sets CGi(k)
 through both sites.
 input : N(= 2) sites. Each site i (i is 1, 2) owns
 the gl-frequent itemsets GLi(k?1).
 output: Each site i obtains the set of triples
 < xi(k), xi(k).supi, fe(imod 2)+1fei(xi(k)) >,
 xi(k) ? CGi(k).
 1 foreach site i do
 2 Generate CGi(k) based on the gl-frequent
 itemsets GLi(k?1) ;
 3 Send fei(CGi(k)) to site (i mod 2) + 1,
 reordered lexicographically;
 4 end
 5 foreach site i do
 6 Encrypt each
 y ? fe(imod 2)+1(CG((i mod 2)+1)(k)) with ei,
 resulting in pairs:
 7 < y, fei(y) >=< fe(imod 2)+1(x((i mod 2)+1)(k)),
 8 fe1fe(imod 2)+1(x((i mod 2)+1)(k)) > ;
 9 Send the pair:
 10 < y, fei(y) >=< fe(imod 2)+1(x((i mod 2)+1)(k)),
 11 fe1fe(imod 2)+1(x((i mod 2)+1)(k)) > back to site(i mod 2) + 1, reordered lexicographically ;
 12 end
 13 foreach site i do
 14 Create the triples
 < xi(k), xi(k).supi, fe(imod 2)+1fei(xi(k)) >
 based on pairs
 < fei(xi(k)), fe(imod 2)+1fei(xi(k)) > by
 replacing each fei(xi(k)) with the corresponding
 locally frequent k-itemset xi(k) and adding its
 support count xi(k).supi ;
 15 Reorder triples
 < xi(k), xi(k).supi, fe(imod 2)+1fei(xi(k)) > by
 xi(k) lexicographically.
 16 end
 There is a place that can be optimized in Protocol 2: the
 data each site sends to the other site can originate from LLi(2)
 instead of the triple set, that is, CGi(2) . Since we assume that
 if an itemset is globally frequent, it must be an element of
 LL1(2) or LL2(2), the optimization will avoid wasting time in
 640637
judging whether or not the itemsets which belong to neither
 LL1(2) nor LL2(2) are globally frequent.
 IV. SOUNDNESS ANALYSIS
 Protocol 1 is simple: Each site encrypts CGi(k) and sends
 it to another site to be encrypted. From this, a two-time
 encryption result is obtained, which is an obviously correct
 process.
 The purpose of Protocol 2 is to determine GLi(k). It first
 matches the equal ciphertexts between the two sites from steps
 1 to 9 (The element of CGi(k) is the corresponding plaintext,
 which is also equal). Then from steps 10 to 27, the protocol
 computes the global support of the ciphertexts (the plaintexts,
 or the itemsets) with a secure two-party division sub-protocol.
 Assume site 1 has the support count x1(k).sup1 , and the
 size of the transaction database is D1. site 2 has the support
 count sup2 , and the size of the transaction database is D2.
 The global support is x1(k)+sup2D1+D2 . It is obvious that
 z? = r1 ? z = r1 ? r2 ?
 z1
 z2
 = r1 ? r2 ?
 r11 ? r
 2
 1 ? (x1(k).sup1 + sup2)
 r21 ? r
 2
 2 ? (D1 + D2)
 =
 r21
 r11
 ?
 r22
 r12
 ?
 r11 ? r
 2
 1 ? (x1(k).sup1 + sup2)
 r21 ? r
 2
 2 ? (D1 + D2)
 =
 x1(k).sup1 + sup2
 D1 + D2
 .
 Protocol 2: Generate GL1(k), GL2(k) (1)
 input : N(= 2) sites number 1, 2; Minimum
 support, s
 output: GLi(k) at each i
 1 At site 1 begin
 2 Locate the first
 < x1(k), x1(k).sup1, fe2fe1(x1(k)) > in its
 ordered triples;
 3 Send fe2fe1(x1(k)) to site 2;
 4 end
 5 At site 2 begin
 6 Search the fe1fe2(x2(k)) that equalsfe2fe1(x1(k));
 7 if Found then Set sup2 = x2(k).sup2;
 8 else Set sup2 = 0;
 9 end
 10 At site 1 begin
 11 Generate two new non-zero random numbers
 r11 , r
 2
 1 and set r1 =
 r21
 r11
 ;
 12 end
 13 At site 2 begin
 14 Generate two new non-zero random numbers
 r12 , r
 2
 2;
 15 Send r2 = r
 2
 2
 r12
 to site 1.
 16 end
 Protocol 2 (Continuing...): Generate GL1(k), GL2(k)
 input : N(= 2) sites number 1, 2; Minimum support, s
 output: GLi(k) at each i
 17 Site 1 and Site 2 begin
 18 Collaborate to securely compute the Scalar Product
 on (r11 ? x1(k).sup1, r11) and (r12, r12 ? sup2); Only
 Site 1 obtains:
 z1 = r
 1
 1 ? r
 1
 2 ? x1(k).sup1 + r11 ? r12 ? sup2 =
 r11 ? r
 1
 2 ? (x1(k).sup1 + sup2);
 19 end
 20 Site 1 and Site 2 begin
 21 Collaborate to securely compute the Scalar Product
 on (r21 ?D1, r21) and (r22, r22 ?D2); Only Site 1
 obtains:
 z2 = r
 2
 1?r
 2
 2?D1+r21?r22?D2 = r21?r22?(D1+D2)
 ;
 22 end
 23 At site 1 begin
 24 Calculate z? = r2 ? r1 ? z1z2 =
 r2 ? r1 ?
 r11?r
 1
 2?(x1(k).sup1+sup2)
 r21?r
 2
 2?(D1+D2) =
 x1(k).sup1+sup2
 D1+D2 ;
 25 if z? ≥ s then Insert x1(k) into GL1(k);
 26 Delete the triple
 < x1(k), x1(k).sup1, fe2fe1(x1(k)) >;
 27 end
 28 Repeat step begin
 29 Site 2 selects the first
 < x2(k), x2(k).sup2, fe1fe2(x2(k)) > in its ordered
 triples and duplicates the procedure from step 1 to
 step 27 in a similar way; Next, Site 1 will go
 through a similar process with the next triple ;
 30 The above processes will repeat until all the triples
 at Site 1 and at Site 2 have been tackled. At the
 completion of the protocol, Site 1 and Site 2 will
 obtain GL1(k) and GL2(k) respectively.
 31 end
 V. SECURITY ANALYSIS
 A. Protocol 1
 We use the simulation paradigm illustrated in Definition 2
 to prove the security of Protocol 1.
 The only communication takes place at step 3 and 7.
 The security measures at both steps are the Commutative
 Encryption (Section 2.4). Specifically, after the execution of
 step 3, what each site sees is the ciphertexts generated by
 Commutative Encryption. Based on Definition 1 in Section 2.4,
 the simulation views can be simply generated by uniformly
 choosing numbers from the domain of the ciphertexts in
 random form. Since the chosen numbers and the ciphertexts
 are uniformly bounded in the same domain, they are indistin-
 guishable.
 The security of step 7 is similar, whose proof is ignored
 due to the space restriction.
 B. Protocol 2
 In Protocol 2, the only data transfer occurs at step 3, 15,
 18, and 21.
 641638
TABLE II: CComp and CCost of Protocol 1
 Step CComp CCost
 1, 4, 5, 8, 9, 12 N/A N/A
 2 O(|GLi(k?1)|2) N/A
 3 O(|CGi(k)| ? Tc) O(|CGi(k)| ? B)
 6 O(|CGi(k)| ? Tc) N/A
 7 N/A O(|CGi(k)| ? B)
 10 Ignored N/A
 11 Ignored N/A
 TABLE III: CComp and CCost of Protocol of Protocol 2
 Step CComp CCost
 1, 4, 5, 9, 10, 12, 13, 16, 17, N/A N/A
 19, 20, 22, 23, 27, 29, 31
 2, 6, 7, 8, 11, 14, 25, 26 Ignored N/A
 3 N/A O(|CGi(k)| ? B)
 15 N/A Ignored
 18, 21 O(Sc) O(St)
 24 Const N/A
 At step 3, since the ciphertext fe2fe1(x1(k)) was received
 from site 2 (step 6 and 7, Protocol 1), so it is not a private
 data.
 At step 15, the randomly generated number r1 is not a
 private data.
 Steps 16 and 21 collaborate to conduct the secure scalar
 product (dot product). Their security is based on the security
 of the scalar product protocol. Many secure scalar product
 protocols have been developed. Interested readers may refer
 to [37] and [18] for further details.
 Based on the above analysis, the security of Protocol 2 can
 be concluded from the Composition Theorem.
 VI. PERFORMANCE ANALYSIS
 A. Communication and Computation Costs
 Suppose that the commutative encryption/decryption cost is
 Tc; transferring plaintexts/ciphertexts needs B bites. We ignore
 simple linear computation and simple linear communication
 since they entail small costs compared with encryption costs
 and ciphertext transferring costs.
 The Computation Complexity (CComp) and Communica-
 tion Costs (CCost) of Protocol 1 are shown in Table 2.
 Suppose the computation cost of the Scalar Product Proto-
 col is Sc, and the communication cost of the protocol is St.
 The computation complexity (CComp) and communication
 costs (CCost) of steps 1 to 31 in Protocol 2 are shown in Table
 3. The work at step 29 repeats the work of steps 1 to 27, and
 its CComp and CCost can be similarly estimated.
 B. Discusses on Performance
 In [13], the authors state that security comparison sub-
 protocol can attribute to the distributed association rules min-
 ing of two-party case. And in our protocols, secure scalar
 product is in fact dominates the complexity in computation
 and communications. In this section, we will discuss how the
 two kinds of solutions perform.
 The initial generic circuit evaluation solution to secure
 comparison problem (Yao’s millionaire problem) is introduced
 in [20], which is a milestone paper in secure two-party
 computation. Such solution is exponential in the number of
 bits of the involved numbers in time and space. Since then,
 there have been some techniques to improve the performance
 in time and communication complexity on such problem. For
 example, based on ElGamal encryption, [38] designs a protocol
 with time complexity of 5nlogp+4n? 6 and communication
 complexity of 6nlogp where n is the length of the private
 inputs and p is the modulus in ElGamal encryption. And
 based on Paillier encryption, [39] designs a protocol with time
 complexity of 16nlogN +28n and communication complexity
 of 4nlogN where n is the length of the private inputs and N
 is the modulus in Paillier’s homomorphic encryption scheme.
 Considering both logp and logN are not small size number
 compared with the private number n, so we agree with the
 conclusion in [13] where it says “there is no significantly
 faster way for arbitrary a and b than using the generic circuit
 evaluation solution ”.
 Contrastingly, there are many efficient protocols to conduct
 secure scalar product, such as [37] where the complexities in
 time and communication are both O(n). Although some extra
 data, such as r12 , r22 , r11 , and r21 , are added to assist the secure
 computation, considering they can be relatively much smaller
 size of data, the protocol still runs more efficiently.
 Therefore, it could be concluded that in time and commu-
 nications, the secure scalar product protocols outperform the
 secure comparison protocols.
 VII. CONCLUSIONS
 Aiming to tackle the privacy issues of the distributed
 mining of association rules on horizontally partitioned data
 in a two-party case, this paper proposed a protocol with
 deliberately designed techniques. The protocol can tell the site
 whether or not its itemsets are globally frequent under the
 union transactions of other sites and itself while guaranteeing
 the related data privacy.
 We believe that the two-party protocol is significant as such
 application scenarios exist in reality, where one party wants to
 know whether or not its itemsets (rules) are globally frequent
 but does not want to reveal its supports and other private data
 to the other party.
 The work in this paper is conducted in the semi-honest
 model as [16] does. The semi-honest model assumes that
 participating parties follow the prescribed protocol but try
 to infer private information using the messages they receive
 during the communication. Although the semi-honest model
 is realistic in many settings, there are cases where it may be
 better to use the malicious model that tries to prevent any
 malicious behavior by using more expensive and complicated
 techniques. Clearly, protocols that are secure in the malicious
 model provide more security compared with those in the semi-
 honest model. At the same time, there is an obvious trade-off:
 The malicious model provides higher security guarantees with
 higher computational cost, whereas the semi-honest model is
 generally more efficient with less security guarantees [19].
 Designing privacy-preserving association rules mining pro-
 tocols, as well as other multi-party data mining protocols under
 642639
malicious models, is a major challenge in SMC applications.
 This issue, along with how to design a protocol that can further
 reduce the time and communication cost, will be dealt with
 further in our subsequent work.
 ACKNOWLEDGMENT
 This work is supported in part by the Guangzhou Re-
 search Infrastructure Development Fund (No. 2012224-12), the
 Guangdong Nature Science Fund (No. S2012030006242), the
 Guangdong-CAS Cooperation Fund (No. 2011A090100003),
 the Guangdong Emerging Industry Key Technology R&D
 Fund (No. 2011A010801007), the Guangzhou Zhujiang Fu-
 ture Fellow Fund (No. 2011J2200089), Guangdong Modern
 Information Service Fund (GDEID2012IS063), and the MOE-
 China Mobile Research Fund (No.MCM20121051).
 REFERENCES
 [1] J. Han and M. Kamber. Data Mining: Concepts and Techniques, 2nd
 edition, Morgan Kaufmann, 2006.
 [2] J. Vaidya, C. Clifton, M. Zhu. Privacy Preserving Data Mining (Ad-
 vances in Information Security). New York: Springer-Verlag, 2005.
 [3] M. Feingold, M. Corzine, and M. Wyden, et al. Data Mining Morato-
 rium Act of 2003. U.S. Senate Bill (proposed). Jan. 16 2003.
 [4] R. Agrawal and R. Srikant. Privacy-preserving data mining. In: Pro-
 ceedings of the 2000 ACM SIGMOD International Conference on
 Management of Data. 2000:439-450.
 [5] Y. Lindell, and B. Pinkas. Privacy preserving data mining. In: Advances
 in Cryptology - CRYPTO 2000, In: Proceedings of the 20th Annual
 International Cryptology Conference, LNCS 1880. 2000:36-54.
 [6] J. Lin, Y. Cheng. Privacy preserving itemset mining through noisy items.
 Expert Systems with Applications. 2009, 36(3): 5711-5717.
 [7] J. Sakuma, S. Kobayashi. Large-scale k-means clustering with user-
 centric privacy-preservation. Knowledge and Information Systems.
 2010, 25(2):253-279.
 [8] J. Vaidya, and C. Clifton. Privacy-preserving outlier detection. In:
 Proceedings of the 4th IEEE International Conference on Data Mining.
 2004:233-240.
 [9] J. Vaidya, M. Kantarcioglu. Privacy preserving naive bayes classifica-
 tion. The VLDB Journal. 2008, 17(4):879-898.
 [10] F. McSherry, I. Mironov. Differentially private recommender systems:
 building privacy into the net. In: Proceedings of the 15th ACM SIGKDD
 International Conference on Knowledge Discovery and Data Mining .
 2009:627-636.
 [11] F. Li, J. Sun, and S. Papadimitriou, et al. Hiding in the crowd:
 privacy preservation on evolving streams through correlation tracking.
 In: Proceedings of the 23rd IEEE International Conference on Data
 Engineering. 2007:686-695.
 [12] B. Zhou, J. Pei. Preserving privacy in social networks against neighbor-
 hood attacks. In: Proceedings of the IEEE 24th International Conference
 on Data Engineering. 2008: 506-515.
 [13] M. Kantarcioglu, and C. Clifton. Privacy-preserving distributed mining
 of association rules on horizontally partitioned Data. IEEE Transaction
 on Knowledge and Data Engineering. 2004, 16(9):1026-1037.
 [14] R. Agrawal, and R. Srikant. Fast algorithms for mining association rules.
 In: Proceeding of the 20th International Conference on Very Large Data
 Bases, 1994:487-499.
 [15] D. Cheung, J. Han, V. Ng, et al. A fast distributed algorithm for mining
 association rules. In: Proceedings of 1996 International Conference of
 Parallel and Distributed Information Systems 1996:31-42.
 [16] R. Agrawal, A. Evfimievski, and R. Srikant. Information sharing
 across private databases. In: Proceedings of The 2003 ACM SIGMOD
 International Conference on Management of Data. 2003:86-97.
 [17] D. Boneh. The decision diffie-hellman problem. In: Proceedings of the
 3rd Algorithmic Number Theory Symposium, LNCS 1423. 1998:48-63.
 [18] W.L. Du. A Study of Several Specific Secure Two-party Computation
 Problems. PhD thesis, Purdue University, West Lafayette, Indiana, 2001.
 [19] M. Kantarcioglu, and O. Kardes. Privacy-preserving data mining appli-
 cations in the malicious model. In: Proceedings of the Seventh IEEE
 International Conference on Data Mining Workshops. 2007: 717-722.
 [20] A. Yao. How to generate and exchange secrets. In: Proceedings of the
 27th Annual Symposium on. Foundations of Computer Science. 1986,
 162-167.
 [21] Y, Lindell1, B. Pinkas. A proof of security of yao’s protocol for two-
 party computation. Journal of Cryptology. 2009, 22(2):161-188.
 [22] O. Goldreich. Foundations of Cryptography (Volumn 2). Cambridge
 University Press. 2004.
 [23] P. Samarati. Protecting respondents’ identities in microdata Release.
 IEEE Transaction on Knowledge Data Engineering. 2001, 13(6): 1010-
 1027.
 [24] A. Machanavajjhala, D. Kifer, and J. Gehrke, et al. -diversity: Privacy
 beyond k-anonymity. ACM Transactions on Knowledge Discovery from
 Data (TKDD), 2007:1-52.
 [25] N. Li, T. Li, and S. Venkatasubramanian. t-closeness: Privacy beyond
 k-anonymity and -diversity. In: Proceedings of the IEEE International
 Conference on Data Engineering (ICDE), 2007:106-115.
 [26] S. R. Ganta, S. Kasiviswanathan, and A. Smith. Composition attacks
 and auxiliary information in data privacy. In: Proceedings of the ACM
 International Conference on Knowledge Discovery and Data Mining
 (SIGKDD), 2008:265-273.
 [27] D. Kifer. Attacks on privacy and de finettis theorem. In: Proceedings of
 the ACM Conference on Management of Data (SIGMOD), 2009:127-
 138.
 [28] C. Dwork. Differential privacy. In: M. Bugliesi, B. Preneel, V. Sassone,
 and I. Wegener, editors, ICALP (2), volume 4052 of Lecture Notes in
 Computer Science, 2006:112.
 [29] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise
 to sensitivity in private data analysis. In: S. Halevi and T. Rabin,
 editors, TCC, volume 3876 of Lecture Notes in Computer Science,
 2006:265284.
 [30] F. McSherry and K. Talwar. Mechanism design via differential privacy.
 In: Proceedings of the IEEE Symposium on Foundations of Computer
 Science (FOCS), 2007:94-103.
 [31] M. Hay, V. Rastogi, and G. Miklau, et al. Boosting the accuracy of
 differentially private histograms through consistency. In Proceedings of
 the International Conference on Very Large Data Bases (VLDB), 2010.
 [32] N. Mohammed, R. Chen, and B. C. M. Fung, et al. Differentially private
 data release for data mining. In Proceedings of the ACM International
 Conference on Knowledge Discovery and Data Mining (SIGKDD),
 2011.
 [33] J. Lee, C. Clifton. Differential identifiability. In: Proceedings of the 18th
 ACM SIGKDD international conference on Knowledge discovery and
 data mining (KDD), 2012:1041-1049.
 [34] S. P. Kasiviswanathan, K. Nissim, and S. Raskhodnikova et al. Analyz-
 ing Graphs with Node Differential Privacy. In: Theory of Cryptography
 Lecture Notes in Computer Science Volume 7785, 2013:457-476.
 [35] Z. Ji, C. Elkan. Differential privacy based on importance weighting.
 Machine Learning. Published online. June 2013.
 [36] Noman Mohammed, Dima Alhadidi, and Benjamin C. M. Fung, et al.
 Secure Two-Party Differentially Private Data Release for Vertically-
 Partitioned Data. IEEE Transactions on Dependable and Secure Com-
 puting. Published online. May 2013
 [37] B. Goethals, S. Laur, H. Lipmaa, et al. On private scalar product
 computation for privacy-preserving data mining. In: Proceedings of
 the 7th Annual International Conference in Information Security and
 Cryptology, 104-120.
 [38] H.Y. Lin, W.G. Tzeng. An efficient solution to the millionires’ prob-
 lem based on hormomorphic encryption. ACNS 2005, LNCS 3531,
 2005:456-466.
 [39] I.F. Blake, V. Kolesnikov. Strong conditional oblivious transfer and
 computing on intervals. In: Proceedings of Advances in Cryptology-
 ASIACRYPT’04, LNCS 3329, 2004:515-529.
 6430
