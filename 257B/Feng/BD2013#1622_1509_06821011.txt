 
eCAD: Cloud Anomalies Detection  
From an Evolutionary View 
Yuchao ZHANG, Bin HONG, Ming ZHANG, Bo DENG, Wangqun Lin  
Beijing Institute of System Engineering, Beijing, China 
{dragonzyc, newredice, zdream99, bodeng, Linwangqun2005}@gmail.com 
 
 
Abstract—Recent years have witness the booming of the cloud 
computing, which provides customers with guaranteed services. 
Since any violation would inevitably lead to a degraded quality of 
service (QoS), anomalies detection has become a demanding task 
in cloud environments. To solve the above problems, the 
unsupervised clustering approaches were put forward for 
identifying those anomalies. However, they all failed to work out 
the anomalies detection from an evolutionary view. In this paper, 
we present a cloud anomalies detection framework called eCAD. 
Motivated by the evolutionary clustering, our eCAD employs an 
evolutionary algorithm with DBSCAN to detect cloud anomalies 
as time steps. Besides, we also propose an M-Nearest Neighbors 
(MNN) algorithm to conduct the inference for those induced 
anomalies. Our eCAD is evaluated on the top of VICCI platform, 
which is a federated cloud test-bed in IaaS level. As demonstrated 
in our experiment, our framework shows an advantage over its 
counterparts. 
Index Terms—Anomalies, Cloud Computing, QoS, SLO, 
VICCI Platform, Evolutionary Clustering.  
I. INTRODUCTION  
In recent years, cloud computing is regarded as an 
emerging network computing model, aiming to provide users 
with services of computing resources. While providing basic 
resources and services, cloud computing has been devoted to 
guarantee the quality of service (QoS) [1]. With the benefit of 
cloud computing model, customers would not need to be 
concerned on their service-level, which in turn poses a 
challenge for those cloud providers. Although many researches, 
such as performance prediction, load balancing, and anomaly 
detection, have been set off in the field of the cloud QoS 
guarantee, it is still difficult for providers to address the default 
of the promised SLO (Service Level Object) [2]. The SLO is a 
contract negotiated between the cloud provider and its 
customers for guaranteeing the QoS in cloud. Any violation 
related to SLO would inevitably bring about a huge loss for 
both parties involved. Therefore, we need to preserve those 
underlying anomalies so as to take action in time.  
As NIST defines, cloud computing comprises three levels, 
namely IaaS, PaaS and SaaS [3]. However, different levels may 
expose various demands their QoS. To some extent, the service 
quality of IaaS cloud always determines that of the upper levels. 
Consequently, we mainly focus on the anomalies detection in 
IaaS cloud, where the virtualization technology plays an 
important role.  
In terms of the virtualized infrastructure, the performance 
of the cloud environment might be challenged by many aspects, 
such the vulnerability in VMM (Virtual Machine Monitor), 
rootkit, and DOS (Deny of Services) [4]-[6]. Since the lower 
infrastructure in cloud is shared through virtualization 
technology, anomalies as well as bottlenecks of the virtualized 
resources might happen frequently [7]. As one of the most 
demanding work, anomaly detection focuses on preserving 
those virtualized resources, which might lead to a violation on 
the SLO. Similar to our work, previous researches undertook 
the clustering approach for identifying outliers in cloud, such as 
the DBSCAN algorithm [8]. However, they neglect taking the 
transitions of those anomalies and its surrounding neighbors 
into consideration. 
In this paper, we present a framework named eCAD (Cloud 
Anomalies Detection) from an evolutionary view for detecting 
the anomalies in the level of the cloud infrastructure. Our 
system is deployed on the VICCI cloud platform, which is a 
global wide cloud test-bed established by Princeton University. 
Many institutes as well as enterprises utilize it to achieve an 
IaaS cloud similar to Amazon EC2 or OpenStack. Compared 
with the traditional clustering methods, our eCAD can not only 
identify evolutionary exceptions, but also help to make 
anomalies inference.  
Our system’s main contribution includes:  
• Our eCAD has the ability to find the outliers in cloud 
environment based on the evolutionary clustering 
algorithm with DBSCAN.  
• Besides, we also propose an MNN (M-Nearest 
Neighbors) method to infer the reasons resulting in the 
anomalies. 
• Our system is deployed on the global cloud test-bed, 
and focuses on the anomalies caused in the HADOOP 
programs.  
The rest of our paper is organized as follows. Section II 
discusses some related works on cloud anomalies detection. 
The motivation and description of our eCAD framework are 
described in Section III. Section IV examines the results of our 
eCAD on the basis of the VICCI cloud platform. Section V 
presents the conclusion and introduces some future work.   
2013 International Conference on Cloud Computing and Big Data
 978-1-4799-2829-3/13 $26.00 © 2013 IEEE
 DOI 10.1109/CLOUDCOM-ASIA.2013.57
 328978-1-4799-2830-9/14 $31.00 © 2014 IEE
II. RELATED WORKS 
As mentioned by Tan et al., the approaches in the field of 
detecting anomalies can be divided into following two aspects, 
namely the pre-active and re-active ones. The former one 
predicts the anomalies and then makes preparation before it 
happens, while the latter one perceives the outliers at running 
time. The representatives of the above two approaches would 
be described as follows. 
A. Pre-active Methods 
Researchers in MSRA put forward a multivariate linear 
regression model named ARMR [9], which could track the 
virtualized resources changing over the time. However, this 
approach tends to model a single resource and ignore the latent 
relation with each other. 
Tan et al. [10][11] described the transitions of the states for 
virtualized resources using a FSM (finite state machine). After 
that, they take advantages of the decision tree model to separate 
the virtualized resources apart from different states. Since their 
work defined the states as normal, anomaly and alert ones, it 
was arduous for them to label those samples. At the same time, 
they also utilize the Triple-States-Markov-Chain to predict the 
potential anomalies in advance. 
Besides, Qiang et al. [12][13] proposed an ensemble of 
Bayesian and decision tree classification models to detect the 
anomalies in the virtualized infrastructure. Their researches 
illustrated the metrics that need to be supervised for virtualized 
resources in cloud.  
Generally speaking, pre-active methods build the detection 
models based on the probability distribution of the previous 
state information. It is often time-consuming for them to label 
between the normal and anomaly ones. Thus, they tend to be in 
a lack of the generalization for the new comers. Therefore, our 
paper would mainly focus on those re-active algorithms. 
B. Re-active Methods 
For the re-active methods, the most commonly used one is 
to monitor those resources based on the pre-defined thresholds 
or even the SLO. Once a violation was detected, the alert 
information would be pushed to the scheduler centers. A 
majority of the current monitoring tools are taking advantages 
of it, including Ganglia, Nagios, Nimsolf and so on. Although 
such method is relatively straightforward, it might lay a hinder 
for specifying those thresholds, which must be improved. 
Dependable Computing Systems Laboratory (DCS Lab) in 
the University of North Texas has carried out a lot of work on 
the re-active methods [14][15]. In the beginning of the learning 
process, there are only normal nodes existing in the cloud, 
while the anomalies would come later. To avoid the lack of 
sufficient labels, Song et al. took a cascading model of one-
 SVM and SVM to solve this problem through iterations. 
However, it usually took too much time to build such a 
cascading model and the boundaries between them are often 
indistinct. Meanwhile, SVM might come across the over-fit 
problems in front of the high dimension datasets.  
Since the clustering method has the ability to identify the 
noise in the dataset, Qiang et al. [8] came up with a model on 
the basis of the density-based clustering algorithm, which is 
similar to our work. Prior to detection, they exploited the PCA 
(Principal Component Analysis) technology to extract the 
significant features of the monitored attributes. Compared with 
our methods, it failed to take the evolution of the anomalies 
into consideration. 
Daniel et al. [16] presented the self-organizing map (SOM) 
model to work out the outlier detection problems. The 
virtualized resources would be defined as neurons of the SOM 
and then the outliers could be caught according to the relations 
between them. However, it showed a poor perform with the 
accumulation of the monitored metrics. 
In addition, methods derived from the field of information 
theory also played an important role. The EBAT frameworks 
proposed by Wang et al. [17] employed the ‘local entropy’ as 
well as the ‘global entropy’ to quantify the changing of 
resources. Although it could be used in different levels, this 
method had a lower precision rate on the whole. 
In sum, re-active methods can build models without the aid 
of previous labeled data. It contributes to the anomalies 
detection in the real time, especially for the cold start period. 
However, most of current approaches employ some static 
strategies, neglecting the evolution for those anomalies. 
Moreover, few of them pay attention to the anomalies inference. 
In this paper, we will discuss the above two problems. 
 
vkog"uvgr"v/3 vkog"uvgr"v vkog"uvgr"v-3cvvtkdwvg4
 cvvtkdwvg3
 ""
  
 
 
 
 Fig.1.  Motivation for cloud anomalies detection between: (a) static clustering, and (b) evolutionary clustering. 
329
III.THE FRAMEWORK OVERVIEW OF ECAD 
In this section, we will describe the motivation of our 
eCAD and overview the framework of our system.  
A. Motivation 
In practice, we all know that virtualized resources of the 
same kind tend to have similar values on their QoS metrics. As 
an unsupervised method, clustering can automatically divide 
the samples into different categories based on the distance, 
density and similarity between them. It has been widely used in 
the field of anomalies detection [8]. Enlightened by this, we 
would take clustering as our basic approach. Compared with 
the traditional classification approaches, the clustering 
algorithm would not only identify the outliers with less prior 
knowledge, but also resist to the change of the cluster numbers. 
Here, we use a simple example to illustrate our motivation.  
Fig.1(a) presents a solution for anomalies detection 
problem with DBSCAN (Density-Based Spatial Clustering of 
Applications with Noise), which is one of the density-based 
clustering algorithms. For it is only capable of recognizing the 
outliers separately at each monitoring period, we define it as a 
static clustering baseline algorithm in our paper.  
However, as a result of the accumulated monitored data, the 
lower clustered resources would evolve over time. To this end, 
we need to develop an evolutionary method to trace those 
transitions of virtualized resources, as shown in Fig.1(b). We 
name it as the evolutionary clustering algorithm. 
B. Framework 
As mentioned by Ferretti et al [18], our eCAD functioning 
as a middleware should comprise three main components: 
monitoring composite, detection composite, and inference 
composite. Our eCAD is deployed in the middle of the cloud 
infrastructure and remote users, which can be seen in the Fig.2. 
To emphasize, we only focus on those anomalies that occur in 
virtual machines of the service level. 
• Physical level and service level are two abstract plains 
in the IaaS cloud. The basic physical devices are 
deployed in the lower layer of cloud, while the VMs 
(virtual machines) provided to users outside the cloud 
lies in the service layer. 
• Monitoring composite collects the basic information, 
such as the CPU and Memory usage, from the virtual 
nodes in the cloud. Some of them might be running in 
the kernel level, and some of them in the user level.  
• Detection composite is in charge of finding the 
anomaly nodes based on the information collected by 
the monitoring composite. The key algorithm used in 
this module is derived from the DBSCAN clustering, 
which would be discussed in the following sections.  
• After the above two stages, inference composite sets 
off to explore the reasons for those anomaly nodes 
detected earlier.  
In general, the real-time performance information generated 
in the physical and service level is intercepted by the 
monitoring composite. Then the detection composite use the 
evolutionary clustering algorithm proposed to perceive the 
anomalies among the VMs in the service layer, in order to 
avoid the SLO negotiated between the counterparts. At last, the 
inference composite utilize the algorithm based on the M-
 Neighbors to present the reasons that might lead to violation.  
IV. EVOLUTIONARY CLUSTERING FOR ANOMALIES 
DETECTION 
In this section, we will first overview the framework of the 
current evolutionary clustering. After that, we propose an 
evolutionary approach with DBSCAN for cloud anomalies 
detection. Our method is considered to have a strong resistance 
to the noise and capable of finding anomalies in the cluster 
with arbitrary shapes. Besides, the algorithm for inferring the 
anomalies will be presented in the end.   
A. Overview 
The evolutionary framework of our research is primarily 
based on the following temporal smoothness penalty theory, 
which was put forward by Chakrabarti [19]. Its main idea aims 
to add a constraint cost function to the traditional static 
clustering algorithms.  
Here, we assume that   and 	  are respectively the 
evolutionary and static clustering results of virtualized nodes in 
cloud at time t. Given a time step t, the object of evolutionary 
clustering is to find the optimal   that minimizes the cost 
function as follows. 

     	         
where the snapshot function snap() denotes the current cost 
between evolutionary and statistic clustering results. Thus, the 
temporal function temp() denotes the historical cost between 
time step t and t-1. Theoretically, we could use any continuous 
k steps before time t to depict the temporal cost in temp(), 
instead of only two steps. Moreover, as mentioned before, we 
could explain the above cost function either into the PQM 
framework or into the PCM framework [20]-[21]. 
 
 
Fig.2.  eCAD framework under the cloud environment 
330
As a weight between the snapshot and temporal cost, the 
parameter alpha (!) in Equation (1) can be set according to the 
status of the cloud environment. In particular, the evolutionary 
algorithms are regarded as an incremental clustering, when ! 
equals to 0. Meanwhile, it turns out to be a static clustering, 
when ! equals to 1. In addition to the linear combination above, 
we might also use another non-linear weight to demonstrate the 
balance of cost between snap() and temp().   
In our context under the density-based evolutionary 
clustering with DBSCAN, we should redefine the snapshot and 
temporal function to illustrate the anomalies detection from an 
evolutionary view.  
B. Evolutionary DBSCAN 
DBSCAN, which is short for the density-based spatial 
clustering of applications with noise, has become one of the 
classical algorithms for anomalies detection. It can not only 
identify the abnormal virtualized nodes, but also automatically 
distinguish those nodes into different clusters. 
Core nodes, boundary nodes and anomaly nodes are three 
basic components in the DBSCAN. For a given virtualized 
node, it would become a core node, only if the number of its 
neighbors exceeds an upper threshold. On the contrary, those 
virtualized nodes within a limited distance are defined as the 
boundary nodes, which are mainly determined by the core 
nodes. Besides, the remaining nodes would become anomaly 
nodes, which usually take a minority of the dataset. Core nodes 
and their boundary nodes that could be directed within a 
limited distance are eventually divided into the same class. 
Anomaly nodes would not belong to any class and thus should 
be regarded as outliers in the virtualized layer. As mentioned 
before, several researches have taken advantage of this method 
to accomplish the anomalies detection in cloud. However, they 
failed to take the transitions of those anomalies and its 
surrounding neighbors into consideration. 
From the analysis above, we could infer that the cores 
nodes are determinant factors in the DBSCAN clustering. 
According to it, we should trace the variation of the core nodes 
to precisely character the evolution for different clusters.  
Nevertheless, we all know that the core nodes are determined 
by two main parameters, EPS and MINPTS, which are 
regularly settled on the basis of data density in DBSCAN 
clustering. To fully trace the variation, we could use the 
neighbor vector to represent the core nodes, which is defined as 
follows. 
(Definition): The element of the neighbor vector represents 
the number of neighbors within the EPS for each virtualized 
node, that would be a core node only if its value is large than 
MINPTS. 
We formally define the vector 	"""""# as the number of 
neighbors for each virtualized node at time t. Meanwhile, the 
vector """# should be the number of neighbors for evolutionary 
clustering. It can be described as follows.  
	"""""#  $% & '( 
"""#  $
 
% &  
'(                                         (2) 
where )  and 
)  represent the statistic number and 
evolutionary number of neighbors for virtualized node i at time 
t. Here, we assume that the node number would not vary with 
time in our cloud environment. 
Given a neighbor vector, we can quantify the temporal 
smoothness cost function into the following one, 

*"""#+  
 """"#
 ,  -*
)  )+%      -*
)  
) +%. / 0 
In such occasions, our goal is to find the optimal solution of 
above function for the evolutionary DBSCAN. Meanwhile, all 
the evolutionary approaches discussed in our context are 
derived under the PCM framework as mentioned before.  
Based on the above observation, we could easily know that 
the value of """#  is optimal only when the first-order derivative 
of the object function equals to zero. It can be seen as follows 
in the Equation (4), 
"""#1234567    	"""""#      """"""""#/8 
In light of this, we can use the above neighbor vector to 
find the outliers in cloud at each time step. The details of our 
evolutionary clustering are described as follows. 
C. Further Discussion 
The evolutionary clustering with DBSCAN above is 
presented under an ideal assumption that the number of 
virtualized nodes would not vary with the time.  Since the 
virtualized nodes are not always stable in the cloud, those 
anomaly nodes should be migrated or killed at a certain period. 
There, we need to discuss the movement of such nodes. 
Moreover, with the variation of cluster nodes, the configuration 
Algorithm 1: Evolutionary DBSCAN 
 Input: set of virtulized noedes VNSet, , 	,  
 EPS, and MINPTS 
 
Output: anomalies at time t 
1 foreach 9) : ;<=  do 
2  calculate evolutionary neighbor vector """# at time t, 
 
  """#    	"""""#      """"""""#/ 
3 end 
4 foreach  ) : ""#  $ > &  (   do 
5 if  )> MINPTS  then 
6  label the nodes 9) as core node 
7 end
 8 end 
9 foreach  ) : ""#  $ > &  (   do 
10 if  )< MINPTS  and  distance(vi)<EPS then
 11  label the nodes 9) as boundary node
 12 else
 13 label the nodes 9) as anomaly node
 14 end
 15 end 
 
331
of parameters, such as the EPS and MINPTS, is also needed to 
be tuned, which is beyond the scope of our paper. 
In terms of the removal and entrance of the cluster nodes, 
our evolutionary framework can easily deal with these 
conditions. To begin with, we could neglect the neighbor 
vectors of those removed anomaly nodes in the subsequent 
intervals, which can be done by deleting a row in the vector"""#. 
At the same time, we could initial the neighbor vectors of these 
new comer nodes as zeros, which can be done by adding a row 
to the vector """"# . Since the derived neighbor vectors for the 
evolutionary clustering is a linear combination of the snapshot 
cost and temporal cost, the removal and entrance of the 
virtualized nodes at any time step would naturally not affect the 
evolution process. 
D. Anomaly Inference  
In order to make adjustments in time, our eCAD also needs 
to undertake the anomaly inference afterwards. Since the 
anomalies in our framework are mainly determined by the 
MINPTS nodes within the EPS, we suggest using the distance 
or similarity of the nearest MINPTS nodes to infer between 
different attributes, which is defined as the M-Nearest 
Neighbors (MNN) algorithm for inference in our paper. 
Besides, we only focus on the categories of those anomalies, 
rather than their specific attributes. For example, the attributes 
contained in the memory-oriented category might include 
memory usage, virtual memory usage and so on. The pseudo-
 code is described as follows. 
V. IMPLEMENTATION AND EXPERIMENT  
In this section, we first introduce the basic environment and 
metrics in our context. Then we present the experiment 
evaluation results of our eCAD on the VICCI based test-bed 
under three different scenarios. Compared with the traditional 
static clustering for anomalies detection, our eCAD can 
performs much better. 
A. Environment 
The prototype of our eCAD is established on the top the 
VICCI, which is promoted by researchers from the PlanetLab 
programs. As a kind of federated cloud, the VICCI platform 
consists of distributed cluster servers in the Princeton 
University, Stanford University, Washington University and 
other seven institutions. Similar to the other IaaS clouds, it can 
provide the VMs for users outside the cloud.  
In our experiment, we use the HADOOP WORDCOUNT 
AND SORTED programs as our benchmark. All of the 
scenarios are hence running under the HADOOP framework. 
In order to obtain the monitored information, we also install 
the VMSTAT tool in each VM. The detailed representative 
symbol of each metric could be found in the Table I.  
TABLE I.  MONITORED METRICS  
Categories Symbols 
CPU-oriented us / sy / id / wa 
Memory-oriented swpd / free/ buff / cache 
IO-oriented bi / bo / si / so 
Process-oriented b / r / in / cs 
B. Simulated scenario 
In our experiment, we simulate three different scenarios 
with injected CPU errors to evaluate our eCAD. It can be seen 
as follows. 
(Scenario 1) NoHead: The eCAD was deployed on the 180 
virtual nodes, where the HADOOP WORDCOUNT 
benchmark ran. Under such a situation, the virtual nodes were 
in single HADOOP mode and independent with each other. 
Besides, all the clusters as well as the anomalies are labeled 
based on the injected CPU errors. 
(Scenario 2) Head: The eCAD was deployed on the 50 
virtual nodes with distributed HADOOP mode. Different from 
the above NoHead Scenario, the SORTED benchmark was 
adopted in this situation.  
(Scenario 3) HeadSLO: This scenario took on the same 
configuration as Head Scenario. Nevertheless, we labeled the 
anomalies on account of the OUTPUT/INPUT rate in the 
service level, so as to investigate the effects of anomalies on 
the SLO. 
C. Index 
To evaluate our approaches, we employ three indexes, 
including Precision, Recall and F-Score, which are the popular 
evaluation approaches in field of machine learning. The details 
of each index are introduced as follows. In the following 
equations, ?@AB/ CDEDFEDG and ?HDI/ CDEDFEDG  respectively 
indicate the number of normal nodes and anomalies detected. 
  
 
  
J
KK 
 ?L/M
N
 ?L/ M
N  ?L/ON
N P
 LQ
 
 ?L/ M
N
 ?L/ M
N  ?<R/ M
N S
 Algorithm 2: Anomalies inference 
 Input: set of attributes AttriSet,  
 set of anomalies AnoSet,  
 
EPS, and MINPTS 
 
Output: Categories of anomalies 
1 foreach 9 : T=  do 
2  foreach  ) : TQ=  do 
3  
 
calculate distance N)  - 19 9)1 between 9 
 
 
 
and other MINPTS nodes 9) within EPS on )
 4  end 
5  calculate weight U)  N) -N)V  on attribute ),
 6  output the category of the ) with WU)  
7 end 
332
 
 
 
D. Results 
Before conducting our evaluation, we need to select the 
parameters in our evolutionary algorithm. According to 
distance trend of the nearest K-neighbors, we theoretically set 
(EPS=10, MINPTS=3) in scenario 1 and (EPS=10, 
MINPTS=4) in the other two scenarios. 
Since each alpha indicates a different strategy, Fig.3 
presents the impact of alpha on our eCAD. As mentioned 
before, our evolutionary approach would be a static clustering 
when the parameter alpha is equal to 1, while it would become 
an incremental algorithm when the alpha is 0. As seen from 
the Fig.3, the static clustering showed the poorest performance 
in cloud anomalies detection. When the alpha equals to 0.1, 
the eCAD can obtain the highest precision in our experiment 
scenarios.  
In terms of the anomalies detection with evolutionary time 
steps, we can find that our eCAD framework exceeds its 
counterparts in Fig.4. At the beginning of our simulated 
experiments, the eCAD with evolutionary approaches takes an 
advantage. When the CPU errors are injected, it starts to fall 
down and returns to a stable status later on. Under that 
condition where the alpha equals to 0.25, the eCAD achieves 
its highest performance.  
To emphasize it, the static strategy always stayed in an 
unstable drift, fluctuating up and down with time stepping. 
Besides, the over-all results shown in the scenario 2 and 
scenario 3 resembles with each other. To some extent, we 
justify that the upper SLO values can reflect statuses of the 
lower virtual resources, and could also help to label those 
anomalies. 
After detection, we utilize the proposed MNN algorithm to 
infer the reason that leads to anomalies. In our experiment, we 
regarded the CPU errors as our incentives. The inference 
results can be found in Table II. 
TABLE II.  ANOMALIES INFERENCE 
Scenarios  # Anomalies # Inferred Precision 
NoHead 47 33 0.721 
Head 57 39 0.6842 
HeadSLO 30 7 0.333 
 
From the table above, we can notice that our eCAD shows 
a poor inference under the HeadSLO scenario. In such an 
X?=
Q  > Y
 LQ
 Y J
KK
 LQ
  J
KK  Z
 
 F
 
 Fig.4.  The performance of eCAD under the: (a) NoHead, (b) Head and (c) HeadSLO scenarios. 

 F
 
 Fig.3.  The impact of alpha values on eCAD under the: (a) NoHead, (b) Head and (c) HeadSLO scenarios. 
333
occasion, the labels were determined based on the upper SLO. 
Thus, other attributes might interfere with its precision. We 
would improve it in the future works. 
VI. CONCLUSION 
In this paper, we proposed a framework named eCAD 
from an evolutionary view to identify anomalies in the IaaS 
cloud. To illustrate our framework, we established a VICCI 
cloud equipped with HADOOP benchmarks. Our experiment 
reveals that the evolutionary clustering method can identify 
cloud anomalies more precisely than its counterparts, 
especially for the traditional static clustering approach. 
Moreover, our framework can also infer the reasons for the 
above anomalies.  
As immediate future work, we plan to simulate more 
scenarios with other injected errors. With the accumulation of 
the anomalies, they might come into being a whole anomaly 
cluster, which would also be solved within our following 
researches.  
REFERENCES 
[1] Michael Armbrust, Armando Fox and Rean Griffith et al. A view of 
cloud computing [J]. Communications of the ACM, Vol.53, No.4, April 
2010. 
[2] Patel Patel, Ranabahu Ajith and Sheth Amit. Service Level Agreement 
in Cloud Computing [C]. In Cloud Workshop at OOPSLA, 2009. 
[3] Mell P., Grance T. The NIST Denition of Cloud Computing. National 
Institute of Standards and Technology, Information Technology 
Laboratory, USA. 
[4] D. Hyde. A Survey on the Security of Virtual Machines. Dept. of Comp. 
Science, Washington Univ., 2009. 
[5] Arvind Seshadri, Mark Luk, Ning Qu, Adrian Perrig: SecVisor: a tiny 
hypervisor to provide lifetime kernel code integrity for commodity OSes 
[C]. SOSP 2007:335-350. 
[6] Fengzhe Zhang, Jin Chen, Haibo Chen, Binyu Zang: CloudVisor: 
retrofitting protection of virtual machines in multi-tenant cloud with 
nested virtualization [C]. SOSP 2011:203-216. 
[7] Maurice Gagnaire, Felipe Diaz, et al. Downtime statistics of current 
cloud solutions. IWGCR 2012. 
[8] Qiang Guan, Song Fu. Auto-AID: A data mining framework for 
autonomic anomaly identification in networked computer systems 
[C]. IPCCC 2010:73-80. 
[9] Ripal Nathuji, Aman Kansal and Alireza Ghaffarkhah. Q-clouds: 
managing performance interference effects for QoS-aware clouds [C]. 
EuroSys 2010:237-250 
[10] Yongmin Tan, Hiep Nguyen, Zhiming Shen, Xiaohui Gu, Chitra 
Venkatramani, Deepak Rajan. PREPARE: Predictive Performance 
Anomaly Prevention for Virtualized Cloud Systems [C]. ICDCS 
2012:285-294. 
[11] Yongmin Tan, Xiaohui Gu, Haixun Wang. ALERT:Adaptive system 
anomaly prediction for large-scale hosting infrastructures [C]. PODC 
2010: 173-182. 
[12] Qiang Guan, Ziming Zhang, Song Fu. Ensemble of Bayesian Predictors 
and Decision Trees for Proactive Failure Management in Cloud 
Computing Systems [J]. JCM 7(1):52-61 (2012). 
[13] Qiang Guan, Chi-Chen Chiu, Ziming Zhang, Song Fu. Efficient and 
Accurate Anomaly Identification Using Reduced Metric Space in Utility 
Clouds [C]. NAS 2012:207-216. 
[14] Husanbir S. Pannu, Jianguo Liu, Song Fu. AAD: Adaptive Anomaly 
Detection System for Cloud Computing Infrastructures [C]. SRDS 
2012:396-397. 
[15] Song Fu. Performance Metric Selection for Autonomic Anomaly 
Detection on Cloud Computing Systems [C]. GLOBECOM 2011:1-5. 
[16] Daniel Dean, Hiep Nguyen, and Xiaohui Gu. UBL: Unsupervised 
behavior learning for predicting performance anomalies in virtualized 
cloud systems [C]. ACM ICAC, 2012. 
[17] Chengwei Wang, Vanish Talwar, Karsten Schwan, Parthasarathy 
Ranganathan. Online detection of utility cloud anomalies using metric 
distributions [C]. NOMS 2010:96-103. 
[18] Stefano Ferretti, Vittorio Ghini, Fabio Panzieri, Michele Pellegrini, Elisa 
Turrini: QoS-Aware Clouds [C]. IEEE CLOUD 2010:321-328. 
[19] Deepayan Chakrabarti, Ravi Kumar, Andrew Tomkins.  Evolutionary 
clustering [C].  ACM SIGKDD International Conference on Knowledge 
Discovery & Data Mining (KDD), 2006:554-560. 
[20] Yun Chi, Xiaodan Song, Dengyong Zhou, Koji Hino, Belle L. Tseng. 
On evolutionary spectral clustering [J]. ACM Transactions on 
Knowledge Discovery from Data, Vol. 3, No. 4, 2009. 
[21] Yun Chi, Xiaodan Song, Dengyong Zhou, et al. Evolutionary spectral 
clustering by incorporating temporal smoothness [C]. ACM SIGKDD 
International Conference on Knowledge Discovery & Data Mining 
(KDD), 2007:153-162. 
[22] Ulrike Luxburg. A tutorial on spectral clustering [J]. Statistics and 
Computing (SAC) 17(4), 2007. 
 
 
 
334
