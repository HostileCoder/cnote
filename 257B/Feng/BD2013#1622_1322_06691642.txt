CloudRS: An Error Correction Algorithm of High-Throughput Sequencing Data 
based on Scalable Framework 
 
Chien-Chih Chen#,1, Yu-Jung Chang#,1, Wei-Chun Chung#,2,3, Der-Tsai Lee1,3,4, Jan-Ming Ho§,1,2 
1 Institute of Information Science 2 Research Center for Information Technology Innovation 
Academia Sinica 
Taipei, Taiwan, ROC 
E-mail: {rocky, yjchang, wcchung, dtlee, hoho}@iis.sinica.edu.tw 
 
 
Abstract—Next-generation sequencing (NGS) technologies 
produce huge amounts of data. These sequencing data 
unavoidably are accompanied by the occurrence of 
sequencing errors which constitutes one of the major 
problems of further analyses. Error correction is indeed one 
of the critical steps to the success of NGS applications such 
as de novo genome assembly and DNA resequencing as 
illustrated in literature. However, it requires computing time 
and memory space heavily. To design an algorithm to 
improve data quality by efficiently utilizing on-demand 
computing resources in the cloud is a challenge for 
biologists and computer scientists. In this study, we present 
an error-correction algorithm, called the CloudRS 
algorithm, for correcting errors in NGS data. The CloudRS 
algorithm aims at emulating the notion of error correction 
algorithm of ALLPATHS-LG on the Hadoop/ MapReduce 
framework. It is conservative in correcting sequencing 
errors to avoid introducing false decisions, e.g., when 
dealing with reads from repetitive regions. We also illustrate 
several probabilistic measures we introduce into CloudRS to 
make the algorithm more efficient without sacrificing its 
effectiveness. Running time of using up to 80 instances each 
with 8 computing units shows satisfactory speedup. 
Experiments of comparing with other error correction 
programs show that CloudRS algorithm performs lower 
false positive rate for most evaluation benchmarks and 
higher sensitivity on genome S. cerevisiae. We demonstrate 
that CloudRS algorithm provides significant improvements 
in the quality of the resulting contigs on benchmarks of 
NGS de novo assembly. 
Availability: The source code of CloudRS is freely 
available at https://github.com/ice91/ReadStackCorrector. 
 
Keywords-error correction; mapreduce; genome assembly; 
next-generation sequencing 
I.  INTRODUCTION 
With the explosive growth of next-generation sequencing 
(NGS) data at continually decreasing costs [1], there is a 
pressing need for applications to handle massive genomic 
sequencing data efficiently using scalable, on-demand, and 
inexpensive commodity cloud servers. Error correction of 
sequencing reads is an effective preprocessing step in many 
applications of NGS data analysis such as sequence 
assembly and DNA resequencing. There are three typical 
ways to correct errors for those applications, i.e., read 
alignment, k-mer spectrum-based [2] and graph-based 
assembly. Note that a mer refers to a base pair of a genome 
sequence. A k-mer spectrum of a genome refers to empirical 
frequencies of DNA k-mers in the specific genome sequence. 
Read alignment depends on identifying all the 
overlapping reads by multiple alignments. A mismatch at a 
specific position of a read can be corrected to the nucleotide 
agreed upon by majority of the aligned reads at the same 
position. The idea has also been implemented in other error 
correction algorithms [3,4]. Another widely used approach is 
k-mer frequency spectrum-based error correction [5-10]. A k-
 mer denotes a sequence of length k in biology A k-mer 
frequency spectrum is derived from the frequencies of k-
 mers in the reads with each k-mer being categorized as 
trusted k-mers and untrusted k-mers, i.e., high-frequency k-
 mers and low-frequency k-mers, respectively. Thus, 
algorithms are developed to convert untrusted k-mers into 
trusted k-mers with minimal changes of their reads. Graph-
 based assembly approaches is the third type of error 
correction. It is based on the observation that sequencing 
errors may create specific types of local defects that can be 
detected in the assembly graph of reads, e.g. tips, bubbles, 
and braids [11,12]. By detecting and removing these local 
defects, the number of sequencing errors can be reduced and, 
thus, allowing an assembler to yield longer contigs. 
Nevertheless, correcting sequencing errors in the huge 
amount of reads generated by NGS technologies is time 
consuming and memory demanding. Furthermore, a huge 
amount of intermediate data is created in the computation 
process. For example, a naive implementation of the read-
 stack algorithm of ALLPATHS-LG [13] would replicate a 
read for each k-mer subsequence of the read. For a 100G 
NGS file of read length 36 and k-mer size 25, this means that 
the total size of intermediate data is 1.2 tera-bytes, i.e., each 
??????????????????? 
# These authors contributed equally to this work (co-First authors). 
3 Department of Computer Science and Information Engineering, 
National Taiwan University, Taipei, Taiwan, ROC. 
4 Department of Computer Science and Information Engineering, 
National Chung Hsing University, Taichung, Taiwan, ROC. 
§ Corresponding author 
2013 IEEE International Conference on Big Data
 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 717
central column left 
column
 right 
column
 R1
 R2
 R3
 R4
 R5
 R1
 R2
 R3
 R4
 R5
 R1
 R2
 R3
 R4
 R5
 R1
 R2
 R3
 R4
 R5
 branch 
point
 branch 
point
 k+1 mer k mer
  
Figure 1. Illustration of read stack construction. 
read is replicated 12 times. Thus, new strategies to store and 
process large quantities of data efficiently are required. The 
MapReduce [14] framework is a scalable distributed 
computing framework for biologists and bioinformatician to 
process huge amount of genomic sequencing data. Though 
MapReduce and its famous implementation Hadoop [15] are 
available for researchers and are highly fault tolerance when 
processing large datasets, the design of MapReduce 
algorithms is not trivial. Thus, it is also the aim of this study 
to coordinate parallel processes in a specific way to balance 
the cost among disk I/O, communication and computation. 
In this paper, we present our design and development of 
CloudRS, an error correction algorithm based on 
MapReduce framework. We also evaluate the performance 
CloudRS and give some discussions. 
II. METHODS 
As shown in benchmark GAGE [16], the error correction 
model of ALLPATHS-LG [13], denoted as Read Stack (RS) 
algorithm in this paper, brings significant improvement for de 
novo NGS genome assembly. Using RS algorithm as a starting 
point, our aim in this study is thus to develop an efficient 
algorithm based on MapReduce framework to fully exploit the 
advantage of on-demand computing, i.e., to acquire computing 
power, physical memory space and disk storage flexibly based 
on the scale of input NGS data size. We’ll begin this section 
with an overview of the RS algorithm and also present the 
algorithm CloudRS designed to run on the MapReduce 
framework. 
A. Overview of ReadStack (RS) algorithm 
Finding read stacks and correcting possible errors by 
majority voting is the basic operation in RS algorithm [13]. As 
shown in Figure 1, a read stack is an alignment of reads that 
share a common k-mer pattern in their sequences. A k-mer 
pattern is either a substring of length k, denoted as a substring 
pattern, or a subsequence composed of k fixed characters and 
some wildcard characters, denoted as a wildcard pattern. The 
substring pattern is useful for correcting errors in the two sides 
of read stacks and the wildcard pattern is useful for correcting 
errors in the middle part of read stacks. For example, in Figure 
1a, the five DNA sequencing reads on top  share the same 
subsequence of length k+1 with a wildcard base in its middle; 
then they are aggregated and aligned into the read stack below, 
where bases located in the central wildcard column will be 
voted and corrected. In Figure 1b, the five reads on top share the 
same substring of length k; then they are aggregated and aligned 
into the read stack below. Each of the left and right columns will 
be voted and corrected except the columns outside the branching 
points. 
There are two phases in correcting errors [13]: 1) 
recommendation, and 2) correction. In the recommendation 
phase, a stack of reads is built by aligning reads containing the 
same k-mer pattern. Once a read stack is built, each column of 
the read stack is processed to generate votes, including replacing 
and preserving votes, for each DNA base of each read of the 
read stack. After summing up the quality values of A, C, G, T, 
respectively on a column of a read stack, bases with scores less 
than a threshold are labeled as error candidates. They will 
receive replacing votes of modifying them to the highest-score 
base. Preserving vote is issued if all the bases of a column are 
equal. Then in correction phase, it collects the votes and makes 
decisions about which base should be corrected. Note that 
corrections are made if the replacing votes for the same base 
agree with each other and no preserving vote is found. After 
correcting errors, RS algorithm has a screening phase to filter 
out the reads containing unique k-mers because they are likely 
to be sequencing errors [13]. 
B. CloudRS?emulating RS algorithm in MapReduce 
Based on RS algorithm, CloudRS algorithm consists of three 
modules: PreCorrect, FindError, and Screening. First, the 
PreCorrect module uses a 25-mer wildcard pattern with one 
wildcard in the middle to build read stacks and correct errors in 
the middle column (Figure 1a). Secondly, the FindError module 
uses a 24-mer substring pattern to build a read stack and correct 
errors in the columns on both sides of the 24-mer pattern of the 
read stack (Figure 1b). Finally, the Screening module filters out 
reads that contain unique 24-mer substrings. The 
aforementioned parameters are the same as those used by the RS 
algorithm [13]. 
In the MapReduce implementation, we utilize multiple map-
 reduce rounds, i.e., one map-reduce round for the 
recommendation phase and one for the correction phase (for 
both PreCorrect and FindError modules), and two map-reduce 
rounds for the screening module. 
In the recommendation phase, each read is scanned with a 
sliding k-mer window by the mapper. To fit the <key, value> 
pair data format of MapReduce, the sliding k-mer window is 
defined as key and the content of a read, including the read ID 
and its sequence, is defined as value. After the shuffle-and-sort 
of MapReduce, the reads with the same k-mer are aggregated to 
the same reducer. We can align those reads and generate the 
replacing/preserving votes according to the process of 
recommendation phase described in Section II.A. Figure 2 
shows the process of recommendation phase in the MapReduce 
framework. In the correction phase, the input of a mapper is 
read data and the corrected messages. The read ID is defined as 
key, whereas read sequence and corrected messages are defined 
as value. Thus, we can aggregate and correct sequencing errors 
by manipulating the replacing/preserving votes in the reducer. 
The nucleotide is corrected only when the replacing action is 
agreed by every vote and there is no preserving vote at the 
specific positions. Figure 3 shows the process of correction 
718
mappermapper mapper mapper
 K2K1 R1 R2
 Shuffle and Sort: aggregate values by keys
 reducer reducer reducer
 K1 R1 R3 K2 R2R4 K3
 R1 M1
 K2K1 R3 R4 K2K3 R5 R6 K2K3 R7 R8
 R6 R8 R5R7R1
 K3 R1
 R3 M3
 R2 M2
 R4 M4
 R6 M6
 R8 M8
 R1 M1
 R5 M5
 R7 M7
 R1
 R2
 R3
 R4
 R5
 R6
 R7
 R8
 corrected 
message 
duplication
  
Figure 2.  The process of recommendation phase in MapReduce 
framework. 
R1
 R2
 R3
 R4
 R5
 R6
 R7
 R8
 R1 M1
 R3 M3
 R2 M2
 R4 M4
 R6 M6
 R8 M8
 R1 M1
 R5 M5
 R7 M7
 mappermapper mapper mapper
 Shuffle and Sort: aggregate values by keys
 reducer reducer reducer
 R1
 R1 M1
 ……………
 bottleneck
 R1’
 R2’
 R3’
 R4’
 R5’
 R6’
 R7’
 R8’
 corrected 
message 
duplication
 Figure 3.  The process of correction phase in MapReduce framework. 
 
Figure 4.  The key design of the group mechanism. 
phase upon MapReduce, where the read Ri’ stands for the 
corrected read of read Ri. The Screening module is implemented 
as two map-reduce rounds to generate the unique k-mer tag by 
counting k-mer frequencies in the first round and to remove 
them in the second round. 
The implementation of recommendation phase and 
correction phase presented earlier, however, may exhibit the 
following side-effects. First, we need to duplicate a read for 
each of its k-mer subsequence and thus may cause message 
flooding in the recommendation phase. Second, the data and 
workload of the reducer may unbalance. For the first problem, it 
is due to that one read have different sliding k-mer. Each k-mer 
generates a read stack and the same read may appear in different 
read stacks. Therefore, one sequencing error may generate the 
same corrected messages distributed on different reducers. 
Message flooding is the bottleneck of the correction phase, since 
it increases the overhead of the shuffle and sort of MapReduce 
framework as shown in Figure 3. The second problem is due to 
the repeat sequence in the genome. The k-mers produced by the 
reads in a repeat region lead to an uneven distribution of read 
stacks of each reducer. 
We introduce grouping mechanism to decrease the effect of 
message duplication make a compromise between 
parallelization and communication cost [17]. Thus, we divide 
the k-mer into primary key and sub key, instead of using the 
entire k-mer as key. Figure 4 shows the design of group 
mechanism in relation to key partitions. The primary key is used 
to replace original key in the MapReduce framework. The sub 
key is used in the reducer to differentiate the group of read 
stack. A reducer in the new scheme received a group of read 
stacks; therefore, the duplicated corrected messages can be 
combined into one message in the same reducer. This 
mechanism can decrease the communication cost of duplicated 
corrected messages. 
We also introduce a high frequency k-mer filter to overcome 
the unbalance workload problem. The read stack build by a k-
 mer in the repeat region are composed of reads from the 
different regions in the genome. It violates the basic idea of 
error correction, i.e., using the majority of reads to correct error; 
therefore, we do not need to analyze read stacks build by the k-
 mer in repeat regions. The straightforward way to determine the 
k-mer in the repeat region is using its frequency. Thus we build 
a high frequency k-mer list as a stop word list in natural 
language. First, we define a threshold of the k-mer occurrence. 
In general, the threshold is set as two times of the coverage 
depth of read data, because the occurrence of k-mer two times 
than average is always belong to repeat region. We use one 
map-reduce round to build a high frequency k-mer list, store the 
list in Hadoop Distributed File System (HDF??, and dispatch the 
list through the functionality of Hadoop distributed cache. Thus, 
the mappers of recommendation phase can skip computing on 
the high frequency k-mers according to the list. High frequency 
k-mer filtering decrease the communication cost between 
mapper and reducer, and avoid the unbalance workload in the 
reducer. 
III. EXPERIMENTAL RESULTS 
A. Datasets 
The seven experimental datasets, downloaded from the 
sequence read archive (SRA) at NCBI, are listed in Table I. All 
the datasets are sequenced by Illumina sequencers. We used 
datasets D1-D6 to evaluate the accuracy of error correction, 
these datasets are from resequencing experiments where the 
719
TABLE I.     DATASETS 
Dataset 
SRA 
accession 
number 
Genome 
(accession 
number) 
Genome 
size 
Read 
length 
#Reads
 (Mega)
 Genome
 coverage
 D1 SRX000429 E. coli  (NC_000913) 4.6 Mb 36 bp 20.8 161x 
D2 SRR022918_1 E. coli (NC_000913) 4.6 Mb 47 bp 7.0  71x 
D3 SRR034509_1 E. coli (NC_000913) 4.6 Mb 101 bp 8.9 195x 
D4 SRR006332 
Acinetobacter
  sp 
(NC_005966)
 3.6 Mb 36 bp 17.7 177x 
D5 SRX100885 S. cerevisiae (PRJNA128) 12 Mb 76 bp 52.0  329x 
D6 SRR022866 S. aureus (NC_003923) 2 Mb 76 bp 25.1 953x 
D7 SRA000271 African Male (NA18507) 3 Gb 36 bp 218.0 2.6x 
TABLE II.    RESULTS OF THE EVALUATION ON DATASET D1-D6
 Dataset Method TP FN FP TN Sensitivity (%) Specificity (%) Gain Precision (%) 
D1 
(E. coli) 
SHREC 2819754 1183861 667435 740842474 70.430% 99.910% 0.5376 80.86% 
Reptile 3164394 839221 133558 741376351 79.038% 99.982% 0.7570 95.95% 
CloudRS 784851 2940697 10860 741777116 21.067% 99.999% 0.2078 98.64% 
D2 
(E. coli.) 
Reptile 3551764 3189748 985674 323583005 52.685% 99.696% 0.3806 78.28% 
CloudRS 1659568 5005959 189119 308857044 24.898% 99.939% 0.2206 89.77% 
D3 
(E. coli.) 
Reptile 17158925 2947342 1298891 874945703 85.341% 99.852% 0.7888 92.96% 
CloudRS 978111 18878806 114042 876379902 4.926% 99.987% 0.0435 89.56% 
D4 
(A. sp.) 
Reptile 7138883 2361813 1138666 610144638 75.141% 99.814% 0.6316 86.24% 
CloudRS 2148235 5878602 19718 612737445 26.763% 99.997% 0.2652 99.09% 
D5 
(S. cer.) 
HSHREC N/A N/A N/A N/A 36.350% 97.730% -2.4975 N/A 
Reptile N/A N/A N/A N/A 22.780% 99.990% 0.2243 N/A 
SOAPec N/A N/A N/A N/A 18.710% 99.950% 0.1257 N/A 
Coral N/A N/A N/A N/A 7.090% 99.990% 0.0678 N/A 
CloudRS 17383865 4737336 143295 3823800700 78.585% 99.996% 0.7794 99.18% 
D6 
(S. aur.) 
HSHREC N/A N/A N/A N/A 22.480% 96.880% -4.2402 N/A 
Reptile N/A N/A N/A N/A 61.940% 99.990% 0.6131 N/A 
SOAPec N/A N/A N/A N/A 32.160% 99.890% 0.2571 N/A 
Coral N/A N/A N/A N/A 2.760% 99.990% 0.0256 N/A 
CloudRS 5484475 10653975 77957 1780836273 33.984% 99.996% 0.3350 98.60% 
genome sequence is known a priori and they are also used to 
evaluate other error correction programs in [7,2]. We use dataset 
D7 to evaluate the efficiency of CloudRS algorithm, since the 
data size of D7 is almost 10 times than other datasets. Using 
dataset D7 as benchmark, we analyze the difference between the 
standalone RS algorithm and MapReduce CloudRS algorithm.  
B. Accuracy evaluation 
To evaluate the accuracy of CloudRS algorithm, we used the 
benchmark provide by [2]. The benchmark identifies sequencing 
errors by using a mapping program to align reads to the 
reference genome. Only uniquely mapped reads are considered 
and mismatched bases in the reads are defined as sequencing 
errors. Then, we can assess the performance of an error 
correction method by identifying how many of erroneous bases 
that are changed to the true bases [true positives (TP)], how 
many true bases changed wrongly [false positives (FP)], how 
many erroneous bases left unchanged [false negative (FN)] and 
how many true bases left unchanged [true negative (TN)] [7]. 
From these numbers, statistics like precision, specificity, 
sensitivity or gain can be inferred, which will be defined in the 
following formulas: 
• Precision = TP / (TP + FP) 
• Specificity = TN / (TN + FP) 
• Sensitivity = TP / (TP + FN) 
• Gain = (TP-FP) / (TP + FN) 
Such statistics are not entirely satisfactory to assess the quality 
of corrections of a method, because it is unclear which statistic 
will indeed yield the best performance for other applications 
depending on the data. However, these statistics can give an 
overview of the characteristics for each error correction 
program. Table II show the results of the evaluation on dataset 
D1-D6. Note that, we do not re-run error correction programs 
such as SHREC [9], HSHREC [18], SOAPec [19] and Coral [3] 
on datasets D1-D6. The evaluated results of these error 
correction programs are extracted from [7,2], thus some fields 
(TP, FN, FP, TN, Precision) do not have information. 
From Table II, Reptile [7] seems perform better than other 
error correction programs in the viewpoint of gain measurement. 
Reptile has highest sensitivity and gain for most datasets except 
dataset D5; on the other hand, CloudRS algorithm has lower 
gain and sensitivity compared to other error correction 
programs. However, CloudRS algorithm has the highest 
specificity and precision for most of the datasets, and the the 
number of false positives of CloudRS algorithm is much less 
than other error correction programs. 
As discussed earlier, it is not entirely clear which statistics 
should be maximized in order to obtain good error correction. 
Since error correction of short read data is a preprocessing step 
for sequence assembly, we assess performance on the impact on 
sequence assembly for short read data. We choose Velvet [11], a 
most popular short read assembler, to run on the corrected read 
sets. 
We used the benchmarks of GAGE [16] to evaluate Velvet 
under 3 different assembly pipelines: (1) Velvet without error 
correction as preprocessing, (2) Velvet using Reptile as 
preprocessing and (3) Velvet using CloudRS algorithm as 
preprocessing. Table III show the results of these 3 assembly 
720
TABLE III. COMPARING ASSEMBLY PIPELINES ON DATASET D1-D6
 Dataset Assembly pipeline 
Number  
of contigs N50(bp) 
N50 
corr. (bp)
 Indel 
> 5bp Misjoins
 D1  
None+Velvet 515 15640 15413 2 17 
Reptile+Velvet 536 15554 13382 11 53 
CloudRS+Velvet 489 15926 15628 3 5 
D2 
None+Velvet 546 15661 15562 1 14 
Reptile+Velvet 546 15661 15562 1 14 
CloudRS+Velvet 458 17794 17761 0 19 
D3 
None+Velvet 275 35173 33558 3 7 
Reptile+Velvet 275 35173 33558 3 7 
CloudRS+Velvet 167 76845 60651 2 8 
D4 
None+Velvet 359 18646 17096 0 15 
Reptile+Velvet 359 18646 17096 0 15 
CloudRS+Velvet 220 31072 30625 0 17 
D5 
None+Velvet 5300 3401 3016 503 98 
Reptile+Velvet 5300 3401 3016 503 98 
CloudRS+Velvet 5230 3472 3054 518 72 
D6 
None+Velvet 267 32066 16037 113 8 
Reptile+Velvet 267 32066 16037 113 8 
CloudRS+Velvet 201 35939 18310 108 9 
 
 
Figure 5.  Runtime profile of CloudRS algorithm on dataset D6. 
pipelines on dataset D1-D6. From Table III, we observe that 
using CloudRS algorithm achieves a positive effect on the 
assembly results for all the datasets. For dataset D3 and D4, the 
corrected N50 value is about 90% higher than the values by the 
other two pipelines. Note that corrected N50 size of contigs is a 
key dimension to judge assembly results and it  is computed 
based on corrected contigs that have no misjoints or indels > 
5bp [16]. On the other hand, the reads corrected by Reptile 
cannot be combined into longer contigs for all datasets and the 
corrected N50 drops by about 13% for dataset D1. Note that 
contigs assembled by Velvet using Reptile as preprocessing has 
the same corrected N50 with contigs assembled by Velvet 
without error correction on datasets D2-D6. This phenomenon 
may be due to the error correction mechanism built in Velvet 
have very similar functionality as the mechanism of Reptile.  
Combining Table II, the experiments show that a critical 
factor to induce more successful assemblies is a low false 
positive rate, where false positive rate can be acquired by 1 
minus precision. This may be caused by the fragile nature of 
low coverage areas in the sequencing data towards error 
correction. An overly ambitious tool can easily identify these 
areas as erroneous and ‘correct’ them towards something similar 
and more prevalent in the data, making them unavailable for the 
assembly tool [3]. In addition, similar results are obtained after 
we replace Velvet by CloudBrush assembler [12] to do the 
experiment in Table III.  
C. Efficiency evaluation 
To evaluate the efficiency of our approach, we performed 
CloudRS algorithm on 5 different sizes of Hadoop clusters 
using machines leased from the Amazon Elastic MapReduce. 
The 5 clusters consisted of 5, 10, 20, 40 and 80 instances, 
respectively. The spec of instance is M1 Extra Large which had 
8 compute unit and 15 GB of RAM. We used the Dataset D7 as 
the benchmark to analyze the runtime of CloudRS algorithm. 
From Figure 5, we observed that the PreCorrect and FindError 
are the primary computation bottleneck of CloudRS algorithm. 
However, with an increase in the number of nodes, the 
computation time of PreCorrect and FindError decreases 
substantially, while the runtime of Screening decreases only 
slightly. In contrast, we use the same data set to evaluate error 
correction model of ALLPATHS-LG [13] (standalone version 
of RS algorithm). ALLPATHS-LG failed to work on the single 
machine which has 16 GB RAM and two 4-core CPUs due to 
memory thrashing. By increasing memory size to 64GB, it takes 
7457 seconds. The experiment shows that ALLPATHS-LG 
requires large physical memory to avoid running into memory 
thrashing. On the other hand, using CloudRS algorithm, we may 
dynamically allocate more computing units to deal with the 
additional memory requirements.  
IV. DISCUSSIONS 
In this section, we will illustrate a major performance 
bottlenecks in CloudRS algorithm. It originates mainly from 
the amount of intermediate data associated with each k-mer 
on the reads processed by the mappers of recommendation 
phase. These intermediate data then become communication 
cost in the shuffle and sort stage. The intermediate data are 
usually much large than original input data especially for 
long reads. For example, using a 10 node cluster to deal with 
the read data with 150 bp length, each node in the reducer 
will receive intermediate data that is over 10 times bigger 
than original input. The reason is that the sliding k-mer 
window is fixed size (24-mer), it will generate the 
intermediate data whose size is about (150-24+1) * (original 
input size) by sliding the 24 mer window on the 150bp reads, 
and the intermediate data spread out on the 10 nodes; 
therefore each node receive data about 10 times bigger than 
original input. 
To deal with such circumstance, one alternative approach 
is to store original input to the distributed cache. With the 
original input as reference, no additional information is 
needed in the posting except the read id; this strategy 
significantly decreases the size of intermediate data. 
However, this strategy will cause the issue of random disk 
seek: as for each read content, we must look up the original 
input with read id to obtain the sequence and quality value. 
Looking up original input implies random disk seeks, since 
for the most original input is too large to fit into memory. It 
721
like a tradeoff between communication cost and cost of 
random disk seeking, and the interfering factor includes size 
of original input, length of reads and size of cluster. 
V. CONCLUSION 
Error correction is an important step to reduce 
sequencing errors and thus to provide more accurate 
sequencing reads for downstream bioinformatics analyses. 
Our experiments show that false positive of an error 
correction method introduced as a result of acting too 
aggressively in judging whether a sequencing error occurs at 
a specific position of a specific read might create the 
negative impact the downstream analyses, e.g., de novo 
genome assembly. It is shown that using the error-corrected 
sequencing data of CloudRS algorithm as input to the de 
novo genome assemblers Velvet and CloudBrush indeed 
yields contigs with good performance indices. As shown in 
Tables II-IV in Results, superior performance in both 
specificity and precision of CloudRS algorithm is the key to 
better genome assemblies, despite the strategy sacrificed the 
sensitivity for partial datasets. Another challenge for error 
correction methods is the ability to handle the explosive 
growth of next-generation sequencing data. The proposed 
CloudRS algorithm for error correction meets the 
aforementioned demands. 
In addition, CloudRS algorithm is designed based on 
MapReduce framework to utilize the widely available cloud 
computing and Hadoop/Mapreduce services. This strategy 
allows users of CloudRS to flexibly acquire resources of 
computing power, physical memory and disk space based on 
the size of their input data. This is especially important for 
big sequencing data today, e.g., Illumina HiSeq2500 
sequencer is able to generate 600Gbp per run. That is, 1.2 
tera bytes of DNA sequences and quality values will be the 
input of error correction algorithms. As shown in Figure 5 in 
Results, CloudRS algorithm provides a scalable way to speed 
up error correction for dataset D6 in MapReduce framework. 
In summary, the feature of minimizing false positives of 
error correction as shown in CloudRS algorithm is important 
to avoid error propagation to downstream bioinformatics 
analysis, such as de novo geonome assembly. The 
MapReduce design of CloudRS algorithm is able to gain 
speed-ups for big NGS data via low-cost on-demand cloud 
computing services. Despite of these achievements, there 
still several performance bottlenecks in CloudRS algorithm 
which we believe might be further improved in the future. 
We are also interested in finding more applications of the 
map-reduce techniques that we developed in designing the 
CloudRS algorithm, such as sequence assembly. 
ACKNOWLEDGMENT 
The authors wish to thank anonymous reviewers for their 
helpful suggestions, and thank Dr. Wen-Liang Hsu and Dr. Chung-
 Yen Lin for their valuable discussions and comments. They wish to 
thank Chunghwa Telecom Co. and National Communication 
Project of Taiwan for providing the cloud computing resources. The 
research is partially supported by National Science Council under 
grant NSC 102-2221-E-001-013-MY3.  
REFERENCES 
 
[1] L. D. Stein, “The case for cloud computing in genome informatics,” 
Genome Biology, vol. 11, no. 5, p. 207, 2010. 
[2] X. Yang, S. P. Chockalingam, and S. Aluru, “A survey of error-
 correction methods for next-generation sequencing,” Brief Bioinform, 
Apr. 2012. 
[3] L. Salmela and J. Schröder, “Correcting errors in short reads by 
multiple alignments,” Bioinformatics, vol. 27, no. 11, pp. 1455–1461, 
Jan. 2011. 
[4] W.-C. Kao, A. H. Chan, and Y. S. Song, “ECHO: a reference-free 
short-read error correction algorithm,” Genome Res., vol. 21, no. 7, 
pp. 1181–1192, Jul. 2011. 
[5] M. Chaisson, P. Pevzner, and H. Tang, “Fragment assembly with 
short reads,” Bioinformatics, vol. 20, no. 13, pp. 2067–2074, Jan. 
2004. 
[6] D. R. Kelley, M. C. Schatz, and S. L. Salzberg, “Quake: quality-
 aware detection and correction of sequencing errors,” Genome 
Biology, vol. 11, no. 11, p. R116, Nov. 2010. 
[7] X. Yang, K. S. Dorman, and S. Aluru, “Reptile: representative tiling 
for short read error correction,” Bioinformatics, vol. 26, no. 20, pp. 
2526–2533, Oct. 2010. 
[8] P. Medvedev, E. Scott, B. Kakaradov, and P. Pevzner, “Error 
correction of high-throughput sequencing datasets with non-uniform 
coverage,” Bioinformatics, vol. 27, no. 13, pp. i137–i141, Jan. 2011. 
[9] J. Schröder, H. Schröder, S. J. Puglisi, R. Sinha, and B. Schmidt, 
“SHREC: a short-read error correction method,” Bioinformatics, vol. 
25, no. 17, pp. 2157–2163, Sep. 2009. 
[10]  L. Ilie, F. Fazayeli, and S. Ilie, “HiTEC: accurate error correction in 
high-throughput sequencing data,” Bioinformatics, vol. 27, no. 3, pp. 
295–302, Feb. 2011. 
[11] D. R. Zerbino and E. Birney, “Velvet: algorithms for de novo short 
read assembly using de Bruijn graphs,” Genome research, vol. 18, no. 
5, p. 821, 2008. 
[12] Y.-J. Chang, C.-C. Chen, C.-L. Chen, and J.-M. Ho, “A de novo next 
generation genomic sequence assembler based on string graph and 
MapReduce cloud computing framework,” BMC Genomics, vol. 13, 
no. Suppl 7, p. S28, Dec. 2012. 
[13] S. Gnerre, I. MacCallum, D. Przybylski, F. J. Ribeiro, J. N. Burton, B. 
J. Walker, T. Sharpe, G. Hall, T. P. Shea, S. Sykes, A. M. Berlin, D. 
Aird, M. Costello, R. Daza, L. Williams, R. Nicol, A. Gnirke, C. 
Nusbaum, E. S. Lander, and D. B. Jaffe, “High-quality draft 
assemblies of mammalian genomes from massively parallel sequence 
data,” PNAS, vol. 108, no. 4, pp. 1513–1518, Jan. 2011. 
[14] J. Dean and S. Ghemawat, “MapReduce: simplified data processing 
on large clusters,” Commun. ACM, vol. 51, no. 1, pp. 107–113, Jan. 
2008. 
[15] “Welcome to ApacheTM HadoopTM!” [Online]. Available: 
http://hadoop.apache.org/. 
[16] S. L. Salzberg, A. M. Phillippy, A. Zimin, D. Puiu, T. Magoc, S. 
Koren, T. J. Treangen, M. C. Schatz, A. L. Delcher, M. Roberts, G. 
Marçais, M. Pop, and J. A. Yorke, “GAGE: A Critical Evaluation of 
Genome Assemblies and Assembly Algorithms,” Genome Res., vol. 
22, no. 3, pp. 557–567, Jan. 2012. 
[17] J. D. Ullman, “Designing good MapReduce algorithms,” XRDS, vol. 
19, no. 1, pp. 30–34, Sep. 2012. 
[18] L. Salmela, “Correction of sequencing errors in a mixed set of reads,” 
Bioinformatics, vol. 26, no. 10, pp. 1284–1290, May 2010. 
[19] R. Li, H. Zhu, J. Ruan, W. Qian, X. Fang, Z. Shi, Y. Li, S. Li, G. 
Shan, K. Kristiansen, S. Li, H. Yang, J. Wang, and J. Wang, “De 
novo assembly of human genomes with massively parallel short read 
sequencing,” Genome Res., Dec. 2009. 
 
 
722
