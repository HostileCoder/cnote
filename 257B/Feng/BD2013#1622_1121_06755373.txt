OAMS: A Highly Reliable Metadata Service for Big Data Storage
 Jiang Zhou
 Computer Application Research Center,
 Institute of Computing Technology, Chinese Academy
 of Sciences
 Graduate University of Chinese Academy of Sciences
 Beijing, China
 zhoujiang@ncic.ac.cn
 Weiping Wang
 Institute of Information Engineering, Chinese Academy
 of Sciences
 Beijing, China
 wangweiping@iie.ac.cn
 Xiaoyan Gu
 Computer Application Research Center,
 Institute of Computing Technology, Chinese Academy
 of Sciences
 Graduate University of Chinese Academy of Sciences
 Beijing, China
 guxiaoyan@ncic.ac.cn
 Jing Guo
 National Computer Network Emergency Response
 Technical Team,
 Coordination Center of China
 Beijing, China
 guoj0000@126.com
 Cuilan Du
 National Computer Network Emergency Response
 Technical Team,
 Coordination Center of China
 Beijing, China
 dcl@isc.org.cn
 Dan Meng
 Institute of Information Engineering, Chinese Academy
 of Sciences
 Beijing, China
 md@iie.ac.cn
 Abstract—As application requirements increase in quantity
 and popularity, big data storage is becoming an important
 technology which data centers and Internet companies de-
 pend on. The cluster file system with centralized metadata
 management often encounters planned or unplanned down-
 time which requires higher reliability for metadata service.
 Current paradigms use the backup server to take over as
 the primary when the latter is in the case of failures. But
 if the backup crashes, the file system is still in an unreliable
 state. In this paper, we present a novel primary-backup policy
 (OAMS), which ensures the availability of metadata service
 in cluster file system. Different from traditional paradigms,
 OAMS employs multiple standbys to tolerate the single point
 of failure. It is based on the built-in shared storage pool for
 metadata synchronization and a series of protocols for active
 election, active-standby switching and etc. By using a prepared,
 automatic state transition among metadata servers, OAMS
 achieves an automatic recovery in the form of hot standby.
 It also supports server self-recovery and dynamical addition
 for standbys at runtime. Evaluation results show that OAMS
 obviously improves the reliability of metadata service while the
 average performance degradation is below 8%.
 Keywords-big data; cluster file system; metadata service;
 high reliability; primary-backup paradigm
 I. INTRODUCTION
 With the expansion of information scale and emergence
 of massive semi-structured or unstructured data, the big data
 period is coming. Applications [1][2] in data centers and
 Internet companies are diversified greatly and often need
 24x7 hours service which requires higher reliability. The
 cluster file system acting as the underlying storage for big
 data analysis and processing faces new challenges. Current
 distributed file system usually adopts a centralized metadata
 management policy. That is, the metadata server manages
 files and directories of the whole file system and responds
 to client requests. For example, GFS [3] uses the master
 to manage namespace of the cluster and provide metadata
 service. HDFS [4] adopts the similar idea and the namenode
 is also a single server. As a big data cluster often encounters
 planned or unplanned downtime which may be caused by
 software upgrade, system configuration and hardware fail-
 ures, the design of centralized metadata management easily
 leads to the single point of failure: once the master crashes,
 the file system will be unavailable. To solve this problem,
 the primary-backup paradigm is currently widely used to
 improve the reliability of metadata service. In this paradigm,
 the backup server takes over as the primary and continues
 2013 IEEE 16th International Conference on Computational Science and Engineering
 978-0-7695-5096-1/13 $31.00 © 2013 IEEE
 DOI 10.1109/CSE.2013.191
 1287
to provide service when the latter encounters failures. It
 tolerates the single point of failure and needs no complicated
 state transition between metadata servers. However, as the
 primary-backup paradigm relies heavily on the backup it
 could lead to another single point of failure. If the backup
 crashes, the primary is still in an unreliable state.
 There are many methods used for the primary-backup
 paradigm. According to the backup mode, it is divided
 into active-standby and cluster manner. The paradigm can
 be classified into three categories denoted as cold standby,
 warm standby and hot standby with the recovery method. It
 is also defined as manual and automatic mode according to
 the switching pattern. When switching from the primary to
 the backup, it needs to keep consistent namespace states
 between them. Traditional log file systems [5] combine
 transaction processing [6] with failover technology to re-
 cover metadata information. They adopt write-ahead logs
 to record metadata operations to local disks firstly and
 then execute them in memory. If the system crashes or
 restarts, it can recover namespace state by reading and
 redoing logs. Namespace consistency of the primary-backup
 paradigm depends on log technology. During running, the
 backup synchronizes metadata operations from the primary
 and commits them in its own namespace. With this approach,
 the backup keeps an up-to-date namespace image with
 the primary and takes over the service of it in the case
 of failures. As the backup needs to synchronize metadata
 information from the primary, the method can be divided
 into two ways: metadata replication and shared storage.
 BackupNode [4] in HDFS is a simple reliable feature.
 The backup is a wrapper of the regular namenode instance
 which implements metadata replication of the primary. It
 keeps an up-to-date namespace image with the primary
 but does not provide service. Once the primary crashes, a
 failover procedure will be done with the manual pattern.
 BackupNode uses replication mechanism to synchronize
 metadata information. When the primary stores log records
 to local disk it flushes them to the backup simultaneously.
 Due to various errors in the cluster, the backup may lose
 metadata modifications and cannot synchronize with the
 primary in time. And BackupNode takes a long time for
 recovery as it needs to reconstruct file locations for failover.
 Yahoo! combines BackupNode with Linux tools to
 achieve active-standby switching. It uses double network
 interface cards for failure detection and DRBD [7] for
 metadata synchronization. Yahoo! uses the shared storage
 to keep metadata consistency between the primary and the
 backup. With this approach it needs additional facility and
 has the risk of conflict for concurrent access.
 AvatarNode [8] at Facebook is designed for a realtime
 HDFS that supports online applications. There are two
 AvatarNodes in the cluster: one providing service as the
 active while the other working as a standby. AvatarNode uses
 NFS [9] to store one copy of the filesystem image and one
 copy of the transaction log. Metadata operations are written
 by the active in NFS and read by the standby simultaneously.
 AvatarNode acts as a hot standby because datanodes report
 block locations to both the active and standby. However,
 AvatarNode depends on NFS and has the problem of IO
 fencing when sharing transaction logs. The implementation
 in Cloudera [10] is similar to AvatarNode which avoids
 the risk of concurrent access. It employs additional tools
 to prevent the isolated sever from writing shared metadata
 logs.
 Hadoop [11] HA Branch uses NFS or the quorum journal
 manager (QJM) for synchronizing metadata information.
 The further step is to use BookKeeper [12] as the sharing
 logging service. Though HA Branch achieves automatic
 active-standby switching to some extent, the reliability will
 be greatly reduced if the standby crashes. And it increases
 the complexity of file system with third-party software
 support. PacaficA [13], HARP [14] and Echo [15] imple-
 ment storage systems based on log technology. By defining
 different replication strategies, they ensure metadata consis-
 tency when recovery. However, these systems are key-value
 storages and cannot satisfy sophisticated operation semantics
 of file system. Table I compares different primary-backup
 paradigms for metadata server.
 Different from above paradigms, we propose a novel
 primary-backup policy called one active multiple standbys
 (OAMS) to achieve the availability of metadata service
 in cluster file system. With a series of protocols, OAMS
 tolerates multiple points of failures and achieves an auto-
 matic switching in the form of hot standby. It is based on
 the built-in shared storage pool to synchronize metadata
 operations. Besides, OAMS supports server self-recovery
 and dynamical addition for standbys at runtime. Theoretical
 analysis [16] proves that the reliability of metadata service
 can be improved by 3 to 4 orders of magnitude comparing
 to traditional primary-backup paradigms. Performance re-
 sults show that OAMS can achieve active-standby switching
 within several seconds while keeping high performance for
 metadata operations.
 The remainder of this paper is organized as follows.
 Section II introduces system model of our primary-backup
 paradigm. Section III describes the OAMS policy and its
 three protocols. In section IV, we evaluate the reliability and
 performance of OAMS and compare it with other paradigms.
 We conclude the paper in Section V.
 II. SYSTEM MODEL
 Our policy is deployed in a cluster file system with
 centralized metadata management, which employs one meta-
 data server as the active and multiple servers as standbys.
 They are connected by high speed network and constitute a
 primary-backup cluster. Besides providing metadata service,
 the active and standby are also treated as storage nodes for
 1288
Table I
 PRIMARY-BACKUP PARADIGMS FOR METADATA SERVER
 Paradigm Recovery method Switching pattern Metadata synchronization
 BackupNode Warm standby Manual Replication
 Yahoo! Warm standby Manual or automatic Shared storage
 AvatarNode Hot standby Manual Shared storage
 Cloudera Hot standby Manual Shared storage
 Hadoop HA Hot standby Manual or automatic Replication or shared storage
 a shared storage pool. The pool is a built-in virtual storage
 which is used for metadata synchronization and persistence.
 Fig. 1 depicts the system model of the primary-backup
 cluster, which comprises one active and two standbys.
 OAMS acts as a highly reliable backup policy to ensure the
 availability of metadata service in cluster file system. Under
 failure free cases, the active responds to client requests
 and provides file system service. When the active modifies
 metadata information and updates namespace, it writes logs
 to local disk and flushes them to standbys through the
 shared storage pool. Standbys receive metadata operations
 and apply them in memory simultaneously. They keep up-
 to-date namespace states with the primary but do not provide
 metadata service. Namespace image can also be persistent
 in the shared storage pool for failover after the metadata
 server restarts. With the heartbeat mechanism, a monitor
 is used to detect the system status in the primary-backup
 cluster. If the active crashes, one standby is elected as the
 new active and takes over its service. To reach a consensus,
 the Paxos protocol [17] is used for active election among
 multiple standbys and to prevent the so-called split-brain
 scenario. After active-standby switching, the client connects
 to the new active for fault tolerance and resends metadata
 requests. The new active receives metadata operations and
 continues file system service. The role of active and standby
 can be assigned from configuration when starting up. At any
 time, there is only one metadata server which is in the active
 state. As metadata and data management are decoupled in
 the cluster file system, file contents are split into large blocks
 and replicated in datanodes. For constructing file locations,
 datanodes talk to both the active and standbys. By using a
 prepared, automatic state transition among metadata servers,
 OAMS achieves an automatic recovery in the form of hot
 standby.
 III. OAMS POLICY
 In contrast to traditional primary-backup paradigms,
 OAMS employs multiple standbys for the active to tolerate
 failures in cluster file system. It provides a highly reliable
 metadata service with each server acting as different roles.
 A global view is cached to maintain states of the active
 and standbys. Combined with the shared storage pool and
 Paxos protocol, OAMS processes metadata synchronization,
 active election and active-standby switching. It includes
  	
 	

 	
 	 
 Heartbeat Heartbeat Heartbeat
 	
 Active electionConfiguration Active-standby
 switching
 Figure 1. System Model of the primary-backup cluster
 three protocols to achieve an automatic recovery in the case
 of failures.
 A. Synchronization Protocol
 When using multiple standbys for backup of the active,
 it needs to synchronize metadata operations among them.
 Synchronization protocol is a replication method which
 transmits journal streams from the active to standbys. Based
 on the shared storage pool, a distributed protocol similar
 to the two-phase commit protocol (2PC) [18] is applied in
 OAMS to provide namespace consistency.
 2PC protocol is a simple and popular atomic commitment
 protocol for distributed transaction. It is divided into two
 phases which is called preparation phase and commitment
 phase respectively. In the preparation phase, a role called the
 coordinator sends “prepare” messages to all participants to
 ask them whether they agree to commit it. Each participant
 checks its status and decides if it satisfies the condition.
 The coordinator waits and collects replies from participants
 in the second phase. When receiving all “ready” messages,
 it sends “commit” messages to participants for execution.
 After all participants have completed operations, they send
 ACK messages to the coordinator to finish the transaction. If
 some participants send “abort” messages, the transaction will
 be cancelled for all. During this process, logs are written in
 local disks for recovery. 2PC protocol achieves consistency
 1289
of transaction but the state is still indeterminable if there are
 failures in the commitment phase. The process of metadata
 synchronization using 2PC is depicted in Fig. 2a.
 In OAMS, standbys need to synchronize metadata opera-
 tions from the active to keep an up-to-date namespace with
 it. This can be regarded as a transaction because it may result
 in inconsistent server states if errors occur. Inspiring by 2PC,
 OAMS presents a synchronization protocol which reduces
 the overhead of replication and achieves namespace consis-
 tency among the active and standbys. For comparison, the
 protocol in OAMS is depicted in Fig. 2b. The key idea here
 is to combine the shared storage pool with the global log to
 reduce the processing latency. After the coordinator decides
 committing or aborting the transaction, it is unnecessary to
 wait for the operations of participants. The coordinator will
 respond to clients when it receives “ACK” messages from
 participants and write the global log.
 For the synchronization protocol, the active is seen as
 the coordinator and standbys as participants. A batch of
 metadata operations are buffered in the active and wait
 for being committed one time. When the active writes log
 records in local disk, it begins to flush them to standbys.
 The standby receives metadata journals and writes “prepare”
 logs in local disk. It then sends the “ACK” message to
 the active to continue these operations. When receiving
 all “ACK” messages from standbys, the active commits
 metadata modifications and writes a global log in the shared
 storage pool. If some standby does not respond after a
 timeout period, the active will cancel all operations and
 marks a tag in the global log. For 2PC protocol, it needs to
 notice all participants to commit or cancel operations before
 the active responds to clients. In OAMS, as the state of
 metadata operations has been stored in the shared storage
 pool, the active can return to clients immediately after it
 writes the global log. As the pool is a reliable virtual storage,
 the standby can decide whether to commit them from the
 global log even if it does not receive notice from the active.
 To finish the processing of synchronization, the active still
 sends “commit” or “abort” messages to participants. The
 participant completes subsequent operations and writes logs
 in local disk. The global log can also be used for recovery
 after the active or standby crash. With the synchronization
 protocol, OAMS ensures the consistency of namespace state
 among the active and standbys while not affecting the
 performance of metadata operations.
 B. Failover Protocol
 The failover protocol is used for fault tolerance when
 the active crashes. With the heartbeat mechanism, OAMS
 monitors server status in the primary-backup cluster. If the
 active crashes, a new one will be elected from standbys
 and takes over the metadata service of it. Combined with
 Paxos protocol for election, OAMS reaches a consensus for
 choosing the new active among servers. With more than one
 

 
	
  9	:
 
 

 9	:	
 	
 		

 

 	
 
  9: 
 9	: 
 
 9: 
 9	:
 

  
 	
  9	:
 
 	
 
 

 
 
 

  9
:
 
 	  !	  "#
 

 
 	

 
 	

 

 
	
   
 	
 $
 	
 

 		

 
 9	:
 
 	 $
 
 
 

 	
 

 

  % 

&	
 
 
 '(
  
 	
 
 9: 
 9	:
 

 9	:	
  	  

 	 	 
 
 
 	

 
 	

 Figure 2. Metadata synchronization protocol
 standby for backup, server state transition is more compli-
 cated than that of traditional primary-backup paradigm.
 In OAMS, the metadata server starts up in different states
 with the configuration. A global view is cached to maintain
 the address and state of each server. It is modified by the
 active dynamically and stored in the shared storage pool
 periodically. The active and standby add event triggers in the
 view which will result in state transition when failures are
 detected by the monitor. In the failover protocol, the state of
 server is classified into three types which are active, standby
 and junior. The active is the master server which provides
 metadata service for cluster file system. During running,
 only one active is allowed in the primary-backup cluster
 while others are in standby or junior states. The standby
 keeps an up-to-date namespace with the active and takes
 over as it when necessary. The synchronization protocol
 contributes to metadata consistency between the active and
 standby. The junior is in an intermediate status which has a
 large gap in namespace state comparing to the active. It may
 be a server which restarts after a short time or is a newly
 added backup node. The junior needs to learn and download
 metadata information from the active for synchronization. It
 will become standby through the renewing protocol (see Sec-
 tion III (C)) at appropriate time. Under different conditions,
 the state of server will be switched to each other for fault
 tolerance.
 Fig. 3 depicts the transition among three states. Metadata
 synchronization and junior renewing are based on the shared
 storage pool. The solid lines depict server state transition
 with the failover protocol. Under failure free cases, there
 are one active and multiple standbys in the primary-backup
 cluster. OAMS monitors the cluster and judges the server
 failed when not receiving heartbeats from it after a timeout
 1290
period. If the active crashes, OAMS starts the process of
 active election. With the Paxos protocol, one is selected as
 the new active among multiple standbys. When reaching a
 consensus, the candidate active enters a stage of upgrading.
 It firstly stops receiving new metadata modifications and
 waits for current operations to be finished. The candidate
 active also visits the global view and checks its state. If
 the standby is in a junior state, it must stop upgrading
 and needs the protocol to reselect active. After committing
 latest logs in memory, the candidate active updates server
 states in the global view. It changes the state of old active
 to standby and set itself to active. The modifications of
 the global view will trigger events which inform others
 to process state transition. To avoid missing operations,
 the candidate active then flushes last batch of metadata
 modifications to others with synchronization protocol. As
 the old active may become standby and receive these logs
 again, it needs to distinguish duplicated operations. OAMS
 assigns a monotone increasing serial number for each batch
 of metadata operations. The standby will decide whether
 to commit logs by comparing values of serial numbers.
 Only if the value from the candidate active is larger than
 current serial number, the standby applies logs to its own
 memory. After the candidate active synchronizes metadata
 modifications to standbys, it receives register information
 from all servers in the primary-backup cluster. When more
 than one standby is registered successfully, the candidate
 active begins receiving new client requests and providing
 metadata service. During the process of state transition, the
 candidate active will stop upgrading if any failures occur.
 It will launch the reelection process with failover protocol
 at this time. Due to block reports from datanodes, the new
 active keeps the same up-to-date file locations as namespace
 state. It can take over the metadata service and ensure
 a hot standby. After active-standby switching, the client
 reconnects to the new active and resends metadata requests
 to it. As the process is completely transparent to upper
 applications, the cluster file system seems to work well when
 failures occur.
 C. Renewing Protocol
 Once the active is detected failures during running, it will
 be degraded to standby and not provide metadata service.
 If there are fatal errors, such as disk faults, the active will
 be directly switched to junior state. Or the namespace state
 of the standby is not up-to-date comparing to the active,
 it is degraded to junior. The junior is in an intermediate
 status which cannot provide backup service. As the active
 does not synchronize logs to the junior, there is a large gap
 in namespace states between them. With the reduction of
 standbys, the cluster file system will turn into an unreliable
 status. To avoid this risk, OAMS adopts the renewing
 protocol to switch the junior to standby. It also supports
 dynamical adding standbys at runtime which improves the
  	
 #	
  	

 )#

 *	
 *	
 	
 	 
 

&+ 	 
 *	
 
" ,	
 

 -#
 	.	 "
 Figure 3. Server state transition in failover protocol
 availability of metadata service.
 When the active or standby is degraded to junior state, it
 enters the state of renewing. The active decides the renewing
 strategy according to the value of serial number from the
 junior. If the subtraction between them is large, the protocol
 firstly launches a process of image recovery. Otherwise, the
 active flushes missing metadata modifications to the junior.
 As the namespace image is stored in the shared storage
 pool, the junior can obtain it directly from the pool and
 reduce the cost of downloading. In the course of reading
 image, the junior applies metadata operations in memory
 and reaches a consistent state with the active gradually. After
 loading namespace image, the protocol starts the procedure
 of synchronization. At this moment, the active commits
 current metadata operations and then stops metadata service
 temporarily. It flushes missing logs to the junior and waits
 for it to reach the same state. Once the junior recovers all
 metadata operations, the active modifies the global view and
 changes its state to standby. Then the junior is upgraded and
 keeps an up-to-date namespace state with the active for a hot
 standby. With this protocol, the server can be newly added
 dynamically and is switched to standby finally. It contributes
 to tolerate multiple points of failures in some scenarios such
 as the standby crashes.
 A server which acts as the junior when starting up
 will register in the active. The active verifies its state and
 upgrades it to standby with the renewing protocol. It also
 watches the global view periodically to check server states
 in the primary-backup cluster. When the server is degraded
 to junior, the active launches the process of renewing. As
 OAMS uses the cluster mode for fault tolerance, there may
 be multiple juniors in some cases. The active compares
 values of serial numbers and selects one whose namespace
 state differs less with it. At the same time there is only one
 junior which is being renewed. If there are failures occur
 during the process, the junior will give up and waits for
 appropriate time to upgrade. To parallel execution, the active
 1291
launches the separate thread for junior renewing. Based on
 the shared storage pool, most of metadata operations can be
 recovered from the image and it has little effects on metadata
 service of the active.
 With upper protocols, OAMS achieves server state transi-
 tion among three types under different conditions. It ensures
 that there always exists one metadata server which is in the
 active state and provides metadata service whenever failures
 occur.
 IV. PERFORMANCE EVALUATION
 To provide a proof of concept, we evaluated a prototype
 implementation of OAMS. As HDFS is a typical distributed
 file system which meets the needs of big data storage
 and supports practical applications such as Hadoop, we
 implements the policy based on it. For failure detection
 and active election, ZooKeeper [19] is used to maintain
 small amounts of coordination data, trigger of event changes
 in the global view and monitor metadata servers. During
 evaluation, we compare OMAS with three paradigms: Back-
 upNode, Hadoop HA with NFS and Hadoop HA using the
 quorum journal manager (QJM). They are all high available
 solutions for HDFS. BackupNode is a warm standby with the
 manual mode while the latter two can achieve an automatic
 hot standby. All of them use one backup server to provide
 failover for the active in the case of failures.
 Experiments are running on a cluster with five machines.
 Each node consists of four Intel Xeon X3320 processors, 8-
 Gbyte memory and 1-Tbyte Seagate disk. All have Linux
 kernel 2.6.32 installed on them and are connected with
 gigabit Ethernet. The configuration of OAMS is one active
 and two standbys. They also constitute the shared storage
 pool as storage nodes. BackupNode and Hadoop HA with
 NFS are deployed with one active and one standby. NFS
 is as a remote filer and mounted on each of the namenode
 machines. For Hadoop HA with QJM, the primary-backup
 configuration is the same as above two while using addition-
 al three journalnode machines for sharing logs. Five nodes
 act as datanodes in all paradigms. Except for BackupNode,
 they reports block locations to both the active and standbys
 for hot standby.
 The evaluation firstly tests failover time with different
 paradigms. To verify automatic recovery, failures are caused
 on the cluster file system to simulate different kinds of
 outage, such as killing the process, powering cycle the
 machine and unplugging the network interface. Time is
 measured for recovering metadata service in the case of
 failures. The second set of test measures the performance
 comparison among OAMS and traditional primary-backup
 paradigms. For a more detailed explanation, we write special
 programs to request various metadata operations, such as
 create, getfileinfo, delete and etc., with one or more clients.
 The evaluation is performed under both failure and failure
 free cases. Finally, an overall measurement is done to prove
 the high improvement on reliability and little effects on
 performance with OAMS in standard applications.
 A. Failover Time
 This experiment measures the ability of fault tolerance
 with different primary-backup paradigms in the case of
 failures. We compute average failover time on servers for ten
 times when the active crashes. After triggering the outage,
 the standby takes over as the active and continues to provide
 metadata service. As BackupNode is a warm standby with
 the manual mode, its results do not include the time spend
 on switching. The amount of time requires to detect a failure
 in ZooKeeper is heartbeat interval and session timeout, with
 the values of 2 seconds and 5 seconds respectively.
 Table II presents failover time comparing OAMS with
 traditional primary-backup paradigms. The size of image file
 indicates the amount of metadata operations in namespace
 which varies from 16MB to 1GB. With the growth of it,
 the failover time of BackupNode is increased. It is because
 BackNode does not involve modifications of the knowledge
 about file block locations and needs to reconstruct this
 information. For OAMS and Hadoop HA, there is a fast
 recovery as datannodes talk to both the active and standby.
 The failover time depends on two issues. One is the time
 it takes for the paradigm to detect a failure, which is
 directly related to the heartbeat interval for monitor. The
 other is the cost for switching which includes active election,
 log synchronization and state transition. Due to different
 approaches for sharing logs, the failover time of Hadoop
 HA with NFS is longer than that with QJM. Comparing
 with Hadoop HA, OAMS spends less time on recovery.
 The combination of synchronization protocol with the built-
 in shared storage pool and maintaining of global view in
 OAMS has an effect in this case. It demonstrates that OAMS
 can achieve a faster recovery than others.
 B. Performance Overhead
 To compare performance overhead, the evaluation is per-
 formed under both failure and failure free cases. Test pro-
 grams are written to produce continuous load for metadata
 operations. The results of HDFS represent the baseline and
 does not involve in any failures. Outage is triggered one time
 to make the active crash for failure test.
 Fig. 4 presents the average performance of different
 paradigms in failure free cases. The evaluation varies the
 number of clients from 1 to 16 on multiple nodes to perform
 mixed metadata operations, including create, getfileinfo and
 etc. Each client finishes 100 kilo operations for computing
 the average value. With the increase of clients, the per-
 formance is improved as the concurrent processing ability
 of metadata server. Comparing to HDFS, performance of
 primary-backup paradigms is respectively worse than the
 former. This is due to the overhead of synchronizing logs
 between the active and standby. BackupNode shows better
 1292
Table II
 FAILOVER TIME WITH DIFFERENT PRIMARY-BACKUP PARADIGMS
 Size of Image File (MB) Failover Time (s)OAMS BackupNode HA with NFS HA with QJM
 16 0.762 2.586 8.395 5.375
 32 1.135 5.372 10.931 8.384
 64 2.416 9.541 11.834 7.533
 128 1.539 21.938 9.673 6.372
 256 2.394 38.346 10.817 8.081
 512 2.725 80.437 9.653 7.845
 1024 2.084 152.634 10.372 7.193
 values than others but it cannot meet the goal for hot standby
 and system reliability is lower. For OAMS, it shows an
 average decrease by 7.18% in terms of performance with
 regard to HDFS. The synchronization protocol based on the
 shared storage pool reduces the latency of log replication
 comparing to Hadoop HA.
 Fig. 5 shows the time spending on metadata operations
 in the case of failures. For each type, a total of 1 million
 operations are performed. Failures are caused one time by
 killing the active process during running except for HDFS.
 The failover time of BackupNode includes block reports
 and manual switching which are 8 seconds and 3 seconds
 respectively. As the primary directly flushes logs to the
 standby, it is intelligible that BackupNode needs less time
 for finishing operations than others. Comparing with Hadoop
 HA, OAMS achieves better performance with the profits
 varying from 2.15% to 42.68%. It proves the advantage of
 synchronization protocol and failover protocol in this policy.
 6
 6.5
 7
 7.5
 8
 8.5
 9
 9.5
 10
 /  0 1 2 3 4 5 6 /7 // / /0 /1 /2 /3
 Av
 er
 a
 ge
  M
 ix
 ed
  O
 pe
 ra
 tio
 ns
  P
 er
  
Se
 co
 nd
  
x103 
Number of Clients 
HDFS
 BackupNode
 OAMS
 HA with QJM
 HA with NFS
 Figure 4. Performance overhead under failure free cases
 C. Overall Measurement
 As OAMS is presented to improve the reliability of
 metadata service for big data storage, we launch standard
 applications to measure the overall performance. Evaluation
 is performed in the Hadoop platform which uses HDFS or
 primary-backup paradigms as underlying storage. Various
 MapReduce jobs are submitted to compare the performance
 0
 50
 100
 150
 200
 250
 300
 350
 	 8
8  $ 
	
 Ti
 m
 e S
 pe
 nt
  fo
 r O
 pe
 ra
 tio
 ns
  (s
 ) 
Metadata Operation 
HDFS
 OAMS
 BackupNode
 HA with NFS
 HA with QJM
 Figure 5. Performance overhead under failure cases
 in the case of failures. As BackupNode and Hadoop HA
 rely on one standby for fault tolerance, outage is triggered
 by making the active crash for one time. To OAMS, the test
 includes three types: (1) kill the active when there are one
 active and two standbys (1A2S); (2) kill one standby under
 upon conditions to generate one junior (1A1S1J); (3) firstly
 kill one active and then kill one standby which leads to two
 junior appear (1A2J).
 Fig. 6 presents the execution time ratio of OAMS and
 other paradigms comparing to HDFS in different scenarios.
 HDFS represents the baseline which is running in failure
 free cases. The negative value of ratios means that it needs
 more time to finish jobs for primary-backup paradigms. Log
 synchronization and active-standby switching constitute the
 reason. For OAMS, the metadata service is recovered and
 all jobs are completed finally under three tests. It proves
 that OAMS can tolerate multiple points of failures. The
 performance of OAMS with 1A1S1J differences little with
 that of 1A2S. This is because OAMS can provide metadata
 service as long as there are one active and one standby
 working. And the renewing protocol for switching from
 junior to standby is mostly performed in the background.
 Evaluation shows that it only costs 0.5 second to reach
 an up-to-date namespace state with the junior for 100 kilo
 operations. OAMS with 1A2J is in a state of read only and
 cannot respond to client requests, which is intelligible for the
 availability of cluster file system. It is worthy for this cost
 1293
since OAMS has highly improved the reliability of metadata
 service while having little effects on performance.
 -14.0%
 -12.0%
 -10.0%
 -8.0%
 -6.0%
 -4.0%
 -2.0%
 0.0%
 "#
    	
!
 "
 


 Ex
 ec
 u
 tio
 n
  T
 im
 e 
R
 at
 io
  o
 f P
 ri
 m
 a
 ry
 -
 ba
 ck
 u
 p 
Pa
 ra
 di
 gm
 s 
C
 om
 pa
 ri
 ng
  to
  H
 D
 FS
  
Mapreduce Jobs Running on OAMS and Others 
BackupNode
 HA with NFS
 HA with QJM
 OAMS with 1A2S
 OAMS with 1A1S1J
 OAMS with 1A2J
 Figure 6. Overall measurement
 V. CONCLUSION AND FUTURE WORK
 In this paper, a highly metadata service OAMS was
 proposed for big data storage. Different from traditional
 primary-backup paradigms, OAMS depends on more than
 one standby to take over the active in cluster file system.
 It is based on the built-in shared storage pool and employs
 a series of protocols to tolerate multiple points of failures.
 OAMS achieves an automatic state transition in the form
 of hot standby. Besides, it supports server self-recovery and
 dynamical addition for standbys at runtime. Measurements
 show that OAMS can obviously improve the system relia-
 bility while keeping the performance with little degradation.
 In the future, we intend to optimize and expand the policy,
 such as supporting failover in the cluster file system with
 multiple metadata servers.
 ACKNOWLEDGMENT
 This work is supported by the National High-Tech Re-
 search and Development Program of China under grant
 numbered 2011AA01A203, 2013AA013204, also supported
 by the National HeGaoJi Key Project under grant num-
 bered 2013ZX01039-002-001-001, and ”Strategic Priority
 Research Program” of the Chinese Academy of Sciences
 under grant numbered XDA06030200.
 REFERENCES
 [1] J. Dean and S. Ghemawat, “Mapreduce: Simplified data
 processing on large clusters,” in Sixth Symposium on Oper-
 ating System Design and Implementation, (OSDI ’04), San
 Francisco, USA, Dec. 2004, pp. 137–150.
 [2] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A.
 Wallach, M. Burrows, T. Chandra, A. Fikes, and R. E. Gruber,
 “Bigtable: A distributed storage system for structured data,”
 in Seventh Symposium on Operating System Design and
 Implementation, (OSDI ’06), Seattle, USA, Nov. 2006, pp.
 205–218.
 [3] S. Ghemawat, H. Gobioff, and S. T. Leung, “The Google file
 system,” in 19th Symposium on Operating Systems Principles,
 (SOSP ’03), New York, USA, Oct. 2003, pp. 29–43.
 [4] K. Shvachko, H. Kuang, S. Radia, and R. Chansler, “The
 Hadoop distributed file system,” in 26th IEEE Transactions
 on Computing Symposium on Mass Storage Systems and
 Technologies, Incline Village, USA, May 2010, pp. 1–10.
 [5] A. Barry, J. Brassow, R. Cattelan, A. Manthei, E. Nygaard,
 S. V. Oort, D. Teigland, M. Tilstra, M. OKeefe, G. Erickson,
 and M. Agarwal, “Implementing journaling in a Linux shared
 disk file system,” in Mass Storage Systems and Technologies
 in Cooperation with the 17th IEEE Symposium on Mass
 Storage Systems, Maryland, USA, Mar. 2000, pp. 351–378.
 [6] T. Haerder and A. Reuter, “Principles of transaction-oriented
 database recovery,” ACM Computing Surveys, vol. 15, no. 4,
 pp. 287–317, 1983.
 [7] F. Haas, P. Reisner, and L. Ellenberg, “The DRBD user’s
 guide,” LINBIT Information Technologies GmbH, 2009.
 [8] D. Borthakur, J. S. Sarma, J. Gray, K. Muthukkaruppan,
 N. Spiegelberg, H. Kuang, K. Ranganathan, D. Molkov,
 A. Menon, S. Rash, R. Schmidt, and A. Aiyer, “Apache
 Hadoop goes realtime at Facebook,” in Proc. of the 2011
 ACM SIGMOD International Conference on Management of
 data, Athens, Greece, Jun. 2011, pp. 1071–1080.
 [9] R. Sandberg, D. Goldberg, S. Kleiman, D. Walsh, and
 B. Lyon, “Design and implementation of the Sun network
 filesystem,” in Proc. of the Summer USENIX conference,
 Portland, USA, Jun. 1985, pp. 119–130.
 [10] Cloudera homepage. [Online]. Available:
 http://www.cloudera.com
 [11] Apache hadoop. [Online]. Available: http://hadoop.apache.org
 [12] Apache BookKeeper. [Online]. Available:
 http://zookeeper.apache.org/bookkeeper
 [13] W. Lin, M. Yang, L. Zhang, and L. Zhou, “Pacifica: Repli-
 cation in log-based distributed storage systems,” Technical
 Report MSR-TR-2008-25, Microsoft Research, Tech. Rep.,
 2008.
 [14] B. Liskov, S. Ghemawat, R. Gruber, P. Johnson, L. Shrira,
 and M. Williams, “Replication in the Harp file system,” in
 13th Symposium on Operating Systems Principles, California,
 USA, Oct. 1991, pp. 226–238.
 [15] G. Swart, A. Birrell, A. Hisgen, and T. Mann, “Availability in
 the Echo file system,” in Research report, Systems Research
 Center, Digital Equipment Corporation. Citeseer, 1993.
 [16] J. R. Norris, Markov Chains. Cambridge University Press,
 1998.
 [17] L. Lamport, “The part-time parliament,” Research Report 49,
 Systems Research Center, Digital Equipment Corporation,
 Tech. Rep., 1989.
 [18] M. T. ¨Ozsu and P. Valduriez, Principles of Distributed
 Database Systems. Springer, 2011.
 [19] Apache ZooKeeper. [Online]. Available:
 http://zookeeper.apache.org
 1294
