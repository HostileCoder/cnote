The Experience of NoSQL Database in 
Telecommunication Enterprise 
Tuncay Yigit 
Department of Computer Engineering 
Suleyman Demirel University 
Isparta, Turkey 
tuncayyigit@sdu.edu.tr 
 
Mehmet Akif Cakar 
Department of Computer Engineering 
Suleyman Demirel University 
Isparta, Turkey 
mehmetakif.cakar@petadata.com.tr 
 
Asim Sinan Yuksel 
Department of Computer Engineering 
Suleyman Demirel University 
Isparta, Turkey 
asimyuksel@sdu.edu.tr 
  
Abstract— The rapid evolution in communication technology 
facilitates the Internet access, and makes it faster and cheaper. 
The advancement of Internet accessibility changes the paradigm 
of application usage methodologies. As a result, data amount in 
application database reaches unprecedented sizes. The increase in 
the data amount and user load concretizes the scalability 
requirements for software components, especially for database 
technologies. This work aims to provide an example solution 
experienced in centralized enterprise application. We examine 
how NoSQL based document store can be adapted according to 
the requirements of telecommunication enterprise. 
Index Terms— Big Data, Cloud Computing Document Store, 
Telecommunication, NoSQL  
I. INTRODUCTION 
The rapid evolution in communication technology facilitates 
the Internet access, and makes it faster and cheaper. The 
advancement of Internet accessibility changes the paradigm of 
application usage methodologies. The new paradigm implies the 
access of massive number of users to the same cloud application. 
As a result, data amount in application database reaches 
unprecedented sizes. Data-incentive cloud applications also 
have to deal with millions of requests every day. Good examples 
of such cloud applications are social platforms like Linked-in 
and Facebook [1]. 
The increase in the data amount and user load concretizes the 
scalability requirements for software components, especially for 
database technologies. Among all software components, 
scalability in data layer has been a popular topic in research 
community. Most relational database management systems 
(RDBMS) are not at desired level [2] in terms of solving the 
problems against both the increase of data amount in services 
and the load intensity. It is seen that NoSQL databases have been 
popular among the solutions that meet the scalability needs and 
big data processing.  Database solutions such as Cassandra [3], 
CouchBase [4], CouchDB [5], Dynamo [6], BigTable [7], 
MangoDB [8] are successful examples of applications in terms 
of horizontal scalability. 
Telecommunication enterprise consists of both data and load 
insensitive applications. Telecommunication enterprise has to 
rely on centralized systems that comprises of several sub 
systems. This study describes the architectural process of a 
centralized telecommunication system in context of managing 
enterprise work force, customer requests, call management and 
decision support. 
II. SUB SYSTEMS 
Developed telecommunication application relies on the feed 
of six basic subsystems. The first system that is to be handled is 
work force management system. Work force management 
system stores its data on Microsoft SQL Server RDBMS. Data 
contains personnel’s daily shift plans, holidays, permits, health 
reports etc. Work Force Management (WFM) data tables contain 
millions of records. However, RDBMS is still suitable for this 
sub system since less than a hundred management staff actively 
uses it. 
Call management system uses hybrid storage solution to 
persist application data. Hybrid solution consists of file system 
and Oracle RDBMS. File system plays a buffering role to 
analyze and validate the real-time data before storing it in 
RDBMS. 
Customer Support and Staff Rating (CSSR) system is built 
on top of IBM DB2 RDBMS. It is the data provider sub system 
that needs the least amount of data in our telecommunication 
application. 
Call Rating System (CRS) uses a custom file system. It 
contains unstructured call records and call quality rating result 
associated with call record file. 
Decision Support System (DSS) relies on a custom data 
warehouse solution. It provides de-normalized data, collected 
from several subsystems using Extract, Transform, and Load 
(ETL) solution. 
Staff Tracking System (STS) provides personnel’s turnstile 
transaction logs. It is a distributed system running on each 
location of company. 
III. DATA MODEL 
The system presented in this study is responsible for business 
decisions related to information collected from sub systems. It 
collects data, analyzes, merges and delivers to decision phase. 
Additionally, it provides real-time requirement analysis for each 
team & department. It handles gigabytes of daily data and high 
volume of requests from thousands of active users. 
ETL component of the system gathers data from more than 
five hundred relational tables. In this study, we will cover pre-
selected part of the data model. Key entities of sub-system’s data 
model (see Figure 1) is composed of seven entities such as Staff, 
Shift, Permit, Work Activity, Service, Turnstile Transaction, 
Department. 
 
Staff
 StaffIdPK
 ManagerId
 Shift
 ShiftIdPK
 StaffId
 1..1
 1..n
 Permit
 PermitIdPK
 StaffId
 1..n
 WorkActivity
 WorkActivityIdPK
 StaffId
 TurnstileTransaction
 TTransactionIdPK
 StaffId1..n
 Department
 DepartmentIdPK
 ServiceId
 1..n
 Service
 ServiceIdPK
 DepartmentId
 1..n
  
Fig. 1.  Data model of key entities 
The Staff entity contains telecom’s personnel information. 
Many attributes such as work type, manager info, average 
performance value that affects the decision takes part in this 
entity. 
The Shift entity maps shift plans of whole department into 
each staff’s shift plans. Permit table holds the real-time and 
previously planned permissions that belong to staff.  
Work activity is the most intensive table in terms of data size. 
All daily activities of personnel are instantly recorded to this 
table. 
In service table, location information and type of service that 
the personnel provide are stored. In turnstile transaction table, 
check-in and check-out information of personnel from all 
turnstile locations within the corporation are stored. Department 
table stores the team, division and hierarchy information 
between them. 
For each personnel information request from the system, all 
of the related entities like staff, permit, shift and work activity 
tables has to be scanned. Although there are temporary solutions 
such as caching for permit and shift tables that are assumed to 
change daily, caching is not an effective solution for the work 
activity table that is updated continuously. 
Furthermore, feeding the same table with different sources 
may cause data redundancy. Previous attempts tried to solve 
redundancy problem by re-scanning whole table to prevent re-
 inserting same data. However this solution made the systems 
unresponsive. 
In our solution we decided to use document model. For this 
purpose we transformed relational data structure to document 
model (see Figure 2). In this context Shift, Permit, Work 
Activity, Turnstile Transaction tables are combined into a 
document structure called ActivityPackage. Each activity 
package is designed in a way that it contains all the activities that 
the personnel has done or should do in the same day. Data that 
comes from different sources are first stored in RDBMS based 
Activity Queue Table and then synchronization service 
transforms relational data to ActivityPackage document. 
 
  
Fig. 2.  Document model of Activity Package 
IV. DATA STORES 
Developed system has to deal with millions of requests every 
day. Previous RDBMS solutions with powerful and expensive 
hardware are not capable of handling daily workload since they 
rely on vertical scalability. However, common NoSQL solutions 
have already proven to perform better in terms of their horizontal 
scalability performance. It is easy to increase load capacity by 
adding new machines to NoSQL database cluster. 
In this study, we use three types of data stores: Document 
Store, RDBMS, and File System. 
 
A. Document Store 
Activity Packages are the primary sources of document 
store. Documents are persisted in JSON format, which are the 
data structures capable of holding arrays and other complex 
information. JSON documents are flexible and information-rich 
structures that enable developers to model objects as individual 
documents. Activity packages are the most frequently used data 
type in our system. That is the major reason why we chose the 
document store for activity packages. 
In terms of optimistic concurrency, we use check-and-set 
token (CAS) associated with document provided by document 
store. Document store checks a CAS value before changing the 
data; it effectively prevents data loss without having to lock 
records. Document store prevents a document from being altered 
by an operation if another process alters the document and its 
CAS value, in the meantime. Additionally, all update operations 
of Activity Package assigned to only one background service 
(daemon service). 
 
B. RDBMS 
Real-time stream listener service captures multiple CMS 
records at once. To handle multi-record transactions, it’s decided 
to use RDBMS in Activity queues. 
 
C. File System 
File system is preferred to store unstructured files and real-
 time buffering records. 
 
V. DISTRIBUTION OF WORKLOAD 
Sources of workload in the system are covered under two 
main titles. 
 
A. Regular Background Tasks 
To generate live analysis results, system needs continuous 
updates from its sub systems. To maintain this requirement, we 
designed several background services. All relational data 
gathering tasks are assigned to ETL service. ETL periodically 
checks for new records from subsystems and takes them in 
associated store. 
Real-time stream capturing tasks are assigned to real-time 
listener (RTL) service. RTL continuously buffers stream data to 
file system. 
Analyzing and parsing tasks are assigned to real-time parser 
(RTP) service. The RTP service checks for buffer size generated 
by RTL, validates and then parses the buffer package to save in 
activity queue. 
Queue processing requirement is handled by real-time 
synchronization (RTS) service. RTS consists of several sub 
synchronization services. All of the sub services check for their 
associated queue store to handle their tasks. Queuing is the key 
mechanism in terms of providing system stabilization. To 
prevent size overflow in queue stores, each RTS sub service has 
right to pick additional thread from thread pool, and then leave 
it back to the pool, if the item size comes to the pre-defined 
threshold. Service workflow is presented in figure 3. 
 
Data 1
 Data 2
 Data 3.
 Real-time Stream
 RTLCMS File System
 RTP
 Activity Queue
 RTS
 WFM
 ETL
 Activity Package
   
Fig. 3.  Service workflow 
System needs to generate warnings to notify users and admin 
staff. Common warning types have deadlines to take actions. 
Once their deadline is passed, they become abandoned records. 
In early attempts, we stored warnings and other disposable 
information in RDBMS and developed another service to delete 
inactive records. In our final system design, all of disposable 
data are stored in document store, since it provides time-to-live 
(ttl) attribute for each document. TTL is an expiration time for a 
document specified in seconds. Document store automatically 
deletes values during regular maintenance, if the ttl for a 
document has expired. 
A failure in any service will not affect other services since 
all of them run in independent app domains. With regular 
background task architecture, the most part of workload over the 
whole system became measurable and scalable. 
A sample workload distribution of regular background tasks 
is shown in figure 4. When the user workload is in its lowest 
rate, system starts running daily ETL tasks. For this reason 
background task workload peaks at around 03:00am. In day time 
background tasks mainly focus on processing real-time data 
taken from CMS. As long as amount of captured real-time data 
decreases the workload of background tasks will also drop off. 
 
 
Fig. 4.  Workload distribution of regular background tasks 
B. User Workload 
Thousands of users actively use the system in their daily 
work. All of the software patterns are developed according to 
cloud architecture [9]. When the workload increases, it is 
distributed by automatically increasing the number of 
application servers behind the load balancer. 
Figure 5 shows one of the daily workload distribution of user 
requests. 
  
Fig. 5.  Daily user workload distribution 
VI.  CONCLUSION 
This work aimed to provide an example solution experienced 
in centralized enterprise application. We examined how NoSQL 
based document store could be adapted according to the 
requirements of telecommunication enterprise. 
Some solution providers attempted to solve this problem. 
However they all failed because of several reasons. Since 
previous solutions didn’t run properly, we were not able to 
capture performance results to compare with our solution. 
Our performance results and horizontal scalability 
requirements were the key factors of storage decision. Different 
from the previous studies [10], NoSQL solution used in our 
project has significant performance advantage over the 
competitive RDBMS solutions. In this project we determined to 
use both NoSQL and RDBMS solutions for data storage.  
 
We conclude that when a system needs to provide a high 
level of scalability, high performance, and flexibility in data 
structure, a NoSQL solution is well suited for the project. If it’s 
required to handle multi-record transactions or needed to 
perform rollback operations, a traditional RDBMS may be a 
better decision to use in a project. 
 
 
 
 
 
 
 
REFERENCES 
 
[1]  F. Cruz, P. Gomes, R. Oliveira and J. Pereira, "Assessing 
NoSQL Databases for Telecom Applications," CEC '11 
Proceedings of the 2011 IEEE 13th Conference on 
Commerce and Enterprise Computing, pp. 267-270, 
2011 .  
[2]  J. Pokorny, "NoSQL databases: a step to database 
scalability in web environment," in iiWAS '11 
Proceedings of the 13th International Conference on 
Information Integration and Web-based Applications and 
Services, New York, NY, USA, 2011.  
[3]  A. Lakshman and P. Malik, "Cassandra: a decentralized 
structured storage system," ACM SIGOPS Operating 
Systems Review, vol. 44, no. 2, pp. 35-40, 2010.  
[4]  Couchbase, Inc, "Couchbase Developer's Guide 2.0," 20 
June 2013. [Online]. Available: 
http://www.couchbase.com/docs/couchbase-devguide-
 2.0/index.html. [Accessed 21 June 2013]. 
[5]  J. Lennon, Beginning CouchDB, Berkely, CA, USA: 
Apress, 2009.  
[6]  G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, 
A. Lakshman, A. Pilchin, S. Sivasubramanian, P. 
Vosshall and W. Vogels, "Dynamo: amazon's highly 
available key-value store," Proceedings of twenty-first 
ACM SIGOPS symposium on Operating systems 
principles, pp. 205-220, 2007.  
[7]  F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. 
Wallach, M. Burrows, T. Chandra, A. Fikes and R. E. 
Gruber, "Bigtable: a distributed storage system for 
structured data," OSDI '06 Proceedings of the 7th 
USENIX Symposium on Operating Systems Design and 
Implementation, vol. 7, p. 15, 2006.  
[8]  10gen, Inc, "MangoDB," [Online]. Available: 
http://www.mongodb.org/. 
[9]  G. Shroff, Enterprise Cloud Computing: Technology, 
Architecture, Applications, Cambridge University Press, 
2010.  
[10] A. Floratou, N. Teletia, D. J. DeWitt, J. M. Patel and D. 
Zhang, "Can the Elephants Handle the NoSQL 
Onslaught?," Proceedings of the VLDB Endowment, vol. 
5, no. 2, pp. 1712-1723, 2012.  
 
 
 
 
 
 
