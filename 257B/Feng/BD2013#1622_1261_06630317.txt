Investigation of Students’ Attitudes to Lectures with Text-Analysis of Questionnaires
 Toshiro Minami
 Kyushu Institute of Information Sciences
 6-3-1 Saifu, Dazaifu, Fukuoka, 818-0117 Japan and
 Kyushu University Library, Fukuoka, Japan
 Email: minami@kiis.ac.jp
 Yoko Ohura
 Kyushu Institute of Information Sciences
 6-3-1 Saifu, Dazaifu, Fukuoka 818-0117 Japan
 Email: ohura@kiis.ac.jp
 Abstract—The eventual goal of our study is to help teachers
 who give lectures in universities and other educational orga-
 nizations with advising them as well as to help the attending
 students in order to maximize the learning performance of
 student. In order to achieve this goal we take the model-
 based approach. We construct student’s learning model at first,
 and then extract appropriate tips on teaching for teachers
 and on learning for students. In this paper, as an attempt in
 this approach, we analyze the text data which were obtained
 as answers to a term-end questionnaire in a course. Firstly
 we make a grouping of students based on a correspondence
 analysis of students and words from the answers to a question
 about the student’s achievement in taking the course. Then we
 compare these student groups in combination with other data
 such as examination scores as achievement, and attendance and
 homework scores as effort, as well as the features of words
 used in the answered texts. We have found that the students
 who have good achievement scores often give the comments
 from a wider view than what they actually learned in the
 class. On the other hand the students who give the comments
 using those terms which were taught in the class tends to have
 low achievement scores. The methods for in-depth analysis
 used in this paper are supposed to be appropriate tools for
 complementing the results from using the big data analysis
 methods and need to be developed more toward the future.
 Keywords-Text Mining; Correspondence Analysis; Free De-
 scription Questionnaire; Educational Data Mining; Lecture
 Data Analysis;
 I. INTRODUCTION
 It has been pointed out in Japan that the students’
 academic skills and achievements have been decreasing.
 There are various factors behind it. One factor comes from
 the declination of birth rate and the increase of university
 enrollment rate. As a result, universities compete so hard that
 even the students with low achievements are able to enter
 universities. Another factor is that the students have been
 educated under the misconception of “yutori (or relaxed)
 education” and thus education were considered to be done
 without stress and thus let them learn as they want, so that
 quite a lot of students have not been encouraged to learn
 even the fundamental academic skills and knowledge. Due
 to the reason that such factors are complicatedly intertwined,
 quite a lot of universities are facing the problem of providing
 with higher education to the students with low academic
 skills together with low motivation to learning.
 In order to cope with this problem, universities have
 introduced remedial courses for students who need to learn
 preparatory materials, and they also enhance the courses for
 the first year students to be got used to the style of teaching
 in university. Furthermore, universities have introduced the
 FD (Faculty Development) program as a promotion of
 changes of the consciousness of university professors and
 improve the quality of university education.
 However, students’ academic skills do not look to be
 improved even with such a lot of efforts. Thus we assume the
 essential problem lies in students rather than professors with
 their educational ability. In combination with our observation
 in the lectures, we presume that the most important factor
 on this problem is not on the students’ academic skills
 and the amount of knowledge, but on their attitudes such
 as eagerness to learn, curiosity to learn something new,
 motivation to learn, and other mental tendencies. Thus it
 is important to take the student side into consideration even
 more, which we would call SD (Student Development), in
 order to find a solution of the issue we have.
 Based on such an awareness, our eventual goal of the
 study presented in this paper and our other related papers
 is to find out the most appropriate teaching/advising/leading
 methods for the students learn the most out of the lectures.
 In order to achieve this goal, we take the model-based
 approach, where (1) make a student’s learner model which
 includes attitudes to learning, and (2) utilize the model
 and advise the student in order to maximize the student’s
 achievement. As a part of this approach, this paper presents
 a case study of analyzing a group of class data; answer
 to a questionnaire, and attendance/homework/examination
 scores. The model dealt with in this paper aims to represent
 the student’s learning style and attitudes, which are obtained
 in the analysis of lecture data.
 Goda et al. [1][2][3] take a similar approach and present
 a method of text analysis, where text data are given by
 students as reports about the everyday lectures. Our studies
 are different as we use such data as attendance, homework,
 exercise, and term-end examination, which are obtainable in
 ordinary lectures. Another difference of our approach is that
 we do not intend to estimate the student’s achievement. We
 focus on to make a learner model of students.
 2013 Second IIAI International Conference on Advanced Applied Informatics
 978-0-7695-5071-8/13 $26.00 © 2013 IEEE
 DOI 10.1109/IIAI-AAI.2013.34
 56
Other studies of educational data analysis have been
 conducted in the research fields such as KDD (Knowledge
 Discovery and Data Mining) and in EDM (Educational Data
 Mining). The paper [15] gives a comparative study of data
 mining algorithms for classifying students using data from
 e-leaning system. Its major interest is on predicting the
 student’s outcome. Ours is on rather the student’s psycho-
 logical tendency in learning such as eagerness, diligence,
 seriousness, etc., which is different from that in KDD and
 EDM where they use the target data those are obtained from
 learning management systems, whereas our target data are
 those we can create in everyday lectures.
 Our aim is to develop practical methods for extracting
 tips for improving lectures from data. We intend to develop
 the tools which are applicable even to small data [6]. We
 have been taking such an approach in the analysis of library
 data. In the papers [7], [8], [10] and [11], we take library’s
 circulation records as the target data and analyze them with
 proposing new concepts such as expertise levels of books
 and library patrons. The seat usage data of a library were also
 analyzed in [5]. From these experiences we are convinced
 that such an approach is useful also for small data.
 In order to achieve the aim, rest of the paper is organized
 as follows. In Section II, we describe about the target data.
 In Section III, we show some of our findings in our previous
 analysis. In Section IV, we conduct the analysis by focusing
 attention to the words used by the students in the answer
 texts of a question about their final evaluation on the effects
 of taking the class. Finally in Section V, we conclude the
 discussions and findings of this paper.
 II. TARGET DATA
 The data used in this paper come from the class of “In-
 formation Retrieval Exercise” in 2009 in a women’s junior
 college [6][7][9]. There were 35 attending year 2 students
 who are going to graduate. This is one of the compulsory
 courses for librarian certificate. Thus the students of this
 course were more diligent than average.
 The most important aim of the course is to let the students
 become expert information searchers in the sense they have
 enough knowledge about information retrieval, search, find-
 ing, and also have enough skills in finding appropriate search
 engine site and search keywords based on the understanding
 of the aim and background of the retrieval. The course
 consists of 15 lectures. The attendant is supposed to solve a
 small quiz at every lecture, which turns into the attendance
 record and the basic data for attendance score.
 Also homework is assigned every week. Its aim is to make
 the students review what they have learned in the class and to
 study preliminary knowledge for the next class. At the same
 time, the students are requested to write a lecture note every
 week, which is also aiming to make the students review
 what they have learned. The homework score reflects the
 frequency and quality of the submitted homeworks.
 A
 C Group
 A 73 8
 EC3
 verage = .
 Average = 65.5D2 D1
 BD Group
 Figure 1. Correlation between Examination Scores (x-axis) and Homework
 Scores (y-axis). Correlation Coefficient r ¡ 0.0
 The term-end examination of the course consists of 3
 problems/questions. The first question is about finding the
 Web sites of search engine, and summarizing their charac-
 teristic features, together with discussing about the methods
 for information retrieval. The second question is on finding
 the Web sites on e-books and on-line material services. The
 third question is to find and discuss about the information
 criminals in the Internet environment.
 The aim of these questions is to evaluate the skill on in-
 formation retrieval including the planning and summarizing
 skills that are supposed to be learned and trained in the
 course as they do their exercises in the classes and as they
 do their homeworks. The scores of term-end examination
 represent the evaluation results according to this aim.
 The number of the answered items varies from student to
 student. Among 35 students, 20 of them answered both of
 the evaluation scores for lectures and themselves. Thus we
 use these 20 score data in analysis on evaluations.
 We also asked the students to answer to the questions
 as the overall evaluation of them for the course. Some of
 them are: (Q1) what the student learns in the lectures, (Q2)
 good points of the lectures, (Q3) bad points that need to be
 improved, (Q4) the score of the lectures as a whole with
 the numbers from 0 to 100, where the pass level is 60 as in
 the same way to the examination score, ... (Q11) the score
 of the student herself in terms of her attitude and attitude
 toward the course from 0 to 100 as in the same way as in
 question 4, and finally (Q12) any other comments.
 III. RESULTS OF PREVIOUS ANALYSIS
 Figure 1 shows the correlation between the examination
 scores (x-axis) and the homework scores (y-axis). It is easy
 to cluster students with big central cluster together with
 some other students off the cluster, even though there is no
 statistical association between them; correlation coefficient
 r ¡ 0.0. The main cluster is the rectangular area that is
 formed from 50 to around 80 in examination scores and
 from 50 to around 90 in homework scores.
 57
There exist some students away from this area. Student
 A, for example, takes the highest score in examination,
 whereas in terms of homework, her score is one of the
 more-than-average, but not the highest. Student B has the
 lowest homework score. However she gets the 4th highest
 examination score. She is a typical student who has high
 performance in comparison with effort.
 On the other hand, the students in C group are the lowest
 in examination scores. Their homework scores are mostly
 more than average and look like as if they do some amount
 of efforts. Thus they are opposite to Student B in the sense
 that their performances are very low in comparison with
 efforts they spent.
 The students in D group have relatively low efforts in
 homework scores and also have lower-than-average exami-
 nation scores. Actually these students belong to the major
 cluster in attendance score. Thus their efforts are somewhat
 superficial; they put efforts in attendance but they do not put
 more laborious efforts in homework.
 By analyzing the relations of attendance and homework
 scores as the indexes for effort and examination scores as
 the index for achievement, together with the scores in the
 questionnaires Q4 and Q11, we have found some interesting
 results. What we have found is that notable ratio of students
 have just attended the lectures and do their homeworks
 without intending to learn and thus without learning, which
 is against lecturer’s intention of letting them to learn. In
 other words, quite a lot of students’ efforts are rather
 superficial which do not affect to the true improvement of
 their academic skills.
 We have also analyzed the answers to Q11 and have
 found that their self-evaluations have more correlation to
 their homework scores than achievement scores. This result
 also suggests that students major concern is rather on their
 efforts than on their achievements which is more important
 from the teacher’s point of view. See the papers [6], [7], [9],
 and [13] for more findings of the analysis.
 IV. ANALYSIS OF QUESTIONNAIRES
 A. Toward Analysis of Answers for Question 1
 In this section, we chose Q1: “What did you learn in this
 class? Did it help you?” for analysis because this question
 asked the students to summarize what they have learned in
 the class. The answer is given as a text that expresses the
 student’s recognition of her achievement.
 In order to conduct text analysis, we have to transform
 them into the data that are available for the analysis method
 we apply. One possible method might be creating data
 manually; one or more human(s) generate data by reading
 and judging the data for analysis. It is popularly done that a
 human judges if an opinion about a commercial product in
 a blog or twitter is positive, negative, or neutral, and create
 a raw data for opinion analysis.
 Table I
 EXTRACTED WORD AND ITS OCCURRENCE (TOP 75)
 Word Occ. Word Occ. Word Occ.
 Search 88 Function 7 Site 3
 Class 37 Result 7 Challenge 3
 Information 37 Important 7 Answer 3
 I think 34 Opportunity 6 Again 3
 Library 33 Now 6 Overseas 3
 Learn 32 Tag 5 Basic 3
 Know 30 Previous 5 Find 3
 Myself 21 Question 5 Device 3
 How 21 Seek 5 Go 3
 Now 17 See 5 Reference 3
 Way 16 Type 5 Librarian 3
 Examine 16 More 5 Time 3
 Keyword 13 Adequate 5 Received 3
 Are various 11 Various * 4 Collect 3
 Use 10 Differ 4 Homework 3
 Help 10 Exercises 4 Leave 3
 Necessary 9 Use of 4 Introduction 3
 Use 9 Lecture 4 Detailed 3
 Internet 8 Learn 4 World 3
 Personal Computer 8 Body 4 Correct 3
 Think 8 Knowledge 4 Other 3
 Do 8 Tune 4 Large 3
 Get 8 Really 4 Content 3
 Various * 7 Good 4 Difficult 3
 Feel 7 Way 3 Usually 3
 * different words in Japanese
 However such method may cause of creating biased,
 or subjective, data because the created data produced by
 humans depend on their interpretation of the expression and
 thus may differ from human to human. In this paper we
 conduct analysis of word occurrences in text, in order to
 avoid such subjective bias and find more objective results.
 On the other hand we are able to pursue analysis about words
 by using information about relations between words, their
 parts of speech, etc.
 We use the KH Coder[4] as the analysis tool in this paper.
 KH Coder is a free software, which is equipped with the
 facilities of morphological analysis for Japanese language,
 and can extract words, or inflection processing together with
 statistical analysis including correspondence analysis. In our
 analysis we consider the answer of each student as one
 document for KH Coder.
 B. Extraction of Words which Appear in the Answers
 Table I shows the top 75 words in their frequencies of
 appearance in the texts, together with their frequencies. The
 verbs are conjugated. Note that two appearences of the
 word “Various” marked with ? are different expressions in
 Japanese which have the common corresponding expression
 58
Grp1
 Grp2 Grp3
 4%
 )
 po
 ne
 nt
 2 
(8.
 44
 Grp4
 Co
 m
 p
 Grp5
 Component1 (10.59%)
 Figure 2. Correspondence analysis map of related words with students.
 (The underlines for each student, and the grouping line and the number by
 the author.)
 in English. The shaded words are those relating deeply to
 the subject the students have learned in the lecture and other
 non-shaded words are generic words.
 We can see in Table I the words related to the lectures
 appear in high frequencies. For example, the word “Search”
 appears 88 times in the answers to Q1, which is the most
 frequently used one among all words. Also the words “Infor-
 mation”, “Library” and so on appear in the list. The lecture-
 related words are 10 (13%) among 75 wrods, whereas 6
 (21%) among 28 with frequencies more than 6.
 C. Correspondence Analysis of Words and Students
 It is important to know not only the words themselves but
 also their relations such as word to word, word to student.
 Analysis of such association would give us more useful
 information about students and their attitudes to learning.
 Figure 2 shows the results of the correspondence analysis
 in a two-dimensional principle component space. The words
 appeared in the figure are those in Table I; those with more
 than 2 times of appearance for Q1. The underlined ones with
 st0** in the figure represent the students of the class.
 Now we divide the students in Figure 2 into 5 clusters;
 from Grp1 to Grp5. Table II summarizes some of their
 features such as number of students of the group, the
 member’s average examination scores, their variance, and
 some others. The groups consist of 3 members in minimum
 (Grp4) and 16 members in maximum (Grp5). For the average
 scores, Grp3 is the highest with the score 83.5, which locates
 in the upper-right part in Figure 2. Grp5 takes the lowest
 score with 59.3 which locates in the lower-left corner. As
 we check the P-value, which is 0.0469, and it can be seen
 Table II
 ANALYSIS OF VARIANCE TABLE OF 5 GROUPS.
 Group No. Number of samples Average Variance
 Grp1 4 65.2 27.3
 Grp2 5 70.5 98.8
 Grp3 5 83.5 107.2
 Grp4 3 69.8 68.7
 Grp5 16 59.3 335.3
 Source Sum ofSquares
 Degree of
 Freedom Mean Square
 Between Samples 2399.34 4 599.84
 Within Samples 6072.57 28 216.88
 Total 8471.91 32 –
 F-Statistics P-value F- Critical Value
 2.76 0.0469 2.71
 Table III
 STUDENT CLASSIFICATION OF TEXT AND TEST SCORE.
 Test Score
 Classification
 Standardized Values Text
 Classi.Examination Homework Attendance
 A 2.08 0.79 0.47 Grp3
 B 0.97 -3.06 -3.18 Grp5
 C1 -1.94 0.55 0.96 Grp5
 C2* -1.65 0.31 -1.23 –
 C3 -2.21 -0.05 0.96 Grp5
 C4 -2.37 0.91 0.23 Grp5
 D1 -0.70 -2.34 -0.50 Grp2
 D2 -0.85 -2.34 0.23 Grp5
 E -0.23 -0.05 0.23 Grp1
 The item marked with – indicates the student gives no answer to the
 question and thus does not belong to any group.
 that there is a difference between the averages of these five
 test scores among the groups statistical significance at the
 5% level.
 D. Investigating Locations of the Students A to E
 In Section III, we have classify the students based on
 the effort-achievement analysis. We picked up some students
 who are typical in some sense and called them from A to E.
 We would like to see their positions in our correspondence
 map (Figure 2).
 Table III shows the examination, homework, and atten-
 dance scores in standardized values, together with the group
 (from Grp1 to Grp5) they belong to. Standardized scores in
 the table are obtained by standardized mean value becomes
 0 and standard deviation becomes 1 so that the different
 scores are comparable in a uniform way. Thus negative
 values indicate that the score is less than average of the
 class. The shaded items indicate that the value is within the
 lowest 2.5%.
 59
All the students except one locating in the lowest 30%
 in either scores of examination, homework, or attendance
 belong to Grp5. Even though the exceptional student belongs
 to Grp2, we can see in Figure 2 that Grp2 and Grp5 are
 located very closely so that we can say that all the students
 locate to within the area for Grp5 and its surrounding area.
 Conclusively, we can say there is no significant difference
 between classification by effort and achievement scores and
 that by used word in the text analysis.
 E. Relation between Used Words and Examination Scores
 We deal with the correlation between the characteristic
 words that appear in the answers to Q1 and the examination
 scores. Table IV shows the top 10 characteristic words of
 some of the students using the Jaccard similarity measure.
 Note that the Jaccard similarity of student p and q is defined
 as the ratio of the number of words which are commonly
 used by p and q against the total number of words which are
 used either or both of p and q. Thus the Jaccard similarity
 ranges between 0 and 1. The value becomes 1 if every words
 used by p and q are the same, and it becomes 0 if p and q
 do not use a word in common.
 The words marked with “Y”, “É” and “Ì” in Table IV
 indicate that they are classified as those for the general
 information, for frequently appearing words that relate to
 the lecture, and for characterizing the subject, respectively.
 The values in the right-hand side of (st0**) represents the
 examination score of the student.
 Table V shows the number of characteristic words, num-
 ber of members, usage ratio of the characteristic words, and
 the average score of the examination, of each group from
 Grp1 to Grp5. The group having the highest examination
 score of 83.5 is Grp3, and it has the highest usage rate 2.40
 as well. On the other hand Grp1 and Grp2 have the lowest
 usage ratio but have the 2nd and 4th highest examination
 scores. Thus we could not find a clear correlation between
 the usage ratios and the examination scores.
 As we investigate further by taking attention on the words
 used by the students, we can find that the students in Grp1 do
 not use many of the characteristic words and the correlations
 between the students are relatively low. Its examination score
 is the 4th highest among 5 groups.
 For Grp2 (2nd highest in examination score) commonly
 use such words as “problem”, “time”, and “examination”,
 which are relating to the actual activity directly relating to
 the lectures. For Grp3 (the highest in examination score)
 characteristically use the technical characteristic words and
 those words from the broader point of view in comparing
 Japan and the world such as “foreign”, “national” and
 “Japan”.
 It is interesting to see that the words relating to the
 homework matters do not appear in Grp3. Thus we can see
 that the students in Grp3 have the lectures in the standpoint
 of seeing things in a broad perspective of the lecture.
 Table IV
 CHARACTERISTIC WORDS OF STUDENTS
 Grp1
 st001 st013 st015 st025
 Think Method Answer Collect
 KeywordÉ Important Get TV
 Seek Consideration Data Practice
 Get Advance Arrangement Net
 Input Things Forecast Announcement
 Quick Important Angle Force
 Have a very
 hard time Think Surely Quality
 One Myself Extraction Art
 Put SearchÉ Students Question
 Conceive Choose Necessary
 Grp2
 st007 st010 st012 st022 st034
 How to
 choose Saving Give up Smooth Important
 Basic Effect Term Increase anddecrease Function
 Challenge Short time Words Margin Simple
 Other Lead Put in Occur Difficult
 Seek Everyday Other Collection Necessary
 Adequate Raise Collect Early Informa-tionÉ
 Get Familiar Tune Do KeyY
 Do Time Differ A lot of Press
 Help Body Adequate Challenge PrintScreen
 Are vari-
 ous
 InternetY Help Time Search
 Grp3
 st005 st006 st003 st004 st014
 ForeignY LibraryÉ Put to-gether Show Go
 LibraryÉ Individuality Country Limit Foreigncountry
 Latest Summary Box Interesting Automatic
 Effort Take HP Photo Especially
 World Relationship ClosedÌ Introduction Completely
 See Plus BooksÌ Familiar LendingÌ
 ICÌ Wholecountry Appear Japan ElectronicY
 TagsÌ At the sametime Root CopyrightY Large
 Various ReferenceÌ Tackle Every time Usually
 Feel Also Province Learn LibraryÉ
 Grp4 (Omitted)
 Grp5 (6 students out of 16)
 st002 st008 st011 st016 st017 st019
 Layout Screen Website
 Y
 Fresh Applica-tion
 A long
 time ago
 Item Open Question In addi-tion to
 Uphill
 battle Question
 Report Menu See Type Barry Really
 Study Word Rich Yahoo!Y Find Now
 Writing
 style Save Qi Learn Nice I think
 Master PCY Someday Now Accurate Learn
 ServerY Help Little GoogleY Number Respond
 Begin Way Interest-ing Various
 Com-
 pared Answer
 Recently Sense Use Increase Prior
 Weak Problem KeywordÉ
 Enor-
 mous
 Current
 60
Table V
 USAGE RATE OF CHARACTERISTIC WORDS.
 Group
 Charac-
 teristic
 Words
 Number of
 Members
 Usage
 Ratio
 Average of Exam-
 ination Scores
 Grp1 2 4 0.50 65.2
 Grp2 3 5 0.60 70.5
 Grp3 12 5 2.40 83.5
 Grp4 4 3 1.33 69.8
 Grp5 18 16 1.13 59.3
 A lot of technical words appear in Grp4, the 3rd in
 examination score, and there does not appear frequent words.
 The students in Grp5, the lowest examination score, uses
 quite a lot of words of frequent general information, and do
 not use technological words.
 It is interesting to see that many students use the words
 learned in the lectures such as “learn”, “master”, “study”,
 “useful” and “used”. So we can guess they are too much
 concentrated on the words themselves and may not pay much
 attention to what they really mean to them and to the society
 they live.
 V. CONCLUDING REMARKS
 We have conducted a morphological analysis of the an-
 swers to Q1. With extracting the high frequency words
 using Jaccard similarity measure based on the hypothesis
 that students who use the similar words are close in their
 learning styles and thus in their outcomes. As we investigate
 by dividing the students into five groups according to the
 distance of the word usages, and have conducted an analysis
 of variance on the average of the examination scores, we
 found that there really are differences between the groups
 in their average scores.
 We have the following problems for future research:
 (1) To develop a method to devise new ideas further,
 and to perform refinement of dedication to the study
 of student effort, and attitudes to learning, especially
 further analysis of the text portion.
 (2) By collecting data from a different class, to analyze
 them, and to verify if the results of this study are also
 holds.
 (3) To generalize the analysis methods, and to integrate
 them into an automated data analysis system.
 ACKNOWLEDGMENT
 This work was supported in part by the Ministry of
 Education, Science, Sports and Culture, Grant-in-Aid for
 Scientific Research (C), 24500318, 2013.
 REFERENCES
 [1] K. Goda and T. Mine, Analysis of students’ learning activities
 through quantifying time-series comments, Proc. 15th Annual
 KES Conference (KES’2011), Part II, Lecture Note in Artificial
 Intelligence (LNAI 6882), pp. 154-164, 2011.
 [2] K. Goda and T. Mine, PCN: Qualifying learning activity for
 assessment based on time-series comments, Proc. 3rd Interna-
 tional Conference on Computer Supported Education (CSEDU
 2011), pp. 6, 2011.
 [3] K. Goda, S. Hirokawa, and T. Mine, Automated Evaluation of
 Student Comments on Their Learning Behavior, ICWL 2013,
 2013. (submitted)
 [4] K. Higuchi, KH Coder. http://khc.sourceforge.net/en/
 [5] T. Minami and E. Kim, Seat usage data analysis and its
 application for library marketing, Proc. Third International
 Conference on Intelligent Information and Database Systems
 (ACIIDS 2011), LNAI 6591, pp. 238-247, 2011.
 [6] T. Minami and Y. Ohura, An attempt on effort-achievement
 analysis of lecture data for effective teaching, Proc. Database
 Theory and Application (DTA 2012), 2012.
 [7] T. Minami, and Y. Ohura, Toward learning support for decision
 making – utilization of library and lecture data –, Proc.
 The 4th KES International Conference on Intelligent Decision
 Technologies (KES-IDT’2012), Springer Smart Innovation,
 Systems and Technologies 16, pp. 137-147, 2012.
 [8] T. Minami and K. Baba, Investigation of interest range and
 earnestness of library patrons from circulation records, Proc.
 International Conference on e-Services and Knowledge Man-
 agement (ESKM 2012) in IIAI-AAI 2012, IEEE CPS, DOI
 10.1109/IIAI-AAI2012.15, pp. 25-29, 2012.
 [9] T. Minami and Y. Ohura, Towards Development of Lecture
 Data Analysis Method and its Application to Improvement of
 Teaching, Proc. 2nd International Conference on Applied and
 Theoretical Information Systems Research (2ndATISR 2012),
 14pp., 2012.
 [10] T. Minami, Profiling of Patrons’ Interest Areas from Library’s
 Circulation Records – An Approach to Knowledge Manage-
 ment for University Students -, Proc. The Fifth International
 Conference on Information, Process, and Knowledge Manage-
 ment (eKNOW 2013), 6pp., 2013.
 [11] T. Minami, Interest Area Analysis of Person and Group Us-
 ing Library’s Circulation Records, Proc. IADIS International
 Conference Information Systems (IS 2013), 8pp., 2013.
 [12] T. Minami, Changes of Interest Range of Students with
 Circulation Record Analysis, Proc. Information Conference
 2013 (Information’13), 4pp., 2013.
 [13] T. Minami and Y. Ohura, Lecture Data Analysis towards to
 Know How the Students’ Attitudes Affect to their Evaluations,
 8th International Conference on Information Technology and
 Applications (ICITA 2013), 2013. (to appear)
 [14] C. Romero and S. Ventura, Educational data mining: A survey
 from 1995 to 2005, Proc. Expert Systems with Applications 33,
 pp. 135-146, 2007.
 [15] C. Romero, S. Ventura, P. Espejo, and C. Hervas, Data
 mining algorithms to classify students, Proc. 1st International
 Conference on Educational Data Mining (EDM 2008), pp.8-17,
 2008.
 61
