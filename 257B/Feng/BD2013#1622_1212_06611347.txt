Unstructured Data Extraction in Distributed NoSQL 
 
Richard K. Lomotey 
Department of Computer Science 
University of Saskatchewan 
Saskatoon, SK, Canada 
richard.lomotey@usask.ca 
Ralph Deters 
Department of Computer Science 
University of Saskatchewan 
Saskatoon, SK, Canada 
deters@cs.usask.ca 
 
Abstract –While “Big data” has brought good tidings in 
terms of easy accessibility to voluminous data, we are 
faced with challenges too. The existing Knowledge 
Discovery in Database (KDD) processes which have been 
proposed for schema-oriented data sources are no longer 
applicable since today’s data is unstructured. Previously, 
we deployed a tool called TouchR which relies on the 
Hidden Markov Model (HMM) to extract terms from 
unstructured data sources (specifically, NoSQL databases). 
This paper has advanced on the initially deployed version 
where we introduced re-usable dictionary and association 
rules to improve on the quality of the extracted terms. Also, 
the tool in its present stage is more adaptable to the user 
search based on the most frequently searched term. 
Keywords: Unstructured data, big data, Hidden Markov 
Model (HMM), terms extraction, NoSQL, Re-usable 
dictionary, Association rules. 
1 Introduction 
The explosion of online services and the high data 
consumerization across the enterprise spectrum is leading 
the business stakeholders to re-align their products and 
services [1]. Thanks to the Internet and the steady decline 
in cloud services cost, there is vast amount of data that can 
be accessed readily for most enterprise specific purposes. 
Taking marketing and sales enterprises for example, the 
online information can be used to reach wider audience on 
product advertisement.  
But, there is a challenge. The vast amount of data is 
unstructured; which means the data is schema-less, and 
comes in different formats such as documents/text, email 
messages, customer feedbacks, audio clips, video files, 
images, blogs from online collaborative forums, and posts 
and conversations on social networking platforms [1]. 
According to Rupanagunta et al. [1], the influx of 
unstructured data is tightly coupled to big data considering 
the fact that Twitter users alone generate 12 terabytes of 
data every day.  
As if Pareto’s 80-20 rule is carefully designed for this 
topic, Feldman [21-22] bemoaned that there is lack of tools 
to effectively manage the exponential growth in data while 
noting that out of the current existing data, only 20% are in 
structured databases and 80% are unstructured. This 
phenomenon which is also reported a decade later by [12] 
and [23] directly leads to challenges regarding the 
management of the data from analytical, processing, 
interpretation, extraction, and storage points of view. 
Further, the existing data mining techniques have been 
designed to work with schema-oriented databases for 
structured data styles [2]. However, these existing 
techniques are no longer relevant to the modern challenges 
of information extraction.  Modern researchers in the areas 
of cloud computing, artificial intelligence, big data 
analytics, etc. have devised techniques based on linguistic 
and Natural Language Processing (NLP) to make sense of 
the unstructured data debris. To this effect, we have seen 
approaches on unstructured data mining such as: templates 
[3], association rules [4-5], topic tracking and topic maps 
[6], term crawling (terms) [7][23-4], document clustering 
[8], document summarization [9], Helmholtz Search 
Principle [10], re-usable dictionaries [11], and so on. The 
works in the area of unstructured data mining is 
summarized in Table I.  
Moreover, in an attempt to accommodate the growing high-
 dimensional data, NoSQL databases have been proposed. 
This style of databases support schema-less, semi-
 structured, and structured data storage while some 
accommodate file attachments (e.g., CouchDB). Examples 
of NoSQL storages are: MEGA, Dropbox, and Amazon S3, 
and so on. Further, there is also a growing trend in 
deploying databases which is graph-based. Currently, we 
have seen the deployment of graph-oriented services such 
as Facebook Open Graph [16], Google Knowledge Graph 
[17], Bing one-ups Knowledge Graph [18], and Twitter 
Interest Graph [19]. 
In our previous studies in [29], we deployed a tool called 
TouchR that employs the Hidden Markov Model (HMM) 
[26] to extract terms from distributed NoSQL databases. 
Though RSenter shows high performance boost in terms of 
the optimization of search time, there were challenges with 
adaptability to search terms. Also, the tool has problems 
with semantics where we are not able to separate two terms 
that are the same (i.e., exact writing/representation) but 
have different meanings. The presence of these issues leads 
to the introduction of False Negative results where search 
terms are returned that the user does not want.  
We have since advanced on the TouchR by adopting the 
techniques of association rules between terms from [4-5] 
and re-usable dictionaries from [11]. The remaining 
sections of the paper are structured as follows. The next 
section gives an overview of the TouchR tool and the 
978-1-4799-0786-1/13/$31.00 ©2013 IEEE 160
advances on the existing work are discussed in Section 3. 
Section 4 details the evaluation of TouchR and the paper 
concludes in Section 5. 
2 The Architecture of TouchR   
The TouchR framework as illustrated in Fig. 1 is deployed 
based on our vision which seeks to aid terms mining in 
NoSQL data silos. The implementation is done in the 
Erlang programming language [27] and the user interface is 
browser-based. In the next section, we discuss the 
architectural overview of the framework. 
2.1 The Architectural Composition 
TouchR is a standalone application that has Erlang backend 
and an HTML5 interface to enhance user interaction. 
Currently, the user interface relies on a visualization tool 
called JavaScript InfoVis Toolkit [28]. The user interface 
(TouchR App) allows the user to specify the query terms? 
which are the actual artifacts that the user is interested in 
extracting from the data debris.  
Once a query term is selected, the selection is forwarded to 
the semantic engine which contains two components; the 
thesaurus and the dictionary. As already posited, topic 
extraction focuses on the actual keywords being searched 
while terms require the extraction of other features 
(keyword dependencies). For instance, in an organization, 
topic extraction can be done by searching for the keyword 
“contract”, where contract may refer to all files and 
information regarding contractual issues. In that case, the 
search will return all results containing the exact topic 
“contract”. However, terms extraction for the same 
keyword “contract” will require other dependencies such as 
agreements, technical description documents, non-
 disclosure agreements, and so on. In effect, terms are 
specified by the user because sometimes, the expected 
result may not even contain the actual keyword being 
searched for because that keyword may not literally exist in 
the data sources while a synonym may exist and be 
returned. Hence, the thesaurus allows the user to specify 
the dependent terms and synonyms. For enterprise users of 
TouchR, we encourage the system administrators to pre-
 populate the thesaurus with possible terms and their 
TABLE I.  SUMMARIZED METHODOLOGIES OF UNSTRUCTURED DATA MINING [29]  
 
Information 
Extraction 
Association 
Rules Topics Terms 
Document 
Clustering 
Document 
Summarization 
Re-Usable 
Dictionaries 
Goal Data Retrieval, KDD Process 
Trend 
discovery in 
text, document 
or file 
Topic 
Recommendation 
Establish 
associative 
relationships 
between terms 
Organize 
documents into 
sub-groups with 
closer identity 
Noise Filtering 
in Large 
Documents 
For 
Knowledge 
Collaboration 
and Sharing 
Data 
Representation 
Long or short 
text, semantics 
and ontologies, 
keywords 
Keywords, 
Long or short 
sentences 
Keywords, 
Lexical chaining Keywords 
Data, 
Documents 
Terms, Topics, 
Documents 
Words, 
Sentences 
Natural 
Language 
Processing 
Feature 
extraction 
Keyword 
extraction Lexical chaining 
Lemmas, 
Parts-of-
 Speech 
Feature 
extraction 
Lexical 
chaining 
Feature 
extraction 
Output 
Documents 
(Structured or 
semi-structured) 
Visualization, 
Summary 
report 
Topic linkages Visualization, crawler depth Visualization 
Visualization, 
Summery 
report 
Summary 
report 
Techniques 
Community 
data mining, 
Tagging, 
Normalization 
of data, 
Tokenizing, 
Entity detection 
Ontologies, 
Semantics, 
Linguistics 
Publish/Subscribe
 , Topics-
 Associations-
 Occurrences 
Linguistic 
Preprocessing, 
Term 
Generation 
K-means 
clustering, 
Hierarchical 
clustering 
Document 
structure 
analysis, 
Document 
classification 
Annotations, 
Tagging 
Search Space Document, Files, Database 
Document, 
Files, Database 
Document, Files, 
Databases 
Topics vector 
space 
Documents, 
Databases 
Databases, Sets 
of documents 
Databases, 
Sets of 
documents 
Evaluation 
metrics 
Similarity and 
relatedness of 
Documents, 
sentences and 
keywords 
Similarity, 
Mapping, Co-
 occurrence of 
features, 
correlations 
Associations, 
Similarity, 
Sensitivity, 
Specificity 
Frequency of 
terms, 
Frequency 
variations 
Sensitivity, 
Specificity, 
Balanced 
Iterative 
Reducing and 
Clustering 
(BIRCH) 
Transition and 
preceding 
matrix, Audit 
trail 
Word 
extensibility 
Challenges and 
Future 
Directions 
Lack of 
research on 
Data Pedigree 
Applies varying 
approaches for 
different data  
Identification of 
Topics of interest 
can be 
challenging 
Community 
based so 
adoption can 
be challenging 
Can be resource 
intensive 
therefore needs 
research on 
parallelization 
Needs research 
on Data 
Pedigree 
Lack of 
research on 
dictionary 
adaptation to 
new words 
978-1-4799-0786-1/13/$31.00 ©2013 IEEE 161
 
Figure 1. Architectural design of TouchR [29] 
dependencies before the actual mining process commences 
by novice users. However, the terms and their 
dependencies can be specified and stored in the thesaurus at 
the time of performing the terms extraction task. Typically, 
the data being sent across the system components is JSON 
so an example of a specified query term can appear as: 
{"R Lomotey": { 
  "project": " iOS”,  
   “unit2”: “Admin Dept”, 
   “unit3”: “HR Dept",   
     } 
} 
The thesaurus will store this information using “R 
Lomotey” as the main artifact while the project and units 
are dependency keywords that will also be extracted as part 
of the terms mining process. The dictionary is implemented 
to provide the TouchR framework with adaptability 
features. Once a terms-extraction task is completed 
successfully, we allow the users to specify their satisfaction 
rate from (0 – 5). The terms extraction is rated very poor 
(0) to excellent (5). Apart from the human rating, we 
analyze the accuracy, precision, and recall of every search 
at the application level. This will be discussed later in the 
paper. But, highly rated terms extraction tasks by the users 
which correspond to the systems accuracy and precision are 
moved into the dictionary. The user does not interact with 
the dictionary but only the system. So, in the future when 
users specify a query term such as “R Lomotey” who is an 
employee but the only dependent or synonymous keywords 
that are specified is project and unit2 or even completely 
different units, the system will add to the query result unit3 
or all the previous results that are returned when other users 
perform the query tasks and report high satisfaction. The 
dictionary actually stores human rated values from (3 – 5). 
At the moment, the thesaurus and dictionary are 
implemented using DETS which is disk storage in Erlang. 
When the semantic definition tasks are completed, the 
query term and its dependency keywords (either specified 
by the user or from the dictionary) are forward to the 
transactor component. The transactor is the main engine 
that determines the number of available NoSQL databases, 
their different MapReduce functions, their REST API 
formats, and their returned results formats. The challenge 
we have at the moment is that, the transactor is not 
adaptable. So, prior to the terms extraction process, the 
query nature of the expected NoSQL databases has to be 
specified. For example, the transactor does not support 
cloud storage such as MEGA or Dropbox so if these 
frameworks are specified as the NoSQL databases, then 
there will be no terms extraction. However, to use these 
storages, their REST APIs has to be pre-defined in the 
transactor; and this activity requires expertise in Erlang 
programming as well as API usage.  
At the moment, TouchR supports NoSQL databases from 
the following providers: Bigdata, CouchDB, MongoDB, 
Neo4J, Cloudata, DynamoDB. The list of the supported 
NoSQL is heterogeneous in the sense that some are the 
traditional NoSQL storages and a few (e.g., Neo4J) are 
graph databases. So, the query engine performs the terms 
extraction tasks on the NoSQL using the key/value pair 
format which is the property of these NoSQL storages. 
However, the graph databases rely on both properties and 
indexes to access the data on the distributed nodes. The 
transactor takes every query term as a key and every 
dependent term is also treated as a key. Hence, the 
transactor generates MapReduce queries with the terms to 
extract the data from the NoSQL sources. We consider the 
details of MapReduce queries of all the NoSQL being 
studied here outside the scope of this paper for brevity. We 
encourage the reader to consult the documentations on the 
websites of each of the products.  
Further, there are some instances where file reading may be 
required (e.g., attachments in CouchDB). This case is 
simplified by just downloading the file and reading its 
content and treating it just as an actual data. All the 
returned data from the queries are sent back to the query 
response engine on the client side. The query response 
engine then displays the result on the user interface.  
In order to traverse the distributed NoSQL databases, we 
employed the Hidden Markov Model (HMM) which aids 
us to reduce the search complexity. The traversing of the 
distributed NoSQL follows the exponential complexity but 
the HMM aids us to reduce the complexity to linear. This 
further aids in the optimization of the time to traverse the 
NoSQL databases. A sample output of the tool in HTML5 
is shown in Fig. 2. The reader is referred to the work in 
[29] for further reading on the HMM. 
978-1-4799-0786-1/13/$31.00 ©2013 IEEE 162
 
Figure 2. Clustering tree result for the extracted term “R. 
Lomotey” who is an employee [29]. 
3 Re-Usable Dictionary and 
Association Rules 
In order to make TouchR more adaptable, we adopted the 
re-usable dictionary technique that is proposed by [11] and 
[30]. The challenges with the initially deployed version of 
TouchR in [29] are that, the search criterion is not adaptive 
to search history and semantic issues were not overcome. 
Specifically, when two keywords (artifacts) are written 
same but have different meanings, TouchR is not able to 
determine the difference in meaning so this leads to False 
Negative and False Positive results. We further explain 
these indices below: 
• True Positive (TP): The search term as specified 
by the user is found and returned.  
• False Positive (FP): The search term specified 
exists in the data source but is not found by the 
search tool. This is a case that is never entertained 
in any working system. 
• True Negative (TN): The specified search term 
does not exist in the data source and the search 
tool reports that it does not exist.   
• False Negative (FN): This is a case of returning 
undesired results. Sometimes, what the user is not 
looking for is equally returned.  
The increasing volume of unstructured data also requires 
the implementation of re-usable dictionaries to further 
facilitate collaboration in a working group. In software 
engineering for example, dictionaries could enable a group 
of developers to rely on shared knowledge (which is 
communicated in an unstructured data format) to better 
speed up the development process. Dictionaries are mainly 
used for annotation and tagging of words. The challenges 
however relate to how dictionaries are built and re-using 
dictionaries. If dictionaries can be re-used, the domain 
experts can just rely on the experiences of previous tasks. 
Godbole et al. [11] built a set of tools that will enable end 
users to construct dictionaries. A dictionary, D, is defined 
as D = Dict(C, X) where C is a concept in a document of 
collection X. The authors further extended the dictionary to 
support single seed words, set of seed words, and positive 
and negative seed sets (i.e., the user can choose to provide 
words of interest as well as words of no interest). The 
possibility of re-using the dictionary is as a result of the 
fact that there is an existing algorithm that supports the 
dictionary agility such that the function adapt(n, D) is true. 
Meaning for n-number of new terms to be added to the 
dictionary, the dictionary D can adapt to accommodate the 
update.  
On the issue of system adaptive learning, Gonzalez et al. 
[30] implemented a dictionary-base framework that 
employs tagging to map entities. The challenge in adaptive 
learning systems is that, new jargons are being added every 
day from the cloud and social networks; which make the 
area evolving. Hence, the idea behind the implementation 
of the dictionary is to adopt semantic data to improve on 
the information extraction process, as well as using the 
information extraction output to discover new terms. 
Moreover, the Association Rules (AR) is applied in 
discovering text with co-occurrences in features [6]. 
Simply put, association rules are employed to achieve 
pattern discovery in the text, document or file. AR works 
by identifying a set T of transactions which is a subset of a 
bigger transaction I. 
FORMALISM: To formalize the AR transaction, Delgado et 
al. [4] express I and its subset T as associative if A ? C 
with A, C ? I, A, C ≠ null and A ?C = null, where |C| = 1; 
to mean that “C” is present in every transaction that “A” is 
present in.  
Association rules are closely related to information 
extraction since AR aims at establishing relationships 
between records [31]. As further outlined by Delgado et al. 
[4], one application of associative rule is trend discovery, a 
very salient measure in accomplishing search tasks. Trend 
discovery can enable us understand from the textual 
content what reports are being generated and how are those 
reports being handled. This is achieved by building 
relationships between the T transactions (or activities) and 
labeling these transactions using timestamps and other 
identifiers. 
In order to improve on the TouchR tool, we adopted the re-
 usable dictionary technique proposed by [11] and [30]. 
Then we further adapted the association rules technique 
proposed by [4] and [6]. We restructured the thesaurus and 
dictionary components of TouchR to store keywords 
(artifacts) with their synonyms and antonyms as illustrated 
in Fig. 3. The synonyms and/or antonyms can be specified 
at the time of performing the terms extraction task or can 
be pre-populated. As noted earlier, the challenge that the 
TouchR framework had was with the differentiation 
between similar terms with different meanings. From 
Figure 3 for instance, previously when searching for the 
term “Contract”, the output will include all terms relating 
978-1-4799-0786-1/13/$31.00 ©2013 IEEE 163
to “Agreement” and “Acquire”. This situation leads to high 
False Negative result which can affect the sensitivity and 
accuracy of the terms extraction. 
 
Figure 3. Sample structure of the stored Terms  
With the introduction of the of the re-usable dictionary, the 
user can perform the terms extraction in three different 
ways that can lead to higher accuracy.  
1) Search Choice 1: The user can specify the search term 
plus the synonyms of the term so that similar terms but 
different meanings can be eliminated. 
2) Search Choice 2: The user can specify the search term 
plus the antonyms which tells the TouchR tool what 
not to search for. 
3) Search Choice 3: Specify the search term and the 
result will include a lot of False Negatives. Then, the 
user can choose any keyword out of the result to 
further refine the serach criteria. This situation leads to 
higher latecny but it is also a sure way to identify 
existing synonyms. For example, if the dictionary is 
not verbose enough, it may not contain some 
synonyms that can be specified by the user.  
Next, we establish association rules between terms. 
However, association rules are not generic; rather, they 
apply to specific domains. For example, association rules 
can be defined as: influenced by, caused by, dependent on, 
related to, searched by, etc. In essence, the association rules 
aid in making the search adaptable. So, when users search 
for a term, those terms are rated high when others are 
searching for those terms later. Thus, assuming previously 
“Contract” was searched to mean “Agreement”, subsequent 
searches will rate the “Agreement” contract ahead of 
“Acquire” contract.     
4 Evaluation 
We deployed TouchR on our Windows powered system 
with the following specifications: Windows 7 System 32, 
3.20 3.12 GHz, 8GB RAM, 1TB HDD. We considered 
training data sets from thesaurus.com where we crawled 
over five (5) million terms and their dependencies. The 
crawled terms are stored in a CouchDB database which is 
deployed on Amazon EC2 instance. Using the above 
highlighted indices, we calculate the reliability of the 
search based on the parameters in Table II. The 
experimental result is reported in Table III.  
TABLE II.  EXTENDING ON THE INDICES 
Precision 
??
 ?? ? ?? 
Recall (Sensitivity) 
??
 ?? ? ?? 
Specificity 
??
 ?? ? ?? 
Accuracy 
?? ? ??
 ?? ? ?? ? ?? ? ?? 
 
TABLE III.  RELIABILITY OF THE TOUCHR SEARCH TOOL 
 1  Million 
Records 
2 Million 
Records 
4 Million 
Records 
5 Million 
Records 
True Positive 100.00% 100.00% 100.00% 100.00% 
False Positive 0.00% 0.00% 0.00% 0.00% 
True Negative 100.00% 100.00% 100.00% 100.00% 
False Negative 0.00% 0.00% 0.00% 0.00% 
Precision 100.00% 100.00% 100.00% 100.00% 
Recall 
(Sensitivity) 
100.00% 100.00% 100.00% 100.00% 
Specificity 100.00% 100.00% 100.00% 100.00% 
Accuracy 100.00% 100.00% 100.00% 100.00% 
Search Time 502.76s 689.95s 734.02s 967.14s 
From Table III, we employ the Search Choice 1 technique 
where we specify search terms with synonyms. Then, we 
repeat the term extraction process using the Search Choice 
2 where terms are specified with antonyms specified. In 
each case, we achieve 100% accuracy for varying number 
of terms (1 million to 5 million) because the False Negative 
and False Positive results are 0%. This is a huge 
improvement on the initially deployed version of TouchR 
in [29]. However, the duration (i.e., the search time) to 
extract the terms has increased in comparison to the 
previous version.   
5 Conclusion 
As data is increasing at an exponential rate, the challenge is 
how to make meaning out of the data. This requires 
information extraction task from the debris of unstructured 
data. Previously, we proposed a tool called TouchR which 
relies on the Hidden Markov Model to extract terms from 
978-1-4799-0786-1/13/$31.00 ©2013 IEEE 164
distributed NoSQL databases. However, there was a 
challenge with the tool regarding the differentiation 
between two similarly written terms with different 
meanings. 
In this paper, we have solved the problem by adopting the 
re-usable dictionary and association rules techniques. The 
users are given three search options that allow them to 
specify search terms with synonyms, antonyms, or 
summarize the search from initial returned result. The 
future direction will consider the implications of the same 
work from other textual and NoSQL sources. 
References 
[1] K. RUPANAGUNTA, D. ZAKKAM, AND H. RAO, “How to 
Mine Unstructured Data,” Article in Information Management, June 29 
2012, http://www.information-management.com/newsletters/data-mining-
 unstructured-big-data-youtube--10022781-1.html  
[2] D. KUONEN, “Challenges in Bioinformatics for Statistical Data 
Miners,” Bulletin of the Swiss Statistical Society, Vol. 46 (October 2003), 
pp. 10-17. 
[3] J. Y. HSU, AND W. YIH, “Template-Based Information Mining 
from HTML Documents,” American Association for Artificial 
Intelligence, July 1997. 
[4] M. DELGADO, M. MARTÍN-BAUTISTA, D. SÁNCHEZ, AND 
M. VILA, “Mining Text Data: Special Features and Patterns,” Pattern 
Detection and Discovery, Lecture Notes in Computer Science, 2002, 
Volume 2447/2002, 175-186, DOI: 10.1007/3-540-45728-3_11 
[5] Q. ZHAO AND S. S. BHOWMICK, “Association Rule Mining: A 
Survey,” Technical Report, CAIS, Nanyang Technological University, 
Singapore, No. 2003116 , 2003. 
[6] W. ABRAMOWICZ, T. KACZMAREK, AND M. 
KOWALKIEWICZ, “Supporting Topic Map Creation Using Data Mining 
Techniques,” Australasian Journal of Information Systems, Special Issue 
2003/2004, Vol 11, No 1.  
[7] B. JANET, AND A. V. REDDY, “Cube index for unstructured text 
analysis and mining,” In Proceedings of the 2011 International Conference 
on Communication, Computing & Security (ICCCS '11). ACM, New 
York, NY, USA, 397-402.  
[8] L. HAN, T. O. SUZEK, Y. WANG, AND S. H. BRYANT, “The 
Text-mining based PubChem Bioassay neighboring analysis,” BMC 
Bioinformatics 2010, 11:549 doi:10.1186/1471-2105-11-549  
[9] L. DEY, AND S. K. M. HAQUE, “Studying the effects of noisy 
text on text mining applications,” In Proceedings of the Third Workshop 
on Analytics for Noisy Unstructured Text Data (AND '09). ACM, New 
York, NY, USA, 107-114. DOI=10.1145/1568296.1568314  
[10] A. BALINSKY, H. BALINSKY, AND S. SIMSKE, “On the 
Helmholtz Principle for Data Mining,” Hewlett-Packard Development 
Company, L.P.  
[11] S. GODBOLE, I. BHATTACHARYA, A. GUPTA, AND A. 
VERMA, “Building re-usable dictionary repositories for real-world text 
mining,” In Proceedings of the 19th ACM international conference on 
Information and knowledge management (CIKM '10). ACM, New York, 
NY, USA, 1189-1198.  
[12] F. S. GHAREHCHOPOGH, AND Z. A. KHALIFELU, “Analysis 
and evaluation of unstructured data: text mining versus natural language 
processing,” Application of Information and Communication 
Technologies (AICT), 2011 5th International Conference on , vol., no., 
pp.1-4, 12-14 Oct. 2011, doi: 10.1109/ICAICT.2011.6111017  
[13] V. TUNALI, AND T. T. BILGIN, “PRETO: A High-performance 
Text Mining Tool for Preprocessing Turkish Texts,” 2012 International 
Conference on Computer Systems and Technologies.   
[14] S. V. VINCHURKAR, AND S. M. NIRKHI, “Feature Extraction of 
Product from Customer Feedback through Blog,” International Journal of 
Emerging Technology and Advanced Engineering, (ISSN 2250-2459, 
Volume 2, Issue 1, January 2012)  
[15] J. SEQUEDA AND DANIEL P. MIRANKER, “Linked Data,” 
Linked Data tutorial at Semtech 2012, Jun 07, 2012. Available: 
http://www.slideshare.net/juansequeda/linked-data-tutorial-at-semtech-
 2012 
[16] Facebook Open Graph, Availlable: 
https://developers.facebook.com/docs/concepts/opengraph/overview/  
[17] Google Knowledge Graph, Available: 
http://www.google.ca/insidesearch/features/search/knowledge.html  
[18] Bing one-ups Knowledge Graph, The Next Web, 
http://thenextweb.com/microsoft/2012/06/07/bing-challenges-googles-
 knowledge-graph-with-new-britannica-encyclopedia-partnership/   
[19] Twitter Interest Graph, http://blogs.ischool.berkeley.edu/i290-abdt-
 s12/2012/11/25/analyzing-the-twitter-social-graph/    
[20] NoSQL, http://nosql-database.org/  
[21] R. FELDMAN, M. FRESKO, H. HIRSH, Y. AUMANN, O. 
LIPHSTAT, Y. SCHLER, AND M. RAJMAN, “Knowledge 
Management: A Text Mining Approach,” Proc. of the 2nd Int. Conf. on 
Practical Aspects of Knowledge Management (PAKM98), Basel, 
Switzerland, 29-30 Oct. 1998.  
[22] R. FELDMAN, M. FRESKO, Y. KINAR, Y. LINDELL, O. 
LIPHSTAT, M. RAJMAN, Y. SCHLER, AND O. ZAMIR, “Text mining 
at the term level,” Proc. of the 2nd European Symposium on Principles of 
Data Mining and Knowledge Discovery (PKDD'98)  
[23] J. C. SCHOLTES, “Text-Mining: The next step in search 
technology,” DESI-III Workshop Barcelona, Monday June 8, 2009. 
[24] J. LEE, D. GROSSMAN, O. FRIEDER, AND M. C. MCCABE, 
“Integrating structured data and text: a multi-dimensional approach,” 
Proceedings of Information Technology: Coding and Computing, 2000. 
International Conference on , vol., no., pp.264-269, 2000, doi: 
10.1109/ITCC.2000.844234 
[25] R. K. LOMOTEY, S. JAMAL, AND R. DETERS, “SOPHRA: A 
Mobile Web Services Hosting Infrastructure in mHealth,” Mobile Services 
(MS), 2012 IEEE First International Conference on , vol., no., pp.88-95, 
24-29 June 2012, doi: 10.1109/MobServ.2012.14 
[26] SCHEFFER, T., DECOMAIN, C., AND WROBEL, S. 2001. 
Mining the Web with active hidden Markov models. Data Mining, 2001. 
ICDM 2001, Proceedings IEEE International Conference on , vol., no., 
pp.645-646, 2001, doi: 10.1109/ICDM.2001.989591 
[27] Erlang Programming Language,  http://www.erlang.org/  
[28] JavaScript InfoVis Toolkit, http://philogb.github.com/jit/ 
[29] R. K. LOMOTEY AND R. DETERS, “Terms Extraction from 
Unstructured Data Silos”, Proc. of the IEEE 8th International Conference 
on System of Systems Engineering (SoSE), pp 19-24, June 2-6 2013, 
Maui, Hawaii, USA 
[30] T. GONZALEZ, P. SANTOS, F. OROZCO, M. ALCARAZ, V. 
ZALDIVAR, A. D. OBESO, AND A. GARCIA, “Adaptive Employee 
Profile Classification for Resource Planning Tool,” SRII Global 
Conference (SRII), 2012 Annual , vol., no., pp.544-553, 24-27 July 2012, 
doi: 10.1109/SRII.2012.67 
[31] A. McCALLUM, “Information Extraction: Distilling Structured 
Data from Unstructured Text”. Queue 3, 9 (November 2005), 48-57. 
DOI=10.1145/1105664.1105679 
 
978-1-4799-0786-1/13/$31.00 ©2013 IEEE 165
