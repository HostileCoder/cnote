   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 1
  Sensor and Computing Resource Management for a Small 
Satellite 
Abhilasha Bhatia, Kyle Goehner, John Sand, Jeremy Straub, 
Atif Mohammad, Christoffer Korvald 
Department of Computer Science 
University of North Dakota 
3950 Campus Road, Stop 9015 
Grand Forks, ND 58202-9015 
+1-701-777-4107 
abhilasha.bhatia@my.und.edu, kyle.goehner.2@my.und.edu, 
jonathan.sand@my.und.edu, jeremy.straub@my.und.edu, 
atif.mohammad@my.und.edu, christoffer.korvald@my.und.edu 
Anders Kose Nervold 
Department of Entrepreneurship 
University of North Dakota 
293 Centennial Drive, Stop 8098 
Grand Forks, ND 58202-8098 
+1-701-777-2135 
anders.nervold@my.und.edu 
 
 
Abstract—A small satellite in a low-Earth orbit (e.g., 
approximately a 300 to 400 km altitude) has an orbital velocity 
in the range of 8.5 km/s and completes an orbit approximately 
every 90 minutes. For a satellite with minimal attitude control, 
this presents a significant challenge in obtaining multiple 
images of a target region. Presuming an inclination in the 
range of 50 to 65 degrees, a limited number of opportunities to 
image a given target or communicate with a given ground 
station are available, over the course of a 24-hour period. For 
imaging needs (where solar illumination is required), the 
number of opportunities is further reduced. Given these short 
windows of opportunity for imaging, data transfer, and 
sending commands, scheduling must be optimized. In addition 
to the high-level scheduling performed for spacecraft 
operations, payload-level scheduling is also required. The 
mission requires that images be post-processed to maximize 
spatial resolution and minimize data transfer (through 
removing overlapping regions). The payload unit includes GPS 
and inertial measurement unit (IMU) hardware to aid in image 
alignment for the aforementioned. The payload scheduler 
must, thus, split its energy and computing-cycle budgets 
between determining an imaging sequence (required to capture 
the highly-overlapping data required for super-resolution and 
adjacent areas required for mosaicking), processing the 
imagery (to perform the super-resolution and mosaicking) and 
preparing the data for transmission (compressing it, etc.). This 
paper presents an approach for satellite control, scheduling 
and operations that allows the cameras, GPS and IMU to be 
used in conjunction to acquire higher-resolution imagery of a 
target region.  
TABLE OF CONTENTS 
1. INTRODUCTION ................................................. 1 
2. BACKGROUND ................................................... 3 
3. TECHNICAL APPROACH .................................... 4 
4. EVALUATION OF TECHNICAL APPROACH ........ 6 
5. FUTURE WORK AND CONCLUSIONS ................. 6 
REFERENCES ......................................................... 7 
 
1. INTRODUCTION 
Description of Payload 
The payload software onboard a small satellite is in charge 
of requesting image captures from the operating software. 
The operating software then returns a series of images to the 
payload system. Once received the images will either be 
mosaicked or analyzed for super-resolution depending on 
the job request. This process of mosaicking [1] the images 
together to create a larger stitched image will require 
analyzing each image individually using feature recognition 
algorithms [2] and the satellite IMU to align the images and 
combine them to form one large image that spans the 
requested area. If the job request was to create a super-
 resolution image the images will still need to be processed 
for their similar features but then the overlapping regions 
will have to be combined to form a higher resolution image 
[3] of the same region. In this way the satellite can increase 
the quality of very specific regions for better analysis at the 
ground station. 
Since the communication window with the ground station is 
very limited (in the range of 1200 baud) the images will 
require some type of compression before being sent to the 
ground station. Depending on the time allotted to the 
payload software for power consumption a simple 
compression algorithm may be used to save storage space 
and especially transfer time from the satellite to the ground 
station. With efficient compression the satellite can be much 
more efficient when transferring data. 
Components of Payload 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 2
 As demonstrated in Figure 1, there are four main 
components to the payload software: image registration, 
image mosaicking [1], super-resolution processing, and 
image compression. Each of these components plays a 
crucial role in the processing of images collected by the 
operating software and in the completion of the requested 
satellite job. 
  
Figure 1. The four main components of the payload 
software are image mosaicking, super resolution processing, 
image compression, and image registration. 
An important component to the payload software [4] will be 
the image registration. Image registration is the process of 
mapping out similar features in a set of images and then 
doing affine transformations on those images to place them 
in the same orientation and allowing the images to be easily 
processed relative to each other. Since both image 
mosaicking [1] and super-resolution processing require 
images to be accurately placed relative to one another the 
image registration plays an important role in the overall 
functionality of the payload software. 
Second is the image compression component. Image 
compression is the process of reducing the overall number 
of bits used to store the images. Once the images have been 
processed and are ready to be sent to the ground station the 
compression component will run a standard lossless image 
compression algorithm (such as JPEG or fractal 
compression) to make the image files smaller and more 
manageable when being sent over a slow network to the 
ground station. 
Next is the mosaicking component. Image mosaicking is the 
process of stitching multiple images together to create a 
larger image and reduce the overlapping components of a 
series of images. This process will be used to reduce the 
overall size and number of images that need to be sent from 
the satellite to the ground station. 
Finally the super-resolution processing component will be 
used to enhance specific regions of the satellite imagery 
when necessary or requested. Super-resolution processing is 
the processing of artificially increasing the resolution of a 
picture. This processing can be requested by the ground 
station to extrapolate extra data from the images.  
Together these four components allow the payload software 
to complete a given task sent from the ground station. The 
payload’s main purpose and functions will be processed 
through these components, optimized, and passed back to 
the main system where they can be queued up and sent 
down to the ground station. 
Functionality of Payload 
The main functionality of the payload software is to send a 
request for execution of a “take picture” command to the 
operating software. The operating software will then record 
the picture at the desired time, and pass the image frames to 
the payload software. The image frames will then be 
processed by the image registration component, then either 
processed through mosaicking or super-resolution, before 
being compressed by the compression component. The 
processed image frames are then sent back to the operating 
software for storage and potential transmission to the 
ground station. 
Image mosaicking solves two main issues of image 
processing: correcting geometric deformations, and stitching 
images together to reduce overlapping areas of multiple 
images. This process will be done by aligning images with 
their GPS and IMU data and then using image registration 
to find feature of the images that can be used to map the 
similar areas in the images to one another. Then the process 
can stitch the images together by removing the overlapping 
areas and creating a wide view image. 
Super-resolution is the process of artificially increasing the 
resolution of a picture. Multiple solutions exist for doing 
this, but the proposed satellite will focus on using four 
images to increase the resolution. It will do this by taking 
numerous images and using the GPS/IMU to determine the 
ordering of the pictures. The ordering will be the first image 
taken from the top will be one, the second on the top will be 
two, the first on the bottom will be three, and the second on 
the bottom four. From these images, image registration will 
find features to accurately determine the overlap on any two 
or more pictures. The satellite will then break down these 
images pixel by pixel and take a pixel from one and put in 
the top left of the new group of pixels that is the super-
 resolution image. The second pixel will take the same pixel 
as the first and put it half a pixel to the right of the first 
pixel.  
The third pixel will be the same pixel as the first and second 
 
 
 
Figure 2–Multi-Image Super-resolution uses four images 
taken of the same region/area. The pixels are matched up 
and then inserted next to each other in an image with four 
times the number of pixels of the original photos. This type 
of super-resolution can increase the original image quality 
by 1.0x to 2.0x. 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 3
 and place it half a pixel under the first pixel in the new 
image, and the last pixel will be taken from the fourth image 
and placed half a pixel to the right and half a pixel down 
effectively creating a rectangle of pixels. This new super-
 resolution image will be twice the size as the original 
overlapped section effectively doubling the resolution. 
Figure 1 shows the process of four 2x2 pixel images being 
made into one higher resolution image through super-
 resolution. The resulting super-resolution image may not 
always provide more detail, as the new picture is based off 
of the four original pictures, those pictures must differ in 
some perspective in order for the super-resolution image to 
show much change. The new image will also only be up to a 
maximum of twice the resolution of the original pictures. 
The purpose of image compression is to reduce the size of 
the image data in order to more efficiently store and 
transmit the image. The satellite image compression 
software will be using JPEG compression to reduce the size 
of the image while attempting to preserve the overall 
quality. To further compress the images, Huffman encoding 
(a lossless compression) will be applied to the JPEG files. 
Finally, Model Based Data Transmission will be utilized to 
effectively compress the transmission data being passed to 
the ground station, achieving significant improvements over 
standard transmission protocols [9]. The compression 
component of the payload software is the most used 
component but also one of the easier components to 
implement. 
2. BACKGROUND  
 Prior work on Mosaicking 
There has been a lot of research done on image mosaicking 
and the processes involved in creating seamless transitions 
between the stitched images. Much of this research is 
covered and re-analyzed in Bowne and Lowe’s paper [5]. 
This includes Automatic Panorama Straightening, Multi-
 Band Blending, Gain Compensation, and Bundle 
Adjustment. Automatic Panorama Straightening is a process 
in which the final image mosaic is straightened out to 
correct for the changes in camera angle that can cause a 
curved mosaic in the end.  
Multi-band blending is a technique to help reduce the edges 
between mosaicked images by correcting for vignetting and 
parallax effects due to camera motion and lens effects. Gain 
compensation is a method to create a constant gain across 
all of the images. This is easy for multiple images, even if 
the images are taken at the exact same location, and there 
are differences in gain and brightness. Gain compensation 
evaluates the overall gain of the images and evens it out as 
much as possible as to reduce inconsistencies. Bowne and 
Lowe [5] have set up a simple list to combine all of the 
above techniques and create crisp consistent mosaics: 
Input: n unordered images 
1. Extract SIFT features from all n images 
2. Find k nearest-neighbors for each feature using a k-d 
tree 
3. For each image: 
a. Select m candidate matching images that have the 
most feature matches to this image 
b. Find geometrically consistent feature matches 
using RANSAC to solve for the homography 
between pairs of images 
c. Verify image matches using a probabilistic model 
4. Find connected components of image matches 
5. For each connected component: 
a. Perform bundle adjustment to solve for the rotation 
?1, ?2, ?3 and focal length f of all cameras 
b. Render panorama using multi-band blending 
Output: Panoramic image(s) 
Prior work on Super-resolution 
When a camera captures an image, the light is funneled 
through the lens, and accumulated by the CCD sensor, the 
charge is shifted and recorded by an analog to digital 
converter where color values are extracted based off of 
interpolation of Beyer mask filter data. When light first 
passes through the camera, the image gets distorted, aliased, 
blurred, and noise is introduced [10]. This is what led to the 
introduction of super-resolution. Super-resolution takes 
multiple images and artificially increases the resolution of a 
picture. 
The goal when doing super-resolution is to get an image that 
provides more detail than the original individual images 
contained. There are several methods available to do super-
 resolution: neighbor interpolation, bilinear interpolation, and 
bicubic interpolation to name but a few. Nearest neighbor 
interpolation takes the nearest pixel to the interpolated point 
and makes it the same color, effectively enlarging the size of 
each pixel. Bilinear interpolation doubles the resolution of 
the image by assigning all the new pixels average color of 
the four closest pixels (see Figure 1). Bicubic interpolation 
is similar to bilinear interpolation, except it uses the nearest 
16 pixels and averages them out, while giving the nearest 
pixels more weight to change the color. Bicubic 
interpolation produces the sharpest image out of the three 
methods discussed [11]. 
The discussed forms of interpolation can help with multi-
 frame super-resolution. Multi-frame super-resolution takes 
images, identifies a common landmark, and combines the 
four images to make a new image with up to twice the 
resolution of the original. Interpolation can  aid in this by 
smoothing out pixels that are irregular, or pixels that do not 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 4
 match the other surrounding pixels. This adds a more 
constant color for groups of pixels within the super-
 resolution image.  
Prior work on Inertial Measurement Units 
Traditional image registration has been done strictly with 
feature matching between the images, but there has also 
been research into using Global Positioning System (GPS) 
and Inertial Measurement Unit (IMU) from UAVs to more 
easily match up images to one another. This can be achieved 
by having the changes in location and orientation of the 
camera recorded when the camera captures the images. 
Most such projects have focused on using very high quality 
IMU and GPS systems that return very accurate results. In a 
paper by Mitch Bryson et al. the topic of using small UAVs 
with lower quality GPS and IMU systems is discussed along 
with the benefits these systems can provide for the image 
processing. [12].  
They used the IMU and GPS to gather the position and 
altitude of the UAV and its trajectory. From the image data, 
point features are found and matched across the group of 
images. The position altitude map is then used with the 
feature-mapped images to form a more accurate mosaic in 
which the orientation of the UAV has been taken into 
account. This process of using GPS and an IMU to ease the 
processing of images onboard the CubeSat will help to 
reduce the time it takes to create the mosaics. 
The Purpose of Payloads on Satellites 
The payload of a satellite is the equipment in the satellite 
dedicated to execute the satellite's primary mission. These 
systems may include a variety of sensors, such as radio, 
infrared, visible, ultraviolet, x-ray, gamma ray, particle or 
field sensors [13]. These sensors collect the data for direct 
transmittal to the ground station or for further processing by 
the payload software before transmittal. 
Typically, the higher the quality data that is required for the 
purpose of the satellite, the larger the sensor will be. In the 
case of CubeSats on the other hand, payload space is 
extremely limited. Creative techniques such as significant 
post-processing of the data are thus utilized to maximize the 
quality of the data being delivered by the limited-in-size 
payload. As discussed in the introduction of this paper, the 
Open Orbiter payload system will utilize techniques such as 
image mosaicking and super-resolution to increase the 
overall quality of the data acquired, and reduce the amount 
of data needed to be transmitted to the ground station. These 
creative techniques can also be utilized in larger satellites to 
increase quality of the data without requiring hardware 
and/or size upgrades.  
3. TECHNICAL APPROACH 
The payload software onboard the small satellite will be 
used to complete the more computationally expensive tasks 
of the satellite: 
• Create a list of times when the satellite should 
collect image data to complete a certain task. 
• Create a mosaicked image from a set of images. 
• Create a super-resolution image from a set of 
images. 
• Use lossless compression to reduce the amount of 
data that needs to be transferred. 
Each of these tasks is required for the small satellite to 
efficiently collect and transfer high-resolution imagery or 
mosaicks to the ground station. 
Implications of Using Onboard IMU and GPS Data 
A satellite in low-Earth orbit is vulnerable to changes in 
perturbations that may have negative effects on the stability 
of the satellite. This in turn affects the input data to the 
satellite through external sources. In the case of CubeSats, 
the small size of these satellites renders them more prone to 
such changes/perturbations. The perturbations in satellite 
orbits can be created by a number of factors; some of which 
being the atmospheric drag, Attitude Determination and 
Control Subsystem (ADCS) generated movement, solar 
emission pressure and others. Solar emissions and ADCS-
 generated movement will fluctuate throughout the orbit – 
particularly when ADCS control is utilized (from the control 
reaction wheels). Atmospheric drag varies somewhat over 
time; however, it will change (additionally) during the 
lifetime of the satellite as its altitude decreases.  
A satellite that takes input as images from a camera attached 
to it and intends to build a clear imagery of the scenario 
requires being robust to the rotational and angular variations 
occurring. To compensate for these variations after the fact, 
it is proposed to use an IMU and a GPS to keep track of the 
orientation and position of the small satellite. Chon el al. 
states, “the position and orientation of the camera can be 
derived from GPS and IMU data with sufficient accuracy to 
allow direct georeferencing without the need for Ground 
Control Points” [1]. 
Determining the Image Capture Time 
The satellite will receive two GPS coordinates from the 
ground station as a task. The two coordinates represent the 
upper left and the lower right corners of a boxed region 
from which to collect image data. This task will be for a 
single image request, a mosaicked image request, a super-
 resolved image request, or both a mosaicked and super-
 resolved image request. Each request from the ground 
station will be analyzed by the satellite operating software 
and then passed to the payload software to be broken into 
small jobs for the operating software. Each job will consist 
of a specific time the satellite should capture an image. The 
image data can then be stored for later processing by the 
payload software. 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 5
 The process of determining when the satellite needs to 
capture images to complete the specified task is a mission 
critical software process and can be computationally 
expensive. The satellite needs to determine if the current 
region has been photographed recently, and if not, what is 
the earliest time it can being photographing that region. The 
current location (GPS) and velocity (IMU/GPS) of the 
satellite can be used to calculate when the satellite will be 
over the region of interest and at what interval images need 
to be captured in order to create a sufficient overlap for 
mosaicking or super-resolution. Since energy consumption 
is an important factor for a small satellite the payload 
software must determine optimal times for image capture. 
When creating mosaics, image overlap is necessary to find 
enough features to properly match regions of each image but 
less overlap means fewer images are required to cover the 
entire area requested by the ground station. A proper 
distance between each image capture is necessary to save 
energy consumption of the satellite while still allowing 
enough overlap for accurate feature recognition. 
Mosaicking with IMU Data 
Imaging depends on the factors whether an image, or 
sequence of images, is being captured from earth’s lower 
orbits or further away. The problem of distortion caused by 
this can be solved through an approach of mosaicking and 
utilizing IMUs. A question that still needs to be answered is 
whether an IMU can aid the system in determining the 
appropriate orientation and angular displacement of the 
camera onboard. This in turn could aid in determining the 
displacement, direction, and the positions of the consecutive 
images taken, with respect to one another. This in turn 
would aid in the construction of correct mosaics of the 
sequence of images. For instance: Let translational 
displacement between two overlapping images be S, angular 
displacement as ?, and the rotational displacement be 
another angle ?. If the IMU aids in determining values of 
these parameters, then theses values could be 
simultaneously decided for each consecutive image. The 
rotational displacement would determine the depth of the 
image, contributing to its 3-D measure. 
After determining the value of each parameter for each 
image, they are brought together according to their 
displacements and stitched by using various available 
algorithms, into the mosaic. 
As discussed above, it is critical for a satellite to be 
stabilized. In situations when its motion is not very 
stabilized, it must be efficient enough to render its geo-
 location information. By doing so, it would aid in 
identifying the correct location of the source of the images, 
of the satellite. The correct angles of the images, and even 
the depth of the objects can become difficult to determine. 
At this point, the role of an IMU can become invaluable in 
determining the attitude and direction of the satellite. An 
IMU is being used on the small satellite to increase the 
accuracy and efficiency of mosaicking and super-resolution 
algorithms. 
The IMU aids in the process of aligning images by 
providing information about how the satellite has changed 
attitude and direction between image captures. This would 
allow a mosaicking algorithm to more quickly match 
features in images with large rotation differences. For 
example if an image was taken and for some reason the 
satellite was rotationally displaced 90º between the next 
image capture the onboard IMU would be able to relay this 
information and the mosaicking or super resolution 
algorithm would be able to compensate for this change prior 
to using a more computationally expensive method. 
The addition of the IMU can potentially save a large amount 
of processing time for the limited onboard hardware 
resources. The small satellite will have very limited 
computation capabilities and battery life, this means if even 
a small amount of computational resources can been saved 
by collecting IMU data it could mean a monumental 
increase in overall satellite productivity. 
Image Sequencing and Feature Recognition 
Once the satellite collects the images, the payload software 
must determine the proper order of images to create the 
requested mosaick or super-resolved image. This is not a 
difficult process since GPS data, IMU data, and current time 
are collected along with the capture of each image. This data 
can quickly be used to determine the how the images align 
and overlap. The known overlapping regions of each image 
can be used to reduce the computations required for the 
feature recognition algorithm since it only needs to find 
features in overlapping regions. This process can help 
reduce the processing time and overall energy consumption 
of the satellite to boost satellite efficiency. 
Mosaicking Approach 
Mosaicking is the concept of stitching images sharing 
common regions, or, bringing together the overlapping 
regions of more than one image. The mosaicking done on 
the satellite is done to reduce the overall amount of data 
needing to be transferred by removing any overlapping 
regions in the images of the photographed area. In this way 
images can be mosaicked and a single image of the 
photographed area can be sent to the ground station. 
The mosaicking process involves feature correlation to be 
done between the overlapping regions of two or more 
images. With the IMU allowing for faster feature correlation 
a large number of images can be mosaicked using a feature 
recognition tool such as SIFT (Scale-Invariant Feature 
Transform).  
Super-resolution Approach 
Super-resolution is the concept of combining the a group of 
low resolution images of the same object to create a higher 
resolution image in the hopes of adding to the overall image 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 6
 quality. The purpose of the on the satellite is to allow for 
higher quality images from the small satellites onboard 
camera. 
The satellites super resolution will be similar to the 
mosaicking process in that it required a set of images to be 
matched by correlating unique features across the images. 
Once this is done we can super-resolve the images to create 
a new, higher quality image. By doing this onboard the 
satellite it reduces amount of data that needs to be 
transmitted to the ground station and thus increases satellite 
performance. 
Super-resolution and Mosaicking Approach 
The implementation of mosaicking with super-resolution is 
done with a goal of producing a final image with higher 
resolution. The super-resolution approach is used to 
accomplish this. A question that has yet to be answered is 
whether super-resolution would enhance the data quality of 
the overlapping regions in the image mosaics. According to 
Zomet, Peleg [8] the super-resolution algorithms make use 
of the image displacements on the overlapping regions. This 
in turn provides for a dense sampling, which restores high 
frequencies and improves resolution. 
Compression of Onboard Data 
The payload software will also be responsible for image 
compression on the satellite. This compression will take 
place after any large processing task such as mosaicking or 
super-resolution. Since the image will be transmitted from 
the satellite to the ground station using very slow data 
transfer rates (approximately 1200 baud) and transfer will 
only be available for very short periods of time, it is very 
important to consider the amount of data being transferred.  
It is important to preserve the image quality since the 
images collected at the ground station will most likely 
require careful analysis or will be further processed in some 
way. Because of this, the image compression used must be 
lossless. Methods such as fractal compression can be used to 
greatly compress the satellite images however the algorithm 
is highly anti-symmetric and can be very computationally 
expensive when compressing the images. This method 
would be very effective for transmitting the images however 
we must also consider the computational expense of fractal 
compression. Due to the limited satellite resources we must 
also consider the use of other lossless compression 
algorithms. 
 
4. EVALUATION OF TECHNICAL APPROACH 
This paper has presented an approach for satellite control, 
scheduling and operations that allows the cameras, GPS and 
IMU to be used in conjunction to acquire higher-resolution 
imagery of a target region. It reviewed the techniques that 
are best suited for this task in light of power budget, transfer 
time, image quality and computing time considerations. 
Strategies for balancing onboard preprocessing and transfer 
time have been reviewed and a selection methodology has 
been discussed. The value of the IMU and the GPS sensors 
in decreasing processing requirements was also discussed.  
Beyond the work presented, several key areas of 
consideration remain.  This includes consideration of the 
tradeoffs between image quality, quantity and timeliness.  A 
framework that can be used to determine a highly optimized 
approach for determining when to capture imagery, when 
and what to transmit, and techniques for conserving power 
and computing cycles is also required. Significant ground-
 based processing must be incorporated to prepare the 
imagery and associated data for transmission to data users. 
Repackaging and region-slicing considerations and 
techniques to optimize the data for public and secondary 
research purposes must be incorporated. 
5. FUTURE WORK AND CONCLUSIONS  
Further work will look into the algorithm that will be 
utilized for aligning the panorama into various panoramic 
images and then applying super-resolution on each of the 
panoramic aligned strip.  There are various other super-
 resolution techniques that could be utilized. Starting with 
the color image super-resolution, with the help of coloring 
pixels in the overlapping regions, similar features could be 
distinguished. The use of fast-Fourier transforms (which are 
computationally economical) could determine the behavior 
of various frames of the scene or in a mosaic, based on the 
frequency matching criteria. As discussed before, the use of 
scale invariant feature extraction (SIFT) would be one of the 
prominent approaches to look at. Figure 3 illustrates a 
mosaic image comprised of 6 separate frames. 
Figure 3–SIFT Feature Matching 
The above has presented a framework that can be used to 
determine a highly optimized approach for determining 
when to capture imagery, when and what to transmit and 
techniques for conserving power and computing cycles. 
Also discussed is the ground-based processing that is 
required to prepare the imagery and associated data for 
transmission to data users. Repackaging and region-slicing 
considerations are discussed as are techniques to optimize 
the data for public and secondary research purposes. 
The lesson of the OpenOrbiter spacecraft mission resource 
management is of main importance for the operational 
robustness of entire mission, both for students and 
researchers. The approach laid forth in this paper can 
acquiesce functional and edifying outcomes in two ways. 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 7
 From an edification position, the project participants gain 
“real-world” understanding of responding to the needs of 
future employers. From a programmatic position, the lack of 
payload utilization introduces lack of mission relevance. 
REFERENCES  
 
[1] J. Chon, H. Kim, C. S. Lin. Seam-line 
determination for image mosaicing: A technique 
minimizing the maximum local mismatch and the 
global cost. ISPRS Journal of Photogrammetry and 
Remote Sensing, Volume 65, Issue 1, January 
2010, Pages 86-92 
 
[2] G. Erus, Nicolas Loménie. How to involve 
structural modeling for cartographic object 
recognition tasks in high-resolution satellite 
images? Pattern Recognition Letters, Volume 31, 
Issue 10, 15 July 2010, Pages 1109-1119 
 
[3] Y. Ling, M. Ehlers, E. L. Usery, M. Madden. FFT-
 enhanced IHS transform method for fusing high-
 resolution satellite images. ISPRS Journal of 
Photogrammetry and Remote Sensing, Volume 61, 
Issue 6, February 2007, Pages 381-392 
 
[4] A. Addaim, A. Kherras, E.B. Zantou. DSP 
implementation of integrated store-and-forward 
APRS payload and OBDH subsystems for low-cost 
small satellite. Aerospace Science and Technology, 
Volume 12, Issue 4, June 2008, Pages 308-317 
[5] Matthew Brown and David G. Lowe. Automatic 
Panoramic Image Stitching using Invariant 
Features.  International Journal of Computer 
Vision. Volume 74, Number 1 (2007), 59-73 
 
[6] D. Turner, , A. Lucieer, & C. Watson, (2012). An 
Automated Technique for Generating Georectified 
Mosaics from Ultra-High Resolution Unmanned 
Aerial Vehicle (UAV) Imagery, Based on Structure 
from Motion (SfM) Point Clouds. Remote Sensing, 
4(5), 1392-1410. 
 
[7] L. Qingyuan, L. Wenyang, Z. Lei, W. Jinling, and 
L. You. "A New Approach To Fast Mosaic UAV 
Images".  International Archives of the 
Photogrammetry, Remote Sensing and Spatial 
Information Sciences. Vol. XXXCIII-1/C22  
 
[8]   A. Zomet, & S. Peleg. (1998, October). Applying 
super-resolution to panoramic mosaics. In 
Applications of Computer Vision, 1998. WACV'98. 
Proceedings., Fourth IEEE Workshop on (pp. 286-
 287). IEEE. 
[9]   J. Straub, “Model Based Data Transmission: 
Analysis of Link Budget Requirement Reduction” 
Communications and Network, 2012. 
[10]  S. C. Park, M.K. Park, & M. G. Kang, (2003). 
Super-resolution image reconstruction: a technical 
overview. Signal processing Magazine, IEEE, 20(3), 
21-36. 
[11]  Cambridgeincolour.com. N.d.  Digital Image 
Interpolation. [Online]. Available: 
http://www.cambridgeincolour.com/tutorials/image-
 interpolation.htm 
[12]  M. Bryson, A. Reid, F. Ramos, & S. Sullarieh 
(2010). Airborne vision-based mapping and 
classification of large farmland environments. 
Journal Of Field Robotics, 27(5), 632-655.  
[13]  Orbital. “Science, Environmental and Technology 
Satellites – Reliable Spacecraft Enabling Affordable 
Missions” (2012). Corporate brochure.  
Biographies 
Abhilasha Bhatia is a graduate student in the Department 
of Computer Science at the University of North Dakota. She 
is a committee member of Student Association of India and 
also actively involved with Women in Science group at 
UND. She holds a Bachelor of Technology degree in 
Computer Science from Gautam Buddh Technical 
University, India. 
 
Kyle Goehner is an undergraduate student pursuing a BS in 
Computer Science with a minor in Mathematics at the 
University of North Dakota.  While at UND, Kyle has 
received numerous honors including the competitive 
Odegard Scholarship (2011), the Microsoft Scholarship 
(2011), the Fetter Scholarship (2010) and the UND 
Community of Learners Scholarship (2009-2013).  Kyle’s 
team placed in the top 10 at the Midwest Instruction and 
Computing Symposium Programming Competition.  He is 
active in the Association for Computing Machinery (ACM), 
serving as the chapter president from 2011 to 2013. 
 
John Sand is an undergraduate student in the Department 
of Computer Science at the University of North Dakota.  
 
Jeremy Straub is a PhD student in the Department of 
Computer Science at the University of North Dakota.  He 
currently serves as the Student Program Director for the 
North Dakota Space Robotics Program.  His research is 
presently focused on artificial intelligence for space 
applications.  Before returning to pursue doctoral studies, 
Mr. Straub held progressively responsible positions in 
industry.  He has over 10 years professional experience in 
developing and managing the development of cutting-edge 
commercial systems, including North America’s first 
commercial traffic-adaptive navigation system.  Jeremy 
holds a BS in Information Technology, a BS in Business, a 
graduate certificate in Space Studies, an MBA and an MS in 
Computer Systems and Software Design.  He is a member of 
the AIAA, IEEE, SPIE and SSPI. 
   978-1-4673-1813-6/13/$31.00 ©2013 IEEE 
 8
 Atif Farid Mohammad is an MIT certified Systems 
Architect and currently a PhD student in the Computer 
Science department at the University of North Dakota 
working on Cloud Computing Security. Atif has more than 
sixteen years of experience in software engineering, 
professional business systems analysis, design, application 
development and staff management for diversified business 
and educational organizations. He is a member of IEEE, 
ACM and AST. 
Christoffer Korvald is a MS student in the Department of 
Computer Science at the University of North Dakota. 
Christoffer is the President of the local chapter of the 
Upsilon Pi Epsilon Honor Society. He is currently the 
president of the Association of Norwegian Students Abroad 
- USA, which has over 1500 members. Christoffer holds a 
BA in Computer Science with a Software Engineering 
specialization from the University of North Dakota. He is 
also the Associate Director of Software for the Open 
Orbiter Satellite Initiative. 
Anders Kose Nervold is an undergraduate student at the 
University of North Dakota pursuing a BA in 
Entrepreneurship with a minor in Space Studies. Anders is 
currently serving as the Associate Director for 
Communications, Outreach and Policy for the Open Orbiter 
Satellite Initiative. While at UND, Anders worked as a 
console operator for the International Space Station 
Agricultural Camera (ISSAC).  In 2012, Anders and his 
business partner claimed the 1st prize in the GIANTS 
international business plan competition for their planned 
service venture in the aerospace industry.  Anders is 
currently serving as the treasurer for the nationwide student 
organization, the Association of Norwegian Students 
Abroad – USA, which has over 1300 members.  He has also 
served as the local president for the Association of 
Norwegian Students Abroad and as the treasurer for the 
Interfraternity Council.  He was awarded the competitive 
Mueller Scholarship in 2012 and the Lillian Elsinga 
Outstanding Student Leader Award in 2011.  Anders is also 
a member of the Dakota Space Society and mentors other 
international students at UND. 
 
 
 
