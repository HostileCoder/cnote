Automatic Analysis of Large Data Sets:
 A Walk-Through on Methods from Different
 Perspectives
 Marcus Hilbrich, Matthias Weber, Ronny Tschu¨ter
 Center for Information Services and High Performance Computing
 Technische Universita¨t Dresden, Germany
 {marcus.hilbrich, matthias.weber, ronny.tschueter}@tu-dresden.de
 Abstract—Analyzing data is one of today’s hot topics. A
 complete list of fields of research and buzzwords associated
 with automatic analysis would extend beyond this document.
 The importance of this topic stems from the amount of data
 currently produced in research, engineering, and other fields.
 The size of these data sets renders manual analysis infeasible.
 Automatic analysis methods are required to cope with the data
 sets produced. The algorithms for filtering, categorization, and
 analysis have a long tradition and are manifold. This raises the
 question for the best algorithm. The authors of this paper give
 an overview about manifold automatic analysis approaches along
 with a classification of these approaches with regard to three
 different fields of research.
 Keywords—comparison, monitoring, visualization, analysis,
 data mining, clustering, genetic algorithm, correlation, machine
 learning, sequence alignment, graph search, resilience
 I. INTRODUCTION
 In our daily work in the fields of monitoring, tracing,
 profiling, and analysis of grid, cloud, cluster and HPC systems
 we see an ever-increasing amount of data. These are, e.g.,
 monitoring data collected on large numbers of sequential
 programs as well as tracing data generated by massively
 parallel application runs. Furthermore a lot of other disciplines
 like life-sciences, astrophysics, or text analysis have to deal
 with a rising amount of data. Consequently, one could assume
 that comparing data sets in an automatic or semi-automatic
 fashion is a common task and categorizing data is just a matter
 of selecting the appropriate algorithm. Yet after some research
 we had to realize, that there is no ready-for-use algorithm
 available. Subsequently, we extended our research to cover
 more literature, started discussions and concluded that data
 comparison is not as easy as we hoped for. Contrary to the
 large amount of related work in this field, no generic ready-
 to-use algorithm, like for number searching or sorting, is avail-
 able. An adoption to the respective problem case is necessary
 and the most suitable algorithm needs to be identified.
 In this paper we focus on automatic methods for identifi-
 cation of irregular or unusual behavior. Irregular data differs
 from usual, often repeating and already analyzed sets of data.
 This data is of special interest and needs to be selected for
 further manual analysis. This identification can be realized by
 comparison of all data sets against a reference. A reference can
 be, e.g., a selected single job or artificially generated from his-
 torical behavior. Data with high dissimilarity to the reference
 is identified as irregular. This process can dramatically reduce
 the amount of data which needs to be analyzed manually.
 Subsequently, the time and attention of the analyst is used more
 efficiently, allowing a deeper and more accurate evaluation
 of occurring problems and faults. Additionally, irregularities
 caused by jobs or system components in complex job execution
 systems, like HPC, Grid, and Cloud systems, can be found
 automatically and visualized transparently.
 The remainder of this paper is organized as follows. In
 Sec. II we describe our analysis problems. We give an overview
 of common visualization techniques for the analysis of data
 sets in Sec. III. In Sec. IV we present a set of automatic
 analysis methods and evaluate these methods with regard to
 our problem cases in Sec. V. In Sec. VI we summarize our
 contributions and describe future work.
 II. FIELDS OF INTEREST
 Each author works on a different field of research that
 requires to find irregularities, compare data sets to identify
 discrepancies and variations, or to categorize data. Following
 we give a brief introduction to these three fields of research.
 A. Job-Centric Monitoring in Distributed Computing Environ-
 ments
 For job-centric monitoring we use a grid-based monitoring
 system called AMon [44] utilizing the monitoring infrastruc-
 ture SLAte [26], [27]. We are looking for a way to present
 the monitoring data in a more meaningful way than to merely
 show thousands of bars and lines where irregularities are easily
 overseen. Yet we are also looking for general methods that
 can be directly adapted to other environments working with
 large job numbers. Such environments could be large cluster,
 HPC, or cloud systems, in particular government, hybrid, and
 federated clouds.
 Monitoring data is recorded using variable time inter-
 vals, ranging from seconds to minutes. Used are common
 monitoring techniques [51] without privileged access rights.
 The recorded data contains information about the job like
 consumed CPU time, CPU load, and main memory. Also
 recorded is information about the executing system like free
 main memory or the state of the storage systems. In addition,
 scheduling information such as time, date, and wall-clock time
 of the job is collected.
 2013 International Conference on Cloud Computing and Big Data
 978-1-4799-2829-3/13 $26.00 © 2013 IEEE
 DOI 10.1109/CLOUDCOM-ASIA.2013.47
 373978-1-4799-2830-9/14 $31.00 © 2014 IEE
B. Tracing of Massively Parallel Applications
 Performance optimization is essential in the design of
 scalable parallel applications. With increasing complexity and
 size of today’s HPC-machines this task is getting increasingly
 important. The identification and elimination of bottlenecks
 and inefficiencies is mandatory to achieve scalability above
 tens of thousands of processes. Tracing has proven to be
 a powerful approach for performance optimization. Using
 tracing application behavior is recorded in detail by storing a
 series of events from an application run. Events could include
 entering or leaving a function, or sending MPI messages.
 Each event consists of a time-stamp along with relevant data,
 e.g., function name, or bytes of data transmitted. The detailed
 performance information included in traces make them very
 suitable for performance analysis. For instance they can be
 used to detect synchronization delays, communication ineffi-
 ciencies, or varying performance behavior over time. However,
 this advantage also presents a challenge. Parallel application
 runs can easily produce extremely large traces, exceeding
 hundreds of gigabytes [50]. Manual analysis of large trace
 volumes remains challenging, even with help of analysis tools
 like Vampir [5] or Scalasca [70]. Currently, users must rely on
 visual inspection of event traces, which is cumbersome and
 error-prone to say the least.
 C. Dealing with Faults in HPC Systems
 Several studies [4], [12] agree that the number of compo-
 nents in future computing systems will increase. The studies
 also predict that the failure rate of single components will not
 improve. As a result the dependability of the whole system
 will decrease and the probability of faults cannot be ignored
 any longer. Our goal is to detect faults in large data sets
 such as system log files, hardware monitoring data, application
 traces, and profiles. Furthermore, we want to understand and
 predict the effects of these faults on applications performance
 to enable developers to implement efficient error handling
 methods.
 Usually computing systems show correlated failures. In
 other words, an error often implies further errors. As a result,
 we not only have to detect single errors but rather find
 correlations between multiple faults and generate models for
 these error chains. Finally we combine the resilience data with
 application performance data to determine the effects of a fault
 on applications performance. For recording performance data
 we use established techniques like tracing and profiling.
 III. VISUALIZATION TECHNIQUES
 The most common method to analyze data is manual
 inspection by the analyst. Manual inspection is the method
 of choice when it is not clear how to obtain the desired
 information automatically, for instance, analyzing the root-
 cause of an error (during a job execution or a machine crash)
 or optimizing a process.
 Today most visualization tools provide graph and statistic
 displays. Graph displays usually show one or multiple param-
 eters over time. Some versions use color-coding to present
 more information on the available screen space. Fig. 1 shows
 the GUI of the tool AMon [44] as an example of a color-coded
 display. Each bar represents an individual job with a measured
 Fig. 1. Screen-shot of the AMon-GUI showing monitoring data of multiple
 jobs (one bar per job) with a color-coded representation of the consumed
 memory of the individual jobs
 parameter, e.g., used memory, in a color-coded fashion. This
 method is only scalable to hundreds of jobs, not only because
 of the limited screen space. The more data to be visualized
 the more challenging it gets for the analyst to find relevant
 information or correlations in reasonable time.
 Another strategy is to reduce the amount of data by
 accumulation. However, data reduction comes along with the
 risk of losing relevant information. Typical representations of
 accumulated data are profiles and statistics. Although profiles
 and statistics are more scalable with respect to available screen
 space, their ability to identify abnormal behavior is limited.
 IV. ANALYSIS METHODS
 Following we describe a selection of algorithms and cat-
 egories of algorithms which appear to be suitable for our
 filtering and analysis challenges. This selection is based on
 experience, discussions with scientists from various fields, and
 literature research. It covers a wide range of algorithms and
 provides an overview of solving strategies applicable to a large
 number of analysis problems from multiple research areas.
 A. Clustering Algorithms
 Clustering algorithms divide data into groups (clusters).
 The resulting groups should be meaningful and facilitate
 understanding and exploration of the data. However clustering
 itself is a difficult action and is based on many assumptions and
 contexts. As a result many differing clustering algorithms have
 been developed. One of the most simple and known clustering
 algorithm is k-means [25], [43], [48]. k-means partitions the
 data in a number of Voronoi cells by minimizing. It assign each
 data point to the cluster with the nearest mean. The number of
 the cells (clusters) k needs to be known a priori. To guide the
 choice of k the tool silhouette [56], [63] is helpful. It measures
 and allows to compare the cluster quality for various numbers
 of k. An adaption of k-means is the k-medoids algorithm [34],
 [35]. In contrast to the k-means algorithm, which computes
 cluster centers from data points, k-medoids chooses data points
 as cluster centers. This makes the algorithm more robust to
 noise and outliers. Both algorithms have a tendency to produce
 374
clusters of the same size, which might not be appropriate for
 all data sets. A different clustering approach is applied by
 the DBSCAN algorithm [14]. This algorithm builds clusters
 using the density of data points. Very similar, close to each
 other, data points build a cluster. The algorithm can produce
 clusters of arbitrary shape and size and is capable of identifying
 noise points. A complete taxonomy of clustering techniques is
 provided by Jain et al. [32], [33].
 All described clustering algorithms are based on points in
 n-dimensional space which forbids a direct application using
 measurement series data. A transformation from series of
 measurements to n-dimensional points, e.g., by compression
 methods, is required. There are various algorithms to realize
 this. One example are Fourier-coefficient-based methods which
 tend to focus on frequency information of time series [16]. The
 wavelet-based approach described by numerous authors [30],
 [58], [62], [66] additionally includes timing information. A
 stepwise approximation approach is described by several au-
 thors [36], [65].
 The combination of clustering algorithms and compression
 is a very generic method and can be used for all kinds of time
 series data. For instance Gavrilov et al. [21] use it to analyze
 the stock-market.
 Considering the large set of available solutions, the most
 challenging part is selecting the most adequate algorithms
 for clustering and compression along with identifying good
 parameters. Only properly adapted and configured algorithms
 will produce meaningful groups out of the input data.
 B. Cross-Correlation
 Correlation functions, known from the field of signal
 analysis [67], calculate the similarity of two functions. The
 cross-correlation function is defined as follows:
 (f1  f2)(?) =
 ∫
 f1(t) · f2(t + ?) dt (1)
 ? denotes the offset between the functions f1 and f2. There are
 also adaptations for discrete signals available and it is possible
 to adapt the continuous function to non-discrete sequences1 of
 measurements by using interpolation.
 A typical application for cross-correlation is to determine
 the time-based shift of two signals. An example is shown
 in Fig. 2. x1(t) is the transmitted signal while x2(t) is the
 received signal. To determine the time shift between both
 signals (e.g., to calculate the distance the signal traveled for
 usage in radar systems) the cross-correlation is calculated.
 The maximum value of the cross-correlation indicates the
 corresponding value of ? , which is the time shift between f1
 and f2.
 The classical usage of cross-correlation allows to align
 two functions with one arbitrary offset. For more complex
 scenarios containing dynamic changes of the offset and extra
 loops with repeating sequences a transformation of one of the
 functions is needed. This transformation can be realized by
 applying a defined fixed offset. Consequently, the offset in
 the cross-correlation can be removed by defining ? = 0. This
 1Non-discrete sequences are series of measurements where it is not guar-
 anteed that the measurements are taken at constant time intervals.
 Fig. 2. Example of two similar, non-identical functions shifted by time ?
 leads to an optimization problem. The cross-correlation has
 to be maximized by finding a transformation respecting the
 dynamic time shift caused by altering input data due to, e.g.,
 heterogeneous hardware (CPU or memory speed) or system
 noise. Without this transformation the cross-correlation result
 would be useless as similarity metric.
 One strategy to determine the dynamic time shift of a
 complete time series is educated guessing. Educated guessing
 uses characteristic points like fast rising CPU usage, starting
 of jobs, or writing output to a file. It matches corresponding
 points in both series for a coarse alignment and recalculates
 the cross-correlation for each pair. Depending on the cross-
 correlation result the respective pair of corresponding points
 is retained or discarded. Additional optimization strategies are
 genetic algorithms or machine learning.
 C. Genetic Algorithms
 Genetic algorithms [64] evolve a start set of solutions
 towards better solutions. They describe a optimization heuristic
 inspired by natural evolution. Goal is to find a solution, called
 a genome, with a high fitness [29]. A genome consists of
 a sequence of parameters which are called characters that
 represent a solution to an arbitrary problem. A high fitness
 classifies a particular genome providing a better solution then
 other genomes.
 The first step in a genetic algorithm is the definition of
 a start set of genomes, a population. The size of the first
 population has to be carefully balanced. If the size is too
 large, a lot of computing resources are needed to process the
 evolution step from population to child population. Also more
 evolution steps are needed to produce good results. Otherwise,
 if the population is too small, the searched parameter range is
 too limited and the result quality might seriously deteriorate.
 Hence, the size of the population is one of the fundamental
 parameters [23] and needs to be carefully chosen.
 Two common strategies exist for the selection of the
 genomes (solutions) for the first population. One strategy is
 to randomly generate a first population [64]. This enables a
 search over the whole parameter range but tends to require
 large populations what poses high demands on computing
 power. The other strategy [11] uses an already found solution
 set as base for further optimization. This reduces the size
 of the population along with the required computing power
 dramatically but also reduces the searched parameter range.
 To evolve from one population to the child population,
 containing better solutions (genomes), the concepts of selec-
 tion, inheritance, and mutation are applied. Selection is the
 375
first step in the evolution process from a population to a child
 population. Therefore the genomes are ranked. This is done by
 testing how well each genome solves the optimization prob-
 lem. Thus, a function calculating the quality of the solution
 produced by a genome is required. This function also defines
 the target of the optimization and has enormous influence on
 the found solution. After the ranking the best genomes, usually
 the best 50%, are selected as source for the generation of a
 new population.
 After the selection the inheritance step generates a new
 population using the selected genomes. There are various
 methods to combine genomes to new ones. A simple solution
 is to randomly create pairs of genomes and to combine the
 first half of one genome with the second half of the other
 genome. The number of characters taken from the first genome
 is also chosen randomly. The order of characters in a genome
 might influence the computed solution [23]. For instance the
 parameter A might improve a solution only if parameter B
 has an appropriate value. In such case both parameters must
 be developed together and the inheritance step should tend to
 take both parameters from the same genome. In the end of the
 inheritance the child population needs to have the same size
 as the original population.
 The last step to complete the evolution phase is mutation.
 Therefore some genomes are chosen randomly and one or more
 characters are altered. The number of mutations depends on
 the algorithm configuration. If the number is too small, the
 algorithm behaves like a hill climbing search [22]. A too high
 mutation rate results in a random search and can prevent a
 stabilization of the population.
 The complete evolution process requires many repetitions.
 The number of repetitions can be either set by the user or the
 evolution process is repeated until the population is stable. In
 a stable population most or all genomes are the same.
 The result of the genetic algorithm is a dominant or the
 fittest genome in the last population. Why one particular
 genome is chosen as result cannot be told [2]. It is not
 guaranteed that the result is reproducible by a re-run of the
 algorithm. There is also no guarantee for the globally best
 solution.
 D. Sequence Comparison
 Comparing sequences is heavily done in the field of
 bioinformatics using sequence alignment techniques. Goal is
 to compare gene and protein sequences. For instance, to find
 genes in large genome databases spanning several species. The
 hope is that the knowledge of many occurrences of a particular
 gene in nature helps in understanding its functionality. The
 difficulty is that genes are likely to mutate across species
 and along the evolutionary process. That makes them hard
 to spot since searching for direct matches is not sufficient.
 The alignment algorithms need to identify similar sequences.
 Mutated gene sequences may consist of equal areas, having
 the same sequence of nucleotides in both genes. Areas can
 be different if they contain different nucleotides at the same
 sequence position. The third possibility is a missing section,
 called a gap, in one sequence.
 The alignment of two sequences is computed using dy-
 namic programming that finds the optimal alignment for
 
 
 
 
 	
 

 

 

 

 

 

 
  	
 
  
 
  
 Fig. 3. Alignment of sequence A and B
 arbitrary sequences [3], [24], [53]. For example consider an
 alignment of the following two sequences:
 Sequence A: m c a c m a m
 Sequence B: m c a c b c m b m
 We use the following notation: Sequence A is of length M
 and sequence B of length N . The ith event in A is Ai and
 the jth event in B is Bj .
 The dynamic programming algorithm separates the full
 pairwise alignment problem into independently optimizable
 sub-problems and then evaluates alignments with scores. It
 uses a recursive scoring scheme to find the optimal alignment
 of sub-problems. The scoring scheme is adapted to the individ-
 ual comparison case. A typical example for arbitrary sequences
 is as follows:
 ?i,j = 2 Match Score
 ?i,j = ?1 Mismatch Score
 ? = ?1 Gap Score
 ?i,j = 2 is chosen if position Ai is the same as Bj , otherwise,
 if Ai differs from Bj then ?i,j = ?1 is used. In case that either
 Ai or Bj are aligned to a gap the gap penalty of ? = ?1 is
 applied. Based on the scores, we define the following recursive
 scoring scheme for a dynamic programming matrix P :
 Pi,j = max
 ??
 ?
 Pi?1,j?1 + ?i,j , Match/Mismatch
 Pi,j?1 + ?, Gap in Sequence A
 Pi?1,j + ?. Gap in Sequence B
 We find the optimal alignment by computing the path with
 the highest score through the matrix P from PM,N to P0,0. We
 show the alignment result for our example using our algorithm
 in Fig. 3.
 The classical dynamic programming algorithm has
 quadratic complexity with respect to the sequence lengths,
 O(M · N), in time and memory. This renders the align-
 ment of large sequences impossible due to the limited size
 of available main memory. A modification of the algorithm
 proposed by Hirschberg [28] computes the optimal alignment
 with quadratic time complexity but with only linear memory
 complexity with respect to the longest sequence.
 A similar approach is proposed by Myers [52]. His O(ND)
 algorithm is used in the Unix diff tool to compare text input.
 Unlike the dynamic programming approach the algorithm does
 not use a scoring scheme. Instead it searches the shortest path
 through the edit graph of the two sequences. The shortest
 path identifies equal and different areas of the sequences.
 Compared to the dynamic programming approach this algo-
 rithm is less flexible. Due to the missing scoring scheme
 it can only decide between two states, equal and different.
 376
The dynamic programming algorithms can work with arbitrary
 states by assigning different scores to possible combinations of
 sequence items. The advantage of the O(ND) algorithm is its
 performance compared to dynamic programming algorithms.
 The performance of the O(ND) algorithm is dependent on
 the result of the comparison. Two almost equal sequences
 can be compared with nearly linear time complexity. The
 more the sequences differ the slower the O(ND) algorithm
 gets. Two completely different sequences require, like dynamic
 programming, quadratic time complexity.
 E. Pattern Matching and Intrusion Detection
 Intrusion detection is a field of research which takes the
 challenge to detect attacks and intrusions into computing sys-
 tems and networks. The used methods and algorithms aim to
 detect patterns that indicate an attack. Often intrusions follow
 already seen patterns. Consequently, many implementations
 for intrusion detection look for these patterns. Examples for
 such implementations are Snort [55], STATE [31], IDES [46],
 IDIOT [38], and Bro [54]. A fuzzy definition of intrusion
 patterns is applied by Dickerson [10].
 A special variant of an intrusion is a worm. A worm tries
 to replicate itself and infect additional systems. This behavior
 forms a known pattern with only little dependence on the actual
 worm. The detection of such behavior is described by several
 authors [37], [47], [60], [68]. However, the detection of a worm
 is bound to a defined scenario, an internal computer network
 connected to an external one. This complicates the adaption to
 other fields of research.
 The search for already known patterns does not allow to
 find new, not yet understood behavior or attacks. To mitigate
 this disadvantage additional concepts have been developed
 to cope with new or changing intrusions. One of the early
 concepts is to analyze the statistic of occurring events as
 described in Sec. IV-F. Another method is machine learning
 which is presented in Sec. IV-G.
 F. Statistic of Events
 The basic idea of this approach is the comparison of
 statistics of events. A description of this strategy is given by
 Denning [9]. Later on several authors extended this concept
 [39], [59].
 In this approach the first step is to define events. An event
 can be the direct occurrence of an action like a log-in attempt
 into a system or a derivative value like a high network load
 for some seconds. The second step is to compare the rate of
 these events against a defined expectation. The expectation is
 based on historical data and can be simple minimal or maximal
 rates or distributions over time. This approach also requires the
 adaption of the expectation to changing user behavior.
 G. Machine Learning
 Machine learning as described in the context of intrusion
 detection [7], [40]–[42] uses a self-learning system. The sys-
 tem is trained with historical data. The training sets teach the
 system how to distinct intrusions from normal user behavior.
 After the training phase the skilled system is used to detect
 intrusions.
 Machine learning can also be used in other fields of re-
 search. We are interested in using machine learning to distinct
 normal from irregular behavior.
 For a non-expert in the field of machine learning it is
 challenging to select a good algorithm for the actual problem
 scenario. Also the preparation of sufficient training data is
 cumbersome and error-prone. After the training phase it is
 recommended to test whether the training was successful.
 Therefore, in addition to the training data, also test data sets
 are required.
 There are additional (self-)learning algorithms available.
 They are in general similar to machine learning. Neural
 network based algorithms are described in [8], [47]. Agent
 based methods can be found in [1], [61].
 H. Tree and Graph Search
 Relationships and dependencies between individual events
 in data sets can be modeled as trees or graphs. This is used for
 instance to organize databases or to construct XML documents.
 Due to enormous research effort in the area of tree and
 graph search algorithms both data structures can be queried
 efficiently today.
 In general, tree and graph search algorithms are differenti-
 ated into depth-first and breadth-first methods [15]. However,
 processing the whole data set is impractical at large-scale.
 In such case heuristics improve the time to find a satisfying
 solution [71]. Heuristics do not guarantee to find the optimal
 solution. Nevertheless, this constraint can often be accepted.
 There are also algorithms which rely on adjustments by
 the user to guide the process of finding a solution for a given
 problem. These approaches are similar to machine learning
 described in Sec. IV-G.
 V. EVALUATION
 Following we provide an evaluation of the methods pre-
 sented in Sec. IV. Since we are interested in several fields
 of research we divide this section according to our fields of
 interest as described in Sec. II. This also allows to evaluate
 the methods in the actual problem context. Furthermore, we
 provide a summary of the evaluation in Table I.
 A. Series of Measurements
 Job centric monitoring requires the analysis of measure-
 ment series. Where a series of measurements represents the
 collected monitoring data of one job. A measurement point in
 a series consists of a time-stamp along with relevant character-
 istics about the job itself (e.g., consumed CPU-time) and the
 respective computing resource (e.g., free main memory).
 Clustering algorithms can be applied to measurement series
 in general. Necessary for clustering is a prior compression of
 the time series data. Subsequently, it has to be ensured that the
 compression does not eliminate relevant information. However,
 with the goal of finding unknown anomalies it is hard to
 distinguish relevant from non-relevant information at this stage
 of the analysis. Also the clustering algorithm parameters have
 to be configured according to the actual scenario. Finally, self-
 learning clustering algorithms, e.g., based on machine learning
 377
TABLE I. EXPECTED USEFULNESS OF ANALYZES METHODS FOR THE
 THREE TOPICS OF RESEARCH
 MONITORING TRACING RESILIENCE
 Clustering Algorithms ? ? ?
 Correlation ? ? ?
 Genetic Algorithms ? ? ?
 Sequence Comparison ? ? ?
 Pattern Matching ? ? ?
 Statistic of Events ? ? ?
 Machine Learning ? ? ?
 Tree and Graph Search ? ? ?
 ? solves problem at least partially and is already in usage
 ? very promising algorithm
 ? probably usable with strong adaption
 ? does not fit well
 strategies, look most promising. They are also the most com-
 plex variants requiring considerable effort for adaption to new
 problem cases.
 Cross-correlation appears to be a direct match to identify
 irregular measurement series. The challenge is to optimize the
 algorithm to avoid false-positives caused by heterogeneous
 systems with, e.g., different CPU and network speeds. This
 can be realized by educated guessing or other optimization
 strategies like genetic algorithms.
 Sequence comparison algorithms use input data in the form
 of a sequence of characters, omitting all timing information.
 However, the exclusion of all timing information eliminates
 a relevant part of the information. Thus, this approach is not
 considered a suitable solution.
 Pattern matching or searching for known problems is
 already implemented for job centric monitoring [13]. However,
 these methods are not capable of detecting new, undefined
 problems and can lead to a high false-positives rate.
 Statistic of events is a straight-forward and easy to adapt
 algorithm. It can be automatically adapted to actual job behav-
 ior. For instance the adaptation can be applied by continuous
 calculation of statistic over historical job behavior. This ap-
 proach looks very promising.
 Machine learning algorithms require a learning phase to
 correctly train the algorithm. The algorithm results depend
 highly on the quality of the learning phase. However, the
 compilation of a suitable, high-quality collection of training
 examples is very time consuming and error-prone. Thus, we
 give preference to other approaches first.
 The data format required to apply tree and graph search
 algorithms as well as for direct use of genetic algorithms
 differs from the generated data format used in job-centric
 monitoring. Due to the needed adaption an implementation
 of these approaches requires considerable effort.
 B. Performance Optimization of Parallel Applications
 In the field of performance optimization of parallel appli-
 cations a range of methods is already successfully applied.
 Casas et al. [6] use wavelet and cross-correlation algo-
 rithms to analyze parallel application executions. With wavelet
 analysis they can automatically divide the execution in ini-
 tialization, finalization, and computation phase. Using cross-
 correlation on the computation phase identifies the individual
 iterations. The automatic identification of the application struc-
 ture enables further analysis methods like detection of load-
 balance problems or automatic speedup analysis.
 Gamblin et al. [20] use clustering for the performance anal-
 yses of massive parallel applications. The clustering process
 builds groups of similar behaving processes, representing the
 application behavior. For each group a representative process,
 representing the behavior of the individual group, is selected.
 The analyst can focus on the representative processes and does
 not need to analyze a massive number of processes anymore.
 Scalasca [70] is able to automatically find predefined
 patterns, like synchronization wait-time, in the trace data.
 However, Scalasca does not guarantee the detection of all
 occurrences of the predefined patterns and is only able to detect
 a subset of all possible performance problems.
 Weber et al. [69] use sequence alignment methods to
 compare event traces of parallel application runs. Due to the
 large number of events manual inspection and comparison of
 the traces is time consuming and error-prone. The described
 alignment methods compare the traces and automatically iden-
 tify differences and similarities.
 Genetic algorithms, machine learning, and graph search
 algorithms seem not do be suitable for automatic analysis
 of trace data. At least they need an extensive adaption. For
 instance the large amount of events in traces along with the
 variety of possible event types and their complex dependencies
 render the preparation of suitable training sets for machine
 learning algorithms an error-prone task. It is challenging to find
 real application traces with isolated performance problems.
 Furthermore it is questionable if the algorithms are able to
 learn the characteristics of certain performance problems and
 are able to detect trained problems in new traces. This is
 especially true if the traces originate from new applications.
 Using statistics of events is suitable to detect a subset
 of performance problems. For instance, it is an appropriate
 method to detect outliers in the data.
 C. Dealing with Faults in HPC Systems
 Common research in the field of resilience at large scale is
 mostly based on statistical data, for example system log files.
 Martino [49], Lu [45], and Fu et al. [17] analyze statistical
 failure data and use clustering to group failures which correlate
 in time and space domain. Analysis of statistical failure data
 can indicate possible failure correlations. However, it does not
 relate causes and effects directly, because statistical data can
 not model relationships between failures.
 Gainaru et al. [19] combine signal analysis and data mining
 techniques to analyze log files. In this work they use signal
 correlation to distinguish individual event types as well as data-
 mining concepts to analyze correlations between events in the
 presence of faults. In addition, Gainaru et al. [18] use machine
 learning techniques to predict normal and faulty application
 behavior based on the analyses of message transfers.
 378
Fault trees and reliability graphs can be used to model
 systems. Nevertheless, they are not suitable to analyze system
 availability [57]. Markov chains or generalized stochastic Petri
 nets are more suitable in this case.
 VI. CONCLUSION
 Methods for automatic or semi-automatic analysis of large
 data sets are still an active research field. Nevertheless, a wide
 range of methods is already available. These methods enable
 automatic identification of irregular data, and hence, provide
 support for tracking down new phenomenons, causalities, or
 faults. Consequently, the amount of information requiring
 manual inspection as well as the time required for the analysis
 might be reduced dramatically.
 This work presents a wide range of algorithms relevant
 for automatic data analysis. Since most papers focus only
 on a single method or compare only very similar or suc-
 cessive versions of algorithms we present a very rare and
 useful overview. Most analysis methods highly depend on
 the data format and analysis context. Hence, we surveyed
 the algorithms for applicability in three different scenarios.
 These use cases have been selected from current research areas.
 Therefore, our evaluation of data analysis methods serves as a
 basis and starting point for scientists facing similar problems.
 A detailed description of the adaption, implementation, and
 evaluation of the presented algorithms with example data is
 beyond the scope of this work. For detailed information about
 individual methods a comprehensive list of related work is
 provided. Additionally, a more detailed evaluation of selected
 methods is planned as future work.
 REFERENCES
 [1] J. Balasubramaniyan, J. Garcia-Fernandez, D. Isacoff, E. Spafford, and
 D. Zamboni. An architecture for intrusion detection using autonomous
 agents. In Computer Security Applications Conference, 1998. Proceed-
 ings. 14th Annual, pages 13–24, 1998.
 [2] D. Beasley, D. R. Bull, and R. R. Martin. An Overview of Genetic
 Algorithms: Part 1, Fundamentals. University Computing, 1993.
 [3] R. Bellman. Dynamic Programming. Princeton University Press,
 Princeton, NJ, USA, 2010.
 [4] K. Bergman, S. Borkar, D. Campbell, W. Carlson, W. Dally, M. Den-
 neau, P. Franzon, W. Harrod, J. Hiller, S. Karp, S. Keckler, D. Klein,
 R. Lucas, M. Richards, A. Scarpelli, S. Scott, A. Snavely, T. Sterling,
 R. S. Williams, K. Yelick, K. Bergman, S. Borkar, D. Campbell,
 W. Carlson, W. Dally, M. Denneau, P. Franzon, W. Harrod, J. Hiller,
 S. Keckler, D. Klein, P. Kogge, R. S. Williams, and K. Yelick. ExaS-
 cale Computing Study: Technology Challenges in Achieving Exascale
 Systems Peter Kogge, Editor & Study Lead, 2008.
 [5] H. Brunst, M. Winkler, W. E. Nagel, and H.-C. Hoppe. Performance
 Optimization for Large Scale Computing: The Scalable VAMPIR Ap-
 proach. In Computational Science - ICCS 2001, volume 2074 of Lecture
 Notes in Computer Science, pages 751–760. Springer Berlin Heidelberg,
 2001.
 [6] M. Casas, R. M. Badia, and J. Labarta. Automatic Phase Detection
 and Structure Extraction of MPI Applications. International Journal of
 High Performance Computing Applications, 24(3):335–360, 2010.
 [7] P. Chan and S. J. Stolfo. Toward Parallel and Distributed Learning
 by Meta-Learning. In AAAI Workshop in Knowledge Discovery in
 Databases, pages 227–240, 1993.
 [8] H. Debar, M. Becker, and D. Siboni. A neural network component
 for an intrusion detection system. In Research in Security and Privacy,
 1992. Proceedings., 1992 IEEE Computer Society Symposium on, pages
 240–250, May.
 [9] D. E. Denning. An intrusion-detection model. IEEE TRANSACTIONS
 ON SOFTWARE ENGINEERING, 13(2):222–232, 1987.
 [10] J. E. Dickerson and J. A. Dickerson. Fuzzy network profiling for
 intrusion detection. In Proc. of NAFIPS 19th International Conference
 of the North American Fuzzy Information Processing Society, Atlanta,
 pages 301–306, 2000.
 [11] R. Dobai and M. Balaz. Genetic method for compressed skewed-load
 delay test generation. In Design and Diagnostics of Electronic Circuits
 Systems (DDECS), 2012 IEEE 15th International Symposium on, pages
 242–247, 2012.
 [12] J. Dongarra and P. B. et al. The International Exascale Software
 Roadmap. International Journal of High Performance Computer
 Applications, 25(1), 2011.
 [13] H. Eichenhardt, R. Muller-Pfefferkorn, R. Neumann, and T. William.
 User- and job-centric monitoring: Analysing and presenting large
 amounts of monitoring data. In Proceedings of the 2008 9th IEEE/ACM
 International Conference on Grid Computing, GRID ’08, pages 225–
 232, Washington, DC, USA, 2008. IEEE Computer Society.
 [14] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A Density-Based
 Algorithm for Discovering Clusters in Large Spatial Databases with
 Noise. In KDD’96, pages 226–231, 1996.
 [15] S. Even. Graph Algorithms. Cambridge University Press, New York,
 NY, USA, 2nd edition, 2011.
 [16] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast subsequence
 matching in time-series databases. In Proceedings of the 1994 ACM
 SIGMOD international conference on Management of data, SIGMOD
 ’94, pages 419–429, New York, NY, USA, 1994. ACM.
 [17] S. Fu and C. zhong Xu. Exploring event correlation for failure
 prediction in coalitions of clusters. In Proceedings of the International
 Conference for High Performance Computing, Networking, Storage, and
 Analysis (SC07, 2007.
 [18] A. Gainaru, F. Cappello, J. Fullop, S. Trausan-Matu, and W. Kramer.
 Adaptive event prediction strategy with dynamic time window for large-
 scale hpc systems. In Managing Large-scale Systems via the Analysis
 of System Logs and the Application of Machine Learning Techniques,
 SLAML ’11, pages 4:1–4:8, New York, NY, USA, 2011. ACM.
 [19] A. Gainaru, F. Cappello, M. Snir, and W. Kramer. Fault prediction under
 the microscope: a closer look into hpc systems. In Proceedings of the
 International Conference on High Performance Computing, Networking,
 Storage and Analysis, SC ’12, pages 77:1–77:11, Los Alamitos, CA,
 USA, 2012. IEEE Computer Society Press.
 [20] T. Gamblin, B. R. de Supinski, M. Schulz, R. Fowler, and D. A. Reed.
 Clustering Performance Data Efficiently at Massive Scales. In Proceed-
 ings of the 24th ACM International Conference on Supercomputing, ICS
 ’10, pages 243–252, New York, NY, USA, 2010. ACM.
 [21] M. Gavrilov, D. Anguelov, P. Indyk, and R. Motwani. Mining the stock
 market (extended abstract): which measure is best? In Proceedings
 of the 6th ACM SIGKDD international conference on Knowledge
 discovery and data mining, KDD ’00, pages 487–496, New York, NY,
 USA, 2000. ACM.
 [22] S. M. Goldfeld, R. E. Quandt, and H. F. Trotter. Maximization by
 Quadratic Hill-Climbing. Econometrica Vol. 34, No. 3, pages 541–551,
 1966.
 [23] J. Grefenstette. Optimization of control parameters for genetic al-
 gorithms. Systems, Man and Cybernetics, IEEE Transactions on,
 16(1):122–128, 1986.
 [24] D. Gusfield. Algorithms on Stings, Trees, and Sequences. Computer
 Science and Computational Biology, 1997.
 [25] J. A. Hartigan and M. A. Wong. Algorithm AS 136: A K-Means
 Clustering Algorithm. Journal of the Royal Statistical Society. Series
 C (Applied Statistics), 28(1):100–108, 1979.
 [26] M. Hilbrich and R. Mu¨ller-Pfefferkorn. A Scalable Infrastructure for
 Job-Centric Monitoring Data from Distributed Systems. In Proceedings
 Cracow Grid Workshop ’09, pages 120–125, ul. Nawojki 11, 30-950
 Krakow 61, P.O. Box 386, Poland, Feb. 2010. ACC CYFRONET AGH.
 [27] M. Hilbrich and R. Muller-Pfefferkorn. IDENTIFYING LIMITS OF
 SCALABILITY IN DISTRIBUTED, HETEROGENEOUS, LAYER
 BASED MONITORING CONCEPTS LIKE SLAte. Computer Science,
 13(3):23–33, 2012.
 379
[28] D. S. Hirschberg. A linear space algorithm for computing maximal
 common subsequences. Communications of the ACM, 18(6):341–343,
 June 1975.
 [29] J. Holland. Genetic Algorithms. Scientific American, 267(1), July 1992.
 [30] T. Huffmire and T. Sherwood. Wavelet-based phase classification. In
 Proceedings of the 15th international conference on Parallel architec-
 tures and compilation techniques, PACT ’06, pages 95–104, New York,
 NY, USA, 2006. ACM.
 [31] K. Ilgun, R. Kemmerer, and P. Porras. State transition analysis: a
 rule-based intrusion detection approach. Software Engineering, IEEE
 Transactions on, 21(3):181–199, 1995.
 [32] A. K. Jain. Data clustering: 50 years beyond K-means. Pattern
 Recognition Letters, 31(8):651–666, June 2010.
 [33] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review.
 ACM Comput. Surv., 31(3):264–323, Sept. 1999.
 [34] L. Kaufman and P. Rousseeuw. Clustering by Means of Medoids.
 Reports of the Faculty of Mathematics and Informatics. Delft University
 of Technology. Fac., Univ., 1987.
 [35] L. Kaufman and P. J. Rousseeuw. Finding Groups in Data: An
 Introduction to Cluster Analysis. Wiley Series in Probability and
 Statistics. Wiley, 2005.
 [36] E. J. Keogh and M. J. Pazzani. An Enhanced Representation of Time
 Series Which Allows Fast and Accurate Classification, Clustering and
 Relevance Feedback, 1998.
 [37] S. Kumar and E. H. Spafford. A Pattern Matching Model for Misuse
 Intrusion Detection. In In Proceedings of the 17th National Computer
 Security Conference, pages 11–21, 1994.
 [38] S. Kumar and E. H. Spafford. A Software Architecture to support
 Misuse Intrusion Detection. In Proceedings of the 18th National
 Information Security Conference, number 95 009, pages 194–204, 1995.
 [39] A. Lazarevic, L. Ertoz, V. Kumar, A. Ozgur, and J. Srivastava. A Com-
 parative Study of Anomaly Detection Schemes in Network Intrusion
 Detection. In D. Barbara´ and C. Kamath, editors, Proceedings of SIAM
 Conference on Data Mining, May 2003.
 [40] W. Lee, S. Stolfo, and K. Mok. A data mining framework for building
 intrusion detection models. In Security and Privacy, 1999. Proceedings
 of the 1999 IEEE Symposium on, pages 120–132, 1999.
 [41] W. Lee and S. J. Stolfo. Data Mining Approaches for Intrusion
 Detection. In Proceedings of the 7th conference on USENIX Security
 Symposium - Volume 7, SSYM’98, pages 6–6, Berkeley, CA, USA,
 1998. USENIX Association.
 [42] W. Lee and S. J. Stolfo. A framework for constructing features
 and models for intrusion detection systems. ACM Transactions on
 Information and System Security, 3(4):227–261, Nov. 2000.
 [43] S. P. Lloyd. Least Squares Quantization in PCM. IEEE Transactions
 on Information Theory, 28(2):129–137, 1982.
 [44] D. Lorenz, S. Borovac, P. Buchholz, H. Eichenhardt, T. Harenberg,
 P. Ma¨ttig, M. Mechtel, R. Mu¨ller-Pfefferkorn, R. Neumann, K. Reeves,
 C. Uebing, W. Walkowiak, T. William, and R. Wismu¨ller. Job moni-
 toring and steering in D-Grid’s High Energy Physics Community Grid.
 Future Generation Computer Systems, 25:308–314, March 2009.
 [45] C.-D. Lu. Failure data analysis of hpc systems. CoRR, abs/1302.4779,
 2013.
 [46] T. Lunt, R. Jagannathan, R. Lee, A. Whitehurst, and S. Listgarten.
 Knowledge-based intrusion detection. In AI Systems in Government
 Conference, 1989.,Proceedings of the Annual, pages 102–107, 1989.
 [47] T. F. Lunt. A survey of intrusion detection techniques. Computers &
 Security, 12(4):405 – 418, 1993.
 [48] J. B. MacQueen. Some Methods for Classification and Analysis
 of MultiVariate Observations. In Proceedings of the 5th Berkeley
 Symposium on Mathematical Statistics and Probability, volume 1, pages
 281–297. University of California Press, 1967.
 [49] C. Martino. One size does not fit all: Clustering supercomputer failures
 using a multiple time window approach. In J. Kunkel, T. Ludwig, and
 H. Meuer, editors, Supercomputing - 28th International Supercomputing
 Conference, ISC 2013, Leipzig, Germany, June 16-20, 2013. Proceed-
 ings, volume 7905 of Lecture Notes in Computer Science, pages 302–
 316. 2013.
 [50] K. Mohror and K. L. Karavanic. Towards Scalable Event Tracing
 for High-End Systems. In High Performance Computing and Com-
 munications, 3rd International Conference, HPCC’07, pages 695–706,
 September 26-28 2007.
 [51] R. Mu¨ller-Pfefferkorn, R. Neumann, and T. William. AMon - a User-
 Friendly Job Monitoring for the Grid. In T. Priol and M. Vanneschi,
 editors, CoreGRID, pages 185–192. Springer, 2007.
 [52] E. W. Myers. An O(ND) difference algorithm and its variations.
 Algorithmica, 1:251–266, 1986.
 [53] S. B. Needleman and C. D. Wunsch. A general method applicable to
 the search for similarities in the amino acid sequence of two proteins.
 Journal of Molecular Biology, 48(3):443–453, 1970.
 [54] V. Paxson. Bro: a system for detecting network intruders in real-time.
 Computer Networks, 31(2324):2435 – 2463, 1999.
 [55] M. Roesch and S. Telecommunications. Snort - Lightweight Intrusion
 Detection for Networks. pages 229–238, 1999.
 [56] P. J. Rousseeuw. Silhouettes: A Graphical Aid to the Interpretation and
 Validation of Cluster Analysis. Journal of Computational and Applied
 Mathematics, 20(0):53–65, 1987.
 [57] R. A. Sahner and K. S. Trivedi. A software tool for learning about
 stochastic models. IEEE Transactions on Education, 36(1):56–61, Feb.
 1993.
 [58] X. Shen, Y. Zhong, and C. Ding. Locality phase prediction. In
 Proceedings of the 11th international conference on Architectural
 support for programming languages and operating systems, ASPLOS
 XI, pages 165–176, New York, NY, USA, 2004. ACM.
 [59] S. E. Smaha. Haystack: An intrusion detection system. In Proc. of the
 IEEE 4th Aerospace Computer Security Applications Conference, 1988.
 [60] S. Staniford-chen, S. Cheung, R. Crawford, M. Dilger, J. Frank,
 J. Hoagl, K. Levitt, C. Wee, R. Yip, and D. Zerkle. GrIDS - A Graph
 Based Intrusion Detection System For Large Networks. In Proceedings
 of the 19th National Information Systems Security Conference, pages
 361–370, 1996.
 [61] S. Stolfo, A. L. Prodromidis, S. Tselepis, W. Lee, W. Fan, and P. K.
 Chan. JAM: Java Agents for Meta-Learning over Distributed Databases.
 In Proceedings of the 3rd International Conference Knowledge Discov-
 ery and Data Mining, pages 74–81. AAAI Press, 1997.
 [62] E. Stollnitz, T. Derose, and D. Salesin. Wavelets for computer graphics:
 a primer.1. Comp. Graphics and Applications, IEEE, 15(3):76–84, 1995.
 [63] P.-N. Tan, M. Steinbach, and V. Kumar. Introduction to Data Mining.
 Addison-Wesley, May 2005.
 [64] K. Tang, K. Man, S. Kwong, and Q. He. Genetic algorithms and their
 applications. Signal Processing Magazine, IEEE, 13(6):22–37, 1996.
 [65] J. van Wijk and E. Van Selow. Cluster and calendar based visualization
 of time series data. In Information Visualization, 1999. (Info Vis ’99)
 Proceedings. 1999 IEEE Symposium on, pages 4–9, 140, 1999.
 [66] M. Vlachos, J. Lin, E. Keogh, and D. Gunopulos. A Wavelet-Based
 Anytime Algorithm for K-Means Clustering of Time Series. In Proc.
 Workshop on Clustering High Dimensionality Data and Its App., 2003.
 [67] D. von Gru¨nigen. Digitale Signalverarbeitung: Mit einer Einfu¨hrung
 in die kontinuierlichen Signale und Systeme. Fachbuchverlag Leipzig,
 2008.
 [68] D. Wagner and D. Dean. Intrusion detection via static analysis.
 In Security and Privacy, 2001. S P 2001. Proceedings. 2001 IEEE
 Symposium on, pages 156–168, 2001.
 [69] M. Weber, R. Brendel, and H. Brunst. Trace File Comparison with
 a Hierarchical Sequence Alignment Algorithm. In Proceedings of the
 2012 IEEE 10th International Symposium on Parallel and Distributed
 Processing with Applications, ISPA ’12, pages 247–254, 2012.
 [70] F. Wolf, B. J. N. Wylie, E. ´Abraha´m, D. Becker, W. Frings, K. Fu¨rlinger,
 M. Geimer, M.-A. Hermanns, B. Mohr, S. Moore, M. Pfeifer, and
 Z. Szebenyi. Usage of the SCALASCA Toolset for Scalable Perfor-
 mance Analysis of Large-Scale Parallel Applications. In Proceedings
 of the 2nd Parallel Tools Workshop, Stuttgart, Germany, pages 157–167.
 Springer, July 2008.
 [71] C. Yang, S. Tian, and B. Long. Application of heuristic graph
 search to test-point selection for analog fault dictionary techniques.
 Instrumentation and Measurement, IEEE Transactions on, 58(7):2145–
 2158, 2009.
 380
