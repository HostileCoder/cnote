An Effective Algorithm and Modeling for Information Resources Scheduling in 
Cloud Computing  
 
Yaojun Han 
School of Business Administration 
Shanghai International Studies University 
Shanghai, 200083, China 
yjhan@shisu.edu.cn 
Xuemei Luo 
School of Economics and Finance 
Shanghai International Studies University 
Shanghai, 200083, China 
xmluo126@shisu.edu.cn
  
 
Abstract—With the development of the Internet and Web 
technology and frequent cross-cultural communication, it is 
necessary for people to be able to access and manage 
information in many different languages. The scheduling of 
multilingual information resources become complex, as 
multilingual information resources stored in different cloud 
datacenters are heterogeneous and their distributions are 
uneven. In this paper, based on Min-Min algorithm, Least 
Languages First Min-Min (LLFMM), a scheduling algorithm 
that is suitable to multilingual information resources and can 
improve information resources scheduling performance in 
cloud computing is proposed. A task with least number of sites 
that can fulfill this task is firstly selected in LLFMM, rather 
than the task with the least execution time among all the tasks 
in Min-Min. Petri net is a powerful graphical and mathematics 
tool for describing the concurrent, asynchronous and dynamic 
events. This paper models and analyzes the multilingual 
information resources scheduling using colored dynamic timed 
Petri nets (CDTdPN). In CDTdPN model, the color represents 
different language information resource, and the time of a 
transition representing scheduling time is a function of tokens 
in input places of the transition. The concurrent scheduling 
marking graph (CSMG) of CDTdPN is defined and the 
algorithm for constructing the CSMG of CDTdPN is given in 
this paper. The CSMG can represent the concurrent relation of 
transitions in Petri nets and reduce the size of the graph to be 
constructed in some extent. Finally, the example and 
simulation show that our scheduling algorithm is effective in 
reducing makespan and our modeling and analyzing 
techniques are convenient for analyzing performance of 
scheduling system. 
Keywords—cloud computing, multilingual; resources 
scheduling; algorithm;  modeling; Petri net 
I.  INTRODUCTION 
Cloud computing [1] provides information resources for 
users in "Cloud" through the Internet. Cloud computing 
utilizes large-scale virtualized data centers to manage such 
large volume of resources. Scheduling is considered to be an 
important issue in Cloud computing. Typically, it is difficult 
to find an optimal resource allocation which minimizes the 
makespan and effectively utilize the resources. The choice of 
the best pair of jobs and resources has been proved to be NP-
 complete problem. Large numbers of heuristic resources 
scheduling algorithms are available to minimize the 
makespan. The simple well-known algorithm used for tasks 
scheduling in heterogeneous computing systems is Min-Min 
[2]
 . The Min-Min heuristic algorithm is becoming the 
benchmark of such kinds of task/host scheduling problems. 
The numbers of languages for information stored in 
different datacenters are uneven. Some languages such as 
English and Spanish could be distributed in many 
datacenters, while some languages such as Korean and 
Japanese may be stored in a few datacenters. So, it is not 
suitable to the multilingual resources scheduling for existing 
mono-lingual resource algorithms. In this paper, we propose 
a different algorithm to the original Min-Min algorithm in 
order to adapt to the characteristics of multilingual 
information requirements. The algorithm proposed in this 
paper called Least Languages First Min-Min (LLFMM) 
considers the characteristics of uneven distribution of 
multilingual information resources in cloud datacenters. A 
task with least number of sites that can fulfill this task is 
firstly selected in LLFMM, rather than the task with the least 
execution time among all the tasks in Min-Min. 
As the complexity of multilingual information resources 
scheduling in cloud computing, there is a need for modeling 
and analyzing techniques for scheduling flow of multilingual 
information resources. Petri nets are perfect mathematical 
and graphic tools for modeling and analysis resources 
scheduling. So it has received increasing application in 
modeling and analyzing resource scheduling. But, the model 
and analysis technology are not suitable to the multilingual 
information resources scheduling in cloud computing. We 
use colored dynamic timed Petri net (CDTdPN) to model and 
analyze multilingual information resources scheduling in 
cloud computing. In CDTdPN model, the color represents 
different language information resource, and the time of a 
transition representing scheduling time is a function of 
tokens in input places of the transition. In this paper, we 
define the concurrent scheduling marking graph (CSMG) of 
CDTdPN and give the algorithm for constructing the CSMG 
of CDTdPN. The CSMG can reduce the size of the graph to 
be constructed in some extent. 
The rest of this paper is organized as follows. Section 2 
presents the related works. In section 3, we give a scheduling 
algorithm LLFMM for multilingual information resources in 
cloud computing. Aiming at the problems of analysis and 
modeling of the multilingual information resources 
scheduling in cloud computing, colored dynamic timed Petri 
2013 International Conference on Advanced Cloud and Big Data
 978-1-4799-3261-0/14 $31.00 © 2014 IEEE
 DOI 10.1109/CBD.2013.11
 14
net (CDTdPN) model and the concurrent scheduling marking 
graph (CSMG) are proposed in section 4. An example and 
simulation show the effectiveness of the scheduling model 
and algorithm in section 5. The conclusions of the paper are 
given in section 6. 
II. RELATED WORK 
Min-Min algorithm starts with a set of all unmapped 
tasks. The machine that has the minimum completion time 
for all jobs is selected. Then the job with the overall 
minimum completion time is selected and mapped to that 
resource. The ready time of the resource is updated. This 
process is repeated until all the unmapped tasks are assigned. 
The Min-min heuristics is now becoming the benchmark of 
such kinds of task/host scheduling problems. However, the 
Min-min algorithm is unable to balance the load well since it 
usually maps small tasks first and did not deal with the 
Quality of Service (QoS). 
Some improved algorithms for the resources scheduling 
in cloud computing have been proposed in the literature. All 
the problems discussed in those methods are taken and 
analyzed to give a more effective schedule. Yang, Zhi et al. 
[3] present a cost-based resource scheduling paradigm in 
cloud computing by leveraging market theory to schedule 
compute resources to meet user's requirement. Yun Fei Cui 
et al. [4] give an improved genetic algorithm for cloud 
computing resource scheduling. Hao Li and Guo Tang [5] 
propose a cloud banking model based on multi-dimensional 
Pareto optimal theory for resource scheduling. Haihua Chang 
and Xinhuai Tang [6] present a resource scheduling 
algorithm based on dynamic load balance in cloud 
computing. Xin Lu and Zilong Gu [7] present a load-
 adaptive cloud resource scheduling model based on ant 
colony algorithm. Chen Ming et al. [8] present a scheduling 
model for cloud computing resource based on buffer-pool 
agent. Dr. M. Dakshayini and Dr. H. S. Guruprasad propose 
a priority and admission control based service scheduling 
policy that aims at serving the user requests satisfying the 
QoS [9]. El-Sayed T. El-kenawy et al. [10] proposed an 
improved Max-min algorithm is based on the expected 
execution time instead of complete time as a selection basis. 
Although there exist many resource scheduling 
algorithms in cloud computing, none involves the scheduling 
of multilingual information resources. So it is not suitable to 
the multilingual resources scheduling for existing resource 
algorithms in cloud computing. An extension of Min-min 
algorithm called Least Languages First Min-Min is proposed 
in this paper. 
As the complexity of cloud computing system, there is a 
need for modeling and analyzing techniques for multilingual 
information resources scheduling. Petri nets are perfect 
mathematical and graphic tools for modeling and analysis 
scheduling problems. W.M.P. van der Aalst modeled and 
analyzed scheduling problems using timed Petri nets in [11]. 
Some Petri nets models for the resources scheduling in grid 
computing have been proposed in the literature. El-Sayed T. 
El-kenawy et al. [10] used Petri net to model the concurrent 
behavior of distributed systems. Mohammad Abdollahi 
Azgomi et al. [12] proposed CPN-based modeling pattern 
formally describing the process of task distribution and 
execution within the grid environment. Xiangang Zhao et al. 
[13] proposed a scheduling net based on a hierarchical color 
Petri net and a job net based on a Petri net with changeable 
structure. In our previous work [14-16], we proposed some 
Petri net models for resources scheduling in grid computing, 
transaction scheduling in grid database and multilingual 
information parallel downloads in data grid. But, above 
model and analysis technologies are not suitable to the 
multilingual information resources scheduling in cloud 
computing environment. Therefore, new models and 
performance analysis technologies for the multilingual 
information resources scheduling in cloud computing are 
proposed in this paper. We use colored dynamic timed Petri 
net (CDTdPN) to model and analyze multilingual 
information resources scheduling in cloud computing. In 
CDTdPN, the time interval of a transition is a function of 
tokens in input places of the transition, which is convenient 
for modeling and analyzing dynamic performance of 
multilingual information resources in cloud computing. 
Reachable marking graph(RMG)[18] is a very important 
tool to analyze the dynamic properties of Petri nets, but the 
major weakness of the RMG is that the size of RMG grows 
with the number of processes and thus creates the state space 
explosion problem. Moreover, the concurrent relation of 
transitions in Petri nets cannot be represented by RMG. In 
this paper, we use the concurrent scheduling marking graph 
instead of RMG to analyze the correctness and effectiveness 
of the system. 
III. SCHEDULING ALGORITHM FOR MULTILINGUAL 
INFORMATION RESOURCES IN CLOUD COMPUTING 
In this section, we give a scheduling algorithm LLFMM 
of multilingual information resources for scheduling agent. 
The algorithm LLFMM starts by sorting the requirements 
(i.e. tasks). It first identifies the number of datacenters 
storing each requirement and sorts the requirements in 
ascending order of the number of datacenters storing 
multilingual requirements. Thus the requirement with 
minimum number of datacenters that can fulfill the 
requirement is scheduled first. The main aim of the 
scheduling algorithm is to minimize the makespan. 
The scheduling problem can be defined as follows: 
Let multilingual requirement set MR= mr1, mr2, mr3 , …. 
, mrn be the group of multilingual requirements submitted to 
scheduler.  
Let multilingual information set MI= mi1, mi2, mi3 , …. , 
mik be the group of multilingual information resources 
provided by cloud datacenters, where MI?MR.  
Let datacenter set DC = dc1, dc2, dc3 , …. , dcm be the set 
of cloud datacenters, where, dci is a sub-set of MI. 
Let EST is a matrix, where ESTij is the estimated 
scheduling time of requirement i on datacenter j. If the 
requirement i do not exist in datacenter j, EST(i,j)=0. 
Let TT is a matrix, where, TTij is the expected transmit 
time taken by transmitting requirement i to datacenter j from 
global scheduling agent. 
15
 Let RTj is the ready time or availability time of 
datacenter j after completing the previously assigned 
requirements. 
Let CT is a matrix, where, ctij that is the expected 
completion time
  
of requirement i on datacenter j is defined 
as the wall-clock time at which datacenter j completes 
requirement i.  
Where,  CT(i,j)= EST(i,j)+ TT(i,j)+ R(j) 
Algorithm: LLFMM scheduling algorithm 
Input: EST, TT and MR. 
Output: CT and Scheduling series {( mri, dcj)|i=1, 2, …, 
n; j=1, 2, … m}, where, mri is some language requirement, 
dcj is datacenter j, (mr i, dcj) means requirement i is assigned 
to datacenter j. 
Let RT=(0,0,...0); 
Define MR as a Queue; 
Calculate the number of datacenters storing each 
requirement; 
Sort MR in ascending order of the number of datacenters 
storing multilingual requirement; 
While (MR is not empty) 
{  
Get mri from MR; 
Find datacenter j such that min1jm{(RT(j)+ TT(i,j)+ 
EST(i,j)| EST(i,j)>0}; 
Assign requirement mri to datacenter j; 
Delete mri from MR; 
Let CT(i,j) = EST(i,j)+ TT(i,j) +RT(j); 
Let RT(j) = RT(j)+ EST(i,j); 
} 
Obviously, the time complexity of LLFMM algorithm is 
same as one of Min-Min algorithm. 
IV. PETRI NET MODEL AND PERFORMANCE ANALYSIS FOR 
MULTILINGUAL INFORMATION RESOURCES SCHEDULING IN 
CLOUD COMPUTING 
Some concepts of Petri nets cannot be discussed here for 
lack of space. See references [18,19,20]for the definitions of 
Petri nets. 
A. Colored Dynamic Timed Petri Net for Multilingual 
Information Resources Scheduling in Cloud Computing 
Definition 1 Suppose that there are n datacenters in cloud 
computing. The ith datacenter includes information resources 
of mi kinds of languages. The colored dynamic timed Petri 
net model (CDTdPN) for multilingual information resource 
scheduling in cloud computing is a eight-tuple CDTdPN =( 
P,T; F, C, W, I, M, D), where, 
P={p0, pb, pf, pe}]{pj1, pj2 |j=1,2,…,n} is a finite set of 
places, where, p0 represents that user is ready to submit a 
request, pb represents the request submitted by user, pf 
represents the expected results on datacenter j, pe represents 
the results expected by user, pj1 represent the requests 
scheduled to datacenter j for executing, pj2 represent the 
results returned from datacenter j. 
T={tb, te}]{tj1, tj2, tj3|j=1,2,…,n}is a finite set of 
transitions, where, tb is used to submit requests to schedule, te 
is used to return the results to user, tj1 is used to schedule a 
request to datacenter j according to LLFMM algorithm, tj2 is 
used to execute the request on datacenter j, tj3 is used to 
finish the request on datacenter j. 
F= {(p0,tb), (tb,pb), (te,pe)} {(pb,tj1), (tj1,pj1), (pj1,tj2), 
(tj2,pj2), (pj2,tj3), (tj3,pf), (pf, te) | j= 1,2,…,n} is a finite set of 
arcs. 
C={LG} {(cj,ej) | j=1,2,…,n } is a set of colors, where, 
LG is a set of languages in the request submitted by user, cj 
and ej are communication time from user site to datacenter j 
and execution time of the request on datacenter j 
respectively. 
W :  F?L(C)+. 
I :   T?L(C)+. 
M :  P?L(C). 
L(C) is a non-negative integer coefficient liner function. 
L(C)+ represents at least one coefficient in L(C) is not 0.   
D(tj1)=[cj], D(tj2)=[ej], D(tj3)=0, j=1,2,…,n 
D(tb)= D(te) =0. 
In the CDTdPN, the firing time delay associated with 
transition t is a function of color token of input places of 
transition t.  
The graphical representation of CDTdPN is shown as Fig. 
1. 
 
 
Figure 1.  CDTdPN model. 
B. Performance analysis of concurrency transactions 
scheduling in Cloud Computing 
A major strength of Petri nets is their support for analysis 
of many properties and problems associated with concurrent 
systems. After modeling the with Petri nets, we will analyze 
the correctness and performance of the multilingual 
information resource scheduling system in order to ensure 
the correctness and effectiveness of the system. We first 
define the concurrent scheduling marking graph and then use 
it to analyze the correctness and effectiveness of the system. 
Definition 2 Let CDTdPN be a colored dynamic timed 
Petri net for multilingual information resource scheduling. 
The concurrent scheduling marking graph (CSMG) of 
CDTdPN is defined as a directed graph with labeled directed 
edges and nodes. 
CSMG (CDTdPN)= (V, E, F, FC), where, 
V={R(M0)}, 
E={( Mi, Mj)| Mi, Mj?R(M0), ?t?T: Mi [ t >Mj , 
F(E)= t/[td], where the marking Mj that results from 
firing t
  
at Mi , td is the time delay of transition t firing. 
FC(E)= t1t2 …tk /[mt], where the marking Mj that 
results from concurrently firing t1 , t2 …, tk at Mi , 
16
mt=max{ td1 , td2 …, dtk }, tdi is the time delay of transition 
ti firing, i=1,2, …, k. 
Definition 3 Let CDTdPN be a colored dynamic timed 
Petri net, P=n, ? t?T, n-vector Xin(t)=(x1, x2,…, xn) and 
Yout(t)=(y1, y2,…, yn) are input vector and output vector of the 
transition t respectively, iff 
 
The CSMG (CDTdPN) is constructed by the following 
algorithm. 
Algorithm 2 Construction of CSMG(CDTdPN) 
Input: CDTdPN. 
Output: CSMG(CDTdPN) 
For each transition t?T 
Construct the input vector Cin(t) and output vector 
Cout(t); 
Let V={M0}; E={}; CE={}; tag M0 “new”; 
While (exists “new” node in V) 
{ Select a “new” marking M from V and tag M “old”; 
 If there no exist enabled transition t at M then tag M 
with “end node”; 
 Else 
     { For each enabled transition t?T at M 
       Construct the concurrent transition set CT={ti1 , ti2 
…, tik} and non-concurrent transition set NT={tj1 , 
tj2 …, tjk2}; 
For each transition t? NT at M 
         {Obtain M’ that results from firing t at M; 
           If M’?V then V=V+{M’}; tag M’ with “new”; 
           E=E+{(M,M’)}; tag (M,M’) with t/[td]; 
}  
 For each concurrent transition set ct? CT at M 
          {Obtain M’ that results from firing ct={ ti1 , ti2 …, 
tik} at M; 
 If M’?V then V=V+{M’}; tag M’ with “new”; 
E=E+{(M,M’)}; tag (M,M’) with t1t2 …tk 
/[mt]; where the marking M’ that results from 
firing ct={ ti1 , ti2 …, tik} at M, M’= M-(Cin(t1)+ 
Cin(t2)+ …, + Cin(tk))+(Cout(t1)+ Cout(t2)+ …, + 
Cout(tk)), mt=max{ tdi1 , tdi2 …, dtik }, tdi is the 
time delay of transition tij firing, j=1,2, …, k. 
} 
      Remove “new” from M ; 
          } 
  } 
The correctness of the algorithm 2 can be easily proven 
according to the definitions of CDTdPN and CSMG.  
Proposition 1 Let CDTdPN be a colored dynamic timed 
Petri net model for a multilingual information resource 
scheduling process. The multilingual information resource 
scheduling process is correct iff for any end node M? 
CSMG (M0), M(pe)0 and any ppe, M(p)=0. 
Proposition 2 Let CSMG(CDTdPN) be the concurrent 
scheduling marking graph of CDTdPN and The multilingual 
information resource scheduling process be correct. The 
makespan of the multilingual information resource 
scheduling process is equal to tdi, where, tdi is the tag of 
marking Mi in CSMG. 
The proof of proposition 1 and 2 are obvious. 
V. EXAMPLE AND SIMULATION 
In this section, we will give an example and a simulation 
to show the effectiveness of our algorithm. 
A. Example 
Consider a cloud environment with 4 datacenters named 
as DL1, DL2, DL3 and DL4. The languages included in 4 
datacenters and the download times of different languages 
information from 4 datacenters are listed in table 1. 
TABLE I.  DOWNLOAD TIME OF DIFFERENT LANGUAGE INFORMATION 
FROM 4 DATACENTERS (UNIT: SECOND) 
Datacenters DC1 DC2 DC3 DC4 
Language a d a b c a b a 
Download time 10 13 15 14 12 16 15 15 
 
Suppose that there are two requirements R1 and R2 
submitted by user. The R1 includes 3 languages: a, b and d.  
The R2 includes 3 languages: a, c and d. 
For R1, the scheduling process is a(DC1)? 
b(DC2)?d(DC1) and the final completion time 
(makespans) is 23 for Min-Min algorithm, and the 
scheduling process is d(DC1)? b(DC2)?a(DC4) and the 
final completion time (makespans) is 15 for LLFMM 
algorithm. For R2, the scheduling process is a(DC1)? 
c(DC3)?d(DC1) and the final completion time (makespan) 
is 23 for Min-Min algorithm, and the scheduling process is 
d(DC1)? c(DC3)?a(DC4) and the final completion time 
(makespans) is 15 for LLFMM algorithm. Therefore, the 
makespan for LLFMM algorithm is less than one for Min-
 Min algorithm. 
Now we model and analyze the example using CDTdPN. 
First, we construct the CDTdPN for multilingual 
information resource scheduling of the task. The graphical 
representation of the CDTdPN for the example is similar to 
Fig. 1, where n=4.  
Second, we construct CSMG, as show in Fig. 2. 
 
 
Figure 2.  CSMG(CDTdPN) of the example with LLFMM algorithm 
From Fig. 2, we know that the scheduling of this example 
is correct because for end node M5, M5(pe)0 and any ppe, 
M5(p)=0. Also we know that the makespan for the 
scheduling is 15 according to proposition 2. 
17
B. Simulation 
To evaluate the efficiency of the proposed algorithm, we 
design a program to execute the Min-Min and LLFMM 
algorithms. Suppose that there are 20 datacenters in cloud 
computing system and the total languages are 10. The 
number of languages stored in each datacenter and the 
download times of requirements on datacenters are produced 
randomly by the program. The experimental evaluation of 
the algorithms is performed for n={1, 2, 3, 4, 5, 6,7, 8, 9, 10} 
languages included in requirement. We run the program 100 
times and get the average makespan for each requirement. 
Table 2 and Fig. 3 show the comparison of makespans 
(Suppose the interval of download times for each 
requirement is 10-50s). 
From table 2 and Fig. 3, we can observe that LLFMM 
algorithm produces same makespan as Min-Min when the 
number of language included in requirement is equal to 1. 
LLFMM algorithm produces less makespan than the Min-
 Min algorithm when the number of language included in 
requirement is greater than 1. The greater number of 
language included in requirement, the bigger difference of 
makespans between two algorithms. 
TABLE II.  MAKESPANS FOR TWO ALGORITHMS 
Number of languages 
included in 
requirement 
Min-Min 
(sec) 
LLFMM 
(sec ) 
1 15 15 
2 18 17 
3 21 19 
4 23 20 
5 25 21 
6 27 22 
7 29 22 
8 32 24 
9 34 24 
10 36 26 
 
 
Figure 3.  Makespans of Min-Min and LLFMM 
 
VI. CONCLUSION  
In this paper, we propose a new algorithm LLFMM for 
multilingual information resources scheduling. It uses the 
advantages of Min-Min algorithm and overcomes its 
disadvantages by choosing the requirement with the least 
number of sites that can fulfill this requirement rather than 
one with the least execution time. The example and 
simulation show that the proposed scheduling model and 
algorithm can reduce the makespan and increase the resource 
utilization. So, it is an effective algorithm for the scheduling 
of multilingual information resources in cloud computing. 
We also construct a colored dynamic timed Petri net 
(CDTdPN) model for multilingual information resource 
scheduling in cloud computing and give a definition of the 
concurrent scheduling marking graph (CSMG) of CDTdPN. 
We give two propositions for analyzing performances such 
as correctness and makespan of multilingual information 
resource scheduling in cloud computing using CSMG of 
CDTdPN. 
 
ACKNOWLEDGMENT 
This work is support partially by projects of The 
Philosophy and Social Sciences Planning Project in Shanghai 
(2010BTQ001), Major Scientific Projects of Shanghai 
International Studies University and high-level cultivation 
program of CIB, Shanghai International Studies University 
 
REFERENCES 
[1] A. Weiss. “Computing in the Cloud,” ACM Networker, 11, 
pp.18-25, 2007. 
[2] Maheswaran M., Ali S., Siegel H. J, Hensgen D. and Freund 
R. F. “Dynamic mapping of a class of independent tasks onto 
heterogeneous computing systems”. Journal of Parallel and 
Distributed Computing, Vol. 59(2), pp.107-131, 1999. 
[3] Yang, Zhi; Yin, Changqin; Liu, Yan. “A Cost-Based 
Resource Scheduling Paradigm in Cloud Computing,” Proc. 
of 12th International Conference on Parallel and Distributed 
Computing, Applications and Technologies (PDCAT), 2011, 
pp.417- 422. 
[4] Yun Fei Cui, Xin Ming Li, Ke Wei Dong, Ji Lu Zhu. Cloud 
Computing Resource Scheduling Method Research Based on 
Improved Genetic Algorithm. Advanced Materials Research, 
Vol. 271-273, pp.552-557, 2011. 
[5] Hao Li, Guo Tang. “Pareto-Based Optimal Scheduling on 
Cloud Resource,” Communications in Computer and 
Information Science, Vol. 163, pp.335-341, 2011. 
[6] Haihua Chang. “A load-balance based resource-scheduling 
algorithm under cloud computing environment,” Proceedings 
of the 2010 international conference on New horizons in web-
 based learning, 2011, pp.85-90. 
[7] Xin Lu, Zilong Gu. “A load-adaptive cloud resource 
scheduling model based on ant colony algorithm,” 2011 IEEE 
International Conference on Cloud Computing and 
Intelligence Systems (CCIS), 2011, pp.296-300. 
[8] Chen Ming Li Mengkun Cai Fuqin. “A Model of Scheduling 
Optimizing for Cloud Computing Resource Services Based on 
Buffer-pool Agent,” 2010 IEEE International Conference on 
Granular Computing (GrC),2010, pp.107-110. 
[9] Dr. M. Dakshayini, Dr. H. S. Guruprasad. “An Optimal 
Model for Priority based Service Scheduling Policy for Cloud 
18
Computing Environment,” International Journal of Computer 
Applications, Vol.32 (9), pp.23-29, 2011. 
[10] El-Sayed T. El-kenawy, Ali Ibraheem El-Desoky, Mohamed 
F. Al-rahamawy. “Extended Max-Min Scheduling Using Petri 
Net and Load Balancing,” International. Journal of Soft 
Computing and Engineering. Vol.2(4), pp.198-203, 2012. 
[11] W.M.P. van der Aalst. Petri net based scheduling. Computing 
Science Reports. No. 95, Eindhoven University of 
Technology, 1995. 
[12] Mohammad Abdollahi Azgomi, Reza Entezari-Maleki. “Task 
scheduling modelling and reliability evaluation of grid 
services using coloured Petri nets,” Future Generation 
Computer Systems,Vol.26(8), pp. 1141-1150, 2010  
[13] Xiangang Zhao, Bai Wang, Liutong Xu, "Grid Application 
Scheduling Model Based on Petri Net with Changeable 
Structure," gcc, pp.733-736, Sixth International Conference 
on Grid and Cooperative Computing (GCC 2007), 2007. 
[14] Yaojun Han, Changjun Jiang, You Fu, Xuemei Luo. 
“Resource Scheduling Algorithms for Grid Computing and Its 
Modeling and Analysis Using Petri Net,” LNCS 3033, 
Springer-Verlag Berlin Heidelberg, 2004, PP73-80. 
[15] Yaojun Han, Changjun Jiang, Xuemei Luo. “Resource 
Scheduling Scheme for Grid Computing and Its Petri Net 
Model and Analysis,” Lecture Notes in Computer Science, 
Vol.3759: pp.530- 539, 2005. 
[16] Yaojun Han, Xumei Luo. “Modeling and Analysis of 
Multilingual Information Parallel Downloads in Data Grid,” 
Applied Mechanics and Materials Vols. 263-266. part 2: 
Information Technology Applications in Industry (2013) pp. 
1424-1428. 
[17] Yaojun Han, Changjun Jiang, Xuemei Luo. “Petri net-based 
modeling and performance analysis of transaction scheduling 
in grid database,” COMPEL: The International Journal for 
Computation and Mathematics in Electrical and Electronic 
Engineering.Vol. 28(6), 2009, pp. 1458-1470. 
[18] T. Murata. “Petri nets: properties, analysis and application,” 
Proceedings of IEEE, Vol.77, Apr.1989, pp. 541-584. 
[19] Jensen, K. Coloured Petri nets: basic concepts, analysis 
methods and practical use. Berlin, Heideberg, New York: 
Springer-Verlag, Vol. 1, 2. ed., 1996. 
[20] W.M. Zuberek. “Timed Petri nets: definitions, properties and 
applications,” Microelectronics and Reliability, vol.31, no.4, 
1991, pp. 627-644. 
 
 
 
 
19
