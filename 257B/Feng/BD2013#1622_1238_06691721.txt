Searching Inter-disciplinary Scientific Big Data
 based on Latent Correlation Analysis
 Eloy Gonzales?, Bun Theang Ong? and Koji Zettsu?
 ? Information Services Platform Laboratory
 Universal Communication Research Institute
 National Institute of Information and Communications Technology
 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan
 Tel: +81-774-98-6866, Fax: +81-774-98-6960
 e-mail: {egonzales, ong bt, zettsu}@nict.go.jp
 AbstractÑIn this paper, a novel cross-database search system
 (Cross-DB) is proposed. The aim of Cross-DB is to facilitate
 the search of interdisciplinary-correlated datasets from large-
 scale, multi-domain and heterogeneous data repositories. With
 conventional systems or portals for searching scientific datasets,
 the scientists must know the relation between the datasets in
 advance or must find their relations manually. In Cross-DB,
 the datasets search process is based on discovering an optimal
 combination of their multiple and latent associations such as
 spatio-temporal, ontological, and citational correlations based on
 evolutionary computing.
 The basic concepts of Cross-DB are introduced as well as its
 main components. Comparisons with an existing search engine
 based on a massive datasets repository demonstrate the feasibility
 and the correctness of the proposed framework. We show that
 offering to the user a full set composed of correlated datasets is a
 useful alternative to the classical ranking methods. Experimental
 result shows that our system can overachieve conventional portal
 search in terms of relevance and novelty.
 KeywordsÑBig Data, Evolutionary Computation, Search En-
 gine, e-Science, Serendipity.
 I. INTRODUCTION
 The proliferation of affordable computing resources, com-
 bined with the pervasive deployment of sensors and large scale
 instruments capable of capturing huge amounts of data, has
 enabled the rapid growth of data-driven computational science,
 also known as e-Science, as defined in the framework of
 the fourth paradigm [1]. This has led to an explosion in the
 availability of scientific datasets [2], including raw data taken
 directly from measuring instruments and also derived data
 from computational models and simulations [3]. These datasets
 can be stored on-line in large volume in public or private
 repositories, and be made accessible to users within a scientific
 community or beyond, in an effort to foster inter-organizational
 and inter-disciplinary research that can accelerate scientific
 discovery [4], [5].
 Finding datasets for scientific work requires to discover
 them across a wide range of domains inter-related, such as an
 interdisciplinary research about a particular natural phenom-
 ena. By using current systems or portals for searching datasets
 it is not possible to find relationships among them, if the user
 does not have any prior knowledge about the data attributes
 and terminology.
 There have been many efforts to create search engines
 suitable for discovering scientific datasets. One of the biggest
 scientific data repository is known as the World Data System
 (WDS) [6]. The system includes data from more than hundreds
 repositories. Among the other data repositories, we can note
 the Global Change Master Directory [7] or the National
 Oceanic and Atmospheric Administration Climate Services [8].
 Although widely used by scientists, all of them implement
 keyword-based search engines, especifically, they allow data-
 attribute search.
 In this paper, a new search engine is introduced named
 ÒCross-DBÓ, for Cross-Database search system. Its specifici-
 ties are: 1) It is especially oriented for datasets discovery,
 facilitating the data access and their usability. 2) It provides
 high quality-ensured data and information especially for the
 scientists since it is capable to find the related and correlated
 datasets.
 The main contributions of this paper are listed as follows:
 ¥ A model and architecture for discovering appropriate
 and comprehensive sets of datasets based on multi-
 correlational optimization process, which considers
 the combination of spatiotemporal, ontological and
 citational correlations.
 ¥ Based on a genetic algorithm enhanced with original
 and specific genetic operators a quality function is
 constructed to effectively optimize and determine the
 quality score for a set of datasets and not for an
 individual dataset.
 II. CROSS-DB SYSTEM ARCHITECTURE
 Fig. 1 shows the architecture of the Cross-DB search
 system. Basically it is composed of three layers. The upper
 layer correspond to the application, where the web-search
 interface is located and where users have direct interaction
 by performing queries and visualizing the results. The middle
 layer is the correlation engine that is composed of a complex-
 join process which integrates several types of correlations in
 order to find not only the objects satisfying the userÕs query,
 but also all the other objects that are somehow linked to
 those objects. The typical objects are datasets, web docu-
 ments, microblogs, etc. Initially, for simplicity, only datasets
 are considered in this paper. In the lower layer, the system
 4235"KGGG"Kpvgtpcvkqpcn"Eqphgtgpeg"qp"Dki"Fcvc"
 ;978-1-4799-1293-3/13/$31.00 ©2013  IEEE 
Fig. 1: Conceptual Architecture of Cross-DB Search System
 collects the description of the objects (metadata) by harvesting
 several digital repositories. Then, metadata is used to find the
 correlations.
 1) Spatio-Temporal Correlation: The spatio-temporal cor-
 relation represents the possibility to find datasets in a surround-
 ing area and/or a specific point of time. Consider two datasets
 a and b with a geographical area represented as a rectangle
 R1 and R2 for each dataset, respectively. Let (x1, y1) be the
 location of the bottom-left corner of R1 and (x2, y2) be the lo-
 cation of its top-right corner. Similarly, let (x3, y3) and (x4, y4)
 be the respective corner locations for R2. The intersection of
 R1 and R2 will be a another rectangle R3 whose bottom-left
 corner is at (max(x1, x3), max(y1, y3)) and top-right corner
 at (min(x2, x4), min(y2, y4)). If max(x1, x3) > min(x2, x4)
 or max(y1, y3) > min(y2, y4) then R3 does not exist, i.e.
 R1 and R2 do not intersect. Then, the spatial correlation CS
 between datasets a and b is defined by: CS(a, b) = 12 [R3R1+R3R2 ].
 If both overlap completely, the result is 1. In case there is no
 intersection, the result is 0.
 For temporal correlation, the starting and ending time of
 the capturing data is considered. For instance, STa and ETa
 represent the starting time and ending time for dataset a,
 respectively. Temporal correlation CT between datasets a and
 b is defined as:
 CT (a, b) = 12 [
 t
 ETa ? STa
 +
 t
 ETb ? STb
 ] (1)
 where t is the overlapping time between datasets a and b.
 Finally the spatio-temporal correlation between datasets a and
 b is defined by:
 CST (a, b) = CS(a, b) + CT (a, b)2 (2)
 2) Ontological Correlation: The ontological correlation
 aims at finding datasets in related subjects and disciplines. It
 is computed as follows:
 1. Clustering the datasets according to their similarity. That
 is, every dataset should belong to one or more clusters. 2. With
 the knowledge of an expert, each cluster is labeled and mapped
 to a specific class or concept in the ontology. As our aim
 is to find scientific datasets, an appropriate public scientific
 ontology is the Semantic Web for Earth and Environmental
 Terminology ontology (SWEET) [9]. 3. Using a conventional
 algorithm, the score similarity between the nodes of the
 ontology is computed. In this paper, the ILIADS algorithm
 [10] is utilized. That is, all the connections among the nodes
 in the ontology have a score. For instance, the score for the
 connection from node x to node y is represented as S(vx, vy).
 Then the ontological correlation between datasets a and b
 can be calculated, as follows: 1. Find the label of the cluster
 Ca and Cb for each dataset, respectively. 2. For Ca and Cb
 find the class or concept associated, say va and vb. 3. Calculate
 the distance between va and vb by using the geodesic distance
 [11] which is the number of edges of the shortest path that
 connect them.
 Let d(va, vb) denote the distance between va and vb where
 va, vb ? V . Obviously if va = vb, then d(va, vb) = 0.
 Otherwise d(va, vb) = S(va, vb), assuming that va and vb are
 first-degree distant.
 10
Therefore d(va, vb) is defined as:
 d(va, vb) = 1
 n(n? 1)
 ·
 i,j
 d(vi, vj) (3)
 where n is the number of vertices in the path between va and
 vb. Finally, the ontological correlation between datasets a and
 b is defined as: CONT (a, b) = ed(va,vb) where e is the base of
 the natural logarithm.
 3) Citational Correlation: Data Citation (DC) refers to the
 relationship between web documents and datasets. Citational
 correlation is used to discover set of datasets that are frequently
 cited together[12]. It allows users to understand which datasets
 have been used for what purpose, or in what other prior works.
 The citational information is harvested together with the
 metadata and stored in a specific repository named Data
 Citation Archive (Fig. 1). Then, a process for association rule
 discovery [13] is executed on this repository to find the text-
 to-data associations between typical text-attributes contained
 in web documents and typical data-attributes contained in
 scientific databases. Each association rule has its support
 value and the hub score for each text-attribute. Citational
 correlation between datasets a and b is calculated as follows: 1.
 Compute STPk: the strength of each path between datasets a
 and b, as follows: ST Pk = hubi ? suppi,j where k ? K, K is
 the number of paths that exist between two datasets, hubi is the
 hub score of text-attribute i, and suppi,j is the support value of
 the rule that associates text-attribute i with data-attribute j. 2.
 Then, count the total strength of all paths:T ST P =
 ·
 k STPk.
 Finally the citational correlation between datasets a and b is
 defined by: CDC(a, b) = 2 ? [ 11+eTSTP ? 12 ] where e is the
 base of the natural logarithm.
 III. COMPLEX-JOIN SEARCH ENGINE
 The design of the Complex-Join search engine is based
 on a genetic algorithm (GA). This choice is motivated by the
 following reasons. First, the search space consists of all the
 datasets (DS) contained in the system. Hence, exploring the
 search space for relevant datasets can be seen as a highly
 dimensional problem that possesses a huge amount of local
 optima. GAs are known for their robustness and their capability
 to rapidly explore noisy and large search spaces. Second, the
 stochastic nature of GA allows the search to keep and to
 discover diversity, independently of the initial query.
 A. Analogy with Graph Theory
 In the proposed GA, a candidate solution is a finite
 collection of datasets lying in the semi-finite space ?. If
 we see ? as the graph ? = (V, E) where V is the set of
 nodes (datasets) and E is the set of edges that symbolize the
 correlations between the datasets, then a candidate solution
 can be represented as the complete graph S = (V ?, E?) where
 V ? ? V , {V ?} = {v?1, . . . , v?|V ?|}, and {E?} = {e?1, . . . , e?|E?|}.
 Since the links can be seen as a distance measurement between
 two nodes, and that the distance is in this case the strength of
 the correlations that links the datasets, we will refer to the
 graphs as Òcorrelational graphsÓ. Each edge of E possesses
 NC components, ei = {ei1, . . . , eiNC}, (i = 1, . . . , |E|), that
 correspond to NC types of correlations.
 B. Problem Definition and GA Objective Function
 Given the set ?, the goal of the GA is to determine the
 optimal set S? = (V ?, E?) such that V ? ? V and 1. At least
 one type of correlations that connect one node to another is
 above a threshold thres corr for each node. 2. The overall
 correlations that group all the nodes together is as high as
 possible. 3. The number of nodes that compose V ? is as big as
 possible. 4. The diversity present in V ? is as high as possible.
 Formally, the Complex-Join seeks an optimal or near-
 optimal solution of the nonconvex optimization problem
 maxS?? f(S), where S is a candidate solution and f is a real-
 valued function that is also used as the GA objective function:
 f(S) = ia?MCS(S)+ib?P LENGTH(S)+ic?DIV (S),
 (4)
 where MCS is the mean correlation strength defined as
 MCS =
 ·NC
 j=1 pj ? µS,j with µS =
 ·|E?|
 i=1 ei|E?| ={µS,1, . . . , µS,NC} and pj ? [0, 1], j = 1, . . . , NC. MSC
 is thus the average of the correlation values for each type of
 correlation, scaled by a preference factor p specified by the
 user. P LENGTH is the size of the biggest connected com-
 ponent of S. The connections of graph S can be represented
 by the adjacency matrix A(S), such that the term
 aij =
 {
 1, if max(e?{ij}) ³ thres corr,
 0, otherwise.
 We then define for our case: Given S = (V ?, E?), a subgraph
 C = (VC , EC) is a maximally connected component if C is
 connected and for all vertices u such that u ? V and u /? VC
 there is no vertex v ? VC for which auv = 1. DIV measures
 the diversity in terms of provenance of the set of nodes V ?. In
 Equation (4), ia, ib and ic are the importance factors attributed
 by the user to each objective.
 IV. EXPERIMENTAL RESULTS
 WDS Pangaea Portal as well as Cross-DB have been
 queried using the same keywords for comparison. The frame-
 work adopted in this paper is as follows. First, a list of ten
 arbitrary keywords mainly inspired from environmental science
 has been created. By using each keyword, Cross-DB and WDS
 have been queried separately and the amount of retrieved DS
 has been recorded (in |Cross-DB| and |WDS|, respectively).
 The number of common DS to, as well as the number of
 DS uniquely retrieved by both systems have also been tracked
 (within |X ? Y |, |X \ Y | and |Y \X|, respectively, assuming
 X = Cross-DB and Y = WDS). Let (X \ Y ) and (Y \X) be
 the sets that represent the DS unique to Cross-DB and WDS,
 respectively. For each DS contained in the sets, three experts
 were asked to judge whether the DS were relevant or not.
 Let F be an arbitrary set of DS. The relevance of a DS i
 of the set F is written r(Fi) and takes the value 1 when Fi
 is considered relevant, 0 otherwise. Then the relevance of the
 set F is equal to
 ·|F |
 i=1 r(Fi)/|F |, where |F | represents the
 number of elements in F .
 Similarly, we have also evaluated the serendipity of Cross-
 DB. The serendipity is defined in [14] as being a measure
 of the extend to which a DS is considered as attractive and
 surprising for the user. Therefore, a serendipitous DS should
 not have been expected by the user but should also be useful.
 11
TABLE I: Comparison Results between Cross-DB and WDS in terms of Relevance
 Query Number of DS retrieved Number of DS retrieved |X ? Y | |X \ Y | r(X \ Y ) |Y \ X| r(Y \ X)
 by Cross-DB = |X| by WDS = |Y |
 1. global warming 74 61 33 41 74.8% 28 42.9%
 2. marine biology 53 114 38 15 40.0% 76 10.6%
 3. ice sheet 147 432 136 11 63.8% 296 6.2%
 4. pollution 344 90 62 282 78.2% 28 20.6%
 5. el nino 184 22 18 166 76.3% 4 41.7%
 6. seasonality 481 337 122 359 60.4% 215 14.2%
 7. aromatic hydrocarbon 68 53 41 27 82.5% 12 32.8%
 8. climate change 488 579 403 85 83.7% 176 15.0%
 9. enzyme 82 101 65 17 65.1% 36 11.3%
 10. heat flux 439 376 287 152 42.6% 89 14.4%
 Mean 236 216.5 120.5 115.5 66.7% 96 21.0%
 TABLE II: Serendipity Evaluation of Cross-DB
 Keyword |X \ Y | serend(X \ Y )
 1. global warming 41 79.7%
 2. marine biology 15 39.8%
 3. ice sheet 11 72.7%
 4. pollution 282 61.1%
 5. el nino 166 68.4%
 6. seasonality 359 55.5%
 7. aromatic hydrocarbon 27 47.6%
 8. climate change 85 72.6%
 9. enzyme 17 66.9%
 10. heat flux 152 47.5%
 Mean 115.5 61.2%
 By assuming that the set Y = WDS contains all the DS that
 are expected by the user, then the originality or unexpect-
 edness provided by Cross-DB lies in the set (X \ Y ) with
 X = Cross-DB. Serendipity of an arbitrary set F is calculated
 with the following formulae: serend(F ) = ·|F |i=1 u(Fi)/|F |,
 where u(Fi) is a function that evaluates the usefulness of the
 DS i of the set F . The averaged serendipity score for each
 keyword are reported in Table II.
 V. CONCLUSIONS AND FUTURE WORK
 A framework for discovering correlated datasets from
 large-scale scientific data has been proposed. It provides
 scientists with a quick selection tool and with improved
 comprehensibility with the results. It relies on an enhanced
 GA as the core of the search engine which performs a multi-
 optimization of several types of correlations among datasets.
 Empirical comparisons between Cross-DB and WDS reveals
 that the result sets contains a proportion of common returned
 DS. However, it is the original DS unique to each system that
 highlight their characteristics. Indeed, our experimentations
 demonstrate that while WDS focuses on displaying documents
 that simply match a given keyword, without much more strat-
 egy, Cross-DB on the other hand emphasizes on the relations
 that exists between the DS contained in the result set. For
 future work, a lot of improvements are considered over the
 current proposed system. 1. Let the users perform queries by
 example data. That is, the users are allowed to discover latent
 correlations among their own datasets and external datasets
 provided by the system. 2. Since scalability is one of the most
 important issue to obtain more interesting results quickly, a
 user-defined harvester method has to be developed to include
 many different large and heterogeneous data repositories. 3.
 Query processing can be extended by a concept dictionary
 for aggregating diversity for better performance. Moreover,
 sophisticated Natural Language Processing and text mining
 techniques may be added so that query processing can better
 capture the userÕs intention.
 REFERENCES
 [1] Tony Hey, Stewart Tansley and Kristin Tolle (eds.), ÒThe Fourth
 Paradigm: Data-Intensive Scientific DiscoveryÓ, Microsoft Research,
 2009.
 [2] Yogesh L. Simmhan, Sangmi Lee Pallickara, Nithya N. Vijayakumar,
 and Beth Plale, ÒData Management in Dynamic Environment-driven
 Computational Science, in Grid-Based Problem Solving EnvironmentsÓ,
 Springer, Boston, MA, USA, July 2007.
 [3] Jia Yu and Rajkumar Buyya, ÒA taxonomy of scientific workflow systems
 for grid computingÓ, SIGMOD Rec. 34, 3. Sept. 2005.
 [4] M. Humphrey, D. Agarwal, and C. van Ingen, ÒFluxdata.org: Publication
 and Curation of Shared Scientific Climate and Earth Sciences DataÓ, In
 Proc. of the 5th IEEE international Conference on e-Science. Oxford,
 UK. December 2009.
 [5] ÒBits of Power: Issues in Global Access to Scientific DataÓ, Committee
 on Issues in the Transborder Flow of Scientific Data, National Research
 Council, 1997, National Academy of Science.
 [6] www.icsu-wds.org/ [Last Accessed: Jun 20, 2013]
 [7] www.climate.gov/search/about.html [Last Accessed: Jun 20, 2013]
 [8] gcmd.nasa.gov/index.html [Last Accessed: Jun 20, 2013]
 [9] Semantic Web for Earth and Environmental Terminology (SWEET).
 http://sweet.jpl.nasa.gov/ontology. [Last Accessed: Feb 20,2013]
 [10] O. Udrea, L. Getoor and R.J. Miller, ÒLeveraging data and structure in
 ontology integrationÓ, in Proc. of the 2007 ACM SIGMOD International
 Conference on Management on Data, pp. 449-460, 2007.
 [11] www.en.wikipedia.org/wiki/Distance (graph theory) [Last Accessed:
 Feb 20,2013].
 [12] E. Gonzales, X. Zhang, Y. Akahoshi, Y. Muruyama and K. Zettsu,
 ÒData Citation Wiki for Harnessing Collective Intelligence on Document-
 to-Data Associations to Interdisciplinary Data AccessÓ, International
 Council of Science: Commitee on Data for Science and Technology,
 Poster Presentation, Taiwan, 2012.
 [13] R. Agrawal and R. Srikant, ÒFast Algorithms for Mining Association
 RulesÓ, in Proc. of the 20th VLDB Conf., pp. 487-499, 1994.
 [14] Herlocker J., Konstan J., Terveen L., and Riedl J, ÒEvaluating
 collaborative filtering recommender systemsÓ, ACM Transactions on
 Information Systems, Vol. 22, No. 1, pp. 5-53, 2004.
 12
