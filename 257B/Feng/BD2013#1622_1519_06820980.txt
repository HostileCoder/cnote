 
Application-aware Resource Allocation for SDN-based Cloud Datacenters 
Weifan Hong 
Department of Computer Science 
National Chiao Tung University 
Hsinchu, Taiwan 300 
dekger11@gmail.com 
Kuochen Wang and Yi-Huai Hsu 
Department of Computer Science 
National Chiao Tung University 
Hsinchu, Taiwan 300 
kwang@cs.nctu.edu.tw 
vince010549.cs99g@nctu.edu.tw 
 
Abstract—? In cloud datacenters, since resource requirements 
change frequently, how to assign and manage resources 
efficiently while meeting service level agreements (SLAs) of 
different types of applications is an important research issue. 
In this paper, we propose an Application-aware Resource 
Allocation (App-RA) scheme to predict resource requirements 
and allocate an appropriate number of virtual machines (VMs) 
for each application in SDN-based cloud datacenters. To the 
best of our knowledge, the proposed App-RA is the first 
application-aware resource allocation scheme that adapts to all 
types of applications. The App-RA can meet SLAs, allocate 
resources efficiently, and reduce power consumption for each 
application in cloud datacenters. The proposed App-RA adopts 
the neural network based predictor to forecast the 
requirements of resources (CPU, Memory, GPU, Disk I/O and 
bandwidth) for an application. In the proposed App-RA, we 
have designed two algorithms which allocate appropriate 
numbers of virtual machines and use the VM allocation 
threshold to avoid SLA violations for five different types of 
applications. In addition, we adopt an SDN-based OpenFlow 
network with CICQ switches to appropriately schedule packets 
for different types of application in the network layer. Finally, 
simulation results show that the power consumption of the 
proposed App-RA is only 9.21% higher than that of the best 
case (oracle) and the power consumption of EAACVA, which is 
a representative resource allocation method for non-graphic 
applications, is 104.58% worse than that of App-RA. 
Furthermore, the SLA violation rate of the proposed App-RA 
is less than 4% for all applications. 
Keywords - Service level agreement; application-aware; 
resource allocation; cloud datacenter; software define network. 
I.  INTRODUCTION 
In cloud datacenters, resource requirements changes 
frequently. Therefore, dynamic allocating and managing 
resources to meet the SLA of each application is an 
important research issue. The objective of dynamic resource 
allocation is to satisfy the SLA while minimizing the power 
consumption in cloud datacenters. In order to satisfy the 
SLA of each application, resource prediction is a 
fundamental technology. A resource prediction tool is used 
to predict resource requirements, and then we can allocate 
resources in advance to avoid SLA violation. In existing 
resource allocation schemes, most of them adopt a neural 
network based prediction, which has been proved its 
prediction accuracy, so we also adopt a neural network 
based predictor. 
There are two types of resource allocation: server-aware 
resource allocation and application-aware resource 
allocation. The server-aware resource allocation, which 
detects loading of a server and allocates VMs for all 
applications in the server, cannot assign different SLAs to 
different applications. In contrast, application-aware 
resource allocation, which detects loading in an application 
and allocates VMs to the application, can assign different 
SLAs to different applications. 
In a cloud datacenter, even if we predict and allocate 
network bandwidth for each application in advance, the 
network may still congest. In order to resolve this problem, 
we adopt an SDN-based OpenFlow [1] network with a 
CICQ switch to schedule packets for different applications 
in the network layer. OpenFlow is an open standard to allow 
researchers to run experimental protocols in realistic 
networks and is currently deployed in large-scale 
datacenters, like GENI [1]. 
In this paper, we propose an Application-aware 
Resource Allocation (App-RA) scheme to predict resource 
requirements and allocate an appropriate number of VMs 
for each application in SDN-based cloud datacenters. The 
rest of the paper is organized as follows. In section II, we 
review existing resource allocation mechanisms, compare 
application-aware and server-aware resource allocation 
schemes for cloud datacenters, and introduce the OpenFlow. 
In section III, we describe the proposed App-RA scheme. In 
section IV, we evaluate our proposed App-RA scheme using 
CloudSim, and we compare the power consumption of the 
proposed App-RA with EAACVA, which is the best 
available related work for non-graphic applications. Finally, 
we conclude this paper and outline future work. 
II. RELATED WORK 
A. Resource allocation architecture 
In order to satisfy the SLA for each application, 
researchers have proposed resource allocation schemes used 
in cloud datacenters. As shown in Figure 1, there are two 
types of resource allocation: server-aware resource 
allocation and application-aware resource allocation. In the 
past, the server-aware resource allocation scheme was used 
in cloud datacenters. However, it cannot assign a different 
SLA to each application. Because there are always different 
applications in cloud datacenters, only setting a single SLA 
cannot satisfy different requirements of different 
applications. Thus, it is difficult to satisfy the SLA of each 
application in cloud datacenters. Nowadays, application-
 aware resource allocation has become the major scheme in 
cloud datacenters. 
2013 International Conference on Cloud Computing and Big Data
 978-1-4799-2829-3/13 $26.00 © 2013 IEEE
 DOI 10.1109/CLOUDCOM-ASIA.2013.44
 106978-1-4799-2830-9/14 $31.00 © 2014 IEE
 
 
 
Figure 1: Classifications of existing resource allocation methods. 
In [2], it presents a scheme which predicts workload 
using a neural network and adopts server-aware VMs 
resource allocation, but it mainly focuses on resource 
prediction. In [3], it introduces a resource prediction scheme 
using a neural network and uses a resource allocation 
scheme to save power in cloud datacenters. However, it did 
not consider an SLA for each application in cloud 
datacenters. 
We first review existing application-aware resource 
allocation which detects an application’s loading and 
allocates VMs to the application. Application-aware resource 
allocation can satisfy different SLAs for different 
applications. Its prediction is still accurate if an application 
migrates to another server, and one still can allocate 
appropriate VMs to the application. To fully utilize the 
advantage we mentioned above, we adopt application-aware 
resource allocation for the proposed App-RA. In [4], it 
proposes an application-aware resource allocation scheme to 
dynamically manage resources, and it can satisfy the SLA 
and can allocate resources efficiently for web applications 
only. In other words, it determines how many VMs should 
be allocated to satisfy the SLA. However, it only adapts to 
web applications. In [5], it proposes an application-aware 
resource allocation scheme with minimum power 
consumption. It runs benchmarks to measure how many 
VMs and power required in each application. The resource 
allocation scheme is based on a benchmark process which 
takes a lot of time. It cannot dynamically adjust numbers of 
VMs for different applications. In other words, it is a static 
scheme rather than a dynamic scheme. In addition, it did not 
consider graphic applications. 
As shown in Table I, the proposed App-RA can adapt to 
all types of applications, meet different SLAs for different  
Table I: Comparison of the proposed App-RA with related work. 
Approach EAACVA [5] App-RA(proposed) 
Suitability for what 
types of applications 
For non-graphic 
applications All types 
Different SLAs for 
different applications Yes Yes 
SLA violation handler No Yes(response time) 
Bandwidth 
provisioning No Yes 
Resource 
prediction No 
Yes
 (neural network based) 
applications, adjust resources if an application violates its 
SLA, adjust bandwidth provisioning in an SDN-based 
datacenter network for all applications, and provide resource 
prediction for each application 
B. SDN-based datacenter network 
In recent years, researchers have proposed several SDN-
 based datacenter networks which combine with cloud 
datacenters. In [6], it proposes a practical virtualization cloud 
datacenter in the SDN network and it defines an APP-ID (a 
24 bits label, which can be stored in the IP header) which is 
used to identify an application in the SDN network. However, 
it does not consider resource allocation in cloud datacenters. 
In [7], it proposes an OpenFlow-based flow level bandwidth 
provisioning scheme for CICQ switches. Because it 
schedules packets at flow level, network delay can be 
decreased by better scheduling for a flow requiring high 
bandwidth. Based on this observation, the proposed SDN-
 based cloud datacenter network schedules packets at 
application level and network delay can be decreased by 
better scheduling for an application requiring low network 
response time to meets its SLA. 
III. APPLICATION-AWARE RESOURCE ALLOCATION FOR 
SDN-BASED CLOUD DATACENTERS 
A. Application-aware resource prediction 
In the proposed App-RA, we propose an application-
 aware resource prediction to predict resource requirements 
for each application. In Figure 2, we adopt a neural network 
to predict the resource requirements (CPU, memory, GPU, 
hard disk I/O and bandwidth utilization) for each application, 
and we also use these five types of resource requirements as 
input factors for the neural network. When the neural 
network training completes, resource requirements can be 
predicted. In addition, because the number of users changes 
all the time in the internet, we also use Time Stamp as an 
input factor for the neural network to make prediction more 
accurate. In the following, we introduce the proposed 
Application-aware Resource Allocation (App-RA) scheme 
based on application-aware resource prediction to assign an 
appropriate number of VMs so as to meet the SLA of each 
applications. 
 
 
Figure 2: The proposed App-RA resource prediction scheme using a 
neural network. 
107
 
B. Application-aware resource allocation 
In this section, we introduce the proposed application-
 aware resource allocation scheme to allocate an appropriate 
number of VMs for each application. The objective of the 
proposed App-RA is to meet SLAs, allocate resources 
efficiently, reduce power consumption for each application 
and adapt all types of applications in cloud datacenters. 
In a cloud datacenters, we may need to adjust the number 
of VMs required to meet each application. Algorithm 1 
shows how to decide when to power-on or power-off VMs 
for an application. If the predicted utilization is greater than 
the VM Allocation Threshold of an application, we power on 
a VM to support this application. If the current utilization is 
less than the sum of all VMs’ capacity and the reserved 
resources (maximum utilization – VM Allocation Threshold) 
in an application, we power off a VM to save power for this 
application in the cloud datacenter. 
 
Algorithm 1 Power-on and power-off VMs for an 
application 
Xi = the number of VMs currently used by application i 
Maximum utilization = Xi * 100% 
Unused resources = Maximum utilization - Predicted 
utilization 
If Predicted utilization > VM Allocation Threshold then 
Xi = Xi + 1; 
VM Allocation Threshold = VM Allocation Threshold + VM 
capacity 
End if 
If Unused resources > (VM capacity + (Maximum 
utilization – VM Allocation Threshold)) then 
Xi = Xi - 1; 
VM Allocation Threshold = VM Allocation Threshold – VM 
capacity 
End if 
 
We also need to adjust the VM Allocation Threshold to 
meet the SLA of each application. Algorithm 2 shows how to 
dynamically adjust the VM Allocation Threshold. When the 
SLA (for example, response time) is violated, the VM 
Allocation Threshold is decreased according to an SLA 
weight (WSLA) which is a value between 0 and 1. If WSLA 
approaches 0, it means more resources are reserved for an 
application which can result in decreasing the SLA violation 
of the application, and vice versa. 
When the response time is lower than half of the 
response time specified in the SLA, the VM Allocation 
Threshold will be increased according to a power 
consumption weight (WP) which a value between 1 and 2. If 
WP approaches 2, it represents that very few resources are 
reserved for an application which can reduce power 
consumption, and vice versa. 
 
 
 
 
 
 
Algorithm 2 Adjustment of VM Allocation Threshold for an 
application 
Xi = the number of VMs currently used by application i 
WSLA = SLA weight (0 < WSLA < 1) 
WP = Power consumption weight (1< WP < 2) 
If Xi >= 1 then 
If Current response time > Response time specified in SLA 
then 
VM Allocation Threshold = VM Allocation Threshold * 
WSLA; 
Else if Current response time < (Response time specified in 
SLA / 2) then  
VM Allocation Threshold = VM Allocation Threshold * WP; 
End if 
End if 
 
C. Proposed SDN-based datacenter network design 
In cloud datacenters, even if we predict and then allocate 
network bandwidth for each application in advance, the 
network may still congest. In order to resolve this problem, 
we adopt an SDN-based OpenFlow [1] network with CICQ 
switches to schedule packets from different applications in 
the network layer. For example, the video streaming 
application needs more bandwidth, but the search engine 
application should have a high scheduling priority, so the 
packets of the search engine application can be sent earlier to 
avoid increasing network delay. We propose the following 
scheduling strategy in order to resolve the above problem: 
1. The controller maintains a bandwidth provisioning 
table for different types of applications and sends it 
to CICQ switches. 
2. The switches decide packet scheduling priorities 
based on the bandwidth provisioning table from the 
controller. 
As shown in Table II, an example bandwidth 
provisioning table is provided; however, the actual 
bandwidth provisioning may be based on the charge of each 
application. First, we need to modify an OpenFlow controller 
to support our method. We add an APP-ID (24 bits) label of 
each application to the OpenFlow packet header [6], and thus 
the controller can identify each application. The controller 
decides bandwidth provisioning for each application and 
modify the flow tables in switches. Second, we modify the 
OpenFlow switches to support our method. In Figure 3, we 
use a CICQ (Combined-Input-Crosspoint-Queued) switch [7] 
to handle packet scheduling for each application. The CICQ 
switch is a kind of crossbar switches with a small exclusive 
buffer at each crosspoint. 
 
Table II: Bandwidth provisioning for different types of applications. 
Type of an applications Bandwidth provisioning 
Search engine 10 
3D Game 8 
Social networking 6 
Video 4 
Message, Mail 2 
108
Figure 3: Using a CICQ switch to adjust the bandw
 each application. 
As shown in Figure 3, we propose a p
 method to forward packet for each applicatio
 1. In application scheduling, input 
packets and put them into corr
 buffers (APPijk’s). Application sc
 packets with minimum executio
 sends them to the corresponding bu
 2. In input scheduling, packets are
 buffers (Xij’s) according to the FIF
 3. In output scheduling, packets ar
 port Outj according to the bandwi
 table. 
 
IV. SIMULATION RESULT
 A. Simulation environment 
We used five different types of applica
 the proposed App-RA’s SLA violation 
consumption using the CloudSim [9] sim
 capacity is according to [8]. However, sin
 obtain video traffic data in Table II, APP4
 social networking with descending traffic
 APP3 with ascending traffic. We concurren
 different types of applications, as shown in
 IV shows related simulation parameters 
CloudSim does not provide the functio
 simulation, we add a network function int
 environment to evaluate the proposed A
 APP-ID to identify different applications, an
 the corresponding buffers. 
 
Table III: Five different types of applica
 Application name Types of an
 APP1 Search
 APP2 3D g
 APP3 Social networki
 tra
 APP4 Social netw
 descend
 APP5 W
  
 
In1
 Inn
 APP111
 APP112
 APP1N1
 APP1N2
 APPN11
 APPN12
 APPNN1
 APPNN2
 X11
 XN1
 Buffe
 B11
 B1N
 BN1
 BNN
 Out
  
 
idth provisioning for 
acket scheduling 
n: 
port Ini receives 
esponding input 
heduling selects 
n time [7] and 
ffer (Bij). 
 sent to output 
O order in Bij. 
e sent to output 
dth provisioning 
S 
tions to evaluate 
rate and power 
ulator. The VM 
ce we could not 
 is replaced with 
 in contrast to 
tly executed five 
 Table III. Table 
setup. Because 
n for network 
o our simulation 
pp-RA. We use 
d put packets to 
tions. 
 application 
 engine 
aming 
ng with ascending 
ffic 
orking with 
ing traffic  
eb 
 
Table IV: Simulation param
 Simulator 
Prediction technique 
Prediction tool MA
 Number of types of applications 
Number of servers 
Maximum number of VMs 
Maximum bandwidth 
WSLA 
WP 
SLA violation threshold 
 
B. Comparison of SLA violation ra
 As shown in Figure 4, we 
applications for 100 minutes. W
 violation rate for each applicatio
 resource allocation schemes. EAA
 resource allocation method for n
 had many SLA violations in APP2
 did not consider GPU in its design. 
as the SLA violation threshold. R
 Engine [10] only guarantees a Mon
 at least 95%, and Amazon EC2 [1
 Uptime Percentage at least 99%. H
 guarantee the response time specif
 application. Furthermore, the SLA
 proposed App-RA is less than 4%
 applications. 
 
Figure 4: SLA violation rate comparison fo
 resource allocation sc
 C. Comparison of power consumpt
 We evaluate the power consu
 physical servers and VMs under diff
 three different resource allocation 
Table V shows that the power cons
 App-RA is only 9.21% higher tha
 (oracle) and the power consumpti
 104.58% worse than that of App-RA
  
 
 
X1N
 XNN
 red crossbar
 1 Outn
 eters setup. 
CloudSim 3.0 
Neural network-based 
TLAB 7.11.0 (R2010b) 
5 types 
20 
80 
40 Mbps 
0.9 
1.1 
100 ms 
te 
executed five types of 
e compare the SLA 
n using three different 
CVA, which is the best 
on-graphic applications, 
 because EAACVA [5] 
Note that we set 100 ms 
emind that Google App 
thly Uptime Percentage 
1] guarantees an Annual 
owever, they could not 
ied in the SLA for each 
 violation rate of the 
 for all five types of 
 
r each application using three 
hemes. 
ion 
mption of power-on/off 
erent loadings [12] using 
schemes. Figure 5 and 
umption of the proposed 
n that of the best case 
on of EAACVA [5] is 
. 
109
 
Figure 5: Power consumption comparison for each app
 different resource allocation scheme
  
Table V: Comparison of power consumption using thr
 allocation schemes. 
Application Best case 
(Oracle) 
APP-RA 
(proposed) 
APP1 91.59% 100% 
APP2 85.66% 100% 
APP3 91.73% 100% 
APP4 89.36% 100% 
APP5 95.60% 100% 
Average 90.79% 100% 
V. CONCLUSIONS 
In this paper, we have presented an A
 Resource Allocation (App-RA) scheme to 
requirements and then allocate an approp
 virtual machines (VMs) for each applicatio
 cloud datacenters. To the best of our 
proposed App-RA is the first application
 allocation scheme that can adapt to all type
 The proposed App-RA can meet SLAs, a
 efficiently, and reduce power consumption f
 of applications in cloud datacenters. It 
network based predictor to forecast the 
resources. We have designed two algo
 proposed App-RA to allocate VMs and dy
 VM Allocation Threshold to avoid SL
 different types of applications. In addition
 presented an SDN-based OpenFlow netw
 switches to better schedule packets from d
 applications in the network layer. Finally, s
 have shown that in terms of power c
  
 
 
lication using three 
s. 
ee different resource 
EAACVA [5] 
174.59% 
264.29% 
217.33% 
184.79% 
181.88% 
204.58% 
pplication-aware 
predict resource 
riate number of 
n in SDN-based 
knowledge, the 
-aware resource 
s of applications. 
llocate resources 
or different types 
adopts a neural 
requirements of 
rithms for the 
namically adjust 
A violation for 
, we have also 
ork with CICQ 
ifferent types of 
imulation results 
onsumption, the 
proposed App-RA is only 9.21% h
 (oracle), and EAACVA, which is th
 method for non-graphic application
 App-RA. In addition, the SLA viola
 App-RA is less than 4% for each app
 VI. ACKNOWLED
 The support by the Inventec unde
 by the National Science Council 
2221-E-009-090-MY3 is gratefu
 authors would like to thank Mr. Jon
 for his valuable comments that imp
 paper. 
REFERENCE
 [1] N. McKeown, T. Anderson, H. Balakri
 J. Rexford, S. Shenker, J. Turner, “Ope
 campus networks,” in ACM SIGCOMM
 74, Apr. 2008. 
[2] Md. T. Imamt, S. F. Miskhatt, R. M. R
 network and regression based process
 scaling of Grid and Cloud resources,"
 Information Technology (ICCIT) Conf.
 [3] J. Prevost, K. Nagothu, B. Kelley, M. 
data center networks loads using stoc
 Proc. IEEE System of Systems Enginee
 27-30 June 2011. 
[4] V. Cardellini, E. Casalicchio, F. L. P
 Resource Management for Applicati
 Cloud," in Proc. IEEE Network Cloud
 (NCCA) Conf., pp.20-27, 21-23, Nov. 2
 [5] H. Viswanathan, E.K. Lee, I. Rode
 "Energy-Aware Application-Centric 
Workloads," in Proc. IEEE Paralle
 Workshops and Phd Forum (IPDPSW)
 2011. 
[6] P. Lin, J. Bi, H. Hu, "VCP: A virtuali
 intra-domain production network," in P
 (ICNP) Conf., pp.1-2, Oct. 30 2012-No
 [7] H. Jin, D. Pan, J. Liu, N. Pissinou, 
bandwidth provisioning for CICQ 
INFOCOM Conf., pp.476-480, 10-15 A
 [8] “Amazon EC2,” [Online]. Available: h
 [9] “CloudSim,” [Online]. Available: http
 [10]  “Google App Engine Service Level A
 https://developers.google.com/appengin
 [11] “Amazon EC2 Service Level Agre
 http://aws.amazon.com/ec2-sla/. 
[12] A. Beloglazov, R. Buyya1, Y. Lee, A
 Survey of Energy-Efficient Data Ce
 Systems,” in Proc. IEEE Advances in C
 igher than the best case 
e best resource allocation 
s, is 104.58% worse than 
tion rate of the proposed 
lication. 
GEMENT 
r Contract 101C179 and 
under Grant NSC102-
 l acknowledged. The 
z Lee from the Inventec 
roved the quality of this 
S 
shnan, G. Parulkar, L. Peterson, 
nFlow: enabling innovation in 
 CCR, vol. 38, no. 2, pp. 69-
 ahmant, M. A. Amin, "Neural 
or load prediction for efficient 
 in Proc. IEEE Computer and 
, pp.333,338, 22-24 Dec. 2011. 
Jamshidi, "Prediction of cloud 
hastic and neural models," in 
ring (SoSE) Conf., pp.276-281, 
resti, L. Silvestri, "SLA-aware 
on Service Providers in the 
 Computing and Applications 
011. 
ro, D. Pompili, M. Parashar, 
VM Allocation for HPC 
l and Distributed Processing 
 Conf., pp.890-897, 16-20 May 
zation cloud platform for SDN 
roc. IEEE Network Protocols 
v. 2 2012. 
"OpenFlow based flow level 
switches," in Proc. IEEE 
pril 2011. 
ttp://aws.amazon.com/ec2/. 
://www.cloudbus.org/cloudsim/. 
greement,” [Online]. Available: 
e/sla?hl=zh-tw/. 
ement,” [Online]. Available: 
. Zomaya, “A Taxonomy and 
nters and Cloud Computing 
omputers Conf., Vol. 82, 2011. 
110
