Implementation of Projected Clustering based on
 SQL queries and UDFs in Relational Databases
 Sandhya Harikumar , H. Haripriyay, M.R. Kaimalz
 Department of Computer Science and Engineering
 Amrita Vishwa Vidyapeetham,
 Amritapuri,
 Kollam, Kerala, India
  sandhyaharikumar@am.amrita.edu yharipriyagireesh@gmail.com zmrkaimal@am.amrita.edu
 Abstract—Projected clustering is one of the clustering ap-
 proaches that determine the clusters in the subspaces of high
 dimensional data. Although it is possible to efficiently cluster a
 very large data set outside a relational database, the time and
 effort to export and import it can be significant. In commercial
 RDBMSs, there is no SQL query available for any type of
 subspace clustering, which is more suitable for large databases
 with high dimensions and large number of records. Integrating
 clustering with a relational DBMS using SQL is an important
 and challenging problem in todays world of Big Data. Projected
 clustering has the ability to find the closely correlated dimensions
 and find clusters in the corresponding subspaces. We have
 designed an SQL version of projected clustering which helps to
 get the clusters of the records in the database using a single SQL
 statement which in itself calls other SQL functions defined by us.
 We have used PostgreSQL DBMS to validate our implementation
 and have done experimentation with synthetic as well as real data.
 I. INTRODUCTION
 Big data is described by a large number of attributes and huge
 volume of records which pose challenges such as standardizing
 the data inorder to have all the attributes to a common scale,
 transforming the data inorder to reduce the dimensionality,
 constructing a distance measure for knowing the similarity
 between two objects, etc. Comprehensible analysis of data is
 required to help data scientists and industry people so that the
 data being loaded into the database can make sense. Clustering
 is one such way to analyze the data and has many applications
 in various domains such as Bank, Supermarket, Bioinformatics
 etc. Recent DBMS like Oracle 11g and SQL Server 2008,
 facilitate clustering using SQL. Clustering algorithm [11] or
 any such algorithm with a relational DBMS [2] is an important
 and challenging problem. Although it is possible to efficiently
 cluster a very large data set outside a relational database,
 the time to export it can be significant. Moreover dynamic
 updating of the databases will decelerate the clustering process.
 When we implement clustering in some other languages like C,
 Java etc we need to frequently export and import the files for
 maintaining the ACID properties of database. Therefore, being
 able to cluster data set stored inside a relational database, has
 significant advantage.
 There are many algorithms for clustering data, such as K-
 means [1], [2], [3], [11], EM [5] and projected clustering [6],
 [7]. One of the main characteristics of projected clustering is
 that the records are projected along the most relevant attributes
 which give us a better understanding of the data. In case of
 big data, the volume of data is too huge and the structure is
 quite unordered. However there is an implicit structured format
 for this type of data too. Nowadays large volume of data are
 generated in every domain and the databases are quite big
 with too many attributes. Not all attributes are relevant for
 all the formed clusters. By knowing the relevant attributes, we
 can remove insignificant attributes thereby reducing the storage
 requirement of each cluster. So we need to apply a clustering
 technique to find the relevant clusters in various subspaces with
 appropriate attributes relevant for that subspace.
 The subspace clustering [8] is the task of detecting all clusters
 in all subspaces of a given dataset. This means that a data
 point might be a member of multiple clusters, each existing in
 a different subspace. Projected clustering is a type of subspace
 clustering which seeks to assign each point to a unique
 cluster, but clusters may exist in different subspaces. This
 technique can be more suitable for high dimensional data, since
 projection of relevant dimensions for a cluster is intended to
 reduce the dimensionality of data specific to that cluster. Thus,
 it is a way of finding the most relevant dimensions for a cluster
 thereby finding the projection of data with high dimensions
 onto these relevant dimensions. Implementation of projected
 clustering using SQL, allows clustering of large data sets stored
 inside a relational DBMS eliminating the need to export data.
 Apart from this we can also have clustered data in the form
 of a table which can help us to build the visualization in a
 comparatively easy manner. The clustered data of a table have
 certain meaning and some order. So when a query comes, the
 probability of accessing the data from the same cluster is more.
 Hence clustering can be a preprocessing step to build some sort
 of organizing structure of the table which can pave the way for
 efficient query processing. This clustered table can also be used
 for the fragmentation of the data in a meaningful manner in
 distributed environment. There are attempts to use SQL queries
 and User Defined Functions(UDFs) for implementing Data
 mining algorithms in [12]. The major challenge in SQL version
 of any algorithm is that apart from executing the required tasks,
 one has to work around the storage of data and manipulating
 the data such that the time complexity of the algorithm is
 not accelerated.SQL version of projected clustering in general,
 has not been addressed in the literature to the best of our
 knowledge.
 The major contributions in this paper are
 2013 IEEE Recent Advances in Intelligent Computational Systems (RAICS)
 978-1-4799-2178-2/13/$31.00 ©2013 IEEE 7
1) Design and Implementation of SQL procedures for
 projected clustering
 2) Optimized version of SQL projected clustering for
 effective and fast computation of the clusters
 II. CLUSTERING RELATIONAL DATABASES USING SQL
 A. Motivating concepts
 In K-means clustering, a data set is partitioned into K clusters
 in such a way that the sum of the total clustering errors for all
 clusters is reduced as much as possible while inter distances
 between clusters are maintained to be as large as possible1.
 Traditional K-means clustering forms clusters with dataset
 consisting of all the attributes. In high dimensional spaces
 not all dimensions may be relevant to a given cluster and
 different sets of points may cluster better for different subsets
 of dimensions. So there may be a possibility of clusters within
 clusters or different clusters within one application based on
 different attributes2.
 A hybridized K-means clustering approach for high
 dimensional dataset is for reducing the dimensions of
 the database [3]. Due to the growth of high dimensional
 dataset, conventional data base querying methods are
 inadequate to extract useful information. Principal Component
 Analysis ( L2 PCA) [9] is used as a first phase for K-means
 clustering for dimensionality reduction. But the relevant
 attribute selection for a cluster is a question here and in
 case of a high dimensional data it is good if we select some
 relevant attributes for a particular cluster and can remove all
 remaining attributes.
 Fast Algorithms for Projected Clustering (PROCLUS) is based
 on some relevant attribute selection for clustering as described
 in [6]. PROCLUS returns clusters along with the relevant
 dimensions in each cluster that signify the correlation among
 the dimensions in that particular cluster. The performance is
 enhanced by computation of Manhattan distance for finding
 potential data points for each cluster as well as finding the
 relevant dimensions of each cluster. Hence it can be adopted
 to cluster high dimensional data with relational DBMS.
 The problem of projected clustering for categorical datasets
 is addressed in [7]. This method has a probability for more
 number of outliers which will not help us in an advantageous
 manner to cluster all the required set of records in the
 database relation. In the paper, mean is used to represent a
 cluster, which implies that center of the cluster may not exist
 physically. Thus a non-existent record may form the center of
 the cluster which may create ambiquity in understanding the
 records within the cluster.
 B. Clustering using SQL
 Programming K-means clustering algorithm in SQL [1] shows
 that it is feasible to get an SQL implementation of the well-
 known K-means clustering algorithm in DBMS, that can work
 on the records of a table with numerical attributes. The paper
 introduced two implementations of K-means in SQL.
 Carlos extended the idea of programming K-means in SQL by
 Integrating K-means clustering with a relational DBMS using
 1http://en.wikipedia.org/wiki/Cluster analysis
 2http://cs.gmu.edu/cne/modules/dau/stat/clustgalgs-/clust5 bdy.html
 SQL [2]. Three SQL implementations of the popular K-means
 clustering algorithm have been presented by him in the paper.
 SQLEM is fast clustering [5] based on the efficient SQL
 implementation of the EM algorithm. It provides a cluster
 membership probability per record. There are three strategies
 to implement EM in SQL: horizontal, vertical and a hybrid one.
 In general EM is based on probability computation which may
 become computationally complex with increase in size and
 dimensionality of RDBMSs. But we do not have a standard
 algorithm that addresses this problem of complexity in EM3.
 A fast K-means prototype to cluster transaction data sets using
 disk-based matrices is an efficient disk-based K-means cluster-
 ing for relational databases [4]. The disk-based implementation
 and the SQL-based implementation represent complementary
 solutions to implement K-means in a relational DBMS, but the
 SQL-based solution will become more valuable as disk density
 and CPU speed increase and hardware costs decrease.
 The problem of integrating projected clustering in relational
 databases using SQL has to take care of many aspects such
 as storage of data, accessing data in an optimized manner,
 manipulation of data inorder to perform the actions as well
 as creation or redesigning a relational schema for storing the
 output of the algorithm. In general, these problems are not
 addressed in the literature. Hence we are focussing on the
 integration of projected clustering using SQL.
 TABLE I. LIST OF SYMBOLS
 Symbol Definition
 N Total number of records in a relation
 Nl Number of records in locality l
 Nk Number of records in cluster k
 K Total number of clusters
 k A cluster
 t Total number of attributes
 l Average number of dimensions
 Bcnt Number of badmedoids
 rij Value of j
 th attribute of ith
 record in a relation
 Rk Set of records in cluster k
 A The set of attributes in a relation
 Ak The set of attributes of k
 th cluster in a relation
 Yk Mean of k
 th cluster
 Ykj The average distance between records in cluster k
 to it’s centroid along dimension j
 Xkj The average distance between records in a
 locality to the medoid k along dimension j
  k The standard deviation of k
 th cluster
 Zkj Value indicating the relationship between mean,
 average distance and standard deviation
 wk Weight of cluster k
 III. DEFINITIONS AND NOTATIONS
 To understand the algorithm a few definitions and notations
 are defined here. The symbols we used are shown in Table
 I. Let D be the database, R = (r1; r2; ::::; rN ) be the set of
 records with each ri being described by a set of t attributes
 as A = (a1; a2::::; at) . In the context of database, each point
 (feature vector) of a cluster is in fact a record ri and each
 dimension (feature) is an attribute ai. The centroid or mean of
 a cluster of records Rk  R with attributes A is the algebraic
 average of all records along each attribute in a cluster k. In
 most of the clustering algorithms the distance between two
 records is calculated with the help of norms [10]. For a record
 3http://en.wikipedia.org/wiki/Expectation-maximization algorithm
 8
Fig. 1. Locality of medoid A with respect to medoid B and medoid C on
 the basis of  value.
 ri and a record rj , with t attributes, Lp ( p-norm distance ) is
 defined in (1).
 Lp =
  Xt
 k=1
 jrik  rjk j
 p
  1
 p
 (1)
 When p = 1, it is L1 norm, when p = 2 it is L2 norm and
 so on. The L1 norm is the absolute difference between two
 records as shown in (1). This is same as Manhattan distance
 [6] or the City block distance4.
 Manhattan segmental distance: This is defined rela-
 tive to some subset of dimensions Ai. Specifically, for
 any two records ri and rj with Ai dimensions, the
 Manhattan segmental distance between ri and rj relative
 to Ai, is defined in (2).
 dAi (ri; rj) =
 P
 k2Ai
 jrik  rjk j
 jAij
 (2)
 Employing the Manhattan segmental distance as opposed
 to the traditional Manhattan distance is useful when com-
 paring records in two different clusters that have varying
 number of attributes.
 Locality : Assume we have a dataset with many clusters and
 each cluster is represented by a medoid mk. If we need to find
 the locality of medoid, Lk then
 1) Calculate the Manhattan distance dk to it’s nearest
 medoid.
 2) Find all the records Rk  R which fall within
 distance dk.
 Rk calculated above is the locality of medoid mk. In Figure 1,
 A, B and C are three medoids and the nearest medoid of A is
 C with distance  . We have taken  instead of  /2 inorder
 to include the possibility of overlapping localities around
 medoids. The average distance, Xkj between records in a
 locality Lk to it’s medoid mk along each attribute j with Nl
 records in it’s locality is shown in (3).
 Xkj =
 PNl
 i=1
  
 mk;j  rij
  
 
Nl
 (3)
 Based on the average distance we can calculate the mean of
 a cluster Yk with t attributes by using (4).
 Yk =
 tP
 j=1
 Xkj
 t
 (4)
 4Books.google.co.in/books?isbn=080582281X
 Fig. 2. SQLPROCLUS takes as input SQL query for clustering a table and
 gives three tables as output signifying the clusters, relevant dimensions for
 each cluster and best medoids.
 The computed mean and average distance of a cluster k can
 be used for finding the standard deviation which is explained
 in (5).
  k =
 s
 P
 j (Xkj  Yk)
 2
 t 1
 (5)
 We can compute Zkj , that indicates how the j-dimensional
 average distance, Xkj associated with the medoid mk is
 related to the average Manhattan segmental distance
 associated with the same cluster with mean Yk, by using (6).
 A smaller value of Zkj indicates that along dimension j the
 records Rk are more closely correlated to the medoid mk.
 Zkj =
 Xkj  Yk
  k
 (6)
 The weight, wk of a cluster k calculated by using Ykj with
 jAkj attributes ( projected cluster ) is defined in (7).
 wk =
 X
 j
 Ykj
 jAkj
 (7)
 IV. SQL VERSION OF PROCLUS
 We have implemented the projected clustering algorithm in
 PostgreSQL5 using the following two methods.
 1) A naive translation of projected clustering in Post-
 greSQL.
 2) An optimized version using efficient indexing, rewrit-
 ten queries, and reduced intermediate database tables.
 SQL PROjected CLUStering has mainly three
 phases. Initialization phase, Iterative phase
 and Refinement phase. The purpose of the
 Initialization phase is to find a potential set of medoids by a
 greedy approach. Thus if K clusters are required to be formed,
 select B  K medoids from the set of original records, where
 B is a small integer constant. This greedy approach has the
 advantage of picking some representatives from each cluster
 using L1 and the reduction to the sample set significantly
 reduces the running time of the Initialization phase. The
 Iterative phase is the core part of SQLPROCLUS for
 selecting a good set of medoids. This is presented as an
 optimization problem. The final Refinement phase is for
 improving the quality of clustering. Refinement phase
 uses the distribution of records in clusters for finding the
 dimensions and assigning records to each cluster.
 We implement each part of PROCLUS as separate SQL
 functions and finally implement PROCLUS in SQL, named
 NAIVE SQLPROCLUS. The advantage of each function is
 that we can use it separately for finding medoids, finding
 dimensions, assigning records to each clusters, detection and
 replacement of bad medoids etc.
 5http://www.PostgreSQL.org/docs/8.0/static/tutorial.html
 9
A. Basic Framework
 The overview of the framework is shown in Figure 2.
 1) Setup: Create and populate tables with the required
 records
 2) PROCLUS
 a) Initialization phase
 b) Iterative phase
 c) Refinement phase
 3) Output
 a) Assign table (Clustered table)
 b) Dimension table
 c) BestMedoid table
 Apart from the main tables specified above, certain temporary
 tables like Medoid, Submedoid, Locality, etc. are also used.
 The main tables as well as the temporary tables used in
 the implementation are shown in Table II and Table III
 respectively.
 TABLE II. MAIN TABLES IN SQLPROCLUS
 Table name Size Contents
 Data N x t Original records
 Dimension (l*K) x 2 Medoids and their
 relevant dimensions
 Assign N x (t+1) Original records with
 their assigned medoid
 BestMedoid K x t Best medoid set
 TABLE III. TEMPORARY TABLES IN SQLPROCLUS
 Table name Size Contents
 Medoid (B*K) x t Potential medoids obtained
 using greedy approach
 SubMedoid K x t Required medoids
 selected during
 iterative phase
 Locality Nl x (t+1) Medoids with records in its
 locality which is
 subject to change during
 iterative phase
 BadMedoid Bcnt x 1 Detected bad medoids
 B. NAIVE SQLPROCLUS
 We implement SQL procedures inorder to facilitate the
 projected clustering within relational databases. The input
 to this algorithm is a Data table which we want to cluster,
 number of clusters, K, the average number of dimensions
 for each cluster, l as explained in Algorithm 1. NAIVE
 SQLPROCLUS is a direct translation of the projected
 clustering algorithm into SQL. We are making use of several
 intermediate tables, various disk accessing statements such as
 Select, Update, Delete, Insert for storing and retrieving
 the result of each function.
 The main algorithm for SQLPROCLUS is as follows
 Algorithm 1 SQLPROCLUS for clustering
 procedure SQLPROCLUS(Datatable;K; l)
 f1.Initialization Phaseg
 Perform Greedy( K )
 f2. Iterative Phaseg
 BestObjective = 1
 Perform Subset ( K )
 repeat
 fApproximate the optimal set of dimensionsg
 Perform locality ( )
 Perform FindDimensions ( K; l )
 f Form the clusters g
 Perform Assignpoints ( K; l )
 Perform Evaluateclusters ( K; l )
 Store the result of Evaluateclusters
 in objectiveV ar.
 if (ObjectiveV ar < BestObjective) then
 BestObjective = ObjectiveV ar
 Insert records of SubMedoid
 table into BestMedoid table.
 Perform Detectbadmedoids ( K )
 end if
 Insert count of records of
 Medoid table in mednt.
 Insert count of records of
 Badmedoid table in badmedcnt.
 if (medcnt and badmedcnt > 0) then
 Perform Replacebadmedoids ( )
 else
 exit
 end if
 if (BestMedoid remains same) then
 Terminate the iterative phase.
 Insert records of BestMedoid
 table into SubMedoid table.
 Perform Assignpoints ( K; l )
 end if
 until termination condition is met
 f3.Refinement Phaseg
 Insert the records of Assign table
 into Locality table.
 Perform FindDimensions ( K; l )
 Perform AssignPoints ( K; l )
 return Assign table.
 end procedure
 Each function takes as input, the number of clusters to
 be formed, K and the average number of dimensions in each
 cluster, l. The output of the functions is in the form of tables.
 At the beginning of each function we delete the records from
 the output table using Truncate statement to make the table
 empty so as to avoid redundancy of data before insertion.
 The excerpts from the implementation of one of the user
 defined functions FindDimensions in SQL is as follows.
 CREATE OR REPLACE FUNCTION
 FindDimensions(K int, l int)
 returns table(medoidid int,.
 .,dimsnvalue numeric) as
 declare
 begin
 10
Fig. 3. Main table flow in SQLPROCLUS
 Fig. 4. Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS
 by varying N
 x := array[[NULL,NULL,...,NULL]];
 ......................................
 x[q][k] := x[q][k]::float/clstrcnt[q];
 .....................................
 FOR k IN 1 .. dim LOOP
 mul:=0;
 mul := (x[q][k]-y[q]);
 mul :=mul*mul;
 squaresigma[q] := squaresigma[q]+mul;
 END LOOP;
 .....................................
 sigma[q] := squaresigma[q]::float/(dim-1);
 z[k] := z[k]::float/sigma[q];
 .....................................
 update Dimset set dimsn=999999
 where dimsn=minval;
 .....................................
 Return query select * from Dimension;
 end;
 language plpgsql;
 C. OPTIMIZED SQLPROCLUS
 The naive translation of PROCLUS into SQL has certain
 limitations in performance. These limitations are due to the
 large number of scans required for convergence in clustering
 algorithm. Iterative phase of PROCLUS require multiple scans
 of the same data in order to compute the segmental distances
 with respect to the medoids selected. Several optimizations
 Fig. 5. Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS
 by varying l
 Fig. 6. Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS
 by varying k
 were done to improve the performance without changing
 the PROCLUS behavior. In this paper, the optimizations in-
 clude index creation, cursor usage, rewrite SQL functions
 for reducing the overhead of disk access, replacing certain
 intermediate tables consisting of few records, by arrays. The
 excerpts from the implementation of optimized SQL version
 of FindDimensions is as follows.
 CREATE OR REPLACE FUNCTION
 FindDimensions(K int, l int)
 returns void as
 declare
 begin
 insert into avg_dim_dist
 select meid,avg(dist_a),...
 ......
 Fig. 7. Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS
 by varying t
 11
from locality group by meid;
 insert into avg_dim
 SELECT meid,COALESCE(am,0) + COALESCE(bm,0) + ...
 FROM avg_dim_dist ;
 .....
 update avg_dim_dist t
 set am = am - s.dist,
 bm = bm - s.dist,
 ....
 from avg_dim s
 where t.meid = s.meid;
 update avg_dim s
 set dist = sqrt((COALESCE(t.am*t.am,0) + ...
 ....
 FROM avg_dim_dist t
 where t.meid = s.meid;
 update avg_dim_dist t
 set am = am/s.dist,
 bm = bm / s.dist, ...
 ....
 from avg_dim s
 where t.meid = s.meid;
 ......
 end;
 language plpgsql;
 V. EXPERIMENTAL EVALUATION
 We evaluated the performance of NAIVE SQLPROCLUS and
 OPTIMIZED SQLPROCLUS on synthetic data and on real
 data by varying the size of database, average dimensionality
 of clusters, number of clusters and dimensions of original table.
 In varying the number of records we fixed the attribute size
 to be 10, average number of dimensions to be 5 and number
 of clusters as 5. This analysis is shown in Figure 4. We can
 see a sudden rise in time from 20000 to 25000. This is due
 to the time taken for page access of the database records
 from the hard disk. In NAIVE SQLPROCLUS the number
 of disk accesses is quite high since the records were fetched
 as and when required and lots of redundant computations were
 done without looking into the optimizations such as batch
 update, local caching and temporary table creation. But in
 OPTIMIZED SQLPROCLUS, the time has reduced drastically
 showing the optimal performance. In varying the average
 number of dimensions we fixed the size of the records to be
 10000 and number of clusters to be 3. The analysis based
 on average dimensionality of clusters shows that the graph
 remains almost constant for both the cases but the time is
 very large for NAIVE as shown in Figure 5. In varying the
 number of clusters we fixed the size of the records to be 10000
 and average number of dimensions to be 5. This analysis is
 shown in Figure 6. In analysis based on varying the number
 of dimensions we fixed the number of records to be 10000,
 average dimensions as 4 and number of clusters as 3. This
 analysis is shown in Figure 7. Figure 4, Figure 5, Figure 6
 and Figure 7 clearly exhibit that OPTIMIZED version has
 significant improvement with respect to all parameters over
 the NAIVE version.
 VI. CONCLUSION
 Integrating clustering algorithm with a relational DBMS using
 SQL is an important and challenging problem. There are
 many algorithms for clustering data such as K-means and EM.
 Among them, projected clustering is the one which is more
 suitable for high dimensional data since it projects the relevant
 dimensions for each cluster. Hence each cluster can be stored
 with limited storage requirement. We incorporated the opera-
 tions needed for projected clustering in SQL. Our experiments
 show that optimized version of SQL for projected clustering
 has good performance. This clustering can be further utilized
 for developing a prototype for efficient query processing. This
 will have significant relevance in query processing applications
 in mobile, tablet and other such portable devices which has
 limited storage.
 ACKNOWLEDGMENT
 We would like to thank the faculty members of the Depart-
 ment of Computer Science and Engineering, Amrita Vishwa
 Vidyapeetham for their support.
 REFERENCES
 [1] C.Ordonez ”Programming the K-Means Clustering Algorithm in SQL”
 Proc. ACM Int’l Conf. Knowledge Discovery and Data Mining, pp.
 823-828, 2004.
 [2] Carlos Ordonez ”Integrating K-Means Clustering with a Relational
 DBMS Using SQL” IEEE transactions on knowledge and data engi-
 neering, vol. 18, no. 2, February 2006.
 [3] Rajashree Dash, Debahuti Mishra, Amiya Kumar Rath2, Milu charya3
 ”A hybridized K-means clustering approach for high dimensional
 dataset” International Journal of Engineering, Science and Technology
 Vol. 2, No. 2, 2010, pp. 59-66.
 [4] Bradley, Fayyad, Cory ”Scaling Clustering Algorithms to Large
 Databases” Microsoft Research Report, 1998.
 [5] Carlos Ordonez, Paul Cereghini ”SQLEM: Fast Clustering in SQL using
 the EM Algorithm” ACM SIGMOD 2000 .
 [6] Charu C. Aggarwal, Cecilia Procopiuc ”Fast Algorithms for Projected
 Clustering” SIGMOD ’99 .
 [7] Minho Kim and R.S.Ramakrishna ”Projected clustering for categorical
 datasets” 2006 Elsevier B.V.
 [8] Carlotta Domeniconi,Dimitris Papadopoulos Dimitrios Gunopu-
 los,Sheng Ma ”Subspace Clustering of High Dimensional Data” SIAM
 Int. Conf. on Data Mining, 2004
 [9] Jolliffe, Ian T ”Principal component analysis” Springer verlag,2002
 [10] Gentle, James E ”Matrix algebra: theory, computations, and applications
 in statistics”Springer Verlag,2007
 [11] Rui Xu, and Donald Wunsch II, Fellow, IEEE ”Survey of Clustering
 Algorithms”,1045-9227 2005 IEEE
 [12] Carlos Ordonez, Carlos Garcia-Alvarado ”A Data Mining System Based
 on SQL Queries and UDFs for Relational Databases” CIKM Conference
 2011
 12
