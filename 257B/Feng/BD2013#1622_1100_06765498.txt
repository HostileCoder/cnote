Organic Streams: Data Aggregation and Integration 
Based on Individual Needs 
 
Xiaokang Zhou, Qun Jin, Bo Wu, Wei Wang 
Graduate School of Human Sciences, 
Waseda University, 
Tokorozawa, Japan 
{xkzhou@ruri., jin@, wubo@ruri., ougi@ruri.}waseda.jp  
Julong Pan, Wenbin Zheng 
College of Information Engineering, 
China Jiliang University, 
Hangzhou, China 
{pjl, zhengwb}@cjlu.edu.cn
  
Abstract—With the high accessibility of the social media, 
more and more people have been accustomed to sharing their 
personal contents across the social networks, which results in an 
explosive increase of data scale. In this study, in order to support 
information and knowledge discovery in big data, we propose an 
approach to aggregation and integration of personal big data 
from life logs in accordance with individual needs, which can 
benefit the sustainable information utilization process. In details, 
the organic stream, which is designed as an extensible data 
carrier, is introduced and developed to formulize and organize 
the personal big data, in order to extract dynamical individual 
needs from the tremendous amount of data posted through social 
media, and further aggregate and integrate the related data in a 
meaningful way, which can also facilitate the personalized 
information retrieval and reuse process. The architecture of the 
system with the foundational modules is given, and the 
experiment result is presented to demonstrate the usability and 
effectiveness of our approach. 
Keywords—Big Data; Life Log; Data Aggregation; Data 
Integration; Individual  Need 
I.  INTRODUCTION 
With the continuous development of social media (such as 
Twitter, Facebook), more and more populations have been 
involved into this social networking revolution, which leads to 
a tremendous increase of data scale, ranging from the daily text 
data to multimedia data that describes different aspects of 
people’s life. For instance, every month, Facebook deals with 
570 billion page views, stores three billion new photos, and 
manages 25 billion pieces of contents [1]. Big data, which 
“includes data sets with sizes beyond the ability of current 
technology, method and theory to capture, manage, and process 
the data within a tolerable elapsed time” [2], are “high-volume, 
high-velocity, and/or high-variety information assets that 
require new forms of processing to enable enhanced decision 
making, insight discovery and process optimization” [3]. That 
is, it has become a big challenge to process such massive 
amounts of these complex big data, which has attracted a lot of 
attentions from academia, industry and government as well.  
Life log, a kind of personal big data, has also attracted 
increasing attentions in recent years. Life logs include a variety 
of data, such as text, location, sound, images and videos, which 
are dynamically produced from multiple sources and with 
different data structures or even no data structures. 
Consequently, it is difficult for an individual (end-user) to 
utilize the useful information hidden in these records, such as 
user experience, knowledge, by simply processing the raw data 
from life logs. Therefore, it is necessary to find a way to 
effectively integrate and mine this kind of personal big data 
that records people’s information behaviors and social 
activities in both cyber space and real world, in order to 
provide people with valuable individualized service. 
In our previous study, we have introduced and defined the 
so-called organic stream with the formal description, which can 
discover and represent the potential relations among data, in 
order to organize the raw stream data into the methodically pre-
 prepared form [4]. In this study, in order to facilitate the 
sustainable data utilization process, we propose and develop an 
effective way to aggregate and integrate the personal big data 
in accordance with individual needs, which can further benefit 
the information fusion and knowledge discovery process. We 
extend and refine the definition of organic stream to be an 
extensible data carrier to formulize and organize the personal 
big data from life logs in a meaningful and flexible way, which 
can assist the transformation from data to information, and 
from information to knowledge, and finally from knowledge to 
asset iteratively. 
The rest of this paper is organized as follows. We give a 
brief overview on the related issues and works in Section II. In 
Section III, we introduce and extend the concept of organic 
stream into the data level, and further propose the mechanism 
to aggregate and integrate the personal big data in accordance 
with individual needs. We present the architecture of a data 
aggregation and integration system, and show empirical 
analysis results in Section IV. We conclude this study and give 
some promising perspectives on future works in Section V. 
 
II. RELATED WORK 
Big data has drawn more and more researchers these years 
[5-10]. Alsubaiee et al. [5] have built a parallel database system 
called ASTERIX, which tried to combine time-tested principles 
from parallel database systems with those of the Web-scale 
computing community, in order to deal with the “Big Data” 
management challenges. Berkovich et al. [6] have developed a 
tool to cluster diverse information items in a data stream mode, 
which can enhance the available information processing 
resources for on-the-fly clusterization from diverse sources. 
Hoi et al. [7] have proposed a feature selection algorithm in 
535
order to solve the online feature selection (OFS) problem. 
Zhang et al. [8] have presented a parallel rough set based 
approach using MapReduce for knowledge acquisition on the 
basis of the characteristics of data, in order to mine knowledge 
from big data. Menon et al. [9] focused on data warehousing 
and analytics platform of Facebook to provide support for 
batch-oriented analytics applications. Han et al. [10] introduced 
a big data model which used social network data for 
information recommendation related to a variety of social 
behaviors. 
There are many analyses, as well as applications, which 
focus on life logs [11-16]. Yamagiwa et al. [11] have proposed 
a system to achieve an ecological lifestyle at home, in which 
sensors measure the social life log by the temperature, 
humidity, intensity of illumination related to human action and 
living environment closely. Hori et al. [12] developed a 
context-based video retrieval system which utilized various 
sensor data to provide video browsing and retrieval functions 
for life log applications. Hwang et al. [13] developed a 
machine learning method for life log management, in which a 
probabilistic network model was employed to summarize and 
manage the human experiences by analyzing various kinds of 
log data. Kang et al. [14] have defined metadata to save and 
search life log media, in order to deal with those problems such 
as high-capacity memory space and long search time cost. 
Shimojo et al. [15] have re-engineered the life log common 
data model (LLCDM) and life log mashup API (LLAPI) with 
the relational database MySQL and the Web services, which 
can help access the standardized data, in order to support the 
integration of heterogeneous life log services. Nakamura et al. 
[16] proposed a method to infer users’ temporal preference 
according to their interests by analyzing the web browsing logs. 
As for data aggregation [17-22], Ozdemir [17] has 
presented a reliable data aggregation and transmission protocol 
based on the concept of functional reputation, which can 
improve the reliability of data aggregation and transmission. 
Jung et al. [18] proposed and developed two data aggregation 
mechanisms based on hybrid clustering: the combined 
clustering-based data aggregation mechanism and the adaptive 
clustering-based data aggregation, in order to improve both 
data aggregation and energy efficiency. Iftikhar et al. [19] have 
presented a rule-based tool to maintain data at different levels 
of granularity, which features automatic gradual data 
aggregation. Rahman et al. [20] proposed a privacy preserving 
data aggregation scheme named REBIVE (reliable private data 
aggregation scheme), which considers both data accuracy 
maintenance and privacy protection, in order to provide 
privacy preservation technique to maintain data accuracy for 
realistic environments. Wei et al. [21] have proposed three 
prediction-based data aggregation approaches: grey-model-
 based data aggregation (GMDA), kalman-filter-based data 
aggregation (KFDA), and combined grey model and kalman 
filter data aggregation (CoGKDA), which can help reduce 
redundant data communications. Ren et al. [22] proposed an 
attribute-aware data aggregation (ADA) scheme which consists 
of a packet-driven timing algorithm and a special dynamic 
routing protocol, to improve the data aggregation efficiency 
and further benefit the data redundancy elimination. 
Research works have also been tried on data integration. 
)?ßß? [23] defined a system for online data integration based on 
the binary operations of relational algebra. Atkinson et al. [24] 
have proposed a framework of data mining, access and 
integration, to deal with the scale-up issue of data integration 
and data mining across heterogeneous and distributed data 
resources and data mining services. Sarma et al. [25] have 
described the approximation algorithms to solve the cost-
 minimization and maximum-coverage problems for data 
integration over a large number of dependent sources. Tran et 
al. [26] have developed a platform for distributed data 
integration and mining, in which data are processed as streams 
by processing elements connected together into workflows. 
Gong et al. [27] introduced the architecture and prototype 
implementation to provide a dynamic solution for integration 
of heterogeneous data sources. 
 
III. DATA AGGREGATION AND INTEGRATION 
In this section, based on the extension of organic stream 
which is employed as a self-adaptive data carrier to 
meaningfully formulize and organize the personal big data 
from life logs, an integrated mechanism is proposed and 
developed for the user need-based data aggregation and 
integration. 
A. Organic Streams: Extension and Refinement 
In our previous study [4], we have introduced and defined 
the concept of organic stream, in order to benefit the 
meaningful organization of social streams. In this study, we 
extend the organic stream as an effective means to formulize 
and organize personal big data from life logs based on 
individual needs, which can assist the data aggregation and 
integration process. 
The following definitions are given for the analysis and 
collection of the data that fit individual needs. 
Heuristic Magnet? The Heuristic Magnet is the data that 
is aggregated to describe an individual’s continuous changing 
need, concern and interest. 
Associative Entity: The Associative Entity is used to 
describe the related data entity that is aggregated in a data 
collection in accordance with individual needs, which can 
further be employed to describe the relationships among data. 
Collective Body?The Collective Body is the meaningfully 
aggregated and integrated data collection based on individual 
need, concern and interest. 
We discover and mine individual needs by analyzing and 
aggregating his/her related data, which are represented by 
Heuristic Magnets, and will further become the aggregating 
center. The data related to this center will be aggregated as the 
Associative Entity. Finally, the Collective Body is generated to 
describe the relationships among data according to individual 
need, concern and interest. 
Based on these discussed above, we extend the concept of 
organic stream as a data carrier in the individual need-based 
data aggregation and integration process. 
536
                             ?? ? ?"???? ??? ??                              (1) 
where, 
Hm = { Hm[u1, t1], Hm[u2, t2], ..., Hm[ux, ty]}: To represent a 
nonempty set of Heuristic Magnet, where H
 m
 [ui, tj] denotes the 
Heuristic Magnet that indicates the need for a specific 
individual ui in a specific time period tj. 
Ae = {Ae1, Ae2, …, Aen}: To represent a set of Associative 
Entities based on inherent or potential relations to the 
individual needs. 
R: To describe the relationships among Heuristic Magnets 
and Associative Entities in organic stream. 
These relationships can be defined as follows. 
Heuristic Magnet ? Associative Entity: The basic 
relationship between Heuristic Magnet and Associative Entity 
in organic stream, which is used to describe relationships 
between aggregated data and individual needs. 
Heuristic Magnet ? Heuristic Magnet: The relationship 
among Heuristic Magnets in organic stream, which is used to 
describe the similarities among different individual needs.  
Associative Entity ? Associative Entity: The relationship 
among Associative Entities in organic stream, which is used to 
describe the relationships among aggregated data in a 
Collective Body. 
Following the definitions given above, in organic stream, 
the raw data can be aggregated according to the Heuristic 
Magnet ? Associative Entity relation, and further be integrated 
based on Heuristic Magnet ? Heuristic Magnet relation and 
Associative Entity ? Associative Entity relation, which can be 
re-organized in an iterative and self-adaptive way. 
 
B. Data Aggregation and  Integration Based on Individual 
Needs 
Based on the discussions above, in order to capture an 
individual’s time-changing needs, the whole time period should 
be divided into several time slices (e.g. one day, one week), in 
which the developed TFIDF method can be employed to 
extract the data to represent individual needs, concerns and 
interests within this specific time slice. After that, the data 
related to the extracted individual need can be selected and 
aggregated according to the Heuristic Magnet ? Associative 
Entity relation in a hierarchical way. Based on these, the 
Collective Body can be generated, in which the selected data 
shall be integrated and organized according to the Heuristic 
Magnet ? Heuristic Magnet relation and Associative Entity ? 
Associative Entity relation. All the Collective Bodies compose 
the organic stream in an extensible way. The procedure for the 
data aggregation and integration process is shown as follows. 
Step 1: For the whole time period T, divide it into a series of 
time slices{t1, t2, …, tn}, accordingly, divide the  data 
set M  into several sub-set Mt in each time slice ti. 
Step 2: For each ??? in the time slice ti, calculate the weight 
based on the TFIDF method, in order to extract the 
Heuristic Magnet set Hm = { Hm[u1, t1], Hm[u2, t2], ..., 
Hm[ux, ty]}. 
Step 3: For each H
 m
 [ui, tj], according to the Heuristic Magnet 
? Associative Entity relation, select the related data 
into the Associative Entity set Ae = {Ae1, Ae2, …, 
Aen}. 
Step 4: Use the data in set Hm and Ae to generate the 
Collective Body as set Cb. 
Step 5: Calculate the Heuristic Magnet ? Heuristic Magnet 
relations and Associative Entity ? Associative Entity 
relations in each Collective Body Cbk, record all the 
relationships in the relation set R. 
Step 6: Return the Heuristic Magnet set Hm and Associative 
Entity set  Ae with the relation set R to form the 
integrated data set M’. 
 
IV. EXPERIMENT AND ANALYSIS 
In this section, after the introduction of the architecture of 
the basic functional modules for data aggregation and 
integration, we show and discuss experiment analysis results to 
illuminate the feasibility of our proposed method. 
A. Functional Modules 
The architecture for the individual need-based data 
aggregation and integration is shown in Fig. 1, which consists 
of five major components: Data Collector, User Need Extractor, 
Data Aggregator, Data Integrator, and Data Relation Analyzer. 
 
 
Fig. 1. Functional modules for data aggregation and integration  
As shown in Fig. 1, the Data Collector, which is the 
fundamental function module in this system, is used to collect 
the raw data from individuals and connect with the major 
database which saves the life logs of all users. The User Need 
Extractor is employed to extract individual needs, concerns and 
interests from his/her life logs to generate the heuristic magnets. 
In addition, the Data Aggregator works for aggregating the data 
related to the extracted individual needs, while Data Integrator 
is responsible for integrating the heuristic magnets with the 
Associative Entities. Finally, Data Relation Analyzer analyzes 
the major relations among these data and further organizes 
them to generate the collective bodies. 
537
 
B. Experiment Analysis 
The Twitter data has been utilized to conduct our 
experiment in order to demonstrate the feasibility of our 
proposed method. 
 
 
Fig. 2. An example of experiment analysis result for data aggregation 
 
Fig. 3. Conceptual image of data integration 
 
We obtained the Twitter dataset from a list of Twitter users 
selected from a famous Twitter list named “twitter”, as well as 
some of their followers. The majority of the tweets that are 
collected for our experiment are published in April 2013. 
Finally, a total of 320,000 tweets were collected. In order to 
illuminate our method, in this case, during the time period 
April 4 to 16, the keyword, “Boston”, is extracted as the 
Heuristic Magnet using the TFIDF method, which can indicate 
the interest or need within this group of users. And then those 
data that is related to “Boston” is aggregated to form the 
538
Associative Entities. An example of experiment analysis result 
is shown in Fig. 2.  
We further integrate the aggregated data according to the 
relation R discussed above. As shown in Fig. 3, the selected 
Heuristic Magnet became the aggregating center, and the 
related data converged to it as the Associative Entity. 
According to the relation, Heuristic Magnet ? Associative 
Entity, the distance from Associative Entity to the center 
namely the Heuristic Magnet, describes the relevance between 
them, that is, the more related Associative Entity would be 
closer to the center. Moreover, according to the relation, 
Associative Entity ? Associative Entity, the Associative 
Entities which have the same relevance to the Heuristic Magnet 
will distribute in the same layer. For instance, in Fig. 3, all 
Associative Entities distribute in four layers, while in each 
layer, the more related data will stay closer to each other. 
Finally, the Heuristic Magnet with these related Associative 
Entities will form the Collective Body. 
 
V. CONCLUSION 
In this paper, we have introduced and extended the organic 
stream to aggregate and integrate personal big data from life 
logs according to individual needs, in order to benefit the 
sustainable information utilization process. 
We developed and refined the organic stream as an 
extensible data carrier, in which we defined Heuristic Magnet, 
Associative Entity, and Collective Body to describe the 
individual need, related data, and integrated data set 
respectively. The major relations: Heuristic Magnet ? 
Associative Entity, Heuristic Magnet ? Heuristic Magnet, and 
Associative Entity ? Associative Entity, were proposed and 
studied in order to organize the aggregated data in a 
meaningful way. Based on these, we developed a mechanism 
to aggregate and integrate the personal big data in accordance 
with individuals’ time-changing needs, which can further 
support the information fusion and knowledge discovery 
process. Finally, we gave the system architecture with major 
functional modules and the experiment analysis results to show 
the feasibility and effectiveness of our proposed method. 
As for our future work, we will develop and complete our 
system with the improved mechanism to realize the data 
aggregation and integration process in real world situations. 
We will further quantify the relations in organic stream. The 
classification of the aggregated data, and the data quality 
assurance will also be considered, in order to deal with 
heterogeneous life log data from multiple sources. Moreover, a 
unified physical storage mechanism in regard to these diverse 
data will be developed, and we will try to utilize the organic 
stream in the information fusion and knowledge discovery 
process, in order to realize the sustainable utilization. 
 
ACKNOWLEDGMENT  
The work has been partly supported by 2012 and 2013 
Waseda University Grants for Special Research Project No. 
2012B-215 and No. 2013B-207.  
 
REFERENCES 
[1] C.Q. Ji, Y. Li, W.M. Qiu, U. Awada, and K.Q. Li, “Big Data Processing 
in Cloud Computing Environments,” in Proc. 12th International 
Symposium on Pervasive Systems, Algorithms and Networks (ISPAN), 
Dec. 13-15, 2012, pp.17-23. 
[2] “Big data: science in the petabyte era,” Nature 455 (7209):1, 2008. 
[3] Douglas and Laney, “The importance of ‘big data’: A definition,”2008. 
[4] X.K. Zhou, J. Chen, Q. Jin and T.K. Shih, “Organic Stream: 
Meaningfully Organized Social Stream for Individualized Information 
Seeking and Knowledge Mining,” Proc. The 5th IET International 
Conference on Ubi- Media Computing (U-Media2012), Xining, China, 
Aug. 16-18, 2012. 
[5] S.Alsubaiee, Y. Altowim, H. Altwaijry, A. Behm, V. Borkar, Y. Bu, M. 
Carey, R. Grover, Z. Heilbron, Y. Kim, C. Li, N. Onose, P. Pirzadeh, R. 
Vernica, and J. Wen, “ASTERIX: an open source system for "Big Data" 
management and analysis (demo),” Proc. VLDB Endow, vol. 5, no. 12, 
August , 2012, pp. 1898-1901. 
[6] S. Berkovich and D. Liao, “On clusterization of "big data" streams,” in 
Proc. the 3rd International Conference on Computing for Geospatial 
Research and Applications (COM.Geo '12), ACM, New York, NY, 
USA, Article 26 , 6 pages. 
[7] S.C.H. Hoi, J. Wang, P. Zhao, and R. Jin, “Online feature selection for 
mining big data,” in Proc. the 1st International Workshop on Big Data, 
Streams and Heterogeneous Source Mining: Algorithms, Systems, 
Programming Models and Applications (BigMine '12), ACM, New 
York, NY, USA, pp. 93-100. 
[8] J. Zhang, T. Li, and Y. Pan, “Parallel rough set based knowledge 
acquisition using MapReduce from big data,” in Proc. the 1st 
International Workshop on Big Data, Streams and Heterogeneous 
Source Mining: Algorithms, Systems, Programming Models and 
Applications (BigMine '12). ACM, New York, NY, USA, pp. 20-27. 
[9] A. Menon, “Big data @ facebook,” in Proc. the 2012 workshop on 
Management of big data systems (MBDS '12). ACM, New York, USA, 
pp. 31-32. 
[10] X. Han, L. Tian, M. Yoon, and M. Lee, “A Big Data Model Supporting 
Information Recommendation in Social Networks,” in Proc. the Second 
International Conference on Cloud and Green Computing (CGC), Nov. 
1-3, 2012, pp. 810-813. 
[11] M. Yamagiwa, M. Uehara, and M. Murakami, “Applied System of the 
Social Life Log for Ecological Lifestyle in the Home,” in Proc. 
International Conference on Network-Based Information Systems (NBIS 
'09), Aug. 19-21, 2009, pp. 457-462. 
[12] T. Hori, and K. Aizawa, “Capturing life-log and retrieval based on 
contexts,” in Proc. IEEE International Conference on Multimedia and 
Expo (ICME '04), Jun. 27-30, 2004, pp. 301-304. 
[13] K.S. Hwang, and S.B. Cho, “Life log management based on machine 
learning technique,” in Proc. IEEE International Conference on 
Multisensor Fusion and Integration for Intelligent Systems (MFI), Aug. 
20-22, 2008, pp.691-696. 
[14] H.H. Kang, C. H. Song, Y.C. Kim, S.J. Yoo, D. Han, and H.G. Kim, 
“Metadata for efficient storage and retrieval of life log media,” in Proc. 
IEEE International Conference on Multisensor Fusion and Integration 
for Intelligent Systems (MFI), Aug. 20-22, 2008, pp. 687-690. 
[15] A. Shimojo, S. Matsumoto, and M. Nakamura, “Implementing and 
evaluating life-log mashup platform using RDB and web services,” in 
Proc. the 13th International Conference on Information Integration and 
Web-based Applications and Services (iiWAS '11), ACM, New York, 
USA, pp. 503-506. 
[16] A. Nakamura and N. Nishio, “User profile generation reflecting user's 
temporal preference through web life-log,” in Proc. the 2012 ACM 
Conference on Ubiquitous Computing (UbiComp '12), ACM, New 
York, USA, pp. 615-616. 
[17] S. Ozdemir, “Functional reputation based reliable data aggregation and 
transmission for wireless sensor networks,” Comput. Commun. vol. 31, 
no. 17, pp. 3941-3953, November 2008. 
539
[18] W.S. Jung, K.W. Lim, Y.B. Ko, and S.J. Park, “Efficient clustering-
 based data aggregation techniques for wireless sensor networks,” Wirel. 
Netw. Vol. 17, no. 5, pp. 1387-1400, July 2011. 
[19] N. Iftikhar and T. B. Pedersen, “A rule-based tool for gradual granular 
data aggregation,” in Proc. the ACM 14th international workshop on 
Data Warehousing and OLAP (DOLAP '11), ACM, New York, USA, pp. 
1-8. 
[20] F. Rahman, E. Hoque, and S.I. Ahamed, “Preserving privacy in wireless 
sensor networks using reliable data aggregation,” ACM SIGAPP 
Applied Computing Review, vol. 11, no. 3, pp.  52-62, August 2011. 
[21] G. Wei, Y. Ling, B. Guo, B. Xiao, and A.V. Vasilakos, “Prediction-
 based data aggregation in wireless sensor networks: Combining grey 
model and Kalman Filter,” Comput. Commun. vol. 34, no. 6, pp. 793-
 802, May 2011. 
[22] F. Ren, J. Zhang, Y. Wu, T. He, C. Chen, and C. Lin, “Attribute-Aware 
Data Aggregation Using Potential-Based Dynamic Routing in Wireless 
Sensor Networks,” IEEE Trans. Parallel and Distributed Systems, vol. 
24, no. 5, pp. 881-892, May 2013. 
[23] J.R. Getta, “Optimization of online data integration,” in Proc. 7th 
International Baltic Conference on Databases and Information Systems, 
2006, pp.91-97. 
[24] M.P. Atkinson, J.I. Hemert, L. Han, A. Hume, and C.S. Liew, “A 
distributed architecture for data mining and integration,” in Proc. the 
second international workshop on Data-aware distributed computing 
(DADC '09), ACM, New York, USA, pp. 11-20. 
[25] A.D. Sarma, X.L. Dong, and A. Halevy, “Data integration with 
dependent sources,” in Proc. the 14th International Conference on 
Extending Database Technology (EDBT/ICDT '11), Anastasia Ailamaki, 
Sihem Amer-Yahia, Jignesh Pate, Tore Risch, Pierre Senellart, and Julia 
Stoyanovich (Eds.). ACM, New York, USA, pp. 40-412. 
[26] V. Tran, O. Habala, B. Simo, and L. Hluchy, “Distributed data 
integration and mining,” in Proc. the 13th International Conference on 
Information Integration and Web-based Applications and Services 
(iiWAS '11), ACM, New York, USA, pp. 435-438. 
[27] P. Gong, I. Gorton, and D.D. Feng, “Dynamic adapter generation for 
data integration middleware,” in Proc. the 5th international workshop on 
Software engineering and middleware (SEM '05), ACM, New York, 
USA, pp. 9-16. 
 
 
540
Top
 Program Guide
 author Index
 iCAST 2013
 Technical Program
 UMEDIA 2013
 Technical Program
