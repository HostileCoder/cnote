Privacy Technology Lessons from Healthcare
Ross J. Anderson
Cambridge University Computer Laboratory
Pembroke Street, Cambridge CB2 3QG
England
ross.anderson@cl.cam.ac.uk
Abstract
The probability that information will be abused depends
both on its value and on the number of people who have ac-
cess. The modern trend to ever larger databases increases
both of these risk factors at the same time. Compartmented
security polices can solve many of the technical issues, and
there are applications – such as healthcare – where they
have been developed in some detail. But the big problem
isn’t technical; it’s legal and regulatory. Insurers, employ-
ers and governments won’t adopt compartmented systems,
or will allow them to be adopted only in places such as hos-
pitals which are not where the real threats lie.
Introduction
In the old days, the only people with easy access to your
medical records were the staff in the relevant practice or
hospital department, and the only people with a copy of
your bank statement were the staff in the branch where your
account was held. Then, in the 1980’s, banks started giving
all their staff access to all customer accounts. This was sim-
pler than re-implementing the compartmentation that was
inherent in paper systems; it also turned out to be conve-
nient. The resulting erosion of privacy caused some inci-
dents but no great public outcry. Now the same thing is
happening in healthcare, and the public anxiety is somewhat
more acute.
Healthcare security policy
What can be done? During 1995-96, I developed a secu-
rity policy model for the British Medical Association which
was presented at Oakland 96 [1]. This model describes
how to implement and manage compartmented security in
healthcare. Systems which broadly comply with it are now
deployed in three English hospitals [2]. They enforce a
number of rules such as ‘a nurse may see the records of
patients who have been on her ward in the previous ninety
days’. The initial implementation was not entirely straight-
forward; it’s a bad idea, for example, for the Trusted Com-
puting Base of the medical records system to include both
the patient and staff administrative systems. However, prob-
lems like this are not too difficult to fix, especially with the
proliferation of support technologies such as smartcards and
public key certificates.
This success should be of interest for a number of rea-
sons. Firstly, it gives a thorough worked example of a se-
curity policy that is of neither the Bell-LaPadula nor Clark-
Wilson flavour. Secondly, it may have much wider appli-
cability. It is hard to believe that the Ames case, or the
recent reported espionage against NATO during the war in
Kosovo, would have been as likely if the relevant agencies
had better tools available to manage compartmentation. (It
is my belief that the Bell-LaPadula model of the universe
was a hugely expensive cul-de-sac. The real problem is not
how to do information separation, but how to control infor-
mation sharing.) Thirdly, it can provide both an inspiration
and a target for research efforts in role-based access control.
The real problems
However, once we’d worked out a policy, got it endorsed
by the profession and got a few real systems to play with,
we found that access control was the easiest of three prob-
lems. Much harder is inference control – how one protects
information in the (often lightly) deidentified data in the
databases which are increasingly widely used for medical
research [3].
The hardest problem of all is how to protect medical in-
formation that passes outside professional control, such as
the payment data collected by both insurers and employ-
ers. Although in theory one could pay for healthcare using
anonymous credit cards linked to a health insurance scheme
0-7695-0665-8/00 $10.00  2000 IEEE 
which managed costs by disease rather than by patient (and
the Japanese experience suggests that this would be a bet-
ter way of controlling costs), there is zero interest in the
industry in such technologies. Databases of people’s ill-
nesses, treatments and costs are seen as a major corporate
asset which insurers (in both the private and public sectors)
are quite unwilling to forego.
Conclusion
The main lesson to be learned is that privacy is funda-
mentally a matter of law and regulation, rather than of tech-
nology. The perhaps somewhat pessimistic view that I take
on the debate is this: that electronic privacy can be achieved,
but it won’t be.
Cambridge, 9th March 2000
References
[1] “A Security Policy Model for Clinical Information
Systems”, RJ Anderson, in Proceedings of the 1996
IEEE Symposium on Security and Privacy pp 30–43
[2] “Privacy in Clinical Information Systems in Sec-
ondary Care”, I Denley, S Weston Smith, in British
Medical Journal v 318 (15 May 1999) pp 1328–1331
[3] “The DeCODE Proposal for an Icelandic
Health Database”, RJ Anderson, in Læknabla-
did (The Icelandic Medical Journal) v 84 no
11 (Nov 98) pp 874–5; full text available from
http://www.cl.cam.ac.uk/users/rja14/#Med
2
0-7695-0665-8/00 $10.00  2000 IEEE 
