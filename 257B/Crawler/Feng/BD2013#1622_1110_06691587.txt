Scientific Discovery through Weighted Sampling
 Lefteris Sidirourgos, Martin Kersten, Peter Boncz
 Database Architectures, CWI
 Amsterdam, The Netherlands
 {lsidir, mk, boncz}@cwi.nl
 Abstract—Scientific discovery has shifted from being an
 exercise of theory and computation, to become the exploration
 of an ocean of observational data. Scientists explore data
 originated from modern scientific instruments in order to
 discover interesting aspects of it and formulate their hypothesis.
 Such workloads press for new database functionality. We aim
 at sampling scientific databases to create many different impres-
 sions of the data, on which the scientists can quickly evaluate
 exploratory queries. However, scientific databases introduce
 different challenges for sample construction compared to
 classical business analytical applications. We propose adaptive
 weighted sampling as an alternative to uniform sampling. With
 weighted sampling only the most informative data is being
 sampled, thus more relevant data to the scientific discovery is
 available to examine a hypothesis. Relevant data is considered
 to be the focal points of the scientific search, and can be defined
 either a priori with the use of functions, or by monitoring
 the query workload. We study such query workloads, and we
 detail different families of weight functions. Finally, we give a
 quantitative and qualitative evaluation of weighted sampling.
 Keywords-Scientific Data Management; Sampling;
 I. INTRODUCTION
 Scientific discovery has shifted from being an exercise
 of theory and computation, to become the exploration of
 an ocean of observational data. This transformation was
 identified by Jim Gray as the 4th paradigm of scientific dis-
 covery [1]. State-of-the-art observatories, digital sensors, and
 modern scientific instruments produce every day petabytes
 of information. This scientific data is stored in massive
 datacenters for later analysis. From the data management
 viewpoint, the capture, curation, and analysis of data are
 not computation-intensive processes any more, but a data-
 intensive ones. The explosion in the amount of scientific
 data presents a new “stress test” for database systems design.
 Meanwhile, the scientists are confronted with new questions:
 how can relevant and compact information be found from
 such a flood of data?
 The predominant answer given by the data management
 community is the raw power of big datacenter installations,
 complemented by new technologies focusing on scalable
 distribution of data and operations [2]. When it comes to
 curating and analysing vast amounts of data one can hardly
 argue that another approach is feasible. However, scientific
 discovery implies also a more delicate and refined task,
 that of forming the scientific question, a hypothesis to be
 later tested for correctness. Such formations of scientific
 questions or hypotheses, as well as the initial proof-of-
 validity, constitute an ad-hoc exploratory scientific query
 workload. During an iterative and interactive query session,
 the scientists pose queries in order to examine the nature of
 the stored data, discover interesting aspects of it, formulate
 their hypotheses, but also test the syntactical correctness of
 their queries.
 Exploratory scientific workloads press for new database
 functionality. Scientists are interested in an initial educa-
 tive answer without having to spend too many valuable
 resources. Nevertheless, it is necessary to provide bounds on
 the quality of the answer and limit the execution time [3],
 [4], [5]. Our approach to this new challenge is sampling
 the database to create many different “snapshots” of the
 data, called impressions, on which the scientists can evaluate
 their queries. Impressions come in various sizes and are
 organised in a multi-layer hierarchical manner. The size
 of an impression determines both the quality of the result,
 and the time spent on query processing. The rule of thumb
 is the smaller an impression, the faster an answer will be
 given, while the bigger an impression is, the better the
 quality of the answer will be. With such a collection of
 impressions, accompanied by a bounded query execution
 engine, we envision a complete framework for scientific data
 management with bounds on runtime and quality [5]. This
 framework serves the purpose of data-intensive scientific
 discovery. Once a scientific hypothesis is formulated, and
 a correct set of queries is written, the scientist may then
 validate his findings over the entire dataset.
 In this work we are concerned with the problem of how to
 create and maintain samples, to be used in impressions. The
 predominant technique in the literature is uniform sampling
 over the data. However, scientific databases introduce differ-
 ent properties for sample construction compared to classical
 business analytical applications. For starters, a scientific
 search can be more focused, drilling into details, while
 a business strategy is made by observing general trends
 along the breadth of the data. Accurately answering focused
 queries stresses existing sampling methods. Secondly, data-
 type domains are different. Scientific data has many double
 precision values, often with strong skew. On the other hand,
 classical OLAP applications usually have predefined cate-
 gorical data types with low cardinality (e.g., product type,
 country, etc.). Another difference of scientific discovery is
 2013 IEEE International Conference on Big Data
 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 300
that group-by and aggregations, such as average and sums,
 are less common. In fact, most of the research in sampling
 presents solutions on overcoming errors introduced by rare
 high values that throw the estimations off track, or by very
 small group that won’t appear in a sample.
 We propose using weighted sampling as an alternative
 to uniform sampling. Our goal is to get the most out of
 scientific data by sampling only the interesting parts. For
 a given statistical test, the power of the test can always be
 increased by increasing the sample size. Clearly, with larger
 sample sizes, the probability of accepting a hypothesis is
 increased as the sample size increases. Weighted sampling
 increases the sample size around areas of interest. Thus,
 although the total resources dedicated to sample storage
 is constant, queries that target areas of interest give better
 approximated answers and with higher confidence levels.
 The areas of interest are defined as the focal points of the
 scientific search. It can be a priori defined (e.g., interest
 only on spikes in the data) or it can be observed during a
 query session. Once the focal points have been established,
 a weight is assigned to each newly ingested tuple. This is
 done with the help of weight functions, which can also be
 adaptive to any changes of focal points over time. With
 adaptive weighted sampling queries are answered faster, are
 less error prone, and fewer physical resources are used.
 II. RELATED WORK
 Sampling is an important database operation primarily
 used for extracting statistical information over the data
 without the need for accessing the entire base. Fundamental
 work on database sampling is due to Olken and Rotem [6].
 The typical usage of samples in modern data management
 systems is to provide an estimation of the result size [7],
 [8], [9] which is then used by the cost model of a query
 optimiser, or to facilitate approximate query answering [10],
 [11]. Biased sampling has been used in the past for non-
 uniform sampling methods based on weight functions [3],
 [12].Dynamic sample selection [12] to answer approximate
 queries is motivated by “ad hoc, exploratory data analysis”
 but in a business analytic environment. In such a setting,
 the data is explored in a breadth search manner looking
 for global trends, as opposed to scientific application where
 a scientist searches in depth, focusing into the details.
 Congressional samples are also constructed for answering
 approximate group-by queries [13]. This technique is also
 known to the literature as stratified sampling [14]. Concise
 and Counting sampling techniques include the number of
 occurrences of a value on the sample [15].ICICLES [16]
 treats the results of a query as being newly appended tuples
 that should be sampled, thus forcing frequently appearing
 results to be more likely to be part of the sample.BlinkDB [3]
 uses samples to achieve interactive query execution times
 over a distributed environment, by extending the Hive/HDFS
 execution stack.
 III. SCIENTIFIC WORKLOAD ANALYSIS
 To improve the way scientists can explore large science
 datawarehouses, a much better understanding of their query
 interaction is needed. Unfortunately, little is known publicly
 to guide us. A notable exception is the SDSS Skyserver
 DR7 database which contains astronomy data. We study
 its publicly accessible query logs to extract query patterns.
 Skyserver contains data for over half a billion sources. A
 source in astronomy is any object in the sky that omits
 energy, for example a star or a nebula. Every source is
 identified in the database with a unique id, and can be
 located by its position in the sky. The position is marked
 with two coordinates, the right ascension (ra), and the
 declination (dec). We study the queries fired against the
 Skyserver DR7 over the span of one month. The total
 number of queries logged is 1,242,767 and originated from
 2,646 distinct IP addresses. Out of all queries, 402,108
 queries had an unknown origin so could not be associated
 with a specific user. The 50 most active users accounted
 for over 90% of the remaining workload (774,924 queries).
 An interesting side observation is the increased number of
 queries originating from crawlers of known search engines
 indexing the so called deep web. Our goal is to identify
 patterns in the queries posed by the scientists over time. We
 consider the coordinates ra and dec to be a natural choice
 of attributes to plot, since they correspond to the area in the
 sky that an astronomer looks at. Due to lack of space, we
 next show the query habits of only four – but representative –
 users. They are all either astronomy observatories or research
 institutes and universities from Asia, Europe, and America.
 Figure 1 depicts the querying habits of these represen-
 tative users. Each query searches for sources over an area
 that Skyserver covers. We plot the values of ra and dec as
 given in the queries’ predicates. In addition we add a third
 dimension that shows the exact sequence these queries were
 fired. We plot 4 graphs for each user: i) a 3-d plot that in
 the x-axis shows the time sequence of the queries and in the
 z- and y- axis, the ra and dec respectively, ii) the ra over
 the query sequence, iii) the dec over the query sequence,
 and iv) the ra and dec. The top left user of Figure 1
 (purple colour) scans over the entire Skyserver many times
 throughout the query sequence. For this user a uniform
 sample may serve his needs better. The next user, seen in the
 top right corner of Figure 1 (yellow colour) scans over the
 same stripes of data over and over throughout the span of the
 entire month. His queries are very concentrated on selected
 areas of interest. Similarly the next user, shown on the left
 lower corner of Figure 1 (green colour) is interested in three
 narrow areas of the Skyserver and for a small period of time.
 Finally, the last user shown on the right lower corner of
 Figure 1 (blue colour) exhibits an exploratory query pattern,
 where the focal point is constantly moving towards a more
 limited area.
 301
 0 50
  100 150
  200 250
  300 350
 -40
 -20
  0
  20
  40
  60
  80
  100
 queries over time
 -40
 -20
  0
  20
  40
  60
  80
  100
  0  50  100  150  200  250  300  350
 declinatio
 n
 right ascension
  0
  50
  100
  150
  200
  250
  300
  350
 right ascensio
 n
 queries over time
 -40
 -20
  0
  20
  40
  60
  80
  100
 declinatio
 n
 queries over time
  0 50
  100 150
  200 250
  300 350
 -1.5
 -1
 -0.5
  0
  0.5
  1
  1.5
 queries over time
 -1.5
 -1
 -0.5
  0
  0.5
  1
  1.5
  0  50  100  150  200  250  300  350
 declinatio
 n
 right ascension
  0
  50
  100
  150
  200
  250
  300
  350
 right ascensio
 n
 queries over time
 -1.5
 -1
 -0.5
  0
  0.5
  1
  1.5
 declinatio
 n
 queries over time
  0 50
  100 150
  200 250
  300 350
 -100-80
 -60-40
 -20 0
  20 40
  60 80
 queries over time
 -100
 -80
 -60
 -40
 -20
  0
  20
  40
  60
  80
  0  50  100  150  200  250  300  350
 declinatio
 n
 right ascension
  0
  50
  100
  150
  200
  250
  300
  350
 right ascensio
 n
 queries over time
 -100
 -80
 -60
 -40
 -20
  0
  20
  40
  60
  80
 declinatio
 n
 queries over time
  0 50
  100 150
  200 250
  300 350
 -10 0
  10 20
  30 40
  50 60
  70 80
  90
 queries over time
 -10
  0
  10
  20
  30
  40
  50
  60
  70
  80
  90
  0  50  100  150  200  250  300  350
 declinatio
 n
 right ascension
  0
  50
  100
  150
  200
  250
  300
  350
 right ascensio
 n
 queries over time
 -10
  0
  10
  20
  30
  40
  50
  60
  70
  80
  90
 declinatio
 n
 queries over time
 Figure 1. Query workload patterns of different users
 IV. WEIGHTED SAMPLING
 Complementary to the informative user-study described
 above, we can now proceed with designing new techniques
 for choosing those data parts of a relational database that
 better serve the exploration of scientists. We study the
 process of sampling a relational database for the purpose
 of providing data impressions. An impression is a different
 view of the data, that may hide details, or bring in the
 foreground details of a specific characteristic of the data.
 The scientist then may explore the impressions for scientific
 discovery. The benefit of an impression lies in the fact that
 it contains only data relevant to the query, thus making the
 exploration easier and faster. The concept of an impression
 is detached from the underlying method of creating it. Our
 approach is based on sampling, while other approaches may
 be applicable.
 The predominant technique for sampling in the literature
 is uniform sampling. However, uniform sampling assumes
 that all data are of equal importance. This may be true for
 traditional analytical workloads with aggregates and group-
 by operators, but for the exploratory scientific workload is
 not. A scientist more often wishes to explore the details
 rather than the overall picture. To address the unique prop-
 erties of scientific discovery, we introduce a framework for
 performing weighted sampling. In weighted sampling, not
 all tuples are sampled with the same probability. A weight
 function determines the probability P with which a tuple is
 included in the sample. The choice and implementation of
 the weight function depends on the demands put forward by
 the application.
 Definition 1: A weight function w is any function that
 assigns a non-negative real number wi to the i-th member
 of the population to be sampled. That is,
 w : N ?? R+, w(i) ? wi
 Notice that we do not require the range of the weight
 function w to be between [0, 1]. Special care is needed
 to normalise the weight functions in order to produce the
 correct probability values. Hence, the probability for the i-
 th member of the population to be sampled is
 P(i) = wi∑N
 j=1 wj
 where N is the total size of the population. However, we
 will also experiment with weight functions that have a range
 between [0, 1] and thus no such normalisation is needed.
 Given a tuple t with A, B, C, . . . attributes, a weight
 function w may be defined in such way that more than
 one attribute takes part in the computation of the weight
 of that tuple. We use w(t) to notate the weight of tuple
 302
t even if it is a combination of many attributes, i.e.,
 w(t) = w(t.A, t.B, t.C, . . .).
 We present three families of weight functions to address
 different application requirements. The first set of functions
 are data independent, the second data dependent, and the
 third query dependent.
 A. Data Independent Weight Functions
 In many scientific applications the latest observations are
 of most interest. For example, in seismographic monitoring
 the earthquakes of the last 24 hours or the last week is the
 focal point of the seismologists. Another example are the
 latest measurements for the meteorologists. Therefore, it can
 be useful to maintain a sample that contains the latest events.
 For example, given the query
 SELECT * FROM Events AS ev WHERE
 ev.timestamp - current_timestamp
 < INTERVAL ‘24 hours‘;
 a weighted sample created such that most of the past 24
 hour events are included will give a more informative and
 complete result, than a uniform sample. We define the
 following data independent weight function, that adds more
 weight to the latest events.
 Definition 2: Given a tuple t, and a sample S of size s, a
 data independent weight function wls that chooses the latest
 appended tuples over the older ones is defined as
 wls(t) = kD
 where D is a parameter that defines the size of the timeframe
 for the latest events, and k ≤ s is the ratio of latest over
 older events to be included in the sample S . If D < s then
 wls(t) = 1, that is all new tuples are included on the sample.
 More specifically, D is equal to the expected amount of
 tuples to be inserted in the database during the timeframe of
 interest. For example, if we are interested in the earthquakes
 that took place on the last 24 hours, and there are on average
 1000 events recorded per day, then D is set to 1000 or more.
 Similarly, if we are interested in events of the last week, then
 D is set to 7000, and so on. Assuming that the size of the
 sample is s, we set the parameter k to be equal to s if the
 application’s interest is on only new events. Otherwise, if
 k < n then there will be k latest events in the sample, and
 n? k older events on average. By tuning k we can set the
 ratio between old and new events in the sample.
 We refer to this family of weight function as latest seen,
 or ls for short. This application of weighted sampling is
 particular useful for examining the latest observations, or for
 grabbing the newest additions in the database and forwarding
 them to third parties.
 B. Data Dependent Weight Functions
 Weight functions that depend on the data are the most
 generic ones. The goal of such functions is to apply filters
 to the data. Only tuples that satisfy these filters are eligible
 for sampling. The existing VIEW infrastructure of relational
 databases often allows the definition of such filtering. For
 example, an SQL statement
 CREATE VIEW name AS
 SELECT * FROM PhotoObj WHERE ra < 180;
 will create a view containing only sources that have ra
 smaller than 180. A uniform sample over such a view will
 produce the desired result. However, the same effect can be
 achieved with a simple weight functions of the form
 w(t) =
 {
 1 if t.ra ≤ 180
 0 otherwise
 Nevertheless, data dependent weight functions can have
 more complicate expressions and multiple weights compered
 to what can be achieved with existing relational database
 functionality. A generic multi-part data dependent weight
 function can be defined as follows.
 Definition 3: Given a tuple t and with attributes
 A, B, C, . . . a multi-part data dependent weight function is
 defined as
 wm(t) =
 ?
 ????
 ????
 w1 if expr1(t)
 w2 if expr2(t)
 .
 .
 .
 0 otherwise
 such that at most one of expr1,expr1, . . . can be true.
 Besides these generic data dependent weight functions,
 more specialised functions are necessary for certain appli-
 cations. In scientific applications more often than usual,
 scientists are interested in the outliers rather than the average
 value distribution. This demand is entirely opposite from
 traditional application, where outliers are considered bad
 cases and need to be avoided because they can drastically
 alter the result of an approximated answer. In scientific ex-
 ploration however, outliers may be of the utmost importance.
 For example, in seismic data, a big earthquake is much
 more important than the many small regular earthquakes that
 repeatedly occur around the globe. Similarly in astronomy,
 objects that emit light in a high spectrum are more suitable
 for observation. For this reasons, we define a family of
 weight functions that assign heavier weights to tuples that
 are further from the usual observed values. We refer to
 these functions as z-weight because they are inspired by
 the standard score z for identifying outliers.
 Definition 4: Given a tuple t and an attribute t.A such that
 we are interested in its outlier values, the z-weight function
 is defined as
 wz(t) = |t.A? µ|
 ?
 where µ is the mean of the values of attribute t.A and ? the
 standard deviation.
 303
Essentially, the z-weight function assigns a higher weight
 to values deviating more from the mean. The distance
 from the mean is then divided by the standard deviation
 to overweight the outliers. If (t.A ? µ) < ?, that is if the
 value of the attribute is between the expected deviation from
 the mean, then wz(t) < 1, otherwise wz(t) > 1. In order to
 calculate the wz function, both the mean and the standard
 deviation of the values of t.A are needed. These can be
 easily computed during the loading phase with the use of an
 online algorithm such as the one detailed in [17]. Finally,
 in order to increase the probability of more outliers to be
 sampled, and less of the common values, the numerator of
 the fraction t.A?µ
 ?
 can be squared as many times as needed.
 In the experimental evaluation we show results also for the
 cases of (t.a?µ)
 2
 ?
 and (t.a?µ)
 4
 ?
 .
 C. Query Dependent Weight Functions
 Query dependent weight functions are steered by the ob-
 served user’s interest in the data. The interest is monitored by
 first identifying the attributes of the data that contain relevant
 scientific observational values rather than annotations or
 metadata. Then, by storing – typically in a histogram – the
 values that appear in the predicates of the query workload.
 We can then define a weight function that promotes those
 tuples that satisfy more often the predicates of the workload.
 More specifically, the predicate set is defined to be all the
 values of the interesting attributes that are requested by the
 queries. These values are regarded as points that suggest the
 entire distribution of values of interest. Therefore, weighted
 sampling should follow that distribution instead of the dis-
 tribution of the stored values, which would have been the
 case of uniform sampling. A histogram H over the predicate
 set is maintain by increasing the counter of the bin that a
 value falls into.qGiven a histogram H the following query
 dependent weight function wq is defined.
 Definition 5: Given a tuple t and a histogram H build
 over the predicate set, the query dependent weight function
 w.q is defined as
 wq(t) = H[i].c
 where i is the bin of the histogram H that tuple t falls into,
 and c is the counter of that bin.
 We can also normalise the weight of tuple t in order to
 be smaller than 1. The normalise weight w?q
 w?q =
 wq(t)∑?
 i=1H(i).c
 .
 Intuitively, the probability of sampling tuple t is equal
 with the percentage of the total surface of the distribution of
 the predicate set it covers. The more queries have predicates
 that fall in a bin, the more likely is that a tuple of that bin is
 sampled. If the predicates are not equalities, but ranges then
 the counters of all bins that fall into that range are increased
 by one.
  0
  20
  40
  60
  80
  100
  0  50  100  150  200  250  300  350
  
right ascension
 uniform sample
  0
  50
  100
  150
  200
  
purple user workoad
 weighted sampling
  0
  50
  100
  150
  20
  
orange user workoad
 weighted sampling
  0
  50
  100
  150
  20
 coun
 t
 green user workoad
 weighted sampling
  
 50
  100
  150
  20
  
blue user workoad
 weighted sampling
 Figure 2. Query dependent weighted sample
 V. EXPERIMENTAL EVALUATION
 In our experimentation we wish to examine the behaviour
 of the different families of the proposed weight functions and
 their effectiveness in query answering. For this we used the
 data and query logs of Skyserver as described in Section III.
 The data of Skyserver have been mirrored locally and loaded
 to the MonetDB [18] database system. The realisation of
 Skyserver in MonetDB uses over 2.6 terabytes of disk
 space, excluding the indexes. All algorithms for weighted
 sampling, including the proposed extensions for SQL, were
 implemented as part of the MonetDB system.
 The first set of experiments study the properties of the
 weighted samples created with the query dependent weight
 functions. We build the histograms needed over the predicate
 set as given by the query workload of the four users in
 Section III. To emulate the process of regular ingests of
 data, we loaded the tuples of the PhotoObj relation of
 Skyserver with an append procedure in batches. The entire
 process of loading all tuples takes just over 20 minutes for
 a total of 500 million tuples. The loading time for each
 batch shows no noticeable variation with or without the
 creation of an impression. This is due to the lightweight
 implementation of the reservoir algorithm. The execution is
 performed by a separate thread, which renders the sampling
 overhead unnoticeable compared to the time spent on parsing
 304
 0
  50
  100
  150
  200
  250
  5  10  15  20  25  30  35
 source
 s
 r
 uniform
  
(t.a-µ)/?
  
(t.a-µ)2/?
  
(t.a-µ)4/?
  
Figure 3. Weighted sampling for outliers
 and loading the data.
 Figure 2 shows the different query dependent weighted
 samples for the four users. The x-axis plots the right
 ascension (ra) found on the PhotoObj relation. The y-
 axis counts how many sources with the specific ra value
 have been found in the sample. In addition we plot the
 histograms capturing the query preferences of each user to
 be easily compared with the samples. The bottom graph of
 Figure 2 shows (in red) the distribution of sources over ra
 for a uniform sample. The samples are configured to contain
 10.000 tuples. However, no matter the size of the sample, the
 distribution of the number of sources in the sample remains
 the same. All plots in Figure 2 are of the same scale.
 The top plot of Figure 2 depicts the query dependent
 weighted sample maintained for the purple user. This is the
 user whose query workload scans the entire Skyserver. We
 previously suggested that a uniform sample will work as
 well. However, there are some differences compared to the
 uniform sample. For the values of ra bigger than 300 there
 is a more concentration of interest, thus more sources com-
 pared to the uniform sample are included. The second plot of
 Figure 2 shows the weighted sample created for the second
 (orange) user, as well as the histogram for the predicate set
 of the query workload. The queries of this user focus on
 sources between 0 < ra < 50 and 300 < ra < 360.
 In this case, the weighted sampling is superior to uniform
 sampling. It manages to only include sources from the areas
 of interest. This is translated to more sources relevant to
 the queries and thus better approximation with tighter error
 bounds. The remaining two plots of Figure 2 exhibit different
 distributions between the weighted sampling and the uniform
 one. When compared with the help of the histograms of
 the predicate sets, one can notice that the weighted samples
 follow the distribution of the query workload instead of that
 of the stored data. The general observation of the first set
 of experiments is that the query dependent weight functions
 and the adaptation of the reservoir algorithm produce the
 desired result.
 Next we study the z-weight function for detecting outliers.
 In this data dependent weight function, sources with values
 that deviate from the mean are more likely to be included
 in a sample. To perform this experiment, a different set of
  0
  50
  100
  150
  200
  250
  0  50  100  150  200  250  300  350
  
 
10 million tuples
 uniform sample
  0
  10
  20
  30
  40
  50
  60
  70
  80
  90
  0  50  100  150  200  250  300  350
  
 
500 million tuples
 uniform sample
  0
  500
  1000
  1500
  2000
  2500
  3000
  0  50  100  150  200  250  300  350
  
right ascension
 last-seen sample D=10m, k=5k
  0
  1000
  2000
  3000
  4000
  5000
  6000
  7000
  8000
  0  50  100  150  200  250  300  350
  
right ascension
 last-seen sample D=10m, k=5k
 Figure 4. Last-seen weighted sampling
 attributes from the PhotoObj relation has to be chosen.
 The ra and dec attributes mark the position of the sources,
 thus they are not relevant for outliers. Instead we use the
 measure of the redshift of a source, denoted with r, which
 is more relevant for our study. The redshift follows a power-
 law distribution where most of the sources have very similar
 value and only few of them vary largely.
 In Figure 3 the distribution of the values of the redshift r
 of a uniform sample are plotted (in red). Most of the values
 are concentrated between 22 and 23. We define, besides the
 uniform sample, three z-weighted samples. One z-weight
 sample is based on the 1st degree weight function, i.e.,
 (t.A ? µ), while the second and third on the 2nd, i.e.,
 (t.A ? µ)2, and 4th (t.A ? µ)4 degree, respectively. The
 comparison between those three weighted samples reveals
 the existence of outliers that are missed otherwise by the
 uniform sample. The smallest value of r that the uniform
 sample contains is around 10, despite the existence of
 sources, in the tail of the distribution of r, that have much
 lower values. Similarly, the 1st degree of a z-weight sample
 considers only few outliers and reduces the sources that
 fall around the mean of the r values. Nevertheless, such
 a weighted sample is still useful for certain applications.
 If, however, the goal is to include many outliers, then the
 4th degree z-weight function is more suitable. In this case,
 many sources with values of r down to 8 are included.
 Also, more outliers are part of the weight sample making
 the approximation of queries about them less error prone.
 The final set of experiments concern the last-seen weight
 function. In this application, only the latest appended tuples
 are included in the sample. Due to the ever evolving nature
 of such sampling we depict the start and the end of a
 series of consecutive experiments. We divide the PhotoObj
 relation into batches of 10 million tuples. We then append
 these batches one by one into the PhotoObj relation. An
 impression with the last-seen weight function is defined
 305
over PhotoObj with parameters D = 10, 000, 000 and
 k = 5, 000, while the size of the sample is set to be 10,000.
 Figure 4 depicts the state of both the uniform and the
 weighted sample after the load of the first 10 million tuples,
 and after the load of the last batch of tuples. The total
 number of tuples in the end is over 500 million. The uniform
 samples are shown on the upper plots of Figure 4 and the
 last-seen weighted samples at the lower part. The uniform
 sample always resembles the distribution of ra values found
 in PhotoObj after each append of the next 10 million
 tuples. Thus, at the end of the loading process the uniform
 samples is exactly like the one shown in the bottom plot of
 Figure 2. However, at the start of the process, the uniform
 sample resembles only the distribution of the ra values
 loaded up until that point. For the last-seen weighted sample
 the story is different. Given that this sample includes only the
 last 5000 tuples that have been appended and 5000 from the
 previous loads, the resulting distribution is much different.
 Notice that D is set to be equal to 10 million since that is
 the size of the batches of tuples that we append. In the left
 lower plot of Figure 4 it is shown that although the weighted
 sample has a spike around the value 230 of ra, there are
 still some remaining tuples between 0 to 50, and 150 to 250.
 They are the remaining tuples of the previous appends. That
 is, since k = 5000 and the size of the sample is s = 10000,
 it follows that there should be about 5000 new tuples and
 5000 older ones. The plots of the last-seen weighted sample
 have similar properties for all the consecutive batch appends.
 At the end, the weighted sample only contains tuples from
 the last append as shown on the right lower plot of Figure 4.
 The spikes in the value distribution have moved to the values
 from the last tuples of the last batch.
 VI. CONCLUSIONS
 Sampling is an important operation of a database system.
 It is used for approximating query results, for advising
 query planers, and for maintaining indexes. In this paper, we
 propose a new use for sampling, that of refining a database
 into smaller parts, called impressions. This refinement allows
 faster evaluation of focused queries by examining only the
 relevant data. For this, we proposed weighted sampling as
 an alternative to uniform. We have described three different
 families of weight functions. To support our approach,
 we analysed the data and query logs obtained by a real-
 world scientific application, namely Skyserver. Finally, we
 have shown experimentally that weighted sampling is more
 suitable for choosing those specific areas of the data that
 better answer focused query workloads, such as those found
 in the scientific discovery paradigm. The future challenge
 is to redesign the execution engine around bounded query
 execution that employs impressions to improve performance
 under user-defined error bounds and execution times using
 multiple, differently sized impressions.
 REFERENCES
 [1] T. Hey, S. Tansley, and K. Tolle, The Fourth Paradigm: Data-
 Intensive Scientific Discovery. Microsoft Research, 2009.
 [2] J. Dean and S. Ghemawat, “MapReduce: Simplified Data
 Processing on Large Clusters,” in Proc. of the 6th OSDI, 2004.
 [3] S. Agarwal, B. Mozafari, A. Panda, H. Milner, S. Madden,
 and I. Stoica., “BlinkDB: Queries with Bounded Errors and
 Bounded Response Times on Very Large Data,” in Proc. of
 the ACM EuroSys, 2013.
 [4] M. L. Kersten, S. Idreos, S. Manegold, and E. Liarou, “The
 Researcher’s Guide to the Data Deluge: Querying a Scientific
 Database in Just a Few Seconds,” PVLDB, vol. 4, no. 12,
 2011.
 [5] L. Sidirourgos, M. Kersten, and P. Boncz, “SciBORQ: Scien-
 tific data management with Bounds On Runtime and Quality,”
 in Proc. of the 5th CIDR, 2011.
 [6] F. Olken and D. Rotem, “Simple Random Sampling from
 Relational Databases,” in Proc. of the 12th VLDB, 1986.
 [7] S. Chaudhuri, R. Motwani, and V. Narasayya, “On Random
 Sampling over Joins,” ACM SIGMOD Record, vol. 28, no. 2,
 1999.
 [8] P. B. Gibbons, Y. Matias, and V. Poosala, “Fast incremen-
 tal maintenance of approximate histograms,” ACM-TODS,
 vol. 27, no. 3, 2002.
 [9] V. Poosala and Y. Ioannidis, “Selectivity Estimation Without
 the Attribute Value Independence Assumption,” in Proc. of
 the 23rd VLDB, 1997.
 [10] S. Acharya, P. B. Gibbons, V. Poosala, and S. Ramaswamy,
 “Join Synopses for Approximate Query Answering,” in Proc.
 of the ACM SIGMOD, 1999.
 [11] Viswanath Poosala and Venkatesh Ganti and Yannis E. Ioan-
 nidis, “Approximate Query Answering using Histograms,”
 IEEE Data Eng. Bull, vol. 22, no. 4, 1999.
 [12] B. Babcock, S. Chaudhuri, and G. Das, “Dynamic Sample
 Selection for Approximate Query Processing,” in Proc. of the
 ACM SIGMOD, 2003.
 [13] S. Acharya, P. B. Gibbons, and V. Poosala, “Congressional
 Samples for Approximate Answering of Group-By Queries,”
 in Proc. of the ACM SIGMOD, 2000.
 [14] W. G. Cochran, Sampling Techniques, 3rd Edition. John
 Wiley & Sons, 1977.
 [15] P. B. Gibbons and Y. Matias., “New sampling-based summary
 statistics for improving approximate query answers,” in Proc.
 of the ACM SIGMOD, 1998.
 [16] V. Ganti, M. L. Lee, and R. Ramakrishnan, “ICICLES: Self-
 Tuning Samples for Approximate Query Answering,” in Proc.
 of the 26th VLDB, 2000.
 [17] D. E. Knuth, Art of Computer Programming, Volume 2:
 Seminumerical Algorithms (3rd Edition). Addison-Wesley
 Publishing Company, 1997.
 [18] “MonetDB,” http://monetdb.cwi.nl.
 306
