Learning from Multiple Data Sets with Different Missing Attributes and Privacy 
Policies: Parallel Distributed Fuzzy Genetics-Based Machine Learning Approach 
 
Hisao Ishibuchi, Masakazu Yamane, and Yusuke Nojima 
Department of Computer Science and Intelligent Systems 
Graduate School of Engineering, Osaka Prefecture University  
Sakai, Osaka 599-8531, Japan 
{hisaoi@, masakazu.yamane@ci., nojima@}cs.osakafu-u.ac.jp 
 
 
Abstract—This paper discusses parallel distributed genetics-
 based machine learning (GBML) of fuzzy rule-based classifiers 
from multiple data sets. We assume that each data set has a 
similar but different set of attributes. In other words, each data 
set has different missing attributes. Our task is the design of a 
fuzzy rule-based classifier from those data sets. In this paper, 
we first show that fuzzy rules can handle missing attributes 
easily. Next we explain how parallel distributed fuzzy GBML 
can handle multiple data sets with different missing attributes. 
Then we examine the accuracy of obtained fuzzy rule-based 
classifiers from various settings of available training data such 
as a single data set with no missing attribute and multiple data 
sets with many missing attributes. Experimental results show 
that the use of multiple data sets often increases the accuracy 
of obtained fuzzy rule-based classifiers even when they have 
missing attributes. We also discuss the learning from a data set 
under a severe privacy preserving policy where only the error 
rate of each candidate classifier is available. It is assumed that 
no information about each individual pattern is available. This 
means that we cannot use any information on the class label or 
the attribute values of each pattern. We explain how such a 
black-box data set can be utilized for classifier design. 
Keywords-Evolutionary algorithms, genetics-based machine 
learning, parallel distributed implementation, fuzzy rule-based 
classifiers, horizontally partitioned data sets. 
I.  INTRODUCTION 
In knowledge extraction and data mining, useful data are 
often collected and stored in different organizations around 
the world (e.g., hospitals in different countries). As a result, 
data can be viewed as a mixture of data sets, each of which is 
from a different site. In this case, data sets are heterogeneous 
due to various reasons such as different testing equipments in 
each organization and different regulations in each country. 
The availability of each data set is also often totally different 
in each site due to different security and privacy policies.  
In this paper, we discuss the learning from multiple data 
sets under the following two scenarios. In one scenario, it is 
assumed that each data set has different missing attributes. In 
the other scenario, some data sets are assumed to have a very 
severe privacy policy as well as different missing attributes. 
The first scenario, in which each data set has different 
missing attributes, is illustrated in Fig. 1 using three data sets 
DA, DB and DC. Missing attributes in each data set in Fig. 1 
are {x1, x4} in DA, {x4, x6} in DB, and {x1, x3, x5} in DC 
among the seven attributes {x1, x2, ..., x6, y} where “y” is a 
special attribute for a class label. We assume that the class 
label attribute is not missing in any data set. In privacy 
preserving data mining [1]-[4], multiple data sets of the type 
in Fig. 1 are called “horizontally partitioned data” [5] where 
the existence of missing attributes is not usually assumed 
explicitly. The main feature of our multiple data sets is that 
each data set has different missing attributes. Our multiple 
data sets are different from “vertically partitioned data” [5] 
in privacy preserving data mining where attributes are 
partitioned into several attribute subsets.  
 
ID x1 x2 x3 x4 x5 x6 y
 C1 9 1 8 0
 C2 6 1 7 1
 C3 5 2 7 1
 Site C
 Data Set DC
 ID x1 x2 x3 x4 x5 x6 y
 A1 9 2 2 9 1
 A2 8 1 3 6 1
 A3 9 5 1 5 0
 Site A
 Data Set DA
 ID x1 x2 x3 x4 x5 x6 y
 B1 1 8 1 1 0
 B2 1 8 2 3 0
 B3 3 9 2 1 1
 Site B
 Data Set DB
  
Figure 1.  Multiple data sets with different missing attributes (Scenario 1). 
In the second scenario, we assume that some sites with 
data sets have a very severe privacy preserving policy. More 
specifically, we assume that only error rates of candidate 
classifiers can be obtained from each of those sites. No other 
information is available. This scenario is illustrated in Fig. 2 
where Sites A and C are assumed to have such a severe 
privacy preserving policy. Whereas the data set DB is fully 
available to the classifier designer, the other data sets DA and 
DC are black-box data sets for the classifier designer. The 
classifier designer cannot see the contents of DA and DC. We 
assume that these two black-box data sets can be used only 
for the calculation of error rates of candidate classifiers.  
 
ID x1 x2 x3 x4 x5 x6 y
 C1 9 1 8 0
 C2 6 1 7 1
 C3 5 2 7 1
 Site C
 Data Set DC
 ID x1 x2 x3 x4 x5 x6 y
 A1 9 2 2 9 1
 A2 8 1 3 6 1
 A3 9 5 1 5 0
 Site A
 Data Set DA
 ID x1 x2 x3 x4 x5 x6 y
 B1 1 8 1 1 0
 B2 1 8 2 3 0
 B3 3 9 2 1 1
 Site B
 Data Set DB
 Full
 access
 Classifier Designer
 Candidate
 classifier
 Candidate
 classifier
 Error 
rate
 Error 
rate
  
Figure 2.  Learning under a severe privacy preserving policy (Scenario 2). 
63
 2013 IEEE International Conference on Big Data
 978-1-4799-1293-3/13/$31.00 ©2013  IEEE 
Applications of evolutionary computation to knowledge 
extraction and data mining are called genetics-based machine 
learning (GBML [7]-[10]). A rule set is often handled as an 
individual and coded as a string. Recently Franco et al. [10] 
demonstrated the high performance of GBML in comparison 
with other classifier design approaches such as decision trees 
and support vector machines. GBML has also been actively 
applied to the design of fuzzy rule-based classifiers under the 
name of fuzzy GBML. Fuzzy GBML is called genetic fuzzy 
systems (GFS) in the fuzzy system community [11]-[14].  
The main advantage of GBML is its flexibility in the 
handling of various goals in classifier design. Complexity 
measures such as the number of rules and the number of 
conditions in each rule as well as accuracy measures such as 
false positive and false negative can be integrated into a 
single fitness function. They can also be handled as separate 
objectives in multiobjective GBML algorithms to search for 
a number of non-dominated tradeoff classifiers [15], [16]. 
Classifiers with different tradeoffs can be obtained by a 
single run of a multiobjective GBML algorithm (e.g., simple 
classifiers with a few rules and complicated classifiers with 
high accuracy). In GBML, it is also easy to use constraint 
conditions such as the upper bound on the number of rules.  
Whereas GBML is a flexible classifier design approach, 
its real-world applications are not always easy due to its 
heavy computation load. Evolutionary search for an accurate 
classifier in a complicated large-scale real-world task often 
needs thousands of generations. In each generation, the 
creation and the fitness evaluation of hundreds of candidate 
classifiers are performed. 
As an efficient speed-up trick of GBML algorithms, we 
proposed their parallel distributed implementation [17], [18]. 
A population of classifiers is divided into multiple sub-
 populations as in an island model of parallel evolutionary 
computation [19], [20]. Training data are also divided into 
multiple subsets. A single training data subset is assigned to 
each sub-population. To avoid the overfitting of classifiers in 
each sub-population to the assigned training data subset, the 
assignment of the training data subsets is rotated periodically 
over the sub-populations. We showed in our former study 
[18] that the computation time of our fuzzy GBML algorithm 
[21] was decreased by its parallel distributed implementation 
to about 2% of that of its standard implementation. This is 
because both the training data and the population were 
divided into seven subsets (i.e., (1/7)2 = 1/49 B  2%).  
In this paper, we show that our fuzzy GBML algorithm 
[18], [21] can handle the above-mentioned two scenarios: 
data sets with missing attributes and black-box data sets with 
the severe privacy preserving policy. After explaining how 
these two scenarios can be handled, we examine the effect of 
using multiple data sets in each scenario on the accuracy of 
obtained fuzzy rule-based classifiers. Experimental results 
obtained from the use of multiple data sets are compared 
with those from a single data set (e.g., DB in Fig. 2). 
This paper is organized as follows. In Section II, we first 
explain fuzzy rules and fuzzy rule-based classifiers. The 
handling of data sets with missing attributes in Fig. 1 is also 
discussed in Section II. Then we explain our fuzzy GBML 
algorithm in Section III where we also show its variant for 
black-box data sets with the severe privacy preserving policy 
in Fig. 2. In Section IV, we examine the accuracy of fuzzy 
rule-based classifiers designed from multiple data sets in 
each of the two scenarios through computational experiments. 
Finally we conclude this paper in Section V. 
II. FUZZY RULE-BASED CLASSIFIERS 
A. Fuzzy Rules for Classification Problems 
A standard classification problem is defined by a set of 
labeled patterns in a pattern space. Let us assume that we 
have m training patterns xp= (xp1, xp2, ..., xpn), p = 1, 2, ..., m 
with n continuous attributes from M classes where p is a 
pattern index and xpi is an attribute value of the i-th attribute 
xi in the p-th pattern xp . Each pattern is assumed to have a 
class label, which is one of the M classes. For ease of 
explanation, we further assume that each attribute value xpi 
has already been normalized into a real number in the unit 
interval [0, 1]. This means that the pattern space of our 
classification problem is an n-dimensional hypercube [0, 1]n.  
The basic form of fuzzy rules for our n-dimensional 
classification problem is as follows: 
   Rule Rq: If x1 is Aq1 and ... and xn is Aqn then Class Cq ,    (1) 
where Rq is a rule label of the q-th fuzzy rule, Aqi is an 
antecedent fuzzy set of Rq on the i-th attribute xi, and Cq is a 
consequent class of Rq.  
Antecedent fuzzy sets often have linguistic labels such as 
“small ”, “medium” and “large”. In Fig. 3, we show typical 
examples of antecedent fuzzy sets with linguistic labels. The 
meaning of each antecedent fuzzy set Aqi is mathematically 
specified by its membership function oAqi( © ). For example, 
the membership functions of the three fuzzy sets in Fig. 3 are 
written for 0 ~ x ~ 1 as follows: 
" oSmall(x) = max{1/ 2x, 0},                                   (2) 
" oMedium(x) = min{2x, 2/ 2x},                                   (3) 
" oLarge(x) = max{2x/1, 0}.                                 (4) 
When antecedent fuzzy sets have linguistic labels, fuzzy 
rules can be interpreted as linguistic rules such as “If x1 is 
small and x2 is large then Class 1” and “If x1 is large and x2 
is small then Class 2”. These rules are easy for human users 
to understand. Linguistic interpretability of fuzzy rules is one 
advantage of fuzzy rule-based classifiers.  
 
Attribute Value
 M
 em
 be
 rs
 hi
 p
 0.0
 1.0
 0.0 1.0
 small medium large
  
Figure 3.  Typical antecedent fuzzy sets with linguistic labels. 
64
Fuzzy rules of the form in (1) have high interpretability. 
However, their classification ability is not always so high. In 
this paper, we use the following type of fuzzy rules with a 
rule weight CFq to enhance their classification ability: 
 Rule Rq: If x1 is Aq1 and ... and xn is Aqn  
    then Class Cq with CFq .      (5) 
The rule weight CFq of Rq , which is a real number in the 
unit interval [0, 1], works as the strength of Rq in fuzzy 
reasoning as explained in the next subsection [22], [23]. 
B. Fuzzy Reasoning in Fuzzy Rule-Based Classifiers 
A fuzzy rule-based classifier is a set of fuzzy rules of the 
form in (5). Let S be a fuzzy rule-based classifier. When an 
input pattern xp= (xp1, xp2, ..., xpn) is presented to the fuzzy 
rule-based classifier S, first the compatibility of xp  with the 
antecedent part of each fuzzy rule Rq  in S is calculated from 
the membership function oAqi( © ) of each antecedent fuzzy set 
Aqi  using the product operation as follows: 
" oAq(xp ) = oAq1(xp1)· oAq2(xp2)· © © © · oAqn(xpn),     (6) 
where Aq= (Aq1, Aq2, ..., Aqn) shows the antecedent part of Rq. 
The input pattern xp  is classified by a single winner rule. The 
winner rule RW  is defined for the input pattern xp  as  
" oAW(xp ) © CFW  = max{oAq(xp ) © CFq  | RqŒS}.        (7) 
The input pattern xp  is classified as the consequent class 
CW of the winner rule RW. If multiple fuzzy rules have the 
same maximum value in (7) and their consequent classes are 
different, the classification of the input pattern xp  is rejected. 
Its classification is also rejected when no fuzzy rule in S is 
compatible with xp . When we use fuzzy rules of the basic 
form in (1), the most compatible rule is chosen as the winner 
rule in (7). As shown in (7), the rule weight CFq of each 
fuzzy rule Rq works as the strength of Rq in the winner rule 
selection. The single winner-based fuzzy reasoning method 
in (7) has been widely used since the early 1990s [24]. One 
advantage of this reasoning method is its high explanation 
ability for the classification decision. The winner rule can be 
used to explain the reason for the classification decision.  
C. Handling of Missing Attribute Values 
We can easily handle input patterns with missing values 
by the single winner-based fuzzy reasoning method. Let us 
assume that the j-th attribute value xpj of the input pattern xp  
is missing. In this case, we calculate the compatibility grade 
oAq(xp ) of the input pattern xp  with the antecedent part Aq  of 
the fuzzy rule Rq  in (6) by specifying oAqj(xpj) as oAqj(xpj) = 1. 
The reason for using this heuristic is its simplicity. Since xpj 
is missing, we only know that its value is a real number in 
the normalized domain interval [0, 1]. By replacing xpj with 
[0, 1] in oAqj(xpj), we have oAqj([0, 1]) = 1.0 since the domain 
interval [0, 1] is fully compatible with any antecedent fuzzy 
set on [0, 1]. It should be noted that the specification of 
oAqj(xpj) as oAqj(xpj) = 1 is the same as removing oAqj(xpj) from 
(6). That is, we can ignore the condition corresponding to the 
missing attribute value. In this manner, we can easily handle 
incomplete patterns with missing values. 
This simple mechanism for the handling of missing value 
has the following potential drawback. Let us assume that a 
fuzzy rule-based classifier is trained using a data set DA with 
two missing attributes x1 and x4 in Fig. 2. In this case, 
classifier performance is independent of the 1st and 4th 
conditions Aq1 and Aq4 of each fuzzy rule. That is, any 
random changes of Aq1 and Aq4 have no effect on the error 
rate. As a result, it is not likely that each rule in the obtained 
fuzzy rule-based classifier has appropriate conditions on x1 
and x4. This issue should be addressed in future research.  
D. Heuristic Fuzzy Rule Generation 
If the antecedent part of a fuzzy rule has already been 
specified, its consequent class and rule weight can be easily 
determined using compatible training patterns with its 
antecedent part in a simple heuristic manner [22]-[24]. Let us 
assume that the antecedent part Aq  of a fuzzy rule Rq  has 
already been specified. In this case, its consequent class Cq  
and rule weight CFq  are determined in the following manner. 
First the compatibility grade of each training pattern xq  with 
the antecedent part Aq  is calculated by (6). Next the 
confidence value from the antecedent part Aq  to each class 
(i.e., Class k, k = 1, 2, ..., M) is calculated as follows: 
 Conf (Aqµ Class k) = 
Â
 Â
 ?
 Œ
 m
 p
 p
 k
 p
 q
 p
 q
 1
 Class
 )(
 )(
 x
 x
 A
 x
 A
 o
 o
 .          (8) 
When no class has a confidence value larger than 0.5, we 
do not generate any fuzzy rule with the antecedent part Aq . 
When the confidence value for a particular class Cq  is larger 
than 0.5, we generate a fuzzy rule with the antecedent part 
Aq  and the consequent class Cq . Then its rule weight is 
specified as follows [23]: 
 Â
 ”?
 µ/µ?
 M
 Ck
 k
 qqqq
 q
 kConfCConfCF
 1
 )Class()Class( AA . (9) 
From (8), this formulation can be rewritten as follows: 
 1)Class(2 /µ©? qqq CConfCF A .                    (10) 
In this manner, we can determine the consequent class Cq 
and the rule weight CFq for the antecedent part Aq. The 
antecedent part of each fuzzy rule in a fuzzy rule-based 
classifier is specified by our fuzzy GBML algorithm as we 
will explain in the next section. It should be noted that our 
heuristic rule generation method is applicable to data sets 
with missing attributes. However, it is not applicable to 
black-box data sets. This is because the confidence value in 
(8) cannot be calculated from black-box data sets. 
III. FUZZY GENETICS-BASED MACHINE LEARNING 
A. Outline of Our Fuzzy GBML Algorithm 
Our fuzzy GBML algorithm in this paper is the same as 
in our former study [18]. Our fuzzy GBML algorithm is used 
to design a fuzzy rule-based classifier with fuzzy rules of the 
65
form in (5). Each fuzzy rule Rq is represented by a string of 
length n using its n antecedent fuzzy sets Aq1, Aq2, ..., Aqn. 
As antecedent fuzzy sets, we use don’t care (i.e., an unit 
interval [0, 1]) and 14 triangular fuzzy sets in Fig. 4. These 
fuzzy sets are denoted by 15 integers from “0” for don’t care 
to “14” for the right-most fuzzy set in the bottom-right plot 
in Fig. 4. Thus a fuzzy rule is represented by an integer string 
of length n using the alphabet of the 15 integers. As a result, 
the total number of different strings is 15n. Each of those 
strings shows a different fuzzy rule. 
 
1.0
 0.0 1.0Attribute value
 3 4 5
 M
 em
 be
 rs
 hi
 p
 1.0Attribute value
 1 21.0
 0.0M
 em
 be
 rs
 hi
 p
  
1.0Attribute value 1.0Attribute value
 10 12 1413116 97 8 1.0
 0.0M
 em
 be
 rs
 hi
 p1.0
 0.0M
 em
 be
 rs
 hi
 p
  
Figure 4.  Fuzzy partitions with 14 antecedent fuzzy sets. 
A fuzzy rule-based classifier S with |S| fuzzy rules is 
represented by a concatenated integer string of length n |S| 
where each substring of length n shows a single fuzzy rule. 
The number of fuzzy rules is not pre-specified (i.e., |S| is not 
a pre-specified constant parameter). Thus the length of each 
string can be different. The number of fuzzy rules can be 
automatically determined for each application task in our 
fuzzy GBML algorithm.  
A fuzzy rule-based classifier S is evaluated in our fuzzy 
GBML algorithm by the following fitness function: 
 fitness(S) = w1 f1(S) + w2 f2(S) + w3 f3(S),              (11) 
where w1, w2 and w3 are non-negative weights, and f1(S), 
f2(S) and f3(S) are as follows: 
 f1(S): Training data error rate of S in percentage, 
 f2(S): The number of fuzzy rules in S (i.e., f2(S) = |S |),  
 f3(S): The total rule length of S. 
The number of antecedent conditions of a fuzzy rule 
excluding don’t care conditions is called the rule length. The 
total rule length is the total number of antecedent conditions 
in S excluding don’t care conditions (i.e., the sum of the rule 
length of fuzzy rules in S). The fitness function in (11) 
should be minimized. The use of (11) is to simultaneously 
perform the accuracy maximization and the complexity 
minimization. The weight values in (11) are specified as 
w1 = 100, w2 = 1 and w3 = 1 in our computational experiments. 
Our fuzzy GBML algorithm is a hybrid algorithm of 
Pittsburgh-style GBML and Michigan-style GBML as shown 
in Fig. 5. In this subsection, we explain the Pittsburgh-style 
framework. The Michigan-style part is explained later. 
Let us denote the population size by NPop. In the 
“Initialization” step in Fig. 5, an initial population with NPop 
integer strings is generated. The number of substrings in each 
initial string (i.e., the number of fuzzy rules in each initial 
rule set) is 30 in our computational experiments. To generate 
an initial string, we randomly choose 30 training patterns. A 
single fuzzy rule is generated from each training pattern 
xp= (xp1, xp2, ..., xpn) by probabilistically choosing an 
antecedent fuzzy set for each attribute xi using its 
compatibility grade with the attribute value xpi. The selection 
probability of each antecedent fuzzy set is proportional to its 
compatibility grade with xpi. After choosing n antecedent 
fuzzy sets, each of them is replaced with don’t care using a 
pre-specified don’t care probability. This probability is 
specified as (n/5)/n in our computational experiments. Thus 
each initial fuzzy rule has five conditions on average.  
In the “Selection” step in Fig. 5, each string in the current 
population is evaluated by the fitness function in (11). Then 
NPop pairs of parents are selected by binary tournament 
selection with replacement based on their fitness values.  
In the “Genetic Operations” step, a string is generated 
from each pair of parents by randomly choosing substrings 
from each parent. The number of selected substrings from 
each parent is randomly specified. Thus the length of a new 
string can be different from that of its parents. This crossover 
operation is applied to each pair of parents with a pre-
 specified probability, which is 0.9 in our computational 
experiments. When the crossover operation is not applied, 
one of the two parents is randomly selected. A new string is 
generated as a copy of the selected parent. 
Each integer in the newly generated string is randomly 
replaced with another integer using a pre-specified mutation 
probability. In our computational experiments, the mutation 
probability is specified for the new string S as 1/n |S| where 
n |S| is the string length of S. In the “Genetic Operations” 
step, NPop strings are newly generated by crossover and 
mutation. A Michigan-style algorithm, which is explained in 
the next subsection, is applied to each of the generated new 
strings with a pre-specified probability. This probability is 
specified as 0.5 in our computational experiments. 
In the “Population Update” step in the left plot of Fig. 5, 
the current population and the newly generated NPop strings 
are merged. The best NPop strings in the merged population 
are selected to form the next population. 
 
Initialization
 Selection
 Genetic operations
 (Crossover and Mutation)
 Michigan-style part
 Termination condition
 Yes
 No
 Population update
 Choose the best individual
 Michigan probability
 New rule generation
 • Genetic rule generation
 • Heuristic rule generation
 Yes
 No
 Michigan-style part
 Population update
 Pittsburgh-style framework
 Rule set
  
Figure 5.  Our hybrid fuzzy GBML algorithm [18]. 
66
If the termination condition (50,000 generations in this 
paper) does not hold, the updated population goes back to the 
“Selection” step. Otherwise, the best string in the updated 
population is chosen as the finally obtained classifier. 
B. Michigan-Style Part of Our Fuzzy GBML Algorithm 
The Michigan-style part in Fig. 5 can be viewed as a 
local search procedure for each string. A single string S in 
the Pittsburgh-style framework is handled as a population of 
fuzzy rules. Each fuzzy rule Rq in the string is an individual 
in the Michigan-style part. The fitness of Rq in S is defined 
by the number of correctly classified training patterns by Rq 
when S is used to classify all training patterns. Since we use 
the single winner-based fuzzy reasoning method, we can 
identify a single responsible fuzzy rule for the classification 
of each pattern. The worst 20% of fuzzy rules are removed 
from S. The number of fuzzy rules to be generated is the 
same as that of the removed rules. A half of new fuzzy rules 
are directly generated from misclassified training patterns in 
the same manner as in the initial fuzzy rule generation. The 
other fuzzy rules are generated from the existing fuzzy rules 
in S by binary tournament selection, uniform crossover with 
the probability 0.9, and mutation with the probability 1/n. 
The modified rule set S is sent back to the Pittsburgh-style 
part after only a single iteration of the Michigan-style part. 
C. Parallel Distributed Fuzzy GBML Algorithm 
Parallel distributed implementation in our former study 
[18] is illustrated in Fig. 6. As in [18], a population of size 
210 is divided into seven sub-populations of size 30 in this 
paper. Training data are also divided into seven subsets of 
the same size: D1, D2, ..., D7. The seven sub-populations and 
the seven data subsets are distributed over seven CPUs. Our 
fuzzy GBML algorithm is locally executed at each CPU for a 
pre-specified number of generations (i.e., rotation interval). 
Then the training data subsets are rotated over the CPUs. 
Three specifications of the rotation interval are examined: 10, 
100 and 1000 generations. A copy of the best rule set in each 
island is migrated to an adjacent island. The migration is 
always performed every 100 generations. As shown in Fig. 6, 
the rotation and the migration are executed in the opposite 
directions. After the 50,000th generation, 210 rule sets are 
evaluated using all data sets. The best rule set with respect to 
the fitness function is chosen as a finally obtained classifier. 
 
CPU
 Training data rotation
 Training data
 Po
 pu
 la
 tio
 n
 CPU CPU CPU CPU CPU CPU
 Rule set migration 
D2 D3 D4 D5 D6 D7D1
  
Figure 6.  Parallel distributed implementation [18]. 
D. Modification of Fuzzy GBML for Black-Box Data Sets 
Let us assume that the classifier designer cannot access 
any data sets except for a single data set D1. As we explained 
in Section I using Fig. 2, we assume that only the error rate 
of a candidate fuzzy rule-based classifier is available from 
each of those black-box data sets. In this situation, we cannot 
use the Michigan-style part since no information about the 
fitness of each fuzzy rule is available. Thus we remove the 
Michigan-style part when our fuzzy GBML algorithm is 
executed on a black-box data set.  
In the Pittsburgh-style framework, we need the full 
information on training patterns to generate initial fuzzy 
rules. Since D1 is fully available, initial fuzzy rules are 
always generated from D1. When the antecedent part of a 
fuzzy rule is changed by mutation, the information on 
training patterns is needed to determine the consequent class 
and the rule weight. In this case, we use the available data set 
D1. That is, D1 is always used to generate new fuzzy rules 
even when fuzzy rule-based classifiers are evaluated on 
another data set. In this manner, we utilize a fully available 
data set and other black-box data sets.  
IV. COMPUTATIONAL EXPERIMENTS  
A. Settings of Computational Experiments  
The main objective of our computational experiments is 
to examine the potential usefulness of our parallel distributed 
implementation in the handling of the two scenarios: One is 
multiple data sets with different missing attributes in Fig. 1, 
and the other is multiple black-box data sets in Fig. 2. We 
use four data sets in Table I in the KEEL database [25]. For 
each data set, we artificially generate multiple training data 
subsets with different missing attributes within the ten-fold 
cross-validation (10CV) framework. In 10CV, given patterns 
are divided into ten subsets: One is used as test data and the 
others are used as training data.  
TABLE I.  FOUR DATA SETS USED IN THIS PAPER.  
Data Set Patterns Attributes Classes 
Phoneme 5,404 5 2 
Page-blocks 5,472 10 5 
Segment 2,310 19 7 
Satimage 6,435 36 6 
 
The training data are further divided into seven subsets of 
the same size: D1, D2, ..., D7. We remove some attributes 
from these subsets in order to generate multiple data sets 
with different missing attributes in the first scenario. In the 
second scenario, we assume that only the first training data 
subset D1 is fully available. Due to the severe privacy 
preserving policy, only error rates of candidate classifiers on 
each of the other data subsets Di (i = 2, 3, ..., 7) are available. 
Our two scenarios can be rewritten in our computational 
experiments as follows: 
Scenario 1: The classifier designer can fully access all 
the seven training data subsets Di (i = 1, 2, ..., 7).  
Scenario 2: The classifier designer can fully access D1. 
Due to the severe privacy preserving policy, only error rates 
of candidate classifiers on Di (i = 2, 3, ..., 7) are available. 
67
We artificially generate multiple data sets with different 
missing attributes in the following two manners:  
Setting 1: We remove only a single attribute from each 
training data subset Di except for D1. More specifically, we 
remove the i-th attribute xi from Di (i = 2, 3, ..., 7). As a result, 
xi is missing in Di (i = 2, 3, ..., 7) while no attribute is missing 
in D1. In the case of the phoneme data with five attributes (x1, 
x2, x3, x4, x5), xi is removed from Di (i = 2, 3, 4, 5), and x1 and 
x2 are removed from D6 and D7, respectively. 
Setting 2: Let n* be the number of attributes to be 
removed from Di (i = 2, 3, ..., 7). For each data set in Table I, 
n* is specified as the smallest integer not smaller than n/6 so 
that every attribute is removed from at least one training data 
subset Di. For example, n* is specified as n* = 4 for the 
segment data with 19 attributes since n/6 ? 19/6 B 3.17. We 
randomly choose n* attributes to be removed from each Di 
(i = 2, 3, ..., 7) under the following conditions: (i) Every 
attribute should be removed from at least one subset, and (ii) 
no attribute should be removed from more than two subsets. 
As a result, a different subset of n* attributes becomes 
missing in Di (i = 2, 3, ..., 7) while no attribute is missing in 
D1. The random selection of removed n* attributes is updated 
when the entire 10CV procedure is completed. In this paper, 
we iterate 10CV five times using different data partitions 
into ten subsets (i.e., 5 · 10CV). Thus the selection of 
removed attributes is updated five times.  
These two settings are examined under the two scenarios. 
Since D1 with no missing attributes is always available, it 
looks a good idea to design a fuzzy rule-based classifier from 
D1 without using any other training data subsets. This idea is 
illustrated in Fig. 7 where D1 is used in all sub-populations. 
In this paper, Fig. 6 with the seven data subsets and Fig. 7 
with only D1 are compared. The same parallel distributed 
algorithm is used in Fig. 6 and Fig. 7. In order to choose the 
final fuzzy rule-based classifier under the same condition in 
Fig. 6 and Fig. 7, only D1 is used for classifier selection. That 
is, 210 individuals at the final population are evaluated using 
D1. Then, the best individual is selected as the final classifier. 
 
   
CPU
 Training data rotation
 Training data
 Po
 pu
 la
 tio
 n
 CPU CPU CPU CPU CPU CPU
 Rule set migration 
D1 D1 D1 D1 D1 D1D1
  
Figure 7.  Parallel distributed implementation with seven duplicates of D1. 
Our computational experiments are performed in the 
same parameter specifications in our former study [18] such 
as the use of seven sub-populations of size 30 (i.e., 210 rule 
sets in each generation in total) and the termination at the 
50,000th generation. The training data rotation interval is 
specified as 10, 100 and 1000 generations while the 
migration interval is specified as 100 generations. We also 
examine an additional specification: no training data rotation 
and no rule set migration. Average accuracy of the finally 
obtained fuzzy rule-based classifiers on test data is evaluated 
over five iterations of 10CV (i.e., 5 · 10CV). We do not 
remove any attributes from the test data. That is, each test 
pattern is classified using its all attribute values in 10CV. In 
the following, we report the average accuracy on test data. 
B. Experimental Results from Setting 1  
In the first setting, D1 has no missing attribute while each 
of the other six subsets Di (i = 2, 3, ..., 7) has a single missing 
attribute. When a data set has many attributes such as the 
satimage data with 36 attributes, negative effects of a single 
missing attribute seem to be small. Thus it may be a good 
idea to use not only D1 with no missing attribute but also the 
other six data sets with a single missing attribute. However, 
when a data set does not have many attributes such as the 
phoneme data with five attributes, negative effects of a single 
missing attribute may be large. Thus the benefit of using all 
the seven training data subsets may be small or negative.  
To numerically examine these discussions, we compare 
the following three cases: the use of D1 as in Fig. 7, the use 
of all the seven subsets Di (i = 1, 2, ..., 7) as in Fig. 6 in 
Scenario 1, and the use of all the seven subsets in Scenario 2 
(i.e., only D1 is fully available). Experimental results on the 
four data sets in Table I are summarized in Figs. 8-11. When 
we use only D1, the same average accuracy is obtained from 
different specifications of the rotation interval. However, a 
slightly different average accuracy is obtained from “None” 
with no rotation and no migration.  
In Fig. 8 on the phoneme data with five attributes, we can 
observe a clear negative effect of using all the seven training 
data subsets (black and red open circles) in comparison with 
the use of only D1 (blue closed circles) as expected. In Figs. 
9-11, better results are obtained by the use of all the seven 
training data subsets (black and red open circles) than the use 
of only D1 (blue closed circles) in many cases.  
Regarding the comparison between the two scenarios, 
better results are obtained in many cases from Scenario 1 
with full access to all data subsets (e.g., Fig. 10 and Fig. 11). 
However, better results are obtained from Scenario 2 in some 
cases than Scenario 1 (e.g., rotation interval 1000 in Fig. 9). 
 
100 100010
 Rotation interval
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 80
 76
 78
 82
 None
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
  
Figure 8.  Results on the phoneme data with five attributes (Setting 1).  
68
100 1000 None10
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 Rotation interval
 95
 93
 96
 94
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
  
Figure 9.  Results on the Page-blocks data with ten attributes (Setting 1). 
100 100010
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 92
 88
 86
 90
 94
 Rotation interval
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
 None
  
Figure 10.  Results on the Segment data with 19 attributes (Setting 1). 
100 100010
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 86
 82
 80
 84
 88
 Rotation interval
 None
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
  
Figure 11.  Results on the Satimage data with 36 attributes (Setting 1). 
C. Experimental Results from Setting 2  
In the second setting, D1 has no missing attribute while 
about n/6 attributes are missing in the other six data subsets. 
Similar results are obtained from the first and second settings 
for the phoneme data with five attributes since the number of 
missing attributes is one in both settings. Figs. 12-14 show 
experimental results on the other data sets in Setting 2.  
Since much more attributes are missing in Figs. 12-14 
(i.e., two in Fig. 12, four in Fig. 13, and six in Fig. 14) than 
Figs. 9-11 with a single missing attribute, positive effects of 
using all the seven data subsets decrease from Figs. 9-11 to 
Figs. 12-14. However, better results are still obtained by the 
use of all the seven data subsets (black and red open circles) 
than the use of D1 (blue closed circles) in Figs. 12-14.  
100 100010
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 Rotation interval
 95
 93
 96
 None
 94
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
  
Figure 12.  Results on the Page-blocks data with ten attributes (Setting 2). 
100 100010
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 92
 88
 86
 90
 94
 Rotation interval
 None
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
  
Figure 13.  Results on the Segment data with 19 attributes (Setting 2). 
100 100010
 Te
 st
  D
 at
 a 
A
 cc
 ur
 ac
 y 
(%
 )
 86
 82
 80
 84
 88
 Rotation interval
 None
 Seven Subsets (Scenario 1)
 Use of only D1
 Seven Subsets (Scenario 2)
  
Figure 14.  Results on the Satimage data with 36 attributes (Setting 2). 
One interesting observation in Figs. 12-14 is that better 
results are obtained in many cases from Scenario 2 than 
Scenario 1. This may be because new fuzzy rules are always 
generated from D1 with no missing attributes in Scenario 2. 
In Scenario 1, new fuzzy rules are generated from D1 with no 
missing attributes and also from the other six data subsets Di 
(i = 2, 3, ..., 7) with missing attributes. 
V. CONCLUSION 
In this paper, we examined the potential usefulness of our 
parallel distributed fuzzy GBML algorithm for fuzzy rule-
 based classifier design from multiple data sets with different 
missing attributes. We also examined its potential usefulness 
under the assumption of the severe privacy preserving policy 
where data sets were handled as black-box data sets. More 
69
specifically, we assumed that a black-box data set was used 
only for calculating the error rate of each classifier. No other 
information (e.g., attribute values of each pattern, its true 
class, and its classification result) were available.  
In our computational experiments, we divided training 
patterns into seven data subsets: one complete data subset 
with no missing attributes and six incomplete data subsets 
with different missing attributes. We observed that classifier 
performance was improved by the use of all the seven data 
subsets in comparison with the use of only the complete data 
subset. This improvement was also observed even when the 
six incomplete data subsets were black-box data sets. 
It was always assumed in our computational experiments 
that one data subset was fully available. It is an interesting 
future research issue to examine the learning from multiple 
data subsets where no data subsets are fully available (i.e., all 
data subsets have different missing attributes and the severe 
private preserving policy). In such a difficult situation, more 
sophisticated handling of missing values may be needed 
since all data subsets have missing attributes. More efficient 
evolutionary learning may be also needed since we cannot 
generate fuzzy rules directly from training patterns.  
REFERENCES 
[1] R. Agrawal and R. Srikant, “Privacy-preserving data mining,” Proc. 
of the 2000 ACM SIGMOD International Conference on Management 
of Data, pp. 439-450, Dallas, May 15-18, 2000. DOI: 10.1145/ 
342009.335438 
[2] Y. Lindell and B. Pinkas, “Privacy preserving data mining,” Proc. of 
the 20th Annual International Cryptology Conference (LNCS 1880: 
Advances in Cryptology - CRYPTO 2000), pp. 36-54, Santa Barbara, 
August 20-24, 2000. DOI: 10.1007/3-540-44598-6_3 
[3] Y. Lindell and B. Pinkas, “Privacy preserving data mining,” Journal 
of Cryptology, vol. 15, no. 3, pp. 177-206, June 2002. DOI: 
10.10071s00145-001-0019-2  
[4] V. S. Verykios, E. Bertino, I. N. Fovin, L. P. Provenza, Y. Saygin, 
and Y. Theodoridis, “State-of-the-art in privacy preserving data 
mining,” Sigmod Record, vol. 33, no. 1, pp. 50-57, March 2004. DOI: 
10.1145/974121.974131 
[5] M. Kantarcioglu and C. Clifton, “Privacy-preserving distributed 
mining of association rules on horizontally partitioned data,” IEEE 
Trans. on Knowledge and Data Engineering, vol. 16, no.9, pp. 1026-
 1037, September 2004. DOI: 10.1109/TKDE.2004.45 
[6] J. Vaidya and C. Clifton, “Privacy preserving association rule mining 
in vertically partitioned data,” Proc. of the 8th ACM SIGKDD 
International Conference on Knowledge Discovery and Data Mining, 
pp. 639-644, Edmonton, July 23-25, 2002. DOI: 10.1145/ 
775047.775142 
[7] A. Fernández, S. García, J. Luengo, E. Bernadó-Mansilla, and F. 
Herrera, “Genetics-based machine learning for rule induction: State 
of the art, taxonomy, and comparative study,” IEEE Trans. on 
Evolutionary Computation, vol. 14, no. 6, pp. 913-941, December 
2010. DOI: 10.1109/TEVC.2009.2039140 
[8] S. García, A. Fernández, J. Luengo, and F. Herrera, “A study of 
statistical techniques and performance measures for genetics-based 
machine learning: Accuracy and interpretability,” Soft Computing, 
vol. 13, no. 10, pp. 959-977, August 2009. DOI: 10.1007/s00500-
 008-0392-y 
[9] J. Bacardit and N. Krasnogor, “Performance and efficiency of 
memetic Pittsburgh learning classifier systems,” Evolutionary 
Computation, vol. 17, no. 3, pp. 307-342, Fall 2009. DOI: 10.1162/ 
evco.2009.17.3.307 
[10] M. A. Franco, N. Krasnogor and J. Bacardit, “GAssist vs. BioHEL: 
critical assessment of two paradigms of genetics-based machine 
learning,” Soft Computing, vol. 17, no. 6, pp. 953-981, June 2013, 
DOI: 10.1007/s00500-013-1016-8  
[11] F. J. Berlanga, A. J. Rivera, M. J. del Jesus, and F. Herrera, “GP-
 COACH: Genetic Programming-based learning of COmpact and 
ACcurate fuzzy rule-based classification systems for High-
 dimensional problems,” Information Sciences, vol. 180, no. 8, pp. 
1183-1200, April 2010. DOI:10.1016/j.ins.2009.12.020 
[12] J. Alcalá-Fdez, R. Alcalá, and F. Herrera, “A fuzzy association rule-
 based classification model for high-dimensional problems with 
genetic rule selection and lateral tuning,” IEEE Trans. on Fuzzy 
Systems, vol. 19, no. 5, pp. 857-872, October 2011. DOI: 10.1109/ 
TFUZZ.2011.2147794 
[13] J. A. Sanz, A. Fernández, H. Bustince, and F. Herrera, “IVTURS: a 
linguistic fuzzy rule-based classification system based on a new 
Interval-Valued fuzzy reasoning method with TUning and Rule 
Selection,” IEEE Trans. on Fuzzy Systems (In Press. Available from 
http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6420926). 
DOI: 10.1109/TFUZZ.2011.2147794 
[14] F. Herrera, “Genetic fuzzy systems: Taxonomy, current research 
trends and prospects,” Evolutionary Intelligence, vol. 1, no. 1, pp. 27-
 46, March 2008. DOI: 10.1007/s12065-007-0001-5 
[15] H. Ishibuchi and Y. Nojima, “Analysis of interpretability-accuracy 
tradeoff of fuzzy systems by multiobjective fuzzy genetics-based 
machine learning,” International Journal of Approximate Reasoning 
44 (1) 4-31, January 2007. DOI: 10.1145/775047.775142 
[16] M. Fazzolari, R. Alcalá, Y. Nojima, H. Ishibuchi, and F. Herrera, “A 
review of the application of multiobjective evolutionary fuzzy 
systems: Current status and further directions,” IEEE Trans. on Fuzzy 
Systems, vol. 21, no. 1, pp. 45-65, February 2013. DOI: 10.1109/ 
TFUZZ.2012.2201338 
[17] Y. Nojima, H. Ishibuchi, and I. Kuwajima, “Parallel distributed 
genetic fuzzy rule selection,” Soft Computing, vol. 13, no. 5, pp. 511-
 519, March 2009. DOI: 10.1007/s00500-008-0365-1 
[18] H. Ishibuchi, S. Mihara, and Y. Nojima, “Parallel distributed hybrid 
fuzzy GBML models with rule set migration and training data 
rotation,” IEEE Trans. on Fuzzy Systems, vol. 21, no. 2, pp. 355-368, 
April 2013. DOI: 10.1109/TFUZZ.2012.2215331 
[19] E. Alba and M. Tomassini, “Parallelism and evolutionary 
algorithms,” IEEE Trans. on Evolutionary Computation, vol. 6, no. 5, 
pp. 443-462, October 2002. DOI: 10.1109/TEVC.2002.800880 
[20] S. Cahon, N. Melab, and E. G. Talbi, “ParadisEO: A framework for 
the reusable design of parallel and distributed metaheuristics,” 
Journal of Heuristics, vol. 10, no. 3, pp. 357-380, May 2004. DOI: 
10.1023/B:HEUR.0000026900.92269.ec 
[21] H. Ishibuchi, T. Yamamoto, and T. Nakashima, “Hybridization of 
fuzzy GBML approaches for pattern classification problems,” IEEE 
Trans. on Systems, Man, and Cybernetics - Part B, vol. 35, no. 2, pp. 
359-365, April 2005. DOI: 10.1109/TSMCB.2004.842257 
[22] H. Ishibuchi and T. Nakashima, “Effect of rule weights in fuzzy rule-
 based classification systems,” IEEE Trans. on Fuzzy Systems, vol. 9, 
no. 4, pp. 506-515, August 2001. DOI: 10.1109/91.940964 
[23] H. Ishibuchi and T. Yamamoto, “Rule weight specification in fuzzy 
rule-based classification systems,” IEEE Trans. on Fuzzy Systems, vol. 
13, no. 4, pp. 428-435, August 2005. DOI: 10.1109/TFUZZ.2004. 
841738 
[24] H. Ishibuchi, K. Nozaki, and H. Tanaka, “Distributed representation 
of fuzzy rules and its application to pattern classification,” Fuzzy Sets 
and Systems, vol. 52, no. 1, pp. 21-32, November 1992. DOI: 
10.1016/0165-0114(92)90032-Y 
[25] J. Alcalá-Fdez, L. Sánchez, S. García, M. J. del Jesus, S. Ventura, J. 
M. Garrell, J. Otero, C. Romero, J. Bacardit, V. M. Rivas, J. C. 
Fernández, and F. Herrera, “KEEL: A software tool to assess 
evolutionary algorithms for data mining problems,” Soft Computing, 
vol. 13, no. 3, pp. 307-318, February 2009. DOI: 10.1007/s00500-
 008-0323-y 
 
70
