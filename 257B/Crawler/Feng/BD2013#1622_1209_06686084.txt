Privacy preserving similarity detection for data
 analysis
 Iraklis Leontiadis, Melek ¨Onen, Refik Molva
 Networking and Security Department
 EURECOM, Sophia-Antipolis, France
 {leontiad,onen,molva}@eurecom.fr
 M.J. Chorley, G.B. Colombo
 School of Computer Science & Informatics
 Cardiff University
 {m.j.chorley, fg.colombo}@cs.cardiff.ac.uk
 Abstract—Current applications tend to use personal sensitive
 information to achieve better quality with respect to their services.
 Since the third parties are not trusted the data must be protected
 such that individual data privacy is not compromised but at the
 same time operations on it would be compatible. A wide range of
 data analysis operations entails a similarity detection algorithm
 between user data. For instance clustering on big data groups
 together objects based on the heuristic that similar objects are
 likely to be put under the same cluster. Similarity decisions are
 important for numerous applications such as: online social net-
 works, recommendations systems and behavioral advertisement.
 In this paper we propose a mechanism that protects user privacy
 and preserves data similarity results although encrypted. We
 analyze the security of the scheme and we further demonstrate
 its correctness and feasibility through a real life experiment
 where “personality traits” by users are collected for a 4square
 application.
 Keywords—Information security, privacy, data analysis, similar-
 ity detection
 I. INTRODUCTION
 Most of today’s ICT applications tend to leverage user
 information more and more to achieve better content delivery.
 In particular recommendation systems collect data about users
 and their interactions with their environment in order to deliver
 the most appropriate and personalized content to them. The
 leveraged information spanning users’ social relations and
 personal interests consist of highly sensitive data and hence
 raises the problem of privacy; a naive solution on the afore-
 mentioned problem could be to encrypt data before analyzing
 them. This would not solve the problem as operations after
 encryption would not be feasible. A more suitable solution
 could be to encrypt data homomorphically thus statistical
 properties on data after encryption are preserved. Even though
 this solution seems approachable the current homomorphic
 encryption schemes fall short of giving a solution for a global
 analysis system applied to some large scale dataset. Moreover
 anonymization techniques do not offer the appropriate security
 guarantees for individual data privacy and also have been
 vulnerable to attacks [1].
 One of the basic building blocks in the vast majority of data
 analysis scenarios is similarity detection. By analyzing users’
 dataset, a recommendation engine can discover similar profiles
 and thus recommend a newly arrived user some content that
 was already consumed by other existing ”similar users”. Online
 advertisers sought to increase their revenues by inspecting
 the online behavior of users. That implies an outsourcing
 of personal sensitive information by online retailers to the
 advertisers.
 The aforementioned applications imply a privacy violation
 risk. Since the input to the data analysis operations is personal
 sensitive private information and operations performed over
 them violate user privacy. As such, users and companies either
 tend not to submit their data for further analysis to untrusted
 parties or they give limited access on it due to individual
 privacy violation risks [1], [2], [3], [4]. Radical solutions
 include a restriction either on the available data analysis
 operations from the analyzer perspective or an outsource of
 aggregate information instead of individual data. But this will
 degrade very much the accuracy on data analysis and also this
 method is not always feasible.
 We analyze a well-known similarity detection algorithm,
 namely the cosine similarity and combine it with some obfus-
 cation mechanisms in order to achieve a privacy preserving
 similarity computation solution.
 In this paper we present a privacy preserving protocol for
 similarity detection. Cosine similarity can recognize similar
 vectors based on the formed angle between the vectors.This
 new privacy preserving mechanism first maps users’ data into
 vectors and applies some geometrical transformations that
 on the one hand preserve the angle between any pair of
 vectors and assures the confidentiality of the content of their
 coordinates. The accuracy of the proposed solution is then
 evaluated with the study on users’ personality characteristics.
 In section II we present related work in the area of privacy
 preserving data analysis. In III there is the problem description.
 We give our solution in section IV and in section V we argue
 for the security of the scheme. The evaluation of solution with
 real world data is analyzed in VI.
 II. RELATED WORK
 We proceed into a taxonomy of previous solutions in the
 area of privacy preserving data analysis. We start with more
 generic solutions and we further describe previous work in
 the context of specific privacy preserving similarity detection
 algorithms for clustering.
 Data perturbation Several techniques have been proposed in
 order to obfuscate data such that when users submit their data
 to the data analyzer individual data privacy is being protected
 but specific data mining algorithms can be applied on it.
 Privacy preserving data mining by adding noise on data has
 been first proposed in [5], [6]. The solution has been proposed
 2013 IEEE Third International Conference on Cloud and Green Computing
 978-0-7695-5114-2/13 $26.00 © 2013 IEEE
 DOI 10.1109/CGC.2013.92
 547
for privacy preserving decision trees as a solution to derive
 association rules from databases. In [7] the authors proposed
 geometrical transformation for data clustering. Transformation
 though are data dependent and do not scale for multidimen-
 sional data.
 Anonymization Data anonymization asks for unlinkability on
 data records and users. K-anonymity [8] has been proposed as
 a solution to protect the release of data to an untrusted party
 such that the personal private information for each data record
 cannot be distinguished from k?1 other users. Suppression and
 generalization are two techniques to achieve k-anonymity. By
 generalization [9] specific attributes are generalized in order to
 protect user anonymity. For instance instead of releasing the
 exact data of birth only the month and the year is released.
 With suppression [10] no data is released. Solutions for data
 anonymity imply an information loss through out the described
 techniques and operation after the release of the data are
 inconsistent.
 Data separation In [11] cryptographic tools are being used to
 protect user data privacy when the id3 tree is constructed for
 association rules. The id3 tree is a widely known technique
 for data classification. The categorical data of a set of records
 is being constructed by choosing the attributes than containing
 the higher information gain. Information gain is expressed as
 conditional entropy and the problem of id3 construction is
 approximated by finding the attributes that information gain is
 maximized. The authors assume that data are split horizontally,
 thus the data analyzer in order to compute the conditional
 entropy of two users should separately and privately obtain
 the data from both. It turns out that information gain for an
 attribute between two users is expressed as (u1+u2)·log(u1+
 u2). The problem has been addressed as a secure multi-party
 computation of this expression for two users.
 Privacy preserving data classification on horizontally par-
 titioned data has been addressed in [12], [13] as well. The
 solution is based on a privacy preserving protocol for sum
 computation based on randomization and privacy preserving
 union set computation. Those two functionalities can securely
 be used by an untrusted party to infer the global confidence
 of an attribute in order to infer the association rules that
 will classify the data. In [14] privacy preserving clustering on
 vertically partitioned data is addressed by submitting only the
 similarities on objects and not the real data. However how
 the users are computing the similarities while at the same
 time preserving their privacy is not clearly addressed. Vaidya
 et al. tackle this issue by constructing a protocol for secure
 dot product computation without the use of a trusted party.
 However the communication cost for computing all the dot
 products between users is high [15]
 Our Contributions As opposed to previous solutions we pro-
 pose a scheme that is data independent and assures higher level
 of privacy. Previous solutions that are based on geometrical
 transformations do not scale for multidimensional data [7]
 and also there is no concrete security analysis with respect
 to the leakages of the protocol for example. We did not tackle
 our similarity problem with respect to data anonymization
 as anonymization does not fully assure data confidentiality.
 Moreover, data separation techniques in which data are split
 in between different sites are not always a real world scenario
 in which each user holds its data in its entire form.
 III. PROBLEM STATEMENT
 A. Similarity and privacy
 We assume a set of n users. Each user Ui holds its personal
 sensitive private data Di. An untrusted data analyzer A seeks
 to obtain Di from each user Ui, where 0 ≤ i ≤ N . We
 consider each Di as a multidimensional vector of size m:
 Di = (d1, d2, d3, · · · , dm). After the data collection, A is
 applying a similarity detection algorithm F over any pair of
 data vectors in order to identify similarities between them
 in order to further form clusters. During the detection of
 similarities in between data the privacy of users should not
 be compromised. As such we are looking for an obfuscation
 mechanism ? : Rm ? Rm such that for any two vectors x,y:
 F(Di, Dj) = F(?(Di), ?(Dj))
 where ? will preserve the privacy of individual data and at
 the same time similarity detection through cosine computation
 will be compatible.
 B. Cosine similarity
 Cosine similarity is a widely used distance metric for
 numerical data. Cosine similarity[16] depicts the geometrical
 similarity of two objects in an Euclidean space by measuring
 the angle ? formed by their vector representation in a n
 dimensional Euclidean space. The dot product < a · b >
 of two vectors a,b is < a · b >= ||a|| · ||b|| cos ? , where
 ||a|| =√∑ni=0 ai2 is the norm of vector a and ai denotes the
 coefficients of this vector. Thus,
 cos ? = < a · b >||a|| · ||b||
 and the more similar the data the closer the angle between
 their corresponding vectors is and the closer to 1 their cosine.
 The cosine similarity is our similarity detection function F .
 C. Correctness and Privacy
 Definition 1 (Privacy Preserving Data Analysis(PPDA)) In
 a Privacy preserving data analysis scheme a set of n users
 Ui are perturbating their data and afterwards the data are
 sent to the data analyzer A for analysis. PPDA consists of 2
 polynomial time algorithms P P DA = Encrypt,Analyze:
 Encrypt(Di) ? ¯Di: It takes as input user data and it
 outputs the encryption of it.
 Analyze( ¯Di, ¯Dj) ? F( ¯Di, ¯Dj): It takes as input two
 encrypted data vectors and it outputs the result of a data
 analysis algorithm F( ¯Di, ¯Dj).
 Definition 2 (Correctness) A PPDA scheme is correct if
 for all pairwise combinations of data Di, Dj the analyzer
 executes Analyze(Encrypt(Di)) and it obtains F( ¯Di, ¯Dj) =
 F(Di,Dj),
 Definition 3 (Confidentiality) Let ? = (Encrypt, Analyze) be
 a PPDA scheme. ? is defined as confidential if any adversary
 cannot recover Di from ¯Di
 Intuitively, the security guarantee we require from a PPDA
 scheme is that given encrypted vectors ¯Di an adversary cannot
 learn any information about the plaintext Di although it may
 learn the outpu of the function F .
 548
IV. SOLUTION
 A. Idea of Solution
 The idea of the solution is to apply some transformations
 to original vectors which on the one hand preserve the angle
 between any pair of them and on the other hand assure
 privacy. Since rotation in a two dimensional space preserves
 angles, we apply this transformation to two-dimension vectors
 named as sub-vectors which originate from the data vector.
 Additionally, these sub-vectors are further randomly scaled and
 thus obfuscated while still not having an impact on the angle.
 The reason why rotation and scaling are combined is that
 random scaling alone raises some security problems. Indeed, if
 only random scaling is applied then an adversary can discover
 whether the coordinates of that vector are similar or not.
 Hence thanks to the rotation, the adversary cannot discover
 similarities between one vector’s coordinates. The mapping
 of vectors into subvectors also decreases the probability of
 discovering the original vector since the scaling factor differs
 from subvector to subvector.
 B. Preliminaries
 Vector scaling
 Vector scaling with a scaling factor s is defined by a
 multiplication operation between the vector v and the identity
 matrix S in which the main diagonal has been substituted with
 the scale factor s.
 v · S = v·
 [
 s 0
 0 s
 ]
 Vector Rotation Vector rotation with an angle ? is defined by
 a matrix multiplication between the vector v and the rotation
 matrix R?: v ·R = v·
 [
 cos(?) ? sin(?)
 sin(?) cos(?)
 ]
 C. Protocol description
 We now describe the details of the protocol with respect
 to Definition 1.
 Encryption During the encryption phase each user Ui holds
 a vector Di = (d1, d2, d3, . . . , dm) of size m. It generates
 subvectors of 2 dimensions d(k,l)i =
 (
 dk
 dl
 )
 . If m is odd then
 (m + 1)/2 are constructed, otherwise if m is even then we
 have m/2 subvectors. In general we have m/2 subvectors.
 Afterwards each user choses a random scaling factor for
 each subvector and it scales each subvector d(k,l)i with the
 random scaling factor si: Sji = s
 j
 i · d
 (k,l)
 i , if k and l are new
 coefficients of the subvector. That is, if any of the coefficients
 of the subvector d(k,l)i has been previously selected to form
 a vector then the old random scale factor si must be used
 for d(k,l)i . Then the intermediate vector Si is further rotated
 with a rotation matrix R? , where ? is the rotation angle:
 ¯dk,li = S
 j
 i · R? = S
 j
 i ·
 [
 cos(?) ? sin(?)
 sin(?) cos(?)
 ]
 .
 In the end each user Ui sends ¯Di =
 ( ¯d(1,2)i , ¯d(2,3)i , · · · , ¯d(k,l)i ), ?k, l ? [0 · · ·m]s.t : ?{k, l}? = m
 to the data analyzer A. In hereafter we will write dji to denote
 the jth subvector of user Ui and ¯dji for the jth encrypted
 subvector of user Ui. As such the obfuscated mechanism
 ? consists of random scalings and rotations by an angle ?:
 ?(di) = sji · dk,li · R?.
 Analyze The analyzer then performs the similarity detection
 function F over the encrypted data: ?Ui,Uj , i 	= j :
 F( ¯di, ¯dj) =
 ?
 ??
 ??
 cos( ¯d1,2i , ¯d1,2j )
 .
 .
 .
 cos( ¯dm/2i , ¯dm/2j )
 D. Correctness
 Theorem 2 The PPDA scheme presented above is correct.
 Proof: It is known that cos(a, b) = <a·b>?a?·?b? = a
 T
 ·b
 ?a?·?b? . For
 the proof of the theorem we need to prove the following three
 lemmas:
 Lemma 1 The transpose of an orthogonal matrix A, AT
 is equal to its inverse A?1
 Proof: It is known that:
 A ·A?1 = IA (1)
 where IA it’s the identity matrix of A. Also we obtain:
 A ·AT =[
 AT1,1 ·A1,1 · · · AT1,m ·A1,m
 ATn,1 ·An,1 · · · ATn,m ·An,m
 ]
 =?
 ??1 · · · 0..
 .
 .
 .
 .
 .
 .
 .
 0 · · · 1
 ?
 ?? = IA (2)
 From (1), (2) we have that for any orthogonal matrix A, AT =
 A?1
 Lemma 2 The multiplication two vectors a, b with a
 rotation matrix R preserves its cosine similarity.
 Proof: cos(Ra, Rb) = <Ra·Rb>?Ra?·?Rb? = (Ra)
 T
 ·Rb
 ?Ra?·?Rb? =
 aTRT ·Rb
 ?a?·?b? =
 aTR?1·Rb
 ?Ra?·?Rb? =
 aT ·b
 ?a?·?b? = cos(a, b) where
 ?Ra?=
 [
 cos(?) ? sin(?)
 sin(?) cos(?)
 ] [
 a1
 a2
 ]
 = ?a? and ?Rb?=[
 cos(?) ? sin(?)
 sin(?) cos(?)
 ] [
 b1
 b2
 ]
 = ?b?
 Lemma 3 The random scaling of two vectors a, b with
 different random scaling factors r1 and r2 preserves its cosine
 similarity
 Proof: cos(r1a, r2b) = <r1a·r2b>?r1a?·?r2b? = (r1a)
 T
 ·r2b
 r1?a?·r2?b? =
 r1a
 T
 ·r2b
 r1?a?·r2?b? =
 aT ·b
 ?a?·?b? = cos(a, b)
 From lemma 1,2 and 3 we have that multiplication of a
 random vector and random scaling is a correct encryption
 mechanism. The proof of lemma 2 is based on lemma 1:
 the rotation matrix R is orthogonal and as such R?1 = RT .
 Furthermore the rotation doesn’t change the vector norms.
 549
V. SECURITY
 Theorem 1 The PPDA scheme presented above is secure
 according to definition 3.
 Proof: The security of the scheme is based on the ran-
 domness of the scale factor Si and on the rotation matrix R?.
 The data analyzer cannot recover the original vector Di of a
 user U unless it performs brute force guesses for the scaling
 factor and the Rotation matrix.
 We observe security leakages when the obfuscated mech-
 anism does not entail both random scalings and rotations.
 If each user only selects random scaling as the encryption
 mechanism then an attacker by obtaining a good guess for a
 coefficient of a user’s vector it can recover the specific two
 dimensional vector by computing the inverse of the guessed
 element and multiplying it by the encrypted coefficient.
 On the other hand, thanks to rotations the aforementioned
 problem is mitigated but the following one is appearing if used
 alone: if two users with secret vectors Di, Dj respectively
 have the same value at the same position of their vectors then
 only by encrypting with a rotation matrix R? of angle ? , the
 corresponding encrypted vectors would have the same value
 at this position. This violates the security definition 3. So in
 order for the cosine similarity to be securely preserved after the
 encryption of the vectors, both random scaling and rotations
 must by applied.
 To be more precise with our security analysis, we consider
 two categories of adversaries: we define external adversaries
 as data analyzers and internal adversaries as users themselves.
 External adversaries Data analyzers do not know the rotation
 matrix and as such the aforementioned attacks cannot happen
 as long as the angle ? of the rotation matrix is kept secret. The
 data analyzers cannot identify common values in a specific
 data vector because the rotation with an unknown angle adds
 an additional security level for the vectors.
 Internal adversaries We consider as internal adversaries the
 users that know the rotation matrix R?. In such a scenario
 the user that has a good guess for the coefficient of another
 user can reveal only the coefficients that are involved in a
 common random scaling factor per vector. That is if Ui has
 5 coefficients and it defines cosine similarity in between the
 ((1,2),(3,4),(1,5)) coefficients then an adversary with a good
 guess for the first coefficient can recover only the second
 and fifth coefficient and nothing more, since for the second
 subvector the user would choose different a random scaling
 factor.
 VI. EVALUATION
 We demonstrate the correctness of our protocol through
 an experimental evaluation setup. We obtain data originating
 from a personality experiment. We first cluster the data based
 on cosine similarity using a well known clustering algorithm.
 The same clustering algorithm is further applied over the
 encryption of the same data using ? which as already described
 combines rotation and random scaling. We proceed into an
 analysis of the data and next on the clustering algorithms that
 we use.
 A. Data Set
 The dataset contains an extract of the results from the
 Foursquare Personality Experiment1 which uses the mobile so-
 cial network Foursquare2 combined with a standard personality
 test to allow the link between personality (as defined by the
 five-factor model [17]) and the places that people visit to be
 examined. To the best of our knowledge, this is the first time
 that it has been possible to correlate personality with place on
 such a granular level.
 When accessing the experiment, users sign in using their
 Foursquare account, allowing us to access the list of venues
 which they have ’checked in’ to on the Foursquare service.
 We access only this list, storing the venues that the user
 has been to and the number of times they have visited each
 venue, but without accessing or storing the information about
 the individual checkins - we do not store when each visit
 to the venue occurred, nor the order in which venues were
 visited. Once users have accessed the system they then take a
 44-item personality test [18], [19], revealing their five-factor
 personality scores. The five-factor model gives each person a
 score between 1 and 5 for each of the five personality traits:
 Openness, Conscientiousness, Extraversion, Agreeableness and
 Neuroticism.
 The users participating in the study are a self-selecting
 group comprised of 173 people who both use Foursquare
 online location based tagging system and are willing to take
 part in a personality-based experiment.
 B. Clustering
 Clustering algorithms seek to group similar objects to-
 gether. Similarity is measured with a distance metric which in
 our case is cosine similarity. Hierarchical clustering is a widely
 known approach for clustering. It constructs a binary tree of
 clustering objects that successively are merged under the same
 cluster with respect to the linkage metric. The linkage metric
 links clusters and objects together. It acts as an intergroup
 similarity measure. Two most popular linkage metrics are
 the complete metric which defines the maximum similarity
 between two objects as a verification to whether or not one
 object would be merged under the same cluster with another
 one and the single metric in which the minimum similarity is
 treated as the intergroup similarity metric. At the first step
 of the algorithm each object belongs to each own cluster.
 Then all the possible pairwise similarities between objects with
 respect to the defined distance metric are defined. Afterwards
 the algorithm iteratively merge clusters with respect to the
 linkage metric until there would be one cluster with the all
 the examined objects.
 C. Simulation Setup and Results
 We apply the hierarchical algorithm over the personality
 dataset with the complete linkage metric and based on cosine
 similarity.
 The data consists of 173 different 5 dimensional vectors
 describing users’ personality with respect to the 5 personality
 traits as previously described. We did not include venue
 1http://www.cs.cf.ac.uk/recognition/foursqexp
 2http://www.foursquare.com
 550
3
 0
 14
 4
 12
 0
 10
 2
 8
 2
 8
 9
 5
 1
 6
 3
 16
 0
 13
 8
 7
 9
 12
 7
 17
 2
 9
 2
 11
 9
 12
 9
 6
 9
 14
 6
 3
 4
 5
 9
 5
 5
 8
 4
 1
 1
 1
 6
 7
 15
 9
 15
 2
 15
 4
 11
 2
 4
 3
 5
 3 2
 14
 2
 15
 7
 2
 1
 4
 6
 15
 5
 8
 7
 11
 8
 2
 2
 5
 8
 8
 0
 13
 9
 9
 4
 6
 8 8
 4
 7
 12
 5
 10
 6
 9
 1
 2
 9
 3
 2
 1
 8
 6
 5
 7
 6
 5
 6
 11
 7
 5
 4
 12
 4 6
 11
 1
 2
 7
 7
 8
 11
 3 5
 16
 2
 2
 3
 3
 5
 3
 8
 12
 1
 4
 9
 10
 4
 10
 1
 17
 1
 3
 3
 7
 4
 4
 8
 16
 5
 9
 3
 15
 0
 2
 8
 12
 8
 9
 0
 6
 4
 10
 3
 12
 2
 13
 3
 15
 3 7
 10
 7
 7
 7
 9
 8
 9
 5
 6
 2
 11
 6
 9
 6 9
 6
 0
 8
 5
 1
 9
 14
 0
 1
 0
 14
 5
 2
 4
 10
 0
 12
 3
 17
 0
 16
 8
 13
 0
 1
 6
 16
 1
 15
 1
 7
 1
 7
 2
 4
 2
 10
 9
 13
 2
 16
 9
 3
 6
 8
 1
 15
 6
 2
 6
 16
 6
 15
 8
 5
 7
 13
 6
 14
 3
 0
 6
 1
 14
 8
 8
 3
 9
 7
 7
 5
 16
 3
 1
 3
 8
 6
 1
 7
 6
 6
 14
 7
 4
 4
 10
 8
 11
 5
 12
 6
 11
 4
 14
 1
 3
 9
 5
 2
 9
 9
 1
 2
 13
 4
 4
 3
 1
 8
 8
 4
 0
 2
 0 3
 11
 0
 3
 7
 13
 7
 1
 4
 14
 9
 7
 3
 4
 1
 10
 5
 16
 4
 2
 5
 5
 0
 13
 5
 16
 7
 1
 5
 13
 1
 4
 5
 7
 0
 0.0
 0.2
 0.4
 0.6
 0.8
 1.0
 Plaintext data
 3
 0
 14
 4
 12
 0
 10
 2
 8
 2
 8
 9
 5
 1
 6
 3
 16
 0
 13
 8
 7
 9
 12
 7
 17
 2
 9
 2
 11
 9
 12
 9
 6
 9
 14
 6
 3
 4
 5
 9
 5
 5
 8
 4
 1
 1
 1
 6
 7
 15
 9
 15
 2
 15
 4
 11
 2
 4
 3
 5
 3 2
 14
 2
 15
 7
 2
 1
 4
 6
 15
 5
 8
 7
 11
 8
 2
 2
 5
 8
 8
 0
 13
 9
 9
 4
 6
 8 8
 4
 7
 12
 5
 10
 6
 9
 1
 2
 9
 3
 2
 1
 8
 6
 5
 7
 6
 5
 6
 11
 7
 5
 4
 12
 4 6
 11
 1
 2
 7
 7
 8
 11
 3 5
 16
 2
 2
 3
 3
 5
 3
 8
 12
 1
 4
 9
 10
 4
 10
 1
 17
 1
 3
 3
 7
 4
 4
 8
 16
 5
 9
 3
 15
 0
 2
 8
 12
 8
 9
 0
 6
 4
 10
 3
 12
 2
 13
 3
 15
 3 7
 10
 7
 7
 7
 9
 8
 9
 5
 6
 2
 11
 6
 9
 6 9
 6
 0
 8
 5
 1
 9
 14
 0
 1
 0
 14
 5
 2
 4
 10
 0
 12
 3
 17
 0
 16
 8
 13
 0
 1
 6
 16
 1
 15
 1
 7
 1
 7
 2
 4
 2
 10
 9
 13
 2
 16
 9
 3
 6
 8
 1
 15
 6
 2
 6
 16
 6
 15
 8
 5
 7
 13
 6
 14
 3
 0
 6
 1
 14
 8
 8
 3
 9
 7
 7
 5
 16
 3
 1
 3
 8
 6
 1
 7
 6
 6
 14
 7
 4
 4
 10
 8
 11
 5
 12
 6
 11
 4
 14
 1
 3
 9
 5
 2
 9
 9
 1
 2
 13
 4
 4
 3
 1
 8
 8
 4
 0
 2
 0 3
 11
 0
 3
 7
 13
 7
 1
 4
 14
 9
 7
 3
 4
 1
 10
 5
 16
 4
 2
 5
 5
 0
 13
 5
 16
 7
 1
 5
 13
 1
 4
 5
 7
 0
 0.0
 0.2
 0.4
 0.6
 0.8
 1.0
 Encrypted data
 Fig. 1. Hierarchical Clustering
 visits frequency since we believe that personality traits are
 considered much more sensitive data compared to location
 information and that users would be more interested in hid-
 ing such information. We consider similarity on 3 subvec-
 tors per user data: the subvectors are constructed with the
 (1st, 2nd), (3rd, 4th) and (1st, 5th) coordinates of the original
 vector respectively. Any pairwise subvector could be have
 chosen such that the union of the set of subvectors entail all
 the coefficients. The main similarity metric is computed as the
 average of the similarities between subvectors.
 In order to protect their privacy, every user chooses a
 random scaling factor per two dimensions. After the random
 scaling process users apply the rotation operation to their
 partially obfuscated subvectors.
 In figure 1 we plot the two dendograms of hierarchical
 clustering before and after the operation ? applied on data. The
 horizontal axis corresponds to cluster indexes that are formed
 by the algorithm and the vertical axis to the linkage similarity
 based on cosines. Clusters are connected with upside-down
 U-shaped lines. The clusters are exactly the same due to the
 correctness of the algorithm as has been previously proved.
 All the cosines between all the binomial coefficients of 2
 over 173 elements has been computed. That results into a
 set of 14878 distances. For the linkage function we chose the
 complete option. Thus, two clusters will be merged together
 according to the maximum distance between their elements.
 Results shown in figure 1 demonstrate the correctness of our
 protocol: Geometrical transformation on data based on random
 scaling and rotation is compatible with cosine similarity for
 clustering and in addition preserves individuals’ privacy.
 D. Discussion
 In our experiments we use as a single point of similarity an
 aggregate output of each three per user similarities. This is the
 average of cosine similarities. As such during the clustering
 the similarity between points depicts similarities between the
 averages. We could have demonstrated three different scenarios
 during the clustering process one for each subvector in order
 to check the correctness of our obfuscation mechanism but
 since this has been demonstrated once the other experiments
 wouldn’t add extra knowledge to us. We also want to state
 that the aggregate function should not always be used for
 every case. This would imply an inconsistency on correctness
 since many inputs could evaluate the same average similarity.
 Suppose for instance that data consist of user interests on m
 items and for each user n similarities per two dimensions
 are computed. Then a single aggregate function on user n
 similarities might group together during clustering dissimilar
 objects that average the same similarities but on different
 inputs.
 551
VII. CONCLUSION
 The interplay between data analysis and privacy is emerg-
 ing rapidly. Researchers from machine learning area have
 highlighted the merit of data analysis operations. However this
 exposure of personal sensitive data, facilitates privacy viola-
 tions. Adversaries by gaining access to personal information
 can learn the real identity of users and overcome data legal
 regulations and restrictions. That postulates a mechanism that
 would shield individual data confidentiality. This would not
 be of significant value since data encryption to protect data
 confidentiality is more mature and well analyzed than 30 years
 before. The tricky approach is to allow operations on data
 by the security mechanism while at the same time personal
 sensitive information is not exposure to third parties.
 In this paper we have presented a mechanism for privacy
 preserving clustering that is based on geometrical transfor-
 mation of objects. Data are encrypted appropriately such
 that operations with respect to cosine similarity detection are
 compatible. We proceed into an analysis of the security risks
 of each operation and we conclude that the most secure way is
 a combination of random scalings and rotations. The rotation
 angle even if its known to the users it can only be used to reveal
 some coordinates of the vector only if the user has a good guess
 for one of the coordinates. Still this weakness is not of crucial
 importance for external adversaries (data analyzer) since they
 don’t know the rotation matrix. Without scaling and only
 with rotation, similarities on the same position coordinates are
 possible to occur by both internal and external adversaries.
 This is mitigated by a random scaling factor, which is different
 per user and per subvectors with no common coefficients. We
 proceed into an experimental evaluation of a scheme in order
 to demonstrate its correctness. Personality traits have been
 obtained by 173 users and identical clustering results have been
 observed before and after the obfuscation proposed solution.
 Acknowledgement This research has been funded by
 RECOGNITION grant 257756, an EC - FP7 Future Emerging
 Technologies project concerning Self-Awareness in Autonomic
 Systems.
 REFERENCES
 [1] A. Narayanan and V. Shmatikov, “Robust de-anonymization of large
 sparse datasets,” in Proceedings of the 2008 IEEE Symposium on
 Security and Privacy, ser. SP ’08. Washington, DC, USA: IEEE
 Computer Society, 2008, pp. 111–125.
 [2] I. Rouf, H. Mustafa, M. Xu, W. Xu, R. Miller, and M. Gruteser,
 “Neighborhood watch: security and privacy analysis of automatic
 meter reading systems,” in Proceedings of the 2012 ACM conference
 on Computer and communications security, ser. CCS ’12. New
 York, NY, USA: ACM, 2012, pp. 462–473. [Online]. Available:
 http://doi.acm.org/10.1145/2382196.2382246
 [3] M. Lisovich, D. Mulligan, and S. Wicker, “Inferring personal informa-
 tion from demand-response systems,” Security Privacy, IEEE, vol. 8,
 no. 1, pp. 11–20, Jan.-Feb.
 [4] S. McLaughlin, P. McDaniel, and W. Aiello, “Protecting consumer
 privacy from electric load monitoring,” in Proceedings of the 18th
 ACM conference on Computer and communications security, ser.
 CCS ’11. New York, NY, USA: ACM, 2011, pp. 87–98. [Online].
 Available: http://doi.acm.org/10.1145/2046707.2046720
 [5] R. Agrawal and R. Srikant, “Privacy-preserving data mining,” 2000.
 [6] D. Agrawal and C. C. Aggarwal, “On the design and quantification
 of privacy preserving data mining algorithms,” in Proceedings of the
 twentieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of
 database systems, ser. PODS ’01. New York, NY, USA: ACM, 2001,
 pp. 247–255.
 [7] S. R. M. Oliveira and O. R. Zaı¨ane, “Privacy preserving clustering by
 data transformation,” JIDM, vol. 1, no. 1, pp. 37–52, 2010.
 [8] L. Sweeney, “k-anonymity: a model for protecting privacy,” Int. J.
 Uncertain. Fuzziness Knowl.-Based Syst., vol. 10, no. 5, pp. 557–570,
 Oct. 2002.
 [9] V. S. Iyengar, “Transforming data to satisfy privacy constraints,” in
 Proceedings of the eighth ACM SIGKDD international conference on
 Knowledge discovery and data mining, ser. KDD ’02. New York, NY,
 USA: ACM, 2002, pp. 279–288.
 [10] P. Samarati and L. Sweeney, “Protecting privacy when disclosing
 information: k-anonymity and its enforcement through generalization
 and suppression,” Tech. Rep., 1998.
 [11] Y. Lindell and B. Pinkas, “Privacy preserving data mining,” in CRYPTO,
 2000, pp. 36–54.
 [12] M. Kantarcioglu and C. Clifton, “Privacy-preserving distributed mining
 of association rules on horizontally partitioned data,” IEEE Trans. on
 Knowl. and Data Eng., vol. 16, no. 9, pp. 1026–1037, Sep. 2004.
 [Online]. Available: http://dx.doi.org/10.1109/TKDE.2004.45
 [13] C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M. Y. Zhu,
 “Tools for privacy preserving distributed data mining,” ACM SIGKDD
 Explorations, vol. 4, p. 2003, 2003.
 [14] S. R. M. Oliveira and et al., “Privacy-preserving clustering by object
 similarity-based representation and dimensionality reduction transfor-
 mation,” in IN PROC. OF THE WORKSHOP ON PRIVACY AND
 SECURITY ASPECTS OF DATA MINING (PSADM04) IN CONJUNC-
 TION WITH THE FOURTH IEEE INTERNATIONAL CONFERENCE
 ON DATA MINING (ICDM04, 2004, pp. 21–30.
 [15] B. Goethals, S. Laur, H. Lipmaa, and T. Mielika¨inen, “On private
 scalar product computation for privacy-preserving data mining,” in
 Proceedings of the 7th international conference on Information Security
 and Cryptology, ser. ICISC’04. Berlin, Heidelberg: Springer-Verlag,
 2005, pp. 104–120.
 [16] C. D. Manning, P. Raghavan, and H. Schu¨tze, Introduction to Infor-
 mation Retrieval. New York, NY, USA: Cambridge University Press,
 2008.
 [17] L. R. Goldberg, “An Alternative ”Description of Personality”: the Big-
 Five Factor Structure.” Journal of Personality and Social Psychology,
 vol. 59, no. 6, pp. 1216–29, Dec. 1990.
 [18] O. P. John, L. P. Naumann, and C. J. Soto, “Paradigm shift to the
 integrative big five trait taxonomy,” Handbook of personality: Theory
 and research, vol. 3, pp. 114–158, 2008.
 [19] O. P. John, E. M. Donahue, and R. L. Kentle, “The big five inven-
 toryversions 4a and 54,” Berkeley: University of California, Berkeley,
 Institute of Personality and Social Research, 1991.
 552
