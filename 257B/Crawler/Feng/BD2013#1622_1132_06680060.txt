Performance Tuning in Distributed Processing of ETL  
Ping Yang, Zaiying Liu, Jun Ni 
School of Information Science and Technology 
Shanghai Sanda University, Shanghai, China, 201209 
brightyang@126.com; fall_water007@sina.com; jun-ni@uiowa.edu 
Abstract— Extract, transform, and load (ETL) is a very 
common and important technology for building data 
warehouse includes business intelligence. When people issue a 
very complex SQL query to acquit data from a transaction 
system into a data warehouse, it involves many procedures 
including table-joining, sort, and aggregation. Such 
procedures require significant retrieving step and huge data 
transferring from tables. The intensive querying very often 
causes performance issues to be concerned. Moreover, it 
commonly generates negative impacts on data instance 
resources. How to improve the performance for ETL becomes 
critical and challenging. This paper presents a parallel 
processing solution that splitting big and complex SQL query
 into small pieces in distributed computing manor. The 
proposed method aims at reducing cost of computation, while 
ensuring data integrity among joined tables. The innovative 
idea can be verified through selected test-beds of performance 
tuning. 
Keywords- ETL; Data extraction; Capture data changes;
 load; Performance tuning 
I. INTRODUCTION
 In processing of extract, transform, and load (ETL), 
there exist three database functions that are integrated 
together to operate data transfer from one table to another 
to form data marts or warehouses. It also functions to 
convert databases from one format to another. Therefore, 
ETL is a very common technology utilized in business 
intelligence.
 There is an example of unexpected ETL performance 
during an implementation of business analysis. The 
transactional data are extracted, transformed, and loaded
 from SIEBEL CRM system to a business intelligence data 
warehouse. As ETL’s components, ProC for extraction,
 Syncsort for capture data changes (CDC), and Informatica 
for loading delta changes (LDC) are all functioning well in 
the first phase. However, after the data volume rapidly 
increased in the system, the performance of complex 
extraction became worse. When sophisticated queries are 
executed and the system retrieved huge data on the system,
 takes about 90% of total ETL computing time. How to 
deal with such performance problem become critical to the 
business data extraction, transactions and distribution in 
real time. In the following section, we would like to 
demonstrate how to analyze such problem. 
II. PROBLEM ANALYSIS
 First, we make sure that all data are read from the 
Siebel CRM system using ProC. The data in previous and 
current steps are compared to check whether there exists 
any data change. Such process can be accomplished by
 using Syncsort. Then captured data changes are loaded 
into the data warehouse. Extensive analysis can be 
conducted to determine bottlenecks occurring in the whole 
process.  The major issues can be addressed as follows. 
All transforms/aggregations can be executed in 
complex extract queries. For example, a most complex 
query can sometimes consists of more than 10 scalar sub 
queries and complex aggregations, loops, or sorts.  
If using the SIEBEL-CRM software system, the 
performance may lack of tuning. As all know, most of 
setups in a transactional system is OLTP-dedicated, which 
only returns first row. It is uncontrollable to all the return 
rows (which are DW characteristics). In addition, the 
system also suffers negative performance due to the 
influence cause by huge complex extraction of retrieving 
data. 
Rapidly-developed commerce markets and business 
generate huge amounts of data volume significantly. The 
corresponding queries become complex and not linearly 
scalable. The more volume increase, more surfer we may 
have. When dealing with big data, the intensive computing 
becomes necessary. Such computation causes low 
performance of operation using existing software. The 
performance issues are getting to be more concerned and 
complained by end-users, especially for Windows-based 
users on their daily PCs. 
Not like a simple query on a huge amount of data 
resource, which can be accomplished within a tolerated 
time scale, a complex query on a big data can significantly 
reduce computing performance. 
Fig. 1 shows the previous solution chart in which 
CM refers to a complex query involved both base table M 
and referred tables A1, A2, A3, B1, B2, etc. d(CM) stands 
for the change (or delta) between the current and previous 
CM. Everyday only delta records can executed on target 
table, while remaining the current CM on source table. M
 is the base table of source. It has the same primary key as 
in the target table. M*, A*, and B* represent the expected 
columns from M, A, and B in a target table T, respectively. 
The d(M*), d(A*), and d(B*) are the delta data 
2013 Seventh International Conference on Internet Computing for Engineering and Science
 978-0-7695-5118-0/13 $26.00 © 2013 IEEE
 DOI 10.1109/ICICSE.2013.24
 85
corresponding to M*, A*, and B* . They are obtained after 
the CDC’s previous and current data steps in daily process. 
One flexible solution is to reduce the complexity of 
extract queries, ensure the data integrity, and reduce the 
any influences on performance on source instance. 
Figure 1. The previous solution chart 
(CM query)
 Select M.rowid,
 .
 (select aggregation
 From A1,A2,A3..
 Where A.rowid=M.rowid),
 .
 (select aggregation
 From B1,B2.
 Where b.rowid=M.rowid),
 .
 .(select aggregation
 From C..
 Where C.rowid=M.rowid),
 .
 From M
 Where ...
 (CM* query)
 Select M.rowid.
 A.aggregation_Values,.
 B.aggregation_Values,.
 C.aggregation_vaules,.
 From M,
 (select aggregation
 From A1,A2,A3..
 group A.rowid) A, .
 (select aggregation
 From B1,B2.
 Group by B.rowid) B,.
 .(select aggregation
 From C..
 Group C.rowid) C
 Where M.rowid=A.rowid(+)
 And M.rowid=B.rowid(+)
 And M.rowid=C.rowid(+);
 (SM query)
 Select M.rowid,...
 From M
 Where ….
 (B query)
 (select aggregation
 From B1,B2.
 group by B.rowid) B,
 (A query)
 (select aggregation
 From A1,A2,A3..
 group A.rowid) A
 1
 2
 (C query)
 (select aggregation
 From C
 Group by B.rowid) C
 2
 2
 2
 Target Table
 3
 4
 4
 4
 Figure 2. The implementation steps 
Sie
 be
 lC
 RM
 DB
 M
 A1
 A3A2
 B1
 B2
 Informatic
 a
 Dat
 aWarehous
 eM*A* B*
 Target table
 Previous M*
 Current M*
 Previous A*
 Current A*
 Previous B*
 Current B*
 Result of simpler SM query
 Subset of refer A query
 Subset of refer B query
 Delta
 d(M*)
 Delta
 d(A*)
 Delta
 d(B*)
 Implement d(M*)
 Update d(A*)
 Update d(B*)
 Pro C
 Execute sql on
 siebel DB to extract
 data to flat file.
 Syncsort CDC
 Process
 Utilize Syncsort to Get
 delta data(insert, update,
 delete) by compare
 previous extracted file
 and current extract file
 Proposed Solution
 Figure 3. The proposed solution chart. 
Siebe
 lCR
 M
 DB
 Syncsort CDC
 Process
 Utilize Syncsort to
 calculate delta data
 (current versus
 previous extract file)
 Pro C
 Execute sql on
 siebel DB to
 extract data to
 flat file.
 Result of complex
 query CM
 M
 A1
 A3A2
 B1
 B2 d(CM)
 M*A* B*
 Current data
 Informatic
 a
 Da
 ta
 W
 ar
 eh
 ou
 se
 M*A* B*
 Target table
 M*A* B*
 Previous data
 d(M*)d(A*) d(B*)
 Delta data
 Previous Solution
 86
III. SOLUTION
 How to reduce the complexity of extract query, while 
still ensuring data integrity is an important issue. We first 
analyze what the kind of data are expected to be delivered
 from source in SIEBEL CRM system to data warehouse 
during a regular daily process. In such case, we have 
d(T)=d(CM)= Current CM(M*,A*,B*) CDC Previous 
CM(M*,A*,B*). T is the target table, which has the 
current result from a complex query CM. It includes 
expected columns of M*, A*, and B*. The d(T) is 
identical to d(CM). The d(T) is executed to obtain the 
target table T to keep the current updated. 
When consider ROWID as the primary key in both M 
and T, the d(T) includes the delta ROWIDS calculated in 
d(CM). In other words, the d(T) includes those ROWIDS 
which have been changed in the base table M or those 
ROWIDS possibly to be changed in M due to the 
influences of scalar sub queries A and B. Therefore, the 
d(T) could be split into small pieces based on ROWID, i.e, 
  
d(T) =d(SM){ Current SM CDC Previous SM) +       
            M*[impacted by d(A*) ] +
             M*[impacted by d(B*) ] } 
SM is the result based on a simple query. It only 
fetches records from base table M (or the base table with 
simple joins) 
The d(SM) stands for the delta data of the current SM
 and previous SM. It includes those that the ROWID are 
changed. 
The M*(d(A*)),M*(d(B*)) includes those ROWIDS 
from base table M*. Whether or not being changed, they 
are always influenced by the delta data d(A*), d(B*),.. 
The d(SM) includes those changed columns from base 
table M. After d(SM) is executed, the target table T has the 
same ROWIDS as M has. Let T have the keys A* and B*
 referenced to M*. It is possible to be ROWID’s or other 
reference key. Then those delta data come from d(A*).
 The d(B*) can be calculated from T. It turns out that the
 calculation of d(A*) and d(B*) are on the source side. The 
T(d(A*)) and T(d(B*)) can be update by EQUAL-JOIN on 
Data Warehouse side. Fig. 2 shows the execution steps: 
Step 1: Restructure a complex query. Put in-line scalar 
sub queries down to select the location to store using 
OUT-JOIN. 
Step 2: Split the complex query into main query (with 
base table) and referred queries 
Step 3: After separating EXTRACT/CDC/LOAD jobs,
 for preparation of distributed main and referred queries, 
load the delta d(SM) into target table. The d(M*) must be 
executed firstly to ensure data integrity.
 Step 4: After the d(M*) is executed, load delta 
M*(d(A*)), M*(d(B*)),  and M*(d(C*)).
 Fig. 3 shows the proposed solution flow chart. A is a
 scalar sub query with tables A1, A2 and A3 which are joined 
each other. B is a scalar sub query with jointed tables B1 
and B2. 
TABLE1 SHOWS THE DIFFERENT COST
 Process Extract CDC Load
 Solution Sum(SM, A, B,C) CM Sum(d(M*), d(A*),d(B*), d(C*)) d(CM)
 Sum(d(M*), d(A*), d(B*),
 d(C*)) d(CM)
 Rows processed 24570 14750 24570 14750 3710 2100
 Consistent gets 194842 355942343 X X X X
 Physical reads 44328 44328 X X X X
 Elapsed time 0:03:36 3:17:06 0:00:17 00:00:07 0:00:17 00:00:09
 After a complex query being spitted into some simpler 
and smaller ones, the previous complex FULL-FULL 
tables OUT-JOIN can be converted to several separated 
simpler queries on source side. In this way, the querying 
can be executed in parallel. The OUT-JOIN (full M
 out-joins to full referred queries) becomes EQUAL-JOIN 
(target table T equal-joins delta data from referred several 
queries). The complexity can be balanced on two sides, 
while the computational performance can be reduced 
significantly. 
IV. TEST-BED OF PROPOSED SOLUTION
 After implement the proposed solution in ETL, three 
processes of extract, CDC, and loading have been changed. 
Taking the most complex query as our test, we split a
 complex query CM into a simple query SM and several 
referred sub queries A, B, and C. Compare the results of 
computational cost using previous and proposed solutions, 
we find the differences which are listed in Table1. 
The total elapsed time for extraction is decreased from 
about 3 hours to 3 minutes using proposed method. 
Moreover, the distributed queries can be executed in 
parallel. Though multiple CDC’s loading jobs can be 
87
present, the total time elapsed is not significantly large, 
compared with of single original CDC and loading jobs.  
V. CONCLUSION
 Many methods have been tried on the complex extract 
query (like adding hints) in ETL process with varying 
instance parameters in data transaction. The cost 
performance is a concern.  
In this work, we propose and experiment a parallel 
method in which a complex query is spited into several 
simple and small ones for execution in parallel. The results 
of increasing performance are very promising. The total 
cost can distributed and decreased, with less influences on 
source database. 
In future, we would like to consider reduce such cost 
through reference sub queries, if queries are very complex 
and cannot hosted on source instance. The relationship 
between main query and reference sub queries with data 
integrity is the most important issue to be considered and 
modeled, if we split complex queries. 
ACKNOWLEDGMENT
 This work is sponsored by Shanghai Education 
Commission Scientific Research Innovation Project 
(11YZ282). The author is grateful to all colleagues in the 
Department of Computer Science and Technology 
Shanghai Sanda University for their support, help, and 
encouragement.
 REFERENCES
 [1] Vishal Gour, S.S. Sarangdevot, Govind Singh Tanwar, 
Anand Sharma, “Improve Performance of Extract, Transform 
and Load (ETL) in Data Warehouse,” International Journal on 
Computer Science and Engineering ,Vol. 02, No. 03, 
pp.786-789, 2010 
[2] Ning Zhang, Jia Ziyan,Shi Zhongzhi, “Research on 
Technology of ETL in Data Warehouse,” Computer Engineering 
and Applications, pp. 213–216, 2002.24 
[3] Sa Liao, “Design and optimization of Data Bank Increment 
ETL,” Journal of Guiyang College, Natural Sciences (Quarterly)
 Vol.3, No.3, pp.5-9, Aug, 2008 
[4] Jiang Licheng, “The ETL Technology for Changed Data,”
 Computer Scinence,Vol.34, No.10 B, pp.219-221, 2007  
[5] Shu Qi, “The Research on Optimization of ETL Process and 
Incremental Data Extraction,” Thesis, Hunan University, 2011 
[6] Ralph Kimball , Joe Caserta, The Data Warehouse ETL 
Toolkit, Wiley, 2004 
[7] Microsoft Technical Champs for Siebel,
 www.siebelonmicrosoft.com
 [8] Alkis Simitsis, Kevin Wilkinson, Umeshwar Dayal, Malu 
Castellanos, “Optimizing ETL Workflows for 
Fault-Tolerance, ” ICDE, 2010 
[9] Fengjuan Yang, “Analysis and Design of ETL in Hospital 
Performance Appraisal System,” Computer and Information 
Science,Vol.2, No.4, pp.116-121, November, 2009 
[10] Kommineni Sivaganesh, P Srinivasu, Dr Suresh Chandra 
Satapathy, “Optimization of  ETL Work Flow in Data 
Warehouse,” International Journal on Computer Science and 
Engineering, Vol. 4 No. 09, pp.1579-1586, Sept. 2012 
88
