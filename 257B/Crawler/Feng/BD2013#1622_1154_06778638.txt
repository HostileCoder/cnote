Utilizing Community Centers to Answer
 Reachability Queries for Large Graphs
 Yifei Zhang?†, Guoren Wang?, Changkuan Zhao? and Ende Zhang?
 ?College of Information Science and Engineering
 Northeastern University, Shenyang, China
 Email: wanggr@mail.neu.edu.cn, {zck,zed}@cc.neu.edu.cn
 †School of Computer
 Shenyang Aerospace University, Shenyang, China
 Email: zhangyifei@sau.edu.cn
 Abstract—As a fundamental problem, reachability query has
 been always the research emphasis in many applications in the
 near 20 years. Especially with the coming of the big data era, its
 efficiency plays a critical role. Although there are many research
 results for this issue, they all reach a scalability bottleneck. In this
 paper, we propose an index structure utilizing community center,
 i.e. to select a group of vertices from the original graph and
 construct a subgraph. With this subgraph, we can answer reach-
 ability queries rapidly. The experimental result shows that our
 approach is superior to the-state-of-the-art algorithms including
 construction time, index size and query time.
 Keywords—Reachability query, Community center, Reachability
 trunk;
 I. INTRODUCTION
 In recent year, we can commonly find that data is modeled
 as graphs in many applications, e.g., social networks, semantic
 web, bioinformatics and so on. For instance, in social net-
 works, we can use vertices to denote every user and use the
 edges to denote the relationship between the users. Among all
 the algorithms involved with graphs, reachability query, which
 test if one vertex can reach another vertex via a path, is one
 of the most fundamental issues. Although it is a quite simple
 problem and has been researched for 20 years, the efficiency
 is still a bottleneck. Especially with the coming of big data
 era, many new challenges are posed to this question.
 A lot of approaches have been proposed to improve the
 query efficiency for graphs. These methods mainly try to
 construct compact indexes of original graphs to achieve a
 balance between query time, index size and constructing time.
 However, with the aggrandizement scale of graph data, they
 all have problems in scalability. For example, the active user
 number of Facebook has reached 1 billion in August 2012.
 Faced with this tsunami of data, the cost of index size and
 construction time of current methods is excessive expense. The
 query time of online BFS (Breadth First Search)/DFS(Depth
 First Search) is liner related to graph size, which is unaccept-
 able for large graphs.
 To sum up, scalability has become the main obstacle for
 reachability query. The big question now is whether we can
 construct indices efficiently when the graph data scale reach
 tens or even hundreds of millions of vertices. In this paper,
 we propose a new community-center-based index structure. To
 achieve reasonable index size and answer query efficiently,
 we first divide the original graph into several independent
 communities. Each community has a unique center and we
 use these centers instead of all the vertices to construct index.
 Because the number of these vertices is much smaller than the
 total vertex number of the original graphs, the index size can
 be significantly reduced. Our approach can not only handle
 medium-sized graphs, but also scales extremely well for large
 or very large graphs.
 A. Overview of Index Structure
 At present, most index algorithm need to preserve the
 whole vertices information. It is the main reason why they have
 problems in scalability. A sensible solution is to select a few
 vertices from the original graph to construct index. Then the
 bottleneck of previous approaches would be broken and large-
 scale even super-large-scale graphs can be handled efficiently.
 Ruoming Jin et. al proposed SCARAB [4], a backbone-based
 method, to construct reachability index. They exact a small
 number of vertices to cover the original graph. Every vertex
 can reach at least one backbone vertex in  steps. In this way,
 the storage cost can be reduced greatly. However, this method
 need to test repeatedly every vertex of the original graph
 while constructing the backbone. This leads to high cost of
 time, especially for those dense graphs. In order to meet these
 challenges, we draw lessons from SCARAB and put forward
 an index construction method which utilizes community center
 to cover the graph. Its basic idea can be summarized as follows:
 1) Community, Community Center and Reachability Trunk:
 Social network is a long-standing issue in sociology and
 many interesting phenomena are found, such as small world
 phenomenon, power-law distribution and so on. We can find
 that in the vast majority of social networks or other similar
 networks, all the vertices have close connection with a small
 amount of vertices and are weakly associated with other
 vertices. For instance, in Facebook, all users are in different
 group organized by affection, politics or hobbies. This kind
 of group can be called a community. In each community,
 there often exist several vertices, called community centers,
 which closely link to other vertices in a direct or indirect way.
 Therefore, we can link these community centers by virtual
 edges to form a reachability trunk. It can be considered as a
 query subgraph of the original graph and the total index storage
 cost can be reduced greatly.
 2013 10th Web Information System and Application Conference
 978-0-7695-5134-0/13 $26.00 © 2013 IEEE
 DOI 10.1109/WISA.2013.47
 205978-1-4799-3219-1/13 $31.00 © 2013 IEE
2) Local Accessing and Employing Recursively: Due to us-
 ing a small proportion of the original graph to construct index,
 other vertices need to do local search to quickly find their
 nearest centers. However, because the distance between every
 vertex and their center is very short, the cost of this operation
 is almost negligible. Our method is similar to SCARAB, which
 can also be used recursively to further reduce the index size.
 Organization. Section 2 defines the problem and the basic
 notations. Section 3 gives a heuristic algorithm to find the
 reachability trunk. Section 4 includes the query processing
 algorithm and the complexity analysis. Section 5 reports the
 experimental results. Section 6 and 7 give the related work and
 the conclusion.
 II. DEFINITION
 We first give the notations used throughout the paper.
 Intuitively, the reachability trunk should have the features as
 follows:
 • Its size must be much smaller than that of the original
 graph.
 • It must reserve the topological structure of the original
 graph.
 • Each vertices in the original graph must reach one of
 its vertex quickly and easily in a few steps.
 In order to meet them, we explicitly separate internal vertex
 pairs from external vertex pairs, and focus on utilizing the
 trunk for recovering the reachability for external reachable
 pairs. To distinguish the two vertex pairs, we define a threshold
 ?. For any pair of vertices u and v, if two vertices can reach
 the same trunk vertex in ? steps, then (u,v) can be called
 the internal-pair, else they can be called the external-pair.
 Therefore, the reachability trunk can be defined as follows:
 Definition 1: Given a directed acyclic graph (DAG) and a
 threshold ?, its reachability is G? = (V ?, E?), where V ? ? V
 and E? may contain edges not in E, then it has the following
 features:
 • Any two vertices in V ? must not be in the same
 community.
 • All the vertices which is in the same community can
 reach its center in ? steps.
 • For any internal-pair (u,v), if u can reach v, then the
 max distance between them is 2?.
 • For any external-pair (u,v), if u can reach v, then there
 must exist u? ? V ? and v? ? V ?, such that (u, u?)
 and (v, v?) are both internal-pair and u? can reach v?.
 Example 1. Figure 1(b) shows a reachability trunk of graph
 G (figure 1(a)) with ? = 3. As an example, for external-pair
 (1,14), there is a trunk vertex 0 where vertex 1 can reach in 1
 hop, there is another trunk vertex 7 where vertex 7 can reach
 14 in 3 hops, and vertex 0 can reach 7 in the reachability
 trunk. Actually, for any external-pair, we can always find their
 corresponding community center and test their reacnability by
 these trunk vertices.
 
 
 
 
 
 
 
 	
 

 
 
 
 
 
 
 (a) Original Graph G
 
  
 	
 (b) G’s Reachability Trunk
 Fig. 1: Running Example
 Apparently, the vertex number of the trunk depends on the
 threshold ?. As is shown in the experimental result Section 5,
 for any real and synthetic graph data, a reachability trunk with
 ? ≤ 3 can dramatically reduce the size of the original graph.
 And in many instances, we can get an ideal result with ? = 2.
 The main purpose of the reachability trunk is to cover the
 original graph with as few vertices as possible. Here we give
 the definition of the minimum reachability trunk discovery.
 Definition 2: Minimum Reachability Trunk (MRT) Dis-
 covery. Given a DAG G=(V,E) and a threshold ?, there must
 be a vertex set V ? ? V which can cover G in ? hops, and in
 all the possible candidate sets, its size is the smallest.
 However, computing the MRT is NP-hard because its corre-
 sponding decision problem is an NP-complete problem.
 Theorem 1: NP-hardness of MRT discovery problem.
 Given a DAG G=(V,E) and a threshold ?, the MRT discovery
 problem is an NP-hard optimization problem.
 Proof: The MRT discovery problem can be to the classic
 vertex set cover (VSC) problem, a well-known NP-complete
 problem. Given a DAG G=(V,E), theorem 1 can be proofed as
 follows:
 (1) Suppose there is a solution S? ? V that meets the VSC
 problem, then for all v ? S?, they must be covered by one and
 only one u ? V ?.
 (2) Suppose there is a solution V ? ? V that meets the
 MRT problem, then for any two vertex u ? V ?, v ? V ?, they
 can not cover the same w ? S?.
 In summary, the MRT problem can be reduced to the VSC
 problem, an NP-hard problem.
 III. REACHABILITY TRUNK DISCOVERY
 Known from the theorem 1, the reachability trunk cannot
 be computed in polynomial time. Therefore, we propose a
 maximum-degree-vertex covering first heuristic algorithm. Its
 basic idea is based on the following discoveries:
 • A community center usually connects closely with
 other vertices which shows that has a much larger
 degree than other normal vertices.
 • The graph partition problem is NP-hard too. Obvi-
 ously, it is more efficient if community centers are
 determined first and then covering other neighbouring
 vertices.
 206
• Practice shows that those vertices which have a larger
 degree are often more stable in actual graphs. This
 means good index structure stability.
 Algorithm 1: Computing the vertex set for G?
 input : G, a directed data graph; ?, a threshold;
 output: V ?, a reachability trunk;
 1 V ? ? ?;
 2 N ? { Order all the vertices of G by degree };
 3 Queue Q;
 4 for each u in N do
 5 if !visited[u] then
 6 V ? ? {u};
 7 Q.enqueue(u);
 8 l = 0;
 9 while !Q.empty() do
 10 v = Q.dequeue();
 11 visited[v] = true;
 12 l? v’s level with respect to u;
 13 if l < ? then
 14 Bout ? {v’s successors };
 15 Bin ? {v’s predecessors};
 16 Q? Bout;
 17 Q? Bin;
 18 return V ?;
 Algorithm 1 gives a brief review of the fast heuristic
 approach. We first order the vertices by degree (including
 indegree and outdegree). At first, the vertex set of G?, V ?, is
 set to be empty. Then for each unvisited u based on the order,
 we check whether it can cover other unvisited adjacent vertices
 in ? steps bidirectionally until all the vertices are visited.
 Fig. 1(b) is the reachability trunk of the original graph G.
 As can be seen from the result, we can use only 4 vertices to
 cover G’s 16 vertices. The index size is significantly reduced.
 The next step is to connect these trunk vertices to construct
 the reachability trunk G?. We first give a property of the
 reachability trunk as follows:
 Property 1. The max distance between any two trunk
 vertices is 2?. Based on definition 1, this property is obvious.
 Therefore, we omit the proof.
 As shown in Algorithm 2, we do BFS from every trunk
 vertex. If it can reach another trunk vertex in 2? steps, then
 we add an edge between them. After traversing all the trunk
 vertices, we build a sub-graph of graph G.
 The output of Algorithm 1 and 2 is a sparse subgraph of G
 because most of the edges have been filtered while computing
 the reachability trunk. This can be verified by the follow-up
 experiments. In many cases, the number of trunk edges is even
 less than that of trunk vertices. Such sparse graph is very
 suitable for other existing index approaches.
 Computational Complexity: In Algorithm 1, the compu-
 tational cost mainly focuses on sorting and local traversing.
 For the sorting problem, we can do it in O(nlog(n)). For
 local traversing, let N?(u) denote the number of vertices and
 edges of u’s forward neighbors that can be reached in ?
 steps. Let N ??(u) denote the number of vertices and edges
 Algorithm 2: Computing the edge set for G?
 input : G, a directed data graph; V ?, the vertex set of
 G?; ?, a threshold;
 output: E?, the edge set of G?;
 1 E? ? ?;
 2 for each u in V ? do
 3 if !visited[u] then
 4 visited[u] = true;
 5 Do BFS from u in 2? steps;
 6 E? ? (u,v);{u can reach v in 2? steps and
 v? V ?}
 7 return E?;
 of u’s backward neighbors that can reach u in ? steps. Then
 this process costs O(∑u?V ? (N?(u) + N ??(u))). Due to the
 diversity of actual graph data, we cannot give exact value of
 |V ?|. As for index size, the storage cost for the reachability
 trunk is O(V ?+E?). If we adopt other index algorithms on the
 trunk, the index size is related to their efficiency. In the worst
 cases, if we construct a transitive closure for the reachability
 trunk, it would cost O(k2), where k = |V ?| and k << |V |.
 IV. QUERY PROCESSING
 Before we introduce how to answer reachability queries by
 the reachability trunk, we give the following property.
 Property 2. Let p denote the distance between u and its
 community center u?. if v? is the neighboring community
 center and u? can reach v?, then u can reach v? in 2? ? p
 steps.
 This property can be proved by definition 1 too, and based
 on it we give a theorem as follows:
 Theorem 2: Given a DAG G=(V,E) and its reachability
 trunk T, we can answer whether u can reach v by their
 community centers and adjacent community centers.
 Proof: When vertex u can reach its community center u?,
 u covers all the u?’s reachability information. However, when
 u? can reach u, we obviously cannot come to this conclusion.
 Therefore, besides searching u’s community center, we also
 need to search u’s adjacent community centers to make sure
 to cover all u’s reachability information.
 Thus, we give the query processing algorithm on the basis
 of property 2 and theorem 2. As shown in Algorithm 3,
 we do bidirectional BFS from the source vertex u and the
 target vertex v, if u can reach v in ? steps or they can
 reach the same community center, that is, u and v are in the
 same community, then they are reachable. If u and v are not
 in the same community, suppose x and y are two different
 community centers and u can reach v, then they are reachable
 too. Otherwise, u can not reach v.
 Complexity. The query cost mainly lies in the bidirectional
 local BFS. And the query efficiency of reachability trunk
 depends on other index methods. Now, there are many ap-
 proaches that can answer reachability queries in constant time.
 Because the threshold ? is often very small, the computation
 cost of local BFS can be negligible compared with global BFS.
 In short, we can answer reachability queries in approximate
 constant time.
 207
Algorithm 3: Query(u,v)
 input : G, a directed data graph; G?, the reachability
 trunk of G;
 ?, a threshold;
 output: The reachability between u and v;
 1 Do forward BFS from u;
 2 Do backward BFS from v;
 3 if u and v can reach the same community center or u
 reaches v in ? steps then
 4 return true;
 5 p ? the distance between u and its community center;
 6 X ? {all u’s forward reachable community centers in
 2?? p steps };
 7 Y ? { all v’s backward reachable community centers
 in 2?? p steps};
 8 for each x in X do
 9 for each y in Y do
 10 if x can reach y then
 11 return true;
 12 return false;
 V. EXPERIMENTAL STUDY
 In this section, we empirically analyze the performance
 of our method. We mainly are interested in the following
 questions:
 • Can our algorithm work efficiently on large scale
 graphs with millions of vertices, including construc-
 tion time, index size and query time?
 • Whether our method is a great improvement over the-
 state-of-the-art existing high performance approaches,
 such as SCARAB?
 • Whether our method can improve the efficiency of
 early proposed algorithms?
 To answer the above questions, we first studied SCARAB,
 an efficient index framework proposed by Ruoming Jin, which
 close to our idea, and compare it with our algorithm. In
 addition, we also studied following state-of-the-art reachability
 approaches.
 • PathTree [3], an improved version of Agrawal’s tree-
 interval method proposed by Ruoming Jin too;
 • 2HOP [5], a famous labeling approach put forward by
 Cohen et al.
 For each of them, we developed their Trunk and SCARAB
 methods, referred to as PT-T,2HOP-T, PT-S and 2HOP-S,
 where T refers to the reachability trunk and S refers to the
 reachability backbone.
 In experiments, we focus mainly on testing 3 important
 indicator, that is query time, index size and construction
 time. For query time, we utilize 1,000,000 completely random
 queries. Our construction time consist of two parts: trunk
 discovery time and index time. Correspondingly, the index
 size of a Reachability Trunk consists of two parts, the size
 of the trunk, and the index size on the trunk. All algorithms
 mentioned in this work are implemented in C++ based on the
 Standard Template Library (STL).
 TABLE I: Real Datasets
 Dataset Nodes Edges Diameter
 p2p-Gnutella25 22,687 31876 11
 p2p-Gnutella30 36,682 49605 10
 p2p-Gnutella31 62,586 84168 11
 Wiki-Vote 8,297 12,374 7
 CiteSeer 723,131 1,085,615 10
 CiteSeer 723,131 790,552 10
 soc-Pokec 1,632,803 2,964,439 11
 cit-Patents 3,774,768 6,622,789 11
 TABLE II: Construction Time on Real Datasets(in ms)
 Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S
 P2PG25 37 256 257 4,270 39 164
 P2PG30 70 462 512 9,973 69 365
 P2PG31 170 1,070 2,980 52,501 266 1,106
 Wiki-Vote 967 80,637 11 13 7 5
 CiteSeer 46,625 518,292 1.3 ? 106 5.5 ? 106 122,121 18,407
 Soc-Pokec 712,182 3.3 ? 106 1.5 ? 107 4.1 ? 107 1.4 ? 106 3.7 ? 106
 Cit-Patents 4.2 ? 106 9.4 ? 106 5.1 ? 107 9.5 ? 107 4.7 ? 106 8.3 ? 106
 All experiments are performed on a Windows 7 machine
 with Intel I5-2400 3.10GHZ and 8G RAM.
 A. Real Data
 To validate our approaches, we first purposefully collected
 7 real datasets, listed in Table I with some important charac-
 teristics, where diameter is the longest path between any pair
 vertices. All these graphs are directed, unweighted, and acyclic.
 For those non-DAG graphs, we transform it into a DAG by
 coalescing strongly connected components (SCC) into virtual
 vertices [7]. This can be done simply by depth first search
 (DFS).
 The graph size ranges from a few thousand to almost
 four million vertices. CiteSeer is from The Koblenz Network
 Collection (KONECT), which is about the digital library for
 scientific and academic papers, primarily in the fields of
 computer and information science. Other datasets are provided
 by Stanford Large Network Dataset Collection (SNAP). P2p-
 Gnutella25-31 are a sequence of snapshots of the Gnutella
 peer-to-peer file sharing network from August 25 to 31 in 2002.
 Wiki-Vote is a free encyclopedia written collaboratively by
 volunteers around the world. Soc-Pokec is the anonymized data
 of the Pokec which is the most popular online social network
 in Slovakia. Cit-Patents is the U.S. patent dataset maintained
 by the National Bureau of Economic Research.
 Due to space limitation, we present results only for Trunk,
 SCARAB, 2HOP-T, 2HOP-S, PT-T and PT-S and set the
 threshold ? to 3. Table II shows the index construction times
 for different approaches. According to results obtained, we can
 find that our algorithm runs much faster and more efficiently
 than SCARAB. Especially for those large data graphs, our
 algorithm can handle them within acceptable time limits.
 Table III shows the subgraph size obtained by Trunk
 and SCARAB. Columns |V ?| and |E?| record the number
 of vertices and edges of the reachability trunk or backbone
 of SCARAB. Figure 2 reports the index size of different
 reachability methods, including 2HOP-T,2HOP-S, PT-T and
 PT-S. We make the following observations on index size:
 208
TABLE III: Index Size of Real Datasets
 Datasets
 Trunk SCARAB
 |V ?| |E?| |V ?| |E?|
 P2PG25 4,416 2,230 2,149 6,032
 P2PG30 7,301 3,247 3,363 9,435
 P2PG31 12,541 6,428 5,832 15,715
 Wiki-Vote 1,285 1,393 78 1,772
 CiteSeer 121,533 110,100 26,087 109,039
 Soc-Pokec 330,804 464,912 320,432 1,940,010
 Cit-Patents 832,530 853,782 412,892 1,165,257
 • Both Trunk and SCARAB can establish subgraphs
 from the original graph and the subgraph size is much
 smaller than the original graph.
 • Although the two approaches provide almost the same
 index size, the result of Trunk is quite sparse which is
 very beneficial to the original methods. It is validated
 in Table II.
 • On the basis of the data in Figure 2, the index size of
 our method is significantly smaller than SCARAB.
 
 
 
 
 
 
 
 
 	
 

 		
 	

 Fig. 2: Index Size on Real Graphs
 Figure 3 reports the query time for different query answer-
 ing approaches. In our results, we can see that the threshold
 ? being equal, there is little difference between Trunk and
 SCARAB in response times.
 
 
 
 
 
 
 
 

 	
 Fig. 3: Query Time on Real Graphs
 Through different types of real data graphs, we can draw
 a conclusion that our method can really improve the index
 construction time and reduce the index size. Meanwhile, our
 method do not decrease the query efficiency.
 B. Synthetic Data
 We ran seven sets of experiments using synthetic random
 directed graphs. Here, we focus on testing the effects of
 graphs’ density on the efficiency of different approaches. We
 set the density |V |/|E| from 1.5 to 3 and vary |V | from 5K
 to 2,000K. In each experiment, we use the same algorithms as
 previous.
 Table IV to IX shows the construction time and index
 size of six approaches. When the density |E|/|V | = 1.5, the
 TABLE IV: Construction Time on Synthetic Datasets
 |E|/|V | = 1.5(in ms)
 Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S
 5K 8 32 2 6 10 9
 10K 17 88 17 30 28 27
 50K 146 833 540 1,618 443 482
 100K 733 2,653 263 10,539 1,924 1,818
 500K 9,410 53,983 67,319 1.2 ? 106 53,983 49,137
 1,000K 165,753 133,730 592,351 9.3 ? 106 211,340 194,791
 2,000K 665,077 1.6 ? 106 4.9 ? 106 7.7 ? 107 863,289 799,615
 TABLE V: Construction Time on Synthetic Datasets
 |E|/|V | = 2(in ms)
 Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S
 5K 6 57 2 32 9 15
 10K 11 120 4 83 17 37
 50K 125 1,110 325 5,874 338 754
 100K 422 3,125 2,475 37,578 1,355 2,907
 500K 8,975 49,931 259,025 4.3 ? 106 40,214 78,600
 1,000K 141,479 162,744 2.4 ? 106 3.0 ? 107 148,267 314,534
 2,000K 557,614 1.0 ? 106 1.6 ? 107 1.8 ? 108 576,957 1.3 ? 106
 TABLE VI: Construction Time on Synthetic Datasets
 |E|/|V | = 3(in ms)
 Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S
 5K 7 252 9 124 10 19
 10K 15 684 26 342 17 49
 50K 140 5,715 1,166 31,252 246 1,116
 100K 420 14,386 7,414 153,345 1,025 3,903
 500K 7,403 120,680 611,920 1.9 ? 107 24,528 104,168
 1,000K 103,981 324,468 6.4 ? 106 1.4 ? 108 100,043 423,538
 2,000K 920,765 2.2 ? 106 5.0 ? 107 9.7 ? 108 398,477 1.8 ? 106
 TABLE VII: Index Size on Synthetic Datasets |E|/|V | = 1.5
 Datasets
 Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S|V ?| |E?| |V ?| |E?|
 5K 1,314 556 446 469 556 436 378 246
 10K 2,617 640 942 1,277 641 1,134 493 550
 50K 13,064 3,354 4,461 5,295 3,362 4,764 2,621 2,583
 100K 26,312 6,444 8,688 9,783 6,436 8,855 5,113 4,930
 500K 132,274 35,427 44,272 50,381 35,383 45,597 27,941 25,364
 1000K 264,508 70,574 87,802 98,408 70,389 89,182 55,976 50,054
 2000K 529,154 141,986 175,980 199,443 141,618 179,457 112,393 100,805
 TABLE VIII: Index Size on Synthetic Datasets |E|/|V | = 2.0
 Datasets
 Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S|V ?| |E?| |V ?| |E?|
 5K 1,202 438 536 1,066 438 1,021 248 369
 10K 2,309 761 1,021 1,824 775 1,592 456 682
 50K 11,550 4,124 5,086 9,081 4,139 8,063 2,385 3,528
 100K 23,359 7,971 10,061 18,085 7,993 15,972 4,917 6,866
 500K 115,026 42,458 51,212 93,957 42,419 82,533 24,979 35,545
 1000K 230,710 88,734 102,660 186,669 88,537 164,184 51,464 70,922
 2000K 460,498 176,609 205,810 376,931 175,929 326,244 102,199 141,597
 performance of Trunk and SCARAB is similar. However, with
 the increase of graph density, our method is much better than
 SCARAB, which is of significance for practical application.
 209
TABLE IX: Index Size on Synthetic Datasets |E|/|V | = 3.0
 Datasets
 Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S|V ?| |E?| |V ?| |E?|
 5K 872 925 558 2146 895 1948 326 471
 10K 1,670 1,534 1,072 3,652 1,553 3,229 485 871
 50K 8,466 6,987 5,495 23,044 7,046 20,721 2,274 4,746
 100K 17,000 15,961 10,621 41,808 16,155 39,118 4,982 9,003
 500K 84,869 74,850 54,383 218,000 75,474 197,107 23,503 46,111
 1000K 169,151 156,231 108,746 445,631 157,571 403,579 47,935 92,276
 2000K 338,874 309,518 218,049 888,661 299,384 85,215 95,080 184,993
 Figure 4 reports the query time of two algorithms. Similar
 to the results of real data graphs, the query performance of
 them don’t differ significantly from each other.
 
 
 
 
 
 
 
 
 
       
 

 	
 (a) |E|/|V | = 1.5
 
 
 
 
 
 
 
 
 
       
 

 	
 (b) |E|/|V | = 2
 
 
 
 
 
 
 
 
 
 
       
 

 	
 (c) |E|/|V | = 3
 Fig. 4: Query Time of Synthetic Datasets (in ms)
 VI. RELATED WORK
 In recent years, as a hot topic in graph data management,
 numerous reachability computation methods [5], [9], [6], [1],
 [2], [12], [8], [10], [13], [3], [14], [4], [11], [15] have been
 proposed.
 BFS and DFS [7] are two most straight methods. They can
 compute reachability queries in O(n+m) time, which is very
 inefficient for those large data graphs.
 Many approaches [5], [3], [14], [11], [8], [12], [15] have
 been used to reduce the index size. But they can only deal
 with small or medium-sized graphs.
 Schaik et al. [13] mainly study how to compress the whole
 transitive closure and did not involve optimization problems.
 Ruoming Jin et al. propose SCARAB [4] to handle large
 scale graphs. However, when dealing with dense graphs, per-
 formance drops off precipitously.
 James et al. [10] give a new way to compress index. But
 this method can only answer certain queries and cannot apply
 to regular reachability queries.
 VII. CONCLUSION
 In this paper, we introduce a simple and practical frame-
 work to reduce the index size of large graphs. It can also help
 improve existing query algorithms greatly. In our work, we
 propose a new opinion that utilize community to construct
 index. The experimental results shows, that our method is
 much faster than SCARAB, the state-of-the-art high perfor-
 mance index approach. In the future work, we will continue
 investigate to apply TRUNK to other reachability problems,
 such as regular expression-based query or dynamic graphs.
 Finally, we plan to study how to further improve the efficiency
 of community and community center discovery.
 ACKNOWLEDGMENT
 This research was supported by the Normal Project Foun-
 dation of Education Department of LiaoNing Province (Grant
 No. L2012045).
 REFERENCES
 [1] Y. Chen. Decomposing dags into spanning trees: a new way to compress
 transitive closure. In ICDE’11, 2011.
 [2] H. Wang, H. He, J. Yang, P. S. Yu, and J. X. Yu. Dual Labeling:
 Answering graph reachability queries in constant time. In ICDE’06,
 2006.
 [3] Ruoming Jin, N. Ruan, Y. Xiang, and H. Wang. Path-tree: An efficient
 reachability indexing scheme for large directed graphs. In TODS’11,
 2011.
 [4] Ruoming Jin, Ning Ruan, Saikat Dey, and Jeffrey Yu Xu. SCARAB:
 scaling reachability comutation on large graphs. In SIGMOD’12, 2012.
 [5] E. Cohen, E. Halperin, H. Kaplan, and U. Zwick.Reachability and
 distance queries via 2-hop labels. In SICOMP’03, 32(5):1338-1355,
 2003.
 [6] R. Agrawal, A. Borgida, and H. V. Jagadish. Efficient mgmt. transitive
 relationships in large data and knowledge bases. In SIGMOD’89, pages
 253-262, 1989.
 [7] Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rvest. Intro-
 ductionto Algorithms. In McGraw Hill, 1990.
 [8] R. Schenkel, A. Theobald, and G. Weikum. HOPI: An efficient connec-
 tion index for complex XML document collections. In EDBT’04, 2004
 [9] R. Jin, Y. Xiang, N. Ruan, and D. Fuhry. 3-HOP: A high-compression
 indexing scheme for reachability query. In SIGMOD’09, 2009.
 [10] James Cheng, Zechao Shang, and Hong Cheng. K-Reach: Who is in
 your small world.In VLDB’12, 2012.
 [11] Yangjun Chen and Yibin Chen. An efficient algorithm for answering
 graph reachability queries. In ICDE’08, 2008.
 [12] H. Yildirim, V. Chaoji, and M.J. Zaki. Grail: Scalable reachability index
 for large graphs. PVLDB, pages 276-284, 2010.
 [13] S. J. Van Schaik and O. de Moor. A memory efficient reachability data
 structure through bit vector compression. In SIGMOD’11, 2011.
 [14] R. Jin, N. Ruan, Y. Xiang, and H. Wang. Efficiently answering reach-
 ability queries on very large directed graphs. In SIGMOD’08, 2008.
 [15] S. Tri?l and U. Leser. Fast and practical indexing and querying of very
 large graphs. In SIGMOD’07, 2007.
 210
