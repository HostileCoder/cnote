Super-sequence Frequent Pattern Mining on
 Sequential Dataset
 Xinran Yu
 Computer Science Department
 University of Texas at San Antonio
 San Antonio, TX 78249
 xyu@cs.utsa.edu
 Turgay Korkmaz
 Computer Science Department
 University of Texas at San Antonio
 San Antonio, TX 78249
 korkmaz@cs.utsa.edu
 AbstractÑDue to the importance of Frequent Pattern Mining
 (FPM) in bioinformatics, web mining, social networks and so
 on, researchers have been paying significant attention to FPM
 and its various forms. In this study, we introduce a new form
 that we call super-sequence pattern mining. In contrast to
 frequent sub-sequence pattern mining studied significantly in the
 literature, frequent super-sequence mining requires to identify
 super-sequences that may contain sequential parts from different
 sequences and that have the total support larger than a given
 threshold. In essence, finding frequent super-sequence patterns
 turns out to be related to the well-known NP-hard longest path
 problem in graphs. Accordingly, we transform a given sequential
 dataset into a sequence graph and formulate the problem as k-
 hop longest path problem. We then propose a heuristic algorithm
 using dynamic programming techniques. The running time of
 our solution is depending on the number of different items in
 the sequence set but not on the size of the dataset. Through
 experiments, we demonstrate the effectiveness of the proposed
 solution. We also illustrate its use on an actual web log dataset
 and find out some interesting facts based on the identified
 frequent super-sequences on the web log dataset.
 I. INTRODUCTION
 Frequent Pattern Mining (FPM) is to seek frequently oc-
 curring patterns or relationships in a large database. It was
 first introduced by Agrawal et al [1] to analyze the item sets
 that appear frequently in the customersÕ shopping baskets. As
 we review in the next section, researchers have proposed many
 algorithms to this problem and investigated various other forms
 of FPM. In this paper, we focus on sequential datasets and
 investigate a new form of sequential pattern mining.
 A sequential dataset is a collection of sequences of or-
 dered elements or events [2]. Traditional sequential pattern
 mining tries to determine the frequently occurring ordered
 (sub)sequences as patterns. As an example, let us consider
 web log sessions in Table I. Each web session is an ordered
 sequence of web clicks, i.e., two consecutive pages AB means
 that a user first visited page A and then page B. In this exam-
 ple, traditional algorithms (e.g., Apriori, downward closure)
 would identify AB and CD as the most frequent sub-sequence
 patterns as they appear three times in the dataset. Finding such
 frequent sub-sequences can be helpful for analyzing the web
 site structure and improving the performance. For example,
 by analyzing the traversal patterns in a web serverÕs log, one
 can gather important information such as web usersÕ browsing
 TABLE I
 AN EXAMPLE OF SEQUENTIAL DATASET CONSISTING OF WEB LOG
 SESSIONS.
 Session Id Session sequence
 1 ABEB
 2 BED
 3 AB
 4 AB
 5 BCD
 6 CD
 7 CD
 behaviors, most popular pages and which pages are likely to
 be visited together [3].
 Extracting the frequent sub-sequences can help in analyzing
 the common structure existing in each of the elements in a
 database. On the other hand, the underlying general structure
 in a database is also important in analyzing the database.
 In this paper, we study a different form that we call super-
 sequence frequent pattern mining (SS-FPM). In contrast to
 sub-sequences, super-sequences may contain several parts
 from different sequences. For example, in the above example,
 the most frequent super-sequence pattern with sequence length
 4 would be ABCD because the total number of occurring times
 of AB, BC, and CD is 7, which is higher than that of any other
 super-sequences with sequence length 4.
 Extracting super-sequences in a sequential dataset is impor-
 tant to analyzing the characteristics of a dataset and predicting
 the underlying patterns in it. It can be used in various areas
 and applications, e.g., in web page design and construction,
 system call analysis, bioinformatics, social networks, etc. For
 example, biologists can better understand the relationships be-
 tween gene structures and functional elements by determining
 the frequent super-sequences in the DNA sequences [4] of
 closely related species. Another example would be malware
 detection [5], where researchers analyze the sequence of sys-
 tem calls [6] [7]. With our technique, researchers can identify
 frequent super-sequence system call patterns from many pro-
 grams and use this information to determine unusual sequence
 of calls that might be invoked by malicious programs. Super-
 sequence patterns can also help in predicting longer patterns
 from shorter sequences available. For example, suppose an
 operating system allows only k system calls to finish a session
 2013 IEEE International Conference on Big Data
 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 52
in the above system call sequences example. Through the
 super-sequence patterns, we can predict what are the possible
 patterns if the system allows l system calls for a session, where
 l > k.
 The SS-FPM problem is related to the longest path problem
 in graphs, which is known to be NP-hard [8]. We first
 transform the given sequential dataset into a sequence graph,
 and then represent it in a matrix. Searching the most frequent
 super-sequence becomes the problem to search the longest
 path.
 In our problem, however, we are interested in finding all the
 k-hop paths ((k +1)-length super-sequence frequent patterns)
 that have a larger weight than a given threshold. Note that k-
 hop longest path is the same as (k+1)-length super-sequence
 frequent pattern (SS-FP).
 In response to solving this new form of the longest path
 problem, we propose a heuristic method that uses Dynamic
 Programming techniques to gradually compute k-hop paths
 from the initial one-step sequence matrix and the (k? 1)-hop
 paths computed in previous iteration.
 As we discuss later in detail, the overall worst-case com-
 plexity of the proposed heuristic will be O(kn4). However,
 in practice, since the sequence graphs are sparse, we will see
 in Section V that the running time is reasonable based on the
 experiments on the web log dataset.
 The remaining part of the paper is organized as follows.
 In Section II we give related work in frequent pattern mining
 area. We formally define super-sequence frequent pattern min-
 ing (SS-FPM) problem and give the graph model in Section III.
 In Section IV we present our proposed heuristic method
 using dynamic programming for solving the SS-FPM problem.
 We then evaluate the performance of our solution through
 experiments on actual web log dataset in Section V. Finally,
 we conclude this paper and point out some issues for future
 research in Section VI.
 II. RELATED WORK
 Frequent Pattern Mining (FPM) plays an important role
 in data mining research area. It deals with extracting pat-
 terns from large databases representing complex relationships
 among various entities.
 After the Apriori algorithm was first proposed, many new
 algorithms and improvements were introduced. For exam-
 ple, researchers have tried to improve Apriori using vari-
 ous techniques including hashing technique [9], partitioning
 technique [10], sampling approach [11], dynamic itemset
 counting [12], incremental mining [13], parallel and dis-
 tributed mining [9] [14] [13] and so on [15]. People have
 also developed new algorithms for the FPM problem such
 as FP-growth [16], which uses FP-tree to store the itemset
 association information, and Eclat [17], which uses an Equiv-
 alence CLASS Transformation method. Moreover, researchers
 have been studying various other types of FPM problem
 including multilevel and multidimensional association rules
 mining [18], closed frequent pattern mining [19], colossal
 pattern mining [20], sequential pattern mining [21], graphs,
 trees and lattices mining [15].
 Our work is mostly related to sequential mining, where the
 frequent itemsets mining is extended with the consideration
 of ordered items. Specifically, sequential mining tries to find
 the set of frequent subsequences in a given sequential dataset.
 One of the first solutions to this problem was AprioriAll [21],
 which extends the similar techniques in Apriori [1] to find
 frequent patterns in transactions of the customers. It generates
 candidate sequences by measuring the support of them in
 passing over the database. Some of the well-known sequential
 mining algorithms are Apriori-based GSP (Generalized Se-
 quential Patterns) [22], Pattern-growth based FreeSpan [23]
 and PrefixSpan [24], Vertical format-based SPADE [25] and
 Constraint-based SPIRIT [26]. All of the above works mainly
 focus on the sub-sequence mining, which is to find the
 common part of all the sequences in a dataset. In our problem,
 we are looking for a general structure, the super-sequence.
 The most frequent super-sequence is the one with the largest
 total support of each consecutive length two sequence in it.
 Although part of the most frequent super-sequence may be
 the most frequent sub-sequence, this is not necessary.
 The longest path problem is known to be NP-hard [8].
 Accordingly, authors have proposed various approximation
 algorithms or developed exact algorithms for specific classes
 of graphs. Karger et. al proposed an approximation method
 for the longest path in a graph using greedy algorithm [27].
 Murat et. al proposed probabilistic longest path problem [28].
 And there are other solutions on specific type of graphs.
 For example, researchers proposed longest path problems on
 interval graphs [29], on co-comparability graphs [30], on
 ptolemaic graphs [31] and so on. Most of these studies tries
 to find the longest path starting from a source without any
 constraints. In our case, however, we are interested in any k-
 hop longest path whose weight is greater than a threshold.
 III. FORMAL DEFINITION AND GRAPH MODEL
 In this section we introduce the notation used in this paper
 and formally define SS-FPM problem.
 We assume that a sequential dataset denoted by S =
 {S1, S2, ..., SN} is given, where Si = {w1, w2, ..., wli} is a
 sequence of ordered elements or events (e.g., sequences of web
 pages in Table I). Let W = {w1, w2, ..., wn} be the complete
 set of all elements or events (i.e., W = ?Ni=1 Si).
 Let p = {w1, w2, ..., wk} be a super-sequence pattern with
 path length of (k ? 1). Note that p is not a set but an
 array, which means we consider the order of the elements
 occurring in the pattern. In contrast to sub-sequence patterns,
 super-sequence patterns may contain different parts of multiple
 sequences in the sequential dataset. For example, the super-
 sequence pattern ABCD identified from the dataset in Table I
 contains parts from most of the sequences in the table.
 Let support(wxwy) be the total number of occurrences of
 the sequence wxwy in S. Similarly, we can define the support
 53
for a pattern p as follows:
 support(p) =
 k?1·
 i=1
 support(wiwi+1)
 We say p is k-length frequent if support(p) is greater than
 a given threshold ?. We can now formally define SS-FPM
 problem as follows:
 Definition 1: Given a sequential dataset S, a sequence
 length k, and a threshold ?, the Super-Sequence Frequent
 Pattern Mining (SS-FPM) problem is to find the set P =
 {p1, p2, ...pr}, where each pattern pj = {w1, w2, ..., wk}
 satisfies the following condition
 support(pj) =
 k?1·
 i=1
 support(wiwi+1) > ?.
 SS-FPM problem is actually related to the longest path
 problem in a graph. So we transform a given sequential dataset
 S into a sequence graph, which can be defined as follows.
 Definition 2: A Sequence Graph is a directed weighted
 graph G = (V, E), where V = {w1, w2, ....wn} and E =
 {e1, e2, ..., em}. Each edge ei connects wa and wb iff there
 is a consecutive sequence wawb in any sequence in S. The
 weight of edge ei is set to support(wawb), which is the total
 number of occurrences of consecutive sequence wawb in all
 sequences in S.
 According to this definition, we can easily construct the
 sequence graph for a given sequential dataset. For example,
 the sequence graph for the sequential dataset in Table I would
 be as shown in Fig. 1. We use the adjacency matrix, which
 1
 0000
 0000
 0000
 0000
 0000
 0000
 0000
 1111
 1111
 1111
 1111
 1111
 1111
 111100000001111111
 A B
 C
 D
 E
 1
 1 3
 3 2
 Fig. 1. The sequence graph for the sequential dataset in Table I.
 we call the initial one-step sequence matrix, to represent the
 sequence graph. Since there are n elements in the set of all
 sequences, the sequence matrix would be n?n. For example,
 the sequence matrix for the above graph would be as in Fig. 2.
 M1 =
 ?
 ?????
 A B C D E
 A 0 3 0 0 0
 B 0 0 1 0 2
 C 0 0 0 3 0
 D 0 0 0 0 0
 E 0 1 0 1 0
 ?
 ?????
 Fig. 2. The sequence matrix for the sequence graph in Fig. 1.
 The sequence matrix denoted by M1 can directly be com-
 puted from the given sequential dataset S. For this, we first
 set M1[wi][wj ] to 0 for every wiwj . We then go through each
 sequence Si and add one to M1[wx][wy] for each wxwy in Si.
 The reason for using the notation M1 is to indicate that
 M1[wi][wj ] actually represents the support of 1-hop path (2-
 length sequence) from wi to wj . In the rest of the paper,
 we will continue to generalize this notation as Mk to store
 the supports of the k-hop longest path ((k + 1)-length most
 frequent super-sequence). Note that Mk[wi][wj ] will show the
 support of the k-hop longest path starting with wiwj , not the
 path from wi to wj . The actual k-hop paths will be stored in
 a hash table, as we discuss later in detail.
 In this paper, we are looking for simple paths (e.g., se-
 quential patterns without duplications). The dataset may have
 duplicates such as the first entry in table I. But when we search
 for a frequent super-sequences, we do not consider loops since
 the path may not be able to get out of the loop. So the frequent
 super-sequences got from the sequence graph is a directed
 acyclic graph(DAG).
 IV. PROPOSED SOLUTION FOR SUPER-SEQUENCE
 FREQUENT PATTERN MINING
 To determine the (k + 1)-length most frequent super-
 sequence patterns, we actually try to compute all the k-hop
 longest paths whose total weights are greater than a given
 threshold. For this, we mainly use Dynamic Programming to
 gradually compute the matrix Mk from M1 and Mk?1. As we
 discussed in last section, M1[i][j] is the support of the 1-hop
 longest path (direct link) from node i to node j. On the other
 hand, for k > 1, Mk[i][j] is the support of the k-hop longest
 path starting with sequence ij rather then being the weight of a
 path from i to j. Along with Mk, we maintain a hash table Hk
 that stores k-hop longest paths ((k+1)-length frequent super-
 sequences) starting with ij. So the keys in Hk are [ij] for all
 the non-zero elements in Mk while the values are the k-hop
 longest paths starting with the corresponding ij. Here there
 can be multiple paths starting with the sequence ij that have
 the same weights. In this paper, we only consider the situation
 that links on the sequence graph all have different numbers of
 weights since in large real world dataset, e.g., web log dataset,
 the numbers of visitings are large and have a large probability
 that they are different. More general cases can be extended
 easily based on our solution. We will first illustrate the details
 of the proposed calculation method through an example. We
 then give its pseudo code and computational complexity.
 Let us now consider the sequence graph in Fig. 1 and
 illustrate the process of getting k-hop longest paths ((k + 1)-
 length frequent super-sequence patterns) when k is 3. So, we
 need to gradually calculate M3 and H3.
 First, let us generate H1. This can easily be done by using
 the non-zero elements from the original one-step sequence
 matrix M1. Resulting keys and 1-hop paths in H1 will be
 as shown below:
 54
H1 =
 ?
 ???????
 ???????
 key : value
 AB : ?AB?,
 BC : ?BC?,
 BE : ?BE?,
 CD : ?CD?,
 ED : ?ED?
 ?
 ???????
 ???????
 We then compute M2 by using M1 twice as follows. For
 each i and j, we first search the largest value in row j of
 M1 and identify its column index as maxC. We then simply
 compute M2[i][j] by taking the summation of M1[i][j] and
 M1[j][maxC]. If M1[i][j] is 0, we keep it 0 in M2[i][j]. Also,
 if the maximum in row j of M1 is 0, we again set M2[i][j]
 to 0.
 The reasons behind the these two checks can be explained
 as follows. When M1[i][j] is zero, there is no visits on page
 j after page i. Thus, there is no need to calculate the super-
 sequence path starting with ij in the sequence. Similarly, when
 the largest value on row j is zero, there is either no outlet in
 the (k?1)-sequence matrix for page j or they could generate
 a circle if we keep adding pages in the path. Thus, we set
 the corresponding Mk[i][j] to zero. In summary, if either one
 of these conditions is true, then we cannot find a k-hop path
 starting with ij; thus, we set Mk[i][j] to 0. Accordingly, the
 resulting M2 will be as shown in Fig. 3.
 M2 =
 ?
 ?????
 A B C D E
 A 0 5 0 0 0
 B 0 0 4 0 3
 C 0 0 0 0 0
 D 0 0 0 0 0
 E 0 2 0 0 0
 ?
 ?????
 Fig. 3. The 2-sequence matrix from the sessions in Table I.
 While computing M2, we can generate the corresponding
 hash table H2 and make sure that the paths in hash table will
 not have loops. After computing M2[i][j], we check if is is 0 or
 not. If it is not 0, then we copy the value of the key [jmaxC]
 in H1 to [ij]Õs value in H1 after the first element. For example,
 the new value in H2 for key [AB] will be ?ABE? . This is
 obtained by copying ?BE? to ?AB? after A since M1[B][E]
 has the largest value on row B. Accordingly, the resulting H2
 will be as follows:
 H2 =
 ?
 ?????
 ?????
 key : value
 AB : ?ABE?,
 BC : ?BCD?,
 BE : ?BED?,
 EB : ?EBC?
 ?
 ?????
 ?????
 This shows that 3-length super-sequence patterns are ABC,
 BCD, BED and EBC with the supports of 5, 4, 3 and 2,
 respectively. Note that we did not choose EBE as a 2-hop
 path since it has a loop. We keep track of the paths and check
 if there is a loop when a path is extended with a the new node.
 If so, we ignore that node and consider the next node.
 Finally, let us compute M3 by using M1 and M2 as follows.
 For each i and j, we first search the largest value in row j of
 M2 and identify its column index as maxC. We then simply
 compute M3[i][j] by taking the summation of M1[i][j] and
 M2[j][maxC]. Accordingly, the resulting M3 will be as shown
 in Fig. 4.
 M3 =
 ?
 ?????
 A B C D E
 A 0 7 0 0 0
 B 0 0 0 0 0
 C 0 0 0 0 0
 D 0 0 0 0 0
 E 0 5 0 0 0
 ?
 ?????
 Fig. 4. The 3-sequence matrix from the sessions in Table I.
 For H3, since M2[B][C] has the largest value on row B,
 we copy the value of [BC] : ?BCD? to the value of [AB] :
 ?ABE?, starting from the second element. Consequently, we
 obtain ?ABCD? and save it in H3 with the key value of [AB].
 Using the same process, we also obtain ?EBCD?. As a result,
 H3 will be as follows:
 H3 =
 ??
 ?
 key : value
 AB : ?ABCD?,
 EB : ?EBCD?
 ??
 ?
 In summary, we computed ABE as the 2-hop longest path
 (3-length most frequent sequence) by combining 1-hop longest
 paths AB and BE from M1 in Fig. 1. Since AB has the support
 of 3 and BE has the support of 2, the support of ABE will be
 5. Continuing this way, we determined ABCD as the 3-hop
 longest path (4-length most frequent super-sequence) with the
 support of 7. We can now present the above steps in a pseudo
 code form, as shown in Fig. 5.
 As we mentioned at the beginning of this section, our
 solution can find the most frequent super-sequence with length
 k starting from ij only when the weight on each link is
 different from each other. When there are the same weights
 links, our solution will miss some super-sequences, e.g., if
 there are 2 most frequent super-sequences starting from ij,
 we will only get one of them. This can also mislead the most
 frequent length k+1 super-sequence. To get a better solution,
 we need another hash table to store all the possible paths that
 can give a most frequent super-sequence and this would be a
 good extension for our future work.
 Let us now consider the computational complexity of the
 heuristic algorithm in Fig. 5. In essence, it computes the n?n
 matrix Mk by performing the above mentioned operations on
 two n? n matrices, namely M1 and Mk?1. The actual paths
 are stored in a hash table Hk by extending the paths in Hk?1
 while making sure that there will be no loops in them. To
 compute each element Mk[i][j], the heuristic algorithm finds
 the maximum in row j of Mk?1, which costs O(n), and checks
 if the new path starting with ij would have a loop, which costs
 O(k). If there is a loop, the heuristic algorithm ignores that
 path and finds another maximum until it finds a path without
 55
Heuristic Algorithm Computing k-hop Longest Path
 Input: M1, Mk?1, and Hk?1
 Output: Mk and Hk
 for 1 ² i ² n do
 for 1 ² j ² n do
 if M1[i][j] = 0 then
 Find maxC such that
 Mk?1[j][maxC] ³ Mk?1[j][l] for 1 ² l ² n
 while there is a loop in the new path do
 Mk?1[j][maxC] = 0,
 Find maxC such that
 Mk?1[j][maxC] ³ Mk?1[j][l] for 1 ² l ² n
 end while
 if Mk?1[j][maxC]! = 0 then
 Mk[i][j] = M1[i][j] + Mk?1[j][maxC],
 update hash table Hk
 else
 Mk[i][j] = 0
 end if
 end if
 end for
 end for
 Fig. 5. The pseudo code of the heuristic algorithm proposed for SS-FPM.
 a loop. In the worst case, the heuristic algorithm may end up
 checking all the elements in row j, which costs O(n). So,
 for each element ij, the heuristic algorithm would perform
 O(n(n + k)) operations, resulting in overall complexity of
 O(n4+kn3). Since we are interested in simple paths, k will be
 less than n and thus the worst-case complexity of the heuristic
 algorithm for a given k will be O(n4). However, since
 our overall solution gradually computes Mk by calling the
 heuristic algorithm k times, the overall worst-case complexity
 of our solution will be O(kn4). However, in practice, since
 the sequence graphs are sparse and the matrix Mk storing
 the weights of the longest k-hop paths gets more and more
 zero elements as the k increases, we would not need to find
 maximum or search for loops in paths for every elements in
 the matrix. This results in reasonable average case complexity,
 as we demonstrate through experiments in the next section.
 V. EXPERIMENTS AND RESULTS
 In our experiments, we have two parts. In the first part, we
 analyze the actual running time of computing the matrix Mk
 in search of the (k+1)-longest super-sequence. In the second
 part, we use the actual web log dataset called BMS-WebView-
 11 to find some interesting facts by analyzing supper-sequence
 patterns in that dataset. BMS-WebView-1 contains several
 months of clicking stream data from an E-commerce website.
 As discussed in Section I, the web log data is transformed
 into a set of sequences. Each sequence is a session showing a
 1BMS-WebView-1 has been used as datasets in KDDCup 2000 competition
 and can be downloaded from The Data Mining Forum (http://forum.ai-
 directory.com).
 sequence of web pages visited by a user. The details on web
 log pre-processing are out of the scope of this paper and the
 details can be found [32] [33] [34]. In BMS-WebView-1, there
 are 59602 sessions and 497 web pages in it. For simplicity,
 we give each web page an ID starting from 0 to 496.
 A. Running Time Analysis
 To analyze the running time under different number of nodes
 in the sequence graph, we generated random dataset similar to
 web log dataset BMS-WebView-1 with ten thousand sessions
 and by changing the number of web pages from 50 to 200.
 The length of the super-sequences that are going to be searched
 ranges from 3 to 7, (since the smallest pattern has two pages
 and the initial sequence matrix shows any length 2 super-
 sequence weight). The steps for generating the random dataset
 is as shown below:
 ¥ Randomly pick a number iter between 3-7.
 ¥ Repeat iter times to randomly pick a number between 0
 to size (size is the session size which is set to 50, 100,
 150 and 200 in different experiment groups). This gives
 a sequence in the session.
 ¥ Repeat last step for 10,000 times and we get a ten
 thousand session dataset with size web pages.
 All of the experiments are run on 2.26 GHz Intel Core
 processor with 4GB memory. Fig. 6 shows the actual running.
 Fig. 6. Running time for searching longest super-sequence on randomly
 generated web log data.
 From Fig. 6, we can see that the actual running time grows
 more like a quadratic function of the number of nodes rather
 than quartic function as in the worst-case complexity. This is
 a good indication that the proposed heuristic algorithm would
 be practical for modest size datsets. However, we still need to
 improve its performance for very large datasets as we plan to
 do in our future work.
 B. Super-sequence pattern analysis
 Before analyzing the super-sequence patterns in the actual
 web log dataset, we would like to show that our heuristic
 algorithm gives almost the same longest path that a brute-
 force algorithm can find. Due to the exponential complexity of
 a brute-force algorithm, we try a small number of nodes (web
 pages) and randomly generated 10000 sessions. Each session
 56
can have less than 10 pages. By using brute force means that
 if we are looking for length k super-sequence in the dataset,
 we to generate all the permutations of a k pages out of the
 10 pages, that is also why we only have 10 pages, since large
 number of pages can be time consuming to do permutations.
 In Fig. 7 we compare the average weight of the longest super-
 Fig. 7. The total weight of the super-sequence found using brute force and
 our algorithm
 sequences that we found using our algorithm to the ones found
 using brute force method. We did five groups of experiments
 with super-sequence lengths from 3 to 7. We use letter A and
 B to for our Algorithm and Brute force, respectively. We can
 see that our algorithm give almost the correct longest super-
 sequences with minor offset.
 We will now use our heuristic algorithm on the actual web
 log dataset to find some interesting facts. In Fig. 8, we show
 the number of sequences (paths) that we found with visiting
 numbers (total weight) from 2000 to 5000 and the sequence
 length (k) varies from 5 to 10. Similarly, Fig. 9 shows the
 number of sequences that have visiting numbers from 5000
 to 8000 and the sequence length goes from 12 to 20. Both
 Fig. 8. Number of paths found for different lengths(5-10) with different
 visiting numbers
 figures confirms that, as expected, our algorithm finds more
 paths under the same visiting numbers as the sequence length
 increases. This is due to the fact that the total weight of a
 path increases as the sequence length increases. Also from
 Fig. 9. Number of paths found for different lengths(12-20) with different
 visiting numbers.
 comparing the two figures, we can see that there are a lot
 of paths (e.g., close to 30000) when path length is relatively
 long and visiting threshold is relatively small. Instead of such
 commonly appearing many paths, it would be useful to focus
 on the small number of paths having a relatively large weight
 (number of visiting). For example, in this data set, one should
 closely analyze the 6-length paths with visiting numbers larger
 than 2200, or the 10-length paths with visiting numbers larger
 than 4000.
 For example, let us consider such distinguished paths to
 investigate if there is any weakest link, which has significantly
 small number of visitings compared to other links in a frequent
 super-sequence pattern. If there are any such links, web
 designers can delete or regroup them. To identify such links,
 we calculated the deviations of the distinguished paths with
 length 3, 4 and 5. From Table II, III and IV we can see
 that the number of paths significantly decreases as the visiting
 threshold increases. Accordingly, we pick the visiting numbers
 of 1000, 1500, and 2000 to get 30, 21, and 26 distinguished
 paths, respectively.
 TABLE II
 THE NUMBER OF PATHS WITH LENGTH 3
 number of total visitings number of paths found
 >900 394
 >1000 30
 >1100 10
 >1200 7
 >1300 2
 >1400 0
 Fig. 10 shows the ordered standard deviation for the 30
 paths found in Table II. We can see that there are 4 paths with
 deviation less than 200 and 7 paths with standard deviation
 larger than 600. The rest of the paths have standard deviation
 between 200 and 600. After checking the path that has the
 smallest standard deviation, we found that the path has the
 web page sequence ?164, 0, 1?. The visitings for page 0 after
 visiting page 164 is 590 and then visitings to page 1 is 621.
 The largest deviation exists in path ?265, 281, 277?, where
 57
TABLE III
 THE NUMBER OF PATHS WITH LENGTH 4
 number of total visitings number of paths found
 >1400 106
 >1500 21
 >1600 14
 >1700 8
 >1800 6
 >1900 1
 >2000 0
 TABLE IV
 THE NUMBER OF PATHS WITH LENGTH 5
 number of total visitings number of paths found
 >1900 144
 >2000 26
 >2100 15
 >2200 8
 >2300 7
 >2400 1
 >2500 0
 the visitings are 48 and 953, respectively. Fig. 11 shows the
 ordered standard deviation for the 21 paths found in Table
 III. The smallest deviation exists at the path with web page
 sequence ?164, 0, 1, 97?. We can see that it is the same path
 before but extended with web page 97 and the visitings
 after page 1 to page 97 is 771. The largest deviation exists
 in path ?277, 281, 2, 45? and the visitings are 953, 8, 877,
 respectively. Fig. 12 shows the ordered standard deviation for
 the 26 paths found in Table IV. We found that the path that
 has the largest standard deviation has the web page sequence
 ?44, 45, 2, 277, 281? and the visitings are 290, 877, 10, 953,
 respectively. This means that visitings on web page 277 after
 users visiting page 2 has only 10 times occurring in the dataset.
 This is very few compared to other visitings in this super-
 sequence. So the designer might want to remove page 277 or
 combine its content with page 281.
 Fig. 10. Visiting numbers standard deviation for length 3 paths with total
 visitings larger than 1000
 VI. CONCLUSION AND FUTURE WORK
 In this paper, we formulated a new form of sequen-
 tial pattern mining, namely frequent super-sequence pattern
 mining. We proposed an heuristic algorithm using dynamic
 Fig. 11. Visiting numbers standard deviation for length 4 paths with total
 visitings larger than 1500
 Fig. 12. Visiting numbers standard deviation for length 5 paths with total
 visitings larger than 2000
 programming techniques.We also looked into frequent super-
 sequence patterns in an actual web log dataset from a different
 perspective. Through experiments, we demonstrated that its
 practical running time is reasonable. But there is a significant
 room for improving its quartic worst-case complexity which
 we leave it for our future work.
 In the future, we would like to scale up our method
 on large datsets, e.g., parallel algorithms on frequent super-
 sequence mining. We also would like to apply our method on
 other areas, e.g., bioinformatics dataset, to discover interesting
 characteristics based on the frequent super-sequences found.
 REFERENCES
 [1] R. Agrawal, R. Srikant et al., ÒFast algorithms for mining association
 rules,Ó in Proc. 20th Int. Conf. Very Large Data Bases, VLDB, vol. 1215,
 1994, pp. 487Ð499.
 [2] J. Han, M. Kamber, and J. Pei, Data mining: concepts and techniques.
 Morgan kaufmann, 2006.
 [3] R. Iva«ncsy and I. Vajk, ÒFrequent pattern mining in web log data,Ó Acta
 Polytechnica Hungarica, vol. 3, no. 1, pp. 77Ð90, 2006.
 [4] F. Sanger, S. Nicklen, and A. R. Coulson, ÒDna sequencing with
 chain-terminating inhibitors,Ó Proceedings of the National Academy of
 Sciences, vol. 74, no. 12, pp. 5463Ð5467, 1977.
 [5] N. Idika and A. P. Mathur, ÒA survey of malware detection techniques,Ó
 Purdue University, p. 48, 2007.
 [6] S. A. Hofmeyr, S. Forrest, and A. Somayaji, ÒIntrusion detection using
 sequences of system calls,Ó Journal of computer security, vol. 6, no. 3,
 pp. 151Ð180, 1998.
 [7] I. Sato, Y. Okazaki, and S. Goto, ÒAn improved intrusion detecting
 method based on process profiling,Ó Transactions of the Information
 Processing Society of Japan, vol. 43, no. 11, pp. 3316Ð26, 2002.
 58
[8] E. L. Lawler, Combinatorial optimization: networks and matroids.
 Courier Dover Publications, 2001.
 [9] J. S. Park, M.-S. Chen, and P. S. Yu, An effective hash-based algorithm
 for mining association rules. ACM, 1995, vol. 24, no. 2.
 [10] A. Savasere, E. R. Omiecinski, and S. B. Navathe, ÒAn efficient
 algorithm for mining association rules in large databases,Ó 1995.
 [11] H. Toivonen et al., ÒSampling large databases for association rules,Ó
 in Proceedings of the International Conference on Very Large Data
 Bases. INSTITUTE OF ELECTRICAL & ELECTRONICS ENGI-
 NEERS (IEEE), 1996, pp. 134Ð145.
 [12] S. Brin, R. Motwani, J. D. Ullman, and S. Tsur, ÒDynamic itemset
 counting and implication rules for market basket data,Ó in ACM SIGMOD
 Record, vol. 26, no. 2. ACM, 1997, pp. 255Ð264.
 [13] D. W. Cheung, J. Han, V. T. Ng, and C. Wong, ÒMaintenance of
 discovered association rules in large databases: An incremental updating
 technique,Ó in Data Engineering, 1996. Proceedings of the Twelfth
 International Conference on. IEEE, 1996, pp. 106Ð114.
 [14] R. Agrawal and J. C. Shafer, ÒParallel mining of association rules,Ó
 Knowledge and Data Engineering, IEEE Transactions on, vol. 8, no. 6,
 pp. 962Ð969, 1996.
 [15] J. Han, H. Cheng, D. Xin, and X. Yan, ÒFrequent pattern mining: current
 status and future directions,Ó Data Mining and Knowledge Discovery,
 vol. 15, no. 1, pp. 55Ð86, 2007.
 [16] J. Han, J. Pei, and Y. Yin, ÒMining frequent patterns without candidate
 generation,Ó in ACM SIGMOD Record, vol. 29, no. 2. ACM, 2000, pp.
 1Ð12.
 [17] M. J. Zaki, S. Parthasarathy, M. Ogihara, W. Li et al., ÒNew algorithms
 for fast discovery of association rules,Ó in 3rd Intl. Conf. on Knowledge
 Discovery and Data Mining, vol. 20, 1997, pp. 283Ð286.
 [18] R. Srikant and R. Agrawal, Mining generalized association rules. IBM
 Research Division, 1995.
 [19] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal, ÒDiscovering frequent
 closed itemsets for association rules,Ó in Database TheoryICDT99.
 Springer, 1999, pp. 398Ð416.
 [20] F. Zhu, X. Yan, J. Han, P. S. Yu, and H. Cheng, ÒMining colossal
 frequent patterns by core pattern fusion,Ó in Data Engineering, 2007.
 ICDE 2007. IEEE 23rd International Conference on. IEEE, 2007, pp.
 706Ð715.
 [21] R. Agrawal and R. Srikant, ÒMining sequential patterns,Ó in Data En-
 gineering, 1995. Proceedings of the Eleventh International Conference
 on. IEEE, 1995, pp. 3Ð14.
 [22] R. Srikant and R. Agrawal, Mining sequential patterns: Generalizations
 and performance improvements. Springer, 1996.
 [23] J. Han, J. Pei, B. Mortazavi-Asl, Q. Chen, U. Dayal, and M.-C. Hsu,
 Òhan2000freespan: frequent pattern-projected sequential pattern mining,Ó
 in Proceedings of the sixth ACM SIGKDD international conference on
 Knowledge discovery and data mining. ACM, 2000, pp. 355Ð359.
 [24] J. Han, J. Pei, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and
 M. Hsu, ÒPrefixspan: Mining sequential patterns efficiently by prefix-
 projected pattern growth,Ó in Proceedings of the 17th International
 Conference on Data Engineering, 2001, pp. 215Ð224.
 [25] M. J. Zaki, ÒSpade: An efficient algorithm for mining frequent se-
 quences,Ó Machine learning, vol. 42, no. 1-2, pp. 31Ð60, 2001.
 [26] M. Garofalakis, R. Rastogi, and K. Shim, ÒSpirit: Sequential pattern
 mining with regular expression constraints,Ó in Proceedings of the
 international conference on very large data bases, 1999, pp. 223Ð234.
 [27] D. Karger, R. Motwani, and G. Ramkumar, ÒOn approximating the
 longest path in a graph,Ó Algorithmica, vol. 18, no. 1, pp. 82Ð98, 1997.
 [28] C. Murat and V. T. Paschos, ÒThe probabilistic longest path problem,Ó
 Networks, vol. 33, no. 3, pp. 207Ð219, 1999.
 [29] K. Ioannidou, G. B. Mertzios, and S. D. Nikolopoulos, ÒThe longest path
 problem has a polynomial solution on interval graphs,Ó Algorithmica,
 vol. 61, no. 2, pp. 320Ð341, 2011.
 [30] K. Ioannidou and S. D. Nikolopoulos, ÒThe longest path problem is
 polynomial on cocomparability graphs,Ó Algorithmica, vol. 65, no. 1,
 pp. 177Ð205, 2013.
 [31] Y. Takahara, S. Teramoto, and R. Uehara, ÒLongest path problems
 on ptolemaic graphs,Ó IEICE transactions on information and systems,
 vol. 91, no. 2, pp. 170Ð177, 2008.
 [32] W. Bin and L. Zhijing, ÒWeb mining research,Ó in Computational Intelli-
 gence and Multimedia Applications, 2003. ICCIMA 2003. Proceedings.
 Fifth International Conference on. IEEE, 2003, pp. 84Ð89.
 [33] R. Cooley, B. Mobasher, and J. Srivastava, ÒGrouping web page refer-
 ences into transactions for mining world wide web browsing patterns,Ó
 in Knowledge and Data Engineering Exchange Workshop, 1997. Pro-
 ceedings. IEEE, 1997, pp. 2Ð9.
 [34] P. Pirolli, J. Pitkow, and R. Rao, ÒSilk from a sowÕs ear: extracting usable
 structures from the web,Ó in Proceedings of the SIGCHI conference on
 Human factors in computing systems: common ground. ACM, 1996,
 pp. 118Ð125.
 59
