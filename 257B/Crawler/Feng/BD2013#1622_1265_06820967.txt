Smart Intermediate Data Transfer for MapReduce on 
Cloud Computing 
 
Tzu-Chi Huang1 Kuo-Chih Chu2  Yu-Ruei Rao3 
Department of Electronic Engineering 
Lunghwa University of Science and Technology 
Taoyuan County, Taiwan123 
tzuchi@mail.lhu.edu.tw1 kcchu@mail.lhu.edu.tw2 hades780215@gmail.com3 
 
 
Abstract—MapReduce is a programming model proposed by 
Google to process large datasets in clusters. However, MapReduce 
often needs to transfer much intermediate data among nodes, which 
is harmful to performances of an application. MapReduce can be 
enhanced by using the proposed Smart Intermediate Data Transfer 
(SIDT) in the runtime system to smartly arrange intermediate data. 
Although SIDT does not reduce intermediate data to the minimal size 
in comparison with other intermediate data arrangement procedures 
such as Huffman coding, bzip2, and gzip, MapReduce is proved to get 
a better performance from SIDT than from others in the experiments 
of this paper. 
Keywords—SIDT; MapReduce; Intermediate Data; Cloud 
Computing 
I.  INTRODUCTION 
MapReduce [1] is a programming model proposed by 
Google to process large datasets in clusters. MapReduce has 
become the important technology on cloud computing [2] [3] 
because it allows programmers to easily develop applications 
in clusters. For applications, all MapReduce needs is 
programmers to prepare two functions (a.k.a. Mapper and 
Reducer) [1] that will be automatically distributed over nodes 
in clusters at runtime by the runtime system. 
When the runtime system works for applications, it 
provides Mappers with input data and transfers intermediate 
data [1] outputted by Mappers to Reducers. However, the 
runtime system often consumes much bandwidth in 
transferring intermediate data among nodes, which is harmful 
to performances. Because intermediate data is just for Reducers, 
the runtime system should have a proposal specially designed 
for MapReduce to reduce bandwidth consumption. Ideally, the 
runtime system can use such a proposal to reduce bandwidth 
consumption in transferring intermediate data without costing 
much CPU time as a tradeoff. 
In this paper, Smart Intermediate Data Transfer (SIDT) is 
proposed to reduce bandwidth consumption in transferring 
intermediate data from Mappers to Reducers. SIDT smartly 
arranges intermediate data when the runtime system moves 
intermediate data from Mappers to Reducers. SIDT improves 
performances without negative impacts on application results. 
SIDT keeps MapReduce intact to have high portability among 
platforms. In the experiments, SIDT outperforms the runtime 
systems that use Huffman coding [4], bzip2 [5], gzip [6], or no 
special arrangement [1] (a default in the existing runtime 
systems) to handle intermediate data. 
The remaining parts of this paper are organized as follows. 
Section 2 is the MapReduce background. Section 3 introduces 
SIDT. Section 4 has experiments. Section 5 concludes this 
paper. 
II. BACKGROUND 
MapReduce [1] mainly has two stages, i.e. the Map stage 
and the Reduce stage, in the progress of application execution. 
In the Map stage, MapReduce needs Mappers to process input 
data and output intermediate data in a format of key and value 
pairs. MapReduce relies on the runtime system to save 
intermediate data in different intermediate files according to a 
hash function based on the key of intermediate data. In the 
Reduce stage, MapReduce uses Reducers to process 
intermediate data and output parts of application results. 
Between the two stages, MapReduce relies on the runtime 
system to choose appropriate nodes, e.g. the idle ones, to run 
Reducers and transfer intermediate data from nodes on where 
Mappers run to nodes on where Reducers run. 
Word Count [1] is an application often used to explain 
MapReduce. Word Count has a Mapper to parse a document 
having words separated by space characters. For each word, 
Word Count outputs a pair of “word” and “1” as the key and 
value pair in the Mapper. In the Reducer, Word Count 
processes intermediate data grouped into different words and 
sums up the values associated with the same word as the count 
of the word. Finally, Word Count gets outputs collected by the 
runtime system from all Reducers and has the counts of all 
words appearing in the document as the application result. 
Although the runtime system may partition input data into 
different blocks before giving Mappers the block data and sort 
outputs of Reducers for an application in some MapReduce 
prototypes, we do not discuss the extra data process issues 
because they are beyond the scope of this paper. In this paper, 
we focus on how to reduce bandwidth consumption in 
transferring intermediate data from Mappers to Reducers, 
because reducing bandwidth consumption usually benefits 
performances and needs to be cared for nodes connected to 
each other with limited bandwidth in a cluster. 
2013 International Conference on Cloud Computing and Big Data
 978-1-4799-2829-3/13 $26.00 © 2013 IEEE
 DOI 10.1109/CLOUDCOM-ASIA.2013.97
 9978-1-4799-2830-9/14 $31.00 © 2014 IEE
III. SMART INTERMEDIATE DATA TRANSFER 
(SIDT) 
A. Overview 
A typical runtime system handles intermediate data as the 
way in the upper part of Fig. 1 and uses a hash function with a 
key as its parameter in order to determine the intermediate file 
for saving the key and value pair. When the intermediate file 
reaches a certain size, a typical runtime system sends it to a 
Reducer on an idle node over networks. Generally, a typical 
runtime system directly saves intermediate data produced by 
Mappers in intermediate files without any further processing. 
 
Fig. 1, SIDT Overview 
In the lower part of Fig. 1, SIDT uses SIDT Encoder at one 
side to translate intermediate data into SIDT Metadata before 
sending it to nodes over networks. SIDT can save bandwidth 
because SIDT Metadata usually is smaller than intermediate 
data. At the other side, SIDT uses SIDT Decoder to restore 
SIDT Metadata to intermediate data before handing over it to a 
Reducer. SIDT uses an algorithm specifically designed for 
processing intermediate data without costing much CPU time. 
Accordingly, SIDT can improve performances by reducing 
bandwidth consumption in networks. 
B. SIDT Encoder 
SIDT Encoder translates intermediate data into SIDT 
Metadata that has a smaller size. SIDT Encoder arranges 
intermediate data and targets redundant keys appearing in it. 
SIDT Encoder slightly uses CPU time to greatly shorten 
intermediate data size in order to reduce bandwidth 
consumption when intermediate data is transferred among 
nodes. 
 
Fig. 2, SIDT Encoder Components 
SIDT Encoder has four components as shown in Fig. 2, i.e., 
Key Lookup Module, Table Update Module, Data Flush 
Module, and Key Lookup Table. SIDT Encoder builds Key 
Lookup Table that uses a different key as a record entry and a 
list of records having values associated with the same key. 
SIDT Encoder uses Key Lookup Module to compare keys in 
intermediate data and those in Key Lookup Table. SIDT 
Encoder calls Table Update Module to add a new record entry 
and related records to Key Lookup Table for a new key and 
value pair found by Key Lookup Module in intermediate data. 
SIDT Encoder uses Data Flush Module to both create SIDT 
Metadata according to Key Lookup Table and save it in 
intermediate files. 
 
Fig. 3, Translating Intermediate Data into SIDT Metadata 
SIDT Encoder translates intermediate data as shown in Fig. 
3. SIDT Encoder updates records in Key Lookup Table for 
each pair of key and value found in intermediate data, and 
creates a record entry with the newly found key on demand. 
Next, SIDT Encoder merges the values associated with the 
same key in Key Lookup Table and translates them into SIDT 
Metadata. If a key or value has the separate character that is 
designed for distinguishing a key and each of its values from 
SIDT Metadata, SIDT Encoder appends an extra separate 
character to the original one. Finally, SIDT Encoder uses a 
newline character to separate keys and their values as groups. 
C. SIDT Decoder 
SIDT Decoder restores SIDT Metadata to intermediate data 
before handing over it to the runtime system. SIDT Decoder 
extracts keys and their values from SIDT Metadata and 
translates them back to the original format of intermediate data. 
In other words, SIDT Decoder executes the reverse procedures 
in Fig. 3. After SIDT Decoder restores and hands over 
intermediate data to the runtime system, the runtime system is 
not aware of the intermediate data translation made by SIDT 
Encoder for transferring intermediate data over networks. 
 
Fig. 4, SIDT Decoder Components 
SIDT Decoder has only two components as shown in Fig. 
4, i.e. Group Scan Module and Data Restore Module. SIDT 
Decoder uses Group Scan Module to locate a key and its values 
in SIDT Metadata. Next, SIDT Decoder uses Data Restore 
Module to restore the key and its values in the format of SIDT 
Metadata to a series of key and value pairs in the format of 
intermediate data. Technically, SIDT Decoder uses Data 
10
Restore Module to restore intermediate data according to the 
reverse procedures in Fig. 3. 
IV. EXPERIMENT 
A. Configurations 
 
Fig. 5, Experiment Configurations 
We use PHP (short for Hypertext Preprocessor) [7] to 
develop a runtime system named PHPMR because PHP is a 
widely-used general-purpose scripting language especially 
suited for Web development. We make PHPMR capable of: 1) 
reading input files from a local disk, 2) locating an idle node to 
run Mappers, 3) distributing input files over Mappers, 4) 
locating an idle node to run Reducers, 5) transferring 
intermediate data from Mappers to Reducers, and 6) collecting 
outputs from Reducers as the application result. For 
experiments, we use PHP to develop SIDT and two 
applications as well to work with PHPMR at nodes. We make 
PHPMR call SIDT Encoder just before saving intermediate 
data in intermediate files. Conversely, we make PHPMR call 
SIDT Decoder before sending intermediate data to Reducers. 
Besides observing performances of PHPMR with SIDT, we 
observe performances of PHPMR that uses Huffman coding 
[4], bzip2 [5], gzip [6], or no special arrangement (i.e. the 
native case) for handling intermediate data. To this end, we 
simply replace SIDT Encoder and SIDT Decoder with the 
encoding and decoding functions of other intermediate data 
arrangement procedures in different experiments. In 
experiments, we prepare several identical PCs connected to 
each other via Gigabit Ethernet. We detail their configurations 
in Fig. 5. 
B. Overhead Breakdown 
We want to observe SIDT overheads. To this end, we 
develop a dummy application that has a Mapper and a Reducer 
both to do nothing more than outputting identical data when 
receiving input data or intermediate data. We provide the 
dummy application with an input file that has totally different 
words to occupy 80 bytes. In Fig. 6, we show the overhead of 
each procedure used in PHPMR with SIDT for the dummy 
application to process the input file. For comparison, we also 
show native overheads of certain procedures without SIDT in 
Fig. 6. 
We observe that the dominant factor is the native overhead 
of the job partition procedure but it will not affect 
performances as much as the procedures of reading input data 
and getting intermediate data because they are in proportion to 
the quantity of data processed by an application. We note that 
SIDT hardly has a negative impact on performances and 
furthermore may have a chance to improve performances. For 
example, we note that the emit function with SIDT can 
outperform the native emit function about 30.79% (i.e. (0.867-
 0.6)/0.867) because SIDT can arrange intermediate data to 
reduce its size in order to shorten the delay of disk I/O in a 
node. 
 
Fig. 6, SIDT Overhead Breakdown 
C. Performance of Word Count 
 
Fig. 7(a), Word Count Performance on Repeated Input Data with Different 
Mapper Numbers 
In the following subsection, we observe performances of 
two typical applications when different intermediate data 
arrangement procedures are taken. For comparison, we also 
observe the case that takes no special arrangement for handling 
intermediate data and refer to it as the native case. We test an 
application with different numbers of Mappers and Reducers 
and limit each PC in the cluster to running either a Mapper or a 
Reducer, in order to clearly observe the performance impacts 
of Mapper and Reducer numbers and bandwidth consumption. 
In order words, we test an application with one Reducer and 
11
multiple Mappers, and then we test the application with one 
Mapper and multiple Reducers. 
At runtime, we provide an application with input data from 
a PC as the role of the Master without using any distributed file 
system. We respectively input repeated data and non-repeated 
data. We let PHPMR automatically and arbitrarily distribute 
Mappers and Reducers of an application to PCs in a cluster 
over networks. Finally, we let PHPMR collect outputs of 
Reducers from all PCs in the cluster. We observe time and 
intermediate data that an application costs in the entire 
execution procedure, i.e., the reception of input data, the 
process of data with Mappers and Reducers, and the collection 
of outputs from Reducers. 
 
Fig. 7(b), Word Count Performance on Repeated Input Data with Different 
Reducer Numbers 
First, we observe performances of Word Count [1] because 
it is a canonical application often used in performance 
evaluation of MapReduce runtime systems. In Word Count, we 
program a Mapper to emit to disks a string “word 1” for each 
word in input data provided by PHPMR. Besides, we program 
a Reducer to merge groups of words in intermediate data 
collected by PHPMR from the corresponding Mappers 
according to a key-length-based hash function. Finally, we 
record the execution time and bandwidth consumed by 
transferring intermediate data among nodes. We test the 
application respectively with a 100 MB input file having 
repeated data and a 100 MB input file having non-repeated data. 
In Figs. 7(a) and 7(b), we observe that increasing Mappers 
and Reducers both can improve performances of Word Count 
in processing repeated input data. Because Word Count can 
process more input data with multiple Mappers, we observe in 
Fig. 7(a) that increasing Mappers can get more performance 
gains than increasing Reducers. We observe that SIDT 
outperforms other intermediate data arrangement procedures, 
although SIDT does not compress intermediate data to the 
minimal size. For example, we observe in Fig. 7(b) that SIDT 
can use 1 Mapper and 7 Reducers to improve 40% (i.e. (188-
 111)/188 = 41%) performance of the native case but gzip only 
can improve 3% (i.e. (188-183)/188 = 3%) performance. 
Although bzip2 and gzip can compress intermediate data to a 
size much smaller than SIDT, we observe that their high 
computation overheads can not make them get performances 
better than SIDT. Similarly, we note that Huffman coding 
seriously degrades performances of the native case due to the 
high computation overhead. 
 
Fig. 8(a), Word Count Performance on Non-Repeated Input Data with 
Different Mapper Numbers 
 
12
Fig. 8(b), Word Count Performance on Non-Repeated Input Data with 
Different Reducer Numbers 
When testing Word Count with non-repeated input data in 
Figs. 8(a) and 8(b), we observe that SIDT works as efficiently 
as other intermediate data arrangement procedures, even 
though SIDT generates intermediate data similar to the native 
case. Because a Mapper can not generate intermediate data 
compressible to SIDT when processing non-repeated input data, 
we are not surprised by the phenomenon that SIDT arranges 
intermediate data similar to the native intermediate data in 
transmission. Although bzip2 and gzip can compress 
intermediate data very well, we observe that their performances 
just are slightly improved due to high computation overheads. 
Nevertheless, we show that SIDT sill can maintain 
performances in processing non-repeated input data even 
though Mappers can not generate intermediate data 
compressible to SIDT. According to Figs. 7 and 8, we note that 
all intermediate data arrangement procedures can get better 
performances in processing repeated input data than non-
 repeated input data, because the runtime system costs less time 
in collecting the application result of repeated input data than 
that of non-repeated input data. 
D. Performance of Quick Sort 
 
Fig. 9(a), Quick Sort Performance on Repeated Input Data with Different 
Mapper Numbers 
In this subsection, we observe performances of Quick Sort 
[8] with different intermediate data arrangement procedures. In 
Quick Sort, we implement a Mapper to process input data and 
save intermediate data into different intermediate files 
according to the digit of a number. We implement a Reducer to 
sort its corresponding intermediate data with the Quick Sort 
algorithm [8]. We expect that the application costs much CPU 
time in Reducers because Mappers merely classify numbers 
according to their digits. We test the application respectively 
with a 100 MB input file having repeated data and a 100 MB 
input file having non-repeated data. 
 
Fig. 9(b), Quick Sort Performance on Repeated Input Data with Different 
Reducer Numbers 
According to Figs. 9(a) and 9(b), Quick Sort can get a 
better performance by increasing Reducers than by increasing 
Mappers because increasing Reducers can alleviate 
computation overheads. When processing repeated input data, 
Quick Sort gets the best performance with SIDT by saving 
much bandwidth consumption in transferring intermediate data. 
For example, we observe in Fig. 9(b) that SIDT can use 1 
Mapper and 7 Reducers to improve 30% (i.e. (218-153)/218 = 
30%) performance of the native case, which is much better 
than other intermediate data arrangement procedures. Although 
bzip2 and gzip can reduce intermediate data more than SIDT, 
Quick Sort hardly gets many performance improvements from 
them because they cost much time in compressing and 
decompressing intermediate data. 
We show results of processing non-repeated input data in 
Figs. 10(a) and 10(b). According to the curves, we know that 
increasing Reducers still improves performances much more 
than increasing Mappers when Quick Sort processes non-
 repeated input data. Although SIDT does not reduce 
intermediate data to the minimal size because no intermediate 
data is compressible to SIDT, we observe that SIDT still 
maintains performances close to bzip2, gzip, and the native 
case. According to Figs. 9 and 10, we observe that Quick Sort 
gets better performances with all intermediate data 
arrangement procedures in processing repeated input data than 
in processing non-repeated input data, because Reducers cost 
more time to search arrays and sort non-repeated numbers. 
In brief, we show that SIDT is a practicable intermediate 
data arrangement procedure and better than other intermediate 
data arrangement procedures such as Huffman coding, bzip2, 
and gzip in experiments because: 1) SIDT can compress 
intermediate data to a certain degree but outperform other 
intermediate data arrangement procedures when processing 
13
repeated input data; and 2) SIDT can maintain performances 
close to bzip2, gzip, and the native case without degrading 
performances when processing non-repeated input data. 
  
Fig. 10(a), Quick Sort Performance on Non-Repeated Input Data with Different 
Mapper Numbers 
 
Fig. 10(b), Quick Sort Performance on Non-Repeated Input Data with Different 
Reducer Numbers 
V. CONCLUSION 
In this paper, we propose Smart Intermediate Data Transfer 
(SIDT) to reduce bandwidth consumption in transferring 
intermediate data from Mappers to Reducers. We use SIDT to 
arrange intermediate data when the runtime system moves 
intermediate data from Mappers to Reducers. By compressing 
intermediate data without costing much CPU time, we use 
SIDT to successfully improve performances without negative 
impacts on application results. Because of keeping MapReduce 
intact without any modification, we make SIDT and 
MapReduce applications portable to various platforms. For 
verifying practicability of SIDT, we implement SIDT on a 
MapReduce runtime system to help Word Count and Quick 
Sort process repeated input data and non-repeated input data. In 
the experiments, we show that SIDT outperforms other 
intermediate data arrangement procedures such as Huffman 
coding, bzip2, and gzip in processing repeated input data and 
non-repeated input data because: 1) SIDT compresses 
intermediate data to a certain degree but outperforms other 
intermediate data arrangement procedures when processing 
repeated input data; and 2) SIDT maintains performances close 
to bzip2, gzip, and the native case without degrading 
performances when processing non-repeated input data. 
Accordingly, we are convinced that SIDT can improve 
performances of MapReduce applications in clusters by 
reducing intermediate data without negative impacts on 
application results. 
ACKNOWLEDGMENT 
We thank the National Science Council of Taiwan for their 
support of this project under grant number NSC 102-2221-E-
 262-014. We thank Lunghwa University of Science and 
Technology for providing us with devices. We further offer our 
special thanks to the reviewers for their valuable comments and 
suggestions. 
REFERENCES 
[1] J. Dean, S. Ghemawat, "MapReduce: Simplified Data Processing on 
Large Clusters", Communications of the ACM, Volume 51, Issue 1, 
2008, pp. 107-113 
[2] S. P. Ahuja, A. C. Rolli, "Survey of the State-of-the-Art of Cloud 
Computing", International Journal of Cloud Applications and 
Computing, Volume 1 Issue 4, 2011, pp.34-43 
[3] B. P. Rimal, E. Choi, I. Lumb, "A Taxonomy and Survey of Cloud 
Computing Systems", in Proceedings of Fifth International Joint 
Conference on INC, IMS and IDC, 2009, pp. 44-51 
[4] M. Sharma, "Compression Using Huffman Coding", IJCSNS 
International Journal of Computer Science and Network Security, Vol. 
10, No. 5, 2010, pp. 133-141 
[5] D. S. Hirschberg, D. A. Lelewer, "Efficient Decoding of Prefix Codes", 
Communications of the ACM, Vol. 33, Issue. 4, 1990, pp. 449-459 
[6] M. F. Nowlan, B. Ford, R. Gummadi, "Non-linear compression: Gzip 
Me Not!", in Proceedings of the 4th USENIX conference on Hot Topics 
in Storage and File Systems, 2012, pp. 11-11 
[7] S. Trent, M. Tatsubori, T. Suzumura, A. Tozawa, T. Onodera, 
"Performance comparison of PHP and JSP as server-side scripting 
languages", in Proceedings of the 9th ACM/IFIP/USENIX International 
Conference on Middleware, 2008, pp. 164-182 
[8] C. A. R. Hoare, "Quicksort", the Computer Journal, Vol. 5, Issue 1, 
1962, pp.10-16 
14
