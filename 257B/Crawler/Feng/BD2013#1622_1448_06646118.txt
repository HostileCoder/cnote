Contradiction Detection between Opinions 
From a Big Data perspective 
 
Bogdan Vancea, Alexandru Marchis, Mihaela Dinsoreanu and Rodica Potolea 
Department of Computer Science, Technical University of Cluj-Napoca, Cluj-Napoca, Romania 
bogdan.aurel.vancea@gmail.com, alexmarchis90@gmail.com, {Mihaela.Dinsoreanu; Rodica.Potolea}@cs.utcluj.ro 
 
 
 
 
 
Abstract— This paper offers a solution to the problem of  
detecting contradictions among opinions on the same topic. The 
opinions are extracted from a large number of unstructured 
documents and stored in a structured format. Due to the increase 
in data available for analysis, we focus on providing a 
storage/retrieval and analysis solution suitable for managing 
large quantities of data while maintaining the speed and 
reliability present in smaller scale systems. Our approach 
consists in building a distributed system able to scale horizontally 
with the increase in input data without any significant 
performance decay. We represent opinions in a tuple based 
structured model, more suitable for retrieval and analysis. This 
approach allows us to formalize an algorithm for detecting 
contradictions between opinion tuples. Furthermore, we present 
a method for improving the recall of the system by using 
synonyms for the opinion target to expand the set of possible 
contradicting opinions. Our main focus is to optimize the 
structure of the opinion tuple to provide the best retrieval time 
and to allow for a simple, structured approach for detecting 
contradictions.  
Keywords— scalability, big data, information retrieval, 
contradiction detection, opinion. 
I.  INTRODUCTION  
As corporations grow larger it is hard to keep track of the 
consistency in the opinions expressed by the employees in 
time. As the number of documents written by employees to 
express opinion and the number of meeting transcripts grow 
very large, the possibility to detect contradictions in opinions 
by human analysis disappears. Therefore, automated detection 
of inconsistencies in opinions, or contradictions, is essential. 
Inconsistencies found in opinions expressed in the politics field 
or in the legal domain might also make a difference by 
detecting fraud and other misdeeds and help in bringing a 
better interpretation to facts. 
The purpose of our work is detecting possible 
contradictions between opinions extracted from a very large 
corpus of opinionated documents. These documents can be 
large documents in the form of articles or short documents 
originated from social networks. Our main objectives are: to 
provide an efficient structured manner for storing the opinions 
existing in the documents and to ensure good response time for 
both detecting contradictions and for opinion search and 
retrieval. Due to the fact that the original opinionated 
documents offer unstructured information, we used a tuple-
 based structured representation for the opinions. The advantage 
of such a representation is that it allowed us to define a 
straightforward algorithm for contradiction detection between 
two or more opinions. We have focused on providing real-time 
contradiction detection while maintaining an acceptable 
accuracy. The contradiction detection system that we have 
envisioned will perform a coarse grained analysis on the 
opinions and prioritize the most common and most obvious 
cases of contradictions. However, our solution allows for a 
more fine-grained, text based contradiction detection system to 
be used to further analyze the contradictions detected and 
validate or invalidate them. Our second objective is to obtain 
good response times when searching for existing opinions and 
when detecting contradicting opinions for one or more opinions 
extracted from new documents. This led us to focus on 
improving the response time of the system for retrieval-
 oriented tasks. We therefore propose a scalable storage and 
retrieval solution that allows for near real-time opinion analysis 
in order to provide the contradictory opinions. To ensure faster 
retrieval, we use an external index, which will be used for the 
searching tasks. 
The rest of the paper is organized as follows. In section II, 
we review the current trends in Information Retrieval and Big 
Data analysis and present related work which has been done in 
the domain of contradiction detection. In section III we 
describe our approach and the main flows of the system 
described. The results we obtained by evaluating our system 
are presented in section IV. Finally, in section V we conclude 
the paper. 
II. RELATED
  WORK 
One can define Information Retrieval as the act of finding 
information sources that satisfy a certain information need 
from a large collection. With the evolution of search engines 
and the internet, information retrieval is rapidly becoming one 
of the most common manners to access information. In [1], the 
authors describe various approaches for designing and 
implementing information retrieval systems. There are a 
number of Information Retrieval models that are used today. 
The simplest and most commonly used model is the Boolean 
retrieval model, in which the documents are grouped in two 
categories with respect to the query, the documents that match 
259978-1-4799-1494-4/13/$31.00 ©2013 IEEE
the query, or the result of the query, and the documents which 
do not match the query. This model can be extended by using 
term weighting techniques to obtain a measure of the relevance 
of a document with respect to the query. Other techniques that 
can be used to enhance the retrieval are relevance feedback and 
query expansions. Finally, probabilistic techniques can be used 
to compute the probability of a document to be relevant to an 
input query. This probability can be used as a score in ranking 
the documents when providing the response to the query. 
Evaluating the performance of an Information Retrieval is 
influenced largely by the user utility of the system response. 
User happiness is the key measure of user utility. While user 
happiness is largely correlated with the user interface design 
and its responsiveness, some quantifiable factors like the speed 
of the response and the size of the index also influence user 
happiness. The relevance of the response is another important 
factor, due to the fact that the user will not be impressed by fast 
responses that return irrelevant information.   
In the recent years, there has been increasingly more 
research focusing on Information Retrieval and Big Data. As 
the available data amount increased, scalability has become a 
vital requirement for any system performing operations on 
data. In [5], the authors present the Google File System (GFS), 
a file system intended for large distributed data-intensive 
applications. Their main objective was to obtain high 
performance and fault tolerance while running the file system 
on a very large number of commodity hardware machines. 
Based on the assumption that inexpensive commodity 
components fail often, the file system is able to monitor itself, 
detect failures and recover. 
A similar system, The Hadoop Distributed Files System 
(HDFS) is presented in [6]. As opposed to GFS, a proprietary 
system, HDFS is open source and has been reported to be 
successfully used for datasets of PB scale. 
The evolution of these distributed file systems has 
determined the evolution of NoSQL data stores. Such data 
stores differ from the relational database as they do not enforce 
a fixed schema onto the data and can be easily scaled 
horizontally. BigTable, a distributed data store based on the 
GFS is presented in [4]. BigTable is designed to scale reliably 
to PB of data and thousands of machines. This data store is a 
sparse, distributed, persistent, multi-dimensional map. The map 
is indexed by a row key, a column key and a timestamp, and 
each value in the map is represented as an array of bytes. Each 
row can be partitioned in groups of columns called tablets, 
which can be stored in different locations. The system proposes 
a Master/Slaves architecture, where data is stored on Tablet 
Servers, while Master servers are responsible for monitoring 
the available Tablet servers.  
Due to the fact that our work is focused in both big data 
analysis and contradiction detection, we will shortly present the 
latest research in the field of sentiment analysis and 
contradiction detection. 
Bing Liu [3] has done some extensive work in the area of 
sentiment analysis and opinion mining. He has described 
several approaches for opinion extraction and has also 
proposed a model used for opinion summarization.  
In [7], the authors present a method for detecting 
contradictions based on negation, antonymic, semantic and 
pragmatic information associated with the discourse relations. 
Another approach for detecting contradictions, based on 
linguistic analysis and alignment between sentence graphs is 
presented in [8]. However, both of these approaches, although 
efficient, are fine-grained and rely and on intensive text 
processing. 
We have decided on storing the opinions extracted from 
documents in the form of tuples consisting of their most 
important features. This approach reduces the size of the data 
that needs to be stored and allows us to analyze/process 
structured data for contradiction detection and therefore to 
decrease the processing time significantly as opposed to 
processing text representations of opinions. 
III. SYSTEM
  DESCRIPTION 
A. Concepts and terms 
From the logical point of view, an opinion is a belief about 
facts or entities, usually viewed as being subjective. An 
opinionated sentence has a form similar to the following 
sentence: 
John likes the display of the camera. 
Considering the above sentence, one can extract several 
grammatical entities. In this example, John represents the 
opinion holder, or the entity that expresses certain beliefs. The 
entity on which the opinion is expressed is the camera. This 
entity can have more attributes, also called aspects, on which 
sentiments can be expressed. In the example presented above, 
the display represents an attribute of the entity camera. The 
actual sentiment that defines the opinion is given by the word 
likes, which we will call the sentiment word. This sentiment 
word also gives a polarity to the opinion. 
These terms can be used to structure any opinion from a 
given text to a tuple of the form: 
  h, e, a, so, sw  
 In (1), h represents the opinion holder, e represents the 
entity, and a represents the attribute that describes the entity. 
The entity and the attribute of the entity can be grouped 
together and thus, the group (e, a) can be viewed as the opinion 
target. The sentiment word is given by sw, which also 
determines the polarity or sentiment-orientation. We have 
quantified the sentiment orientation as a real value between -1 
and 1, following the model presented in [3]. This would imply 
that positive opinions would have a sentiment orientation close 
to 1 while negative opinions would have a sentiment 
orientation closer to -1. A value close to 0 of the sentiment 
orientation will coincide to neutral opinions. 
To further describe the opinion, we also add the document 
identifier, which is a generated string that uniquely identifies 
the document, and the time ts at which the opinion was 
expressed to the tuple. 
260
A problem that arises when attempting to formally 
represent opinions is that individuals can use different words 
when expressing opinions on certain targets. For example, the 
same user can express two different opinions on the same 
concept, but the use of different, synonymic, expressions for 
the same concept will cause the system to fail to detect the 
contradiction. We address this problem by extending the 
opinion tuple with a set of target expansions. Thus, each target 
has an associated set of pairs of the form (tik,dk). tik represents a 
synonym of  the target ti, while dik  is a real value bound in the 
interval [0,1], representing the strength of the synonymy 
relationship between ti and  tik. A distance of 0 would imply 
perfect synonymy, while a distance of 1 would imply that ti and 
tik are totally unrelated. 
 Ti=[(ti1,di1), (ti2,di2),…, (tin,din)] 
 We refer to the set Ti as the set of target expansions of an 
opinion Oi. Another observation that can be made is that the 
same procedure can be applied for sentiment words. 
Therefore, we extend the representation of the opinion further 
using the set Si of sentiment word expansions.  
 Si=[(swi1,di1), (swi2,di2),…, (swin,din)] 
 For each opinion tuple, the sets T and S are stored in the 
repository.  
B. System architecture  
 Our approach for solving the problem is represented in the 
diagram in Fig 1. The two central modules marked with red 
will be described in this paper as a storage and opinion analysis 
solution integrated in the contradiction detection system. The 
Repository is the core of the system providing data 
management services while ensuring high availability and 
scalability. The Opinion Extraction Module extracts a set of 
opinions for each document received as input and passes them 
to the Repository and the Contradiction Detection Module for 
storing and processing purposes. The Expansion Module will 
work offline to provide close synonyms to the entities and 
sentiment words of stored opinions, which will be stored as 
different versions of the same opinion. The distances di, 
corresponding to each synonym will also be provided by the 
Expansion Module. The Community Detection and 
Contradiction Detection module uses the opinion data stored in 
the repository perform clustering on the set of opinion holders 
and opinions on those clusters. The Text Based Contradiction 
Detection module used text-based techniques to validate the 
contradiction detected by the Contradiction Detection module. 
These last two modules are part of the whole system, but are 
not relevant for the functionality discussed in this paper. 
 Given a new opinion, the Contradiction Detection module 
will extract the set of contradicting opinions of the same holder 
and on the same target. Due to the real-time constraint, only 
shallow contradiction detection is possible, therefore marking 
the relation between the input opinion and each of the 
contradiction opinions as suspected contradictions. The pairs of 
opinions, considered suspected contradictions, are further 
evaluated, by another module in the system, offline, using more 
 
Fig 1. Proposed architecture 
261
time consuming techniques to give more accurate results and 
validate or invalidate the suspected contradictions. 
 For storing the opinions and documents, we propose an 
approach that is optimized for retrieval  response time. The 
repository will integrate an indexing mechanism to increase the 
performance in terms of response time. To allow the repository 
to gracefully handle a large number of documents, we consider 
using a distributed database. 
  
C. System flows 
     The functionality of the system, viewed through the main 
flows, is presented in the following section. 
1) Opinion Search Flow 
In addition to contradiction detection, the Repository can be 
used to manage and analyze previously stored opinions. Some 
example use cases are: retrieving all opinions on a certain 
target or the opinions that contain a certain sentiment word. 
Such queries can be resolved by simply retrieving opinion 
tuples with the same target and the same word. To improve the 
recall for the cases when users refer to the same targets by 
using synonymic expressions, the input target can be matched 
against the set Ti of previously stored tuples. The input 
sentiment word can also be matched against the sets Si.  
2) Storing expansions flow 
At discrete time intervals, the Query Expansion module 
will be notified to check the repository for new opinions 
(marked as not-expanded) with new targets. It retrieves the set 
of new opinions and returns a sets T and S for each 
unexpanded opinion oi. These sets are then stored in the 
repository to increase the recall for the contradiction detection 
operations. 
 
3) Contradiction Detection Flow 
 The contradiction detection flow consists of finding and 
retrieving opinions that are suspected to be contradictory to an 
input opinion. If we consider the holder and target of the input 
opinion a query, we can view the task of finding contradicting 
opinions as an opinion retrieval task.  
 A set of opinion tuples [o1,o2,...,on], which has been mined 
from new documents by the Opinion Extraction module, is 
passed to the Contradiction Detection module, but will also be 
stored in the repository for further use. Further on, the 
Contradiction Detection module takes each opinion from the 
set and compares it with contradiction candidate opinions 
retrieved from the repository which have the same holder and 
the same target, to detect the possible contradictions. The pairs 
of opinions are compared and only the ones with a difference 
in the sentiment orientation above a threshold are kept: 
 | sok  - soi  | > thresh 
  
For example, applying (4), if soi and sok represent the 
sentiment orientations of the opinions oi and ok, the two 
opinions are marked as suspected contradictions. The sentiment 
orientation of an opinion can take values from the [-1, 1] 
interval. If the signs of two sentiment orientations 
corresponding to two opinions, which refer to the same target, 
are different, then there is a greater chance that the opinions are 
contradicting. For example if we consider the following two 
sentences and their corresponding opinion tuples: 
Jenny thinks that bicycles are an excellent means of 
transportation in large cities. 
(h: Jenny, e: bicycles, sw: excellent, so: 0.9) 
Jenny thinks that bicycles are a good means of 
transportation in large cities. 
(h: Jenny, e: bicycles, sw: good, so: 0.3) 
For the above pair of opinion tuples and a threshold of 0.6, 
the system will detect a contradiction. This is not accurate, 
because considering a bicycle to be “good” is included in 
considering a bicycle to be “excellent”, so it is just a partial 
reconfirmation of the same statement. Considering the same 
threshold of 0.6 and this pair:  
(h: Jenny, e: bicycles, sw: good, so: 0.3)  
(h: Jenny, e: bicycles, sw: bad, so: -0.3) 
 the system will detect a contradiction, but this time it will 
be correct. A threshold of value 1 would help to eliminate the 
possibility of these errors to occur as no pairs of sentiment 
orientations with the same sign will be marked as 
contradictions. The opinions which have a sentiment 
orientation close to zero are considered neutral or objective and 
should not be taken in consideration when searching for 
contradictions as they may result in false positive 
contradictions. An example of such a neutral opinion would be: 
Jenny realized that bicycles have two wheels. 
(h: Jenny, e:bycicles, a: -, so: 0.0, sw: realized ) 
 By choosing a threshold value of 1, we reduce the chance 
to obtain false positives determined by the neutral opinions, 
because even if an opinion is considered fully positive – with a 
sentiment orientation of 1 – a contradiction will be detected an 
opinion is found to have a sentiment orientation smaller than 0. 
 
Fig 2. Contradiction detection flow 
262
The strength of a contradiction, which refers to the level of 
certainty that two opinions contradict each other, can be 
controlled by the value of the threshold. A higher threshold, 
such as 1, will provide fewer, stronger contradictions and will 
possibly omit more subtle contradictions, while a lower 
threshold such as 0.6 will detect the subtle contradictions but 
might also introduce some false positives. 
To improve the recall, we can also match the target of the 
input opinion against the target expansions sets Ti of the 
opinions in the repository. For each match, one would need to 
modify the sentiment orientation of the opinion oi from  the 
repository by the distance dik corresponding to the target 
expansion tik before subtracting from the input opinion 
sentiment orientation and comparing to the threshold. 
 | so
   
- (soi  - dik)  | > thresh 	
   
 The pseudocode for the contradiction detection operation is 
described in Fig. 3, through the procedure CONTRADICTION-
 DETECTION(O, n).  
The input set O represents the set of new opinions mined 
from the new document. At lines 6, the RETRIEVE-
 CANDIDATES(h,t) procedure receives as arguments the holder 
and target of each new opinion. The function retrieves existing 
opinion tuples stored in the repository that have the same 
holder h and the same target t to form the set Candidates of 
opinions candidate for contradiction. To further increase the 
search space for candidate opinions, existing opinions having 
the same holder and do not have the same target t, but have t in 
the set T of target expansions, are also added to the Candidates 
set. The DISTANCE-TEST is applied on all the pairs formed 
between the new opinion and each opinion from the 
Candidates set to discriminate between the candidates which 
are actually contractions and those that are not. This function 
can use either one of the tests presented in equations (4) and 
(5). 
The opinions from the repository for which the sentiment 
orientation is larger than sentiment orientations of opinions 
from new documents by the threshold thresh will the form the 
Contradictions set of possible contradictions.  
 Contradictions = [ck1, ck2,..., ckn ] 

  
Thus, for each input opinion ok of the set O and its 
corresponding Contradictions set, a set of pairs of the form       
[ [ ok, ck1], [ ok, ck2],…,[ ok, ckn] ] is created. This set of pairs can 
be viewed as a graph, where opinions represent vertices and 
each pair represents a “suspected contradiction” edge”.  
IV. METHODS AND EXPERIMENTS 
A. Experimental setup description 
Our solution for modeling the repository consists of a 
distributed NoSQL database and a separate indexing server. 
We chose a NoSQL database over an SQL relational database 
due to the fact that NoSQL databases do not suffer from the 
performance penalty induced by joins when dealing with large 
volumes of data. Due to the distributed architecture and storage 
model, NoSQL databases provide the possibility to scale 
horizontally. This means that an increasing volume of data can 
be easily handled by simply adding more data nodes, compared 
with relational databases, which require better hardware and 
are much harder to scale. 
 We have used HBase, a distributed column oriented 
database for storing all the data in the system. This includes all 
the opinion tuples, all the documents from which the opinions 
were extracted and the contradiction graph. 
 To increase the performance we stored the opinions in a 
separate index. We have chosen Apache Solr for implementing 
the opinion index. Our implementation allows the distribution 
of the index over a larger number of machines. The index is 
split in a number of logical partitions, also called shards. 
Distributing the index allows us to gracefully scale the retrieval 
time when the number of total opinions in the system is 
increased.  
 To prevent the index from becoming too big to affect the 
search times, we have decided to limit indexing to opinions. 
This is mainly due to the fact that it is desirable to keep as 
much of the documents indexed in the computer main memory 
and avoid the penalty of disk input/output operations.  By only 
storing the fields of the tuple that are either used for querying 
or for the contradiction detection flow, we can decrease the 
space required for storing an opinion in the index and thus 
allow more opinions to be stored on the same space 
dimensions.  
 A complete list of the  tools we chose for the 
implementation are: 
 (1) Apache HBase. This distributed datastore provides high 
performance and scalability when dealing with very large data, 
billions of rows and millions of columns.  
 (2) Hadoop File System (HDFS) is required for configuring 
HBase to run in a distributed fashion. 
CONTRADICTION-DETECTION(O, n) 
1. Contradictions = []; 
2. for i = 1 to n 
3.   s = SENTIMENT-ORIENTATION(O[i]) 
4.   h = HOLDER(O[i]); 
5.   t = TARGET(O[i]); 
6.   Candidates = RETRIEVE-CANDIDATES(h,t) 
7.   for j = 1 to SIZE(Candidates) 
8.    so=SENTIMENT-ORIENTATION(Candidates[j]) 
9.    if DISTANCE-TEST(so,s) then 
10.      ADD(Contradictions, O[i], Candidates[j]) 
11.  Return Contradictions. 
Fig 3. Pseudocode for Contradiction Detection 
263
 (3) Apache Zookeeper is an orchestration framework used for 
coordinating and maintaining the database cluster. 
 (4) Apache Solr will be used as an external indexing server and 
will allow complex lookups on the data. 
 (5) The SpringData project is used for accessing the HBase 
functionalities in the Java programming language.  
 The communication with the Repository will be made through 
a REST API, which will create very little coupling between the 
repository and modules that will access it. 
B. HBase Experiments 
In order to perform these experiments, we implemented the 
HBase database using two servers which have been deployed 
in the cloud. These servers have the following specifications: 
10 GB of HDD memory, 2 GB of RAM, a single CPU core, 
Ubuntu Linux 12.04 OS and a fast network connection, which 
provided a smooth communication between the servers. 
The HBase implementation requires a Hadoop Distributed 
File System (HDFS) to store the data files on and also an 
instance of HBase. The HDFS has been configured as follows: 
the first server has the responsibilities of a master as well as a 
slave, while the second server had only slave responsibilities.   
The HBase has been configured similarly with the first 
server having master and slave responsibilities while the 
second one is only a slave. The recommended settings suggest 
that the master should have a server of its own and use the 
whole server’s computing power to orchestrate the slaves, but 
we did not have the necessary hardware available at that 
moment. 
For these experiments the REST API has been deployed on 
an Apache Tomcat server on a local PC with the following 
specifications: 4 GB of RAM, two CPU cores, Windows 7 OS. 
The experiments have been done by using a simple Java 
console application, which acts as a REST client for the API 
and calls a set of random queries on the API, which 
communicates with the HBase cloud servers to return the 
result. 
One of the most important queries from the point of view 
of retrieval time is finding all opinions that match a certain 
holder and a certain target, because these opinions are the 
candidates for possible contradictions, as contradicting 
opinions must have the same holder and must refer to the 
same target. The searching speed for certain records in HBase 
is highly dependent on the design of the table structure. The 
fastest search is done by matching the row key, which is the 
unique identifier for a row in an HBase table and thus it is 
most efficient to store data attributes for relevant searches. For 
these experiments, the table containing the opinions has the 
row key constructed from the name of the holder concatenated 
with the target entity of the opinions stored in this row, which 
gives us the ability to rapidly find the desired row using the 
holder name. Each row contains the opinions from the holder 
and referring to the entity, which are stored in the row key. 
The opinions are stored as nested entities in each row on 
columns, which means that each column represents an 
opinion. After finding the right rows, we need to find the right 
opinions, which means finding the right columns. The query is 
finding all opinions by holder and target; by placing the holder 
in the row key we have optimized the table for finding all 
rows of a holder very fast and by using the column as the key 
for each opinion and constructing it by concatenating the 
opinion target with the generated id of the opinion we have 
optimized the intra-row search to find the right target fast. In 
order to obtain relevant results regarding the retrieval speed of 
the HBase system a fairly large amount of data has been 
generated randomly. As we had the intention to test the 
opinion table, we needed to generate opinion tuples of the 
form presented in section III. To do this we used three files 
containing: names, nouns and sentiment words with their 
orientation and randomly generated 200 000 opinion tuples 
and for each of these a set of 10 expanded opinions by the 
target expansions so that would result in a total of 2 000 000 
stored opinions. 
By running the query to find all opinions by holder and 
target with randomly generated holder and target parameters 
over this data, we have obtained an average retrieval time of 
approximately 2 seconds with a maximum spike of 6.63 
seconds. The average time is the most relevant result as it 
shows what the user should expect when it comes to the 
response time of such a request as finding contradictions. Two 
seconds is a fairly good response time, but as we have the Solr 
indexer as the primary query handler for most important 
queries we will consider HBase as being the backup solution 
for important queries, when and if Solr fails, and as being the 
primary storage database, because of its scalability and its 
reliability. 
The scattered line in Fig. 5 shows the response time of the 
REST API given the above mentioned generated queries, 
which is plotted on the same values that have provided the 
above test results. As 100 random queries were generated, 
their number is placed on the horizontal axis, which represents 
the order in which they have been generated. 
 
Fig 4. Implementation architecture 
264
C. Solr/Index Experiments 
 For evaluating the performance of the indexing mechanism, 
we have varied the number of partitions for the same index and 
have measured the performance of system response time for 
each case.  
 For the following index performance test, each shard was 
deployed on a machine having 1 CPU core, 2GB of RAM, 
10GB SSD for disk storage and Linux 12.04 OS.  The 
orchestration was performed by a dedicated node which ran an 
instance of Apache Zookeeper.  
 We have generated the opinions by using a list of 150,000 
holders, 2300 targets and 2,500 sentiment words. The 
sentiment words used were taken from the AFINN list of 
affectionate words. We generated 100 opinions for each holder. 
For each of these opinions, a target and a sentiment word were 
chosen randomly from the word lists. For each opinion, we 
have also generated 10 targets and 10 sentiment words. We 
obtained around 5.1 GB of data, consisting of roughly 
15,000,000 opinion tuples.  
 Fig. 6 shows the evolution of average contradiction 
detection response time by having the index partitioned in 1, 2 
and 3 shards. The times depicted in Fig 6. represent the average 
over 1000 executions of the contradiction detection flow for a 
random input opinion. The blue column represents the average 
response time for a contradiction detection query when the 
index resides on a single machine and has a value of 261ms. 
The red and orange column represent the average response 
time for an index partitioned into 2, respectively 3 shards. The 
response time for 2 shards is 192 ms, while the response time 
for 3 shards is 156 ms. We observe that the response time 
decreases by increasing the number of shards that host the 
index. However, it is of note that the improvement decreases 
with each new shard added. 
 We have tested the impact of the index cache to the overall 
response time of the system. For each query that receives a 
response, a certain number of the files returned will be stored 
in the index cache. For smaller indexes, all the response 
documents could be stored in the cache. However, in the case 
of larger collections, where the response can have hundreds or 
even thousand results, it is possible that storing all returned 
documents in the cache will add too much locality information 
in the cache. We have tested for 2 different values of the 
maximum number of documents from the query result stored in 
the cache per query.  Fig. 7 presents a comparison between the 
average response times for 3 different queries for the 2 
different values of the maximum number of documents cached.  
The index contained approximately 4,500,000 opinions 
generated from 150,000 holders and 30 opinions for holder. 
The queries we have used to measure the performance are the 
most common ones for opinion search or contradiction 
detection.  
 These queries are: 
(1) Retrieving all opinions which have the same holder. This 
query is represented by the leftmost two columns in Fig 7. 
(2) Retrieve all opinion by holder and target. This query 
retrieves all opinion with a holder h and a target t and is 
represented by the two middle columns in Fig 7. 
(3) Retrieve all opinions by holder, target and target 
expansions. This query retrieves all opinions with a holder h 
and a target t or which have t as a target expansions. This query 
is represented by the rightmost two columns line in Fig 7. 
 For the experiment we have used a single Solr Node and 
the SolrMeter benchmarking tool to create 60 queries per 
minute, each with variables chosen at random. We have 
performend the experiment  on an index where the maximum 
number of results stored in the cache for each query was 200 
and then performed the experiment again on an index where 
the value for the maximum number of results sotred in cache is 
2000. The blue color column represent the cases with 200 
maximum results stored in cache for a query, while the red 
column represents the cases where the maximum number of 
documents cached was 2000. From these experimenst we learn 
that larger cache value offers better performance for the 
described dataset. This is due to the fact that the number of 
 
Fig. 6 Evolution of index response time given the increase in indexing nodes  Fig 5. HBase scatter plot 
265
maximum elements received on the response, and thus eligible 
for caching, is usually small, and therefore a larger number of 
queries can take use the cache directly for the results.   
V. CONCLUSIONS 
 This paper presents an approach to perform 
contradiction detection on very large opinion datasets. Our 
approach addresses the challenge of real-time retrieval of 
structured opinions against a given query in order to identify 
the set of possible contradictory opinions. We employed an 
architecture that consists in combining a sharded index with a 
distributed NoSQL data store to provide both scalability and 
performance. 
 We have presented the opinion model and main 
procedure we have used for performing the contradiction 
detection. We have evaluated our system and presented our 
findings. The results we have obtained show that increasing 
the number of partitions of the same index gives a 
performance increase. We have also noted that query 
configuration can affect the system response time. 
  
REFERENCES 
 
[1] D. Manning et al, “An Introduction to Information Retrieval”, 2009, 
Cambridge Press 
[2] A. Rajamaran, J. Lesovec, J.D.Ullman, “Mining of Massive Datasets” 
2012, Cambridge Press 
[3] Bing Liu et al, “Sentiment Analysis and Opinion Mining”, Morgan & 
Claypool Publishers, 2012  
[4] F. Cheng et al,  “Bigtable: A Distributed Storage System for Structured 
Data”, 7th USENIX Symposium on Operating System Design and 
Implementation, 2006. 
[5] Sanjay Ghemawat et al, “The Google File System”, 19th ACM 
Symposium on Operating System Principles, 2003 
[6] K Shvachko, H. Kuang, S. Radia, R. Chansler, “The Hadoop Distributed 
File System”, 26th IEEE Symposium on Massive Storage Systems and 
Technologies. 
[7] S. Harabagiu, A. Hickl, F. Lacatusu, Negation, Contrast and 
Contradiction in Text Processing, AAAI'06 Proceedings of the 21st 
national conference on Artificial intelligence - Volume 1, Pages 755-
 762. 
[8] M.C. de Marneffe, A. Raffery, C.D. Manning, “Finding Contraditions in 
Text”, Proceedings of the ACL-08: HLT, pages 1039-1047. 
[9] Apache HBase, available online at http://hbase.apache.org/.  
[10] Apache Solr, available online at http://lucene.apache.org/solr/. 
[11] Rod Cope, “Real-Time Searching of Big Data with Solr and Hadoop”, 
O’Reilly Strata, Making Data Work Conference, 2011, available online 
at http://shop.oreilly.com/product/0636920018896.do  
[12] AFINN dataset, available online at   
http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010 
 
 
 
 
 
Fig 7. Comparison between different values of cached documents per 
query 
 
266
