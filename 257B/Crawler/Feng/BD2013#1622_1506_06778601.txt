Two Layer Cache for RDF Database 
Xiaolin Yi 
Beijing University of 
Technology/College of Computer 
Science 
Beijing, China 
yixiaolin@bjut.edu.cn
 Fan Zheng 
Beijing University of 
Technology/College of Computer 
Science 
Beijing, China 
zhengfan1988@gmail.com
 Wei Jia 
Lenovo Reseach& Technology 
Group, Lenovo Group Limited. 
Beijing, China 
jiaweia@lenovo.com
 Abstract—With the Semantic Web[1]has been paid more and 
more attention, there are more and more related applications. 
For instance, Google has provided semantic retrieval functions, 
you can get the information of some famous people directly. 
RDF[2]database as the data storage tool of Semantic Web also 
gets many attentions. Now, there are some well-known RDF 
databases such as Jena[3], Sesame[4], Bigdata[5] and so on. 
The role of RDF database is to provide data service for 
Semantic Web applications. The important metric of database is 
the query efficiency. Now, most of RDF database’s efficiency has 
not reached high level and there is a large gap between it and 
commercial demand[6][7].
 In this paper, we present a two layer cache mechanism: RC 
(RDF database Cache) to speed up the queries and relieve the 
problem that the runtime of some queries is too long in RDF 
database. By implementing and test, the query efficiency can 
increase thirty-one percent or more after using this cache 
mechanism. 
Keywords—RDF(ResourceDescriptionFramework), Database, 
Cache, RC(RDF database Cache)
 I. INTRODUCTION (Heading 1) 
In 2001, Berners Lee put forward the concept of Semantic 
Web. It is the change and extension of the World Wide Web 
and its goal is to make the computers understand the semantic 
of the information and be able to provide the dynamic and 
active service. In the Semantic Web, the info between people 
and computer or computer and computer can get more fully 
utilization. 
RDF database is an important part of the Semantic Web. 
Whatever Semantic Web application you do, you can’t
 complete it without it. With the Semantic Web gets a hot topic, 
more and more applications have appeared in our life and the 
applications have more and more high demand for query 
efficiency of RDF database in the same time. 
To use cache is the most direct way to improve the query 
efficiency. There is not cache special for RDF database and 
the cache meets the user's query features. So, RC was 
designed and realized.  
The RC is a two layer cache for RDF database. The first 
layer uses ARC-Memory algorithm to improve the query 
efficiency and the second layer uses Key-Value DB to relieve 
the problem: the runtime is too long when query is too 
complicated or query result is too large. 
The rest of the paper is structured as follows. Section 2 
introduces related base info about RC and original intention of 
designing it. Section 3 describes the framework of RC. Section 
4 describes the algorithm in RC. In Section 5 the performance 
results will be presented. 
II. BACKGROUND
 A. Cache Replacement Algorithm 
There are many cache replacement algorithms, and it can be 
divided into two kinds. One is the traditional replacement 
algorithm, the other is self-adaptive algorithm. The traditional 
algorithm has FIFO, LRU, MRU and so on. They decide to 
replace by its call frequency and its call time. The method of 
judgment is very simple and most of them are especially for a 
fixed access model. 
Because of the traditional algorithm is not very efficiency 
and comprehensive, so the researchers put attention to the self-
 adaptive algorithm. The most of self-adaptive algorithms use 
strategy based on the time and frequency balance. There are 
many famous algorithm, for instance ARC[8], LRFU and so on. 
B. RDF Database 
Now, There are many RDF databases, we can divide them 
into two kinds by storage media. One is relational database, 
the other is non-relational database. The non-relational 
database is more and more popular with the Semantic Web 
development and the researchers found low-performance of to 
store RDF data in relational database. 
The loading rate and query efficiency are the metric of the 
RDF database. From the application point of view, it pays 
more attention to query efficiency. If the RDF database can’t
 support fast concurrent query, it will be eliminated by 
Semantic Web after some time. 
There are many open-source RDF database, for example 
Bigdata, Sesame and so on. AllegroGraph[9]is a famous 
commercial RDF database, it supports storing a large number 
triples and provides high-performance data service. 
There is not a cache mechanism that meets user’s query 
features and improves query efficiency significantly. 
C. Important Problem 
RDF database is a very important part of Semantic Web. 
Along with the Semantic Web is more and more popular, there 
is more and more commercial application about Semantic 
Web. It proposes more stringent requirements about RDF 
database at the same time. 
There are many tests for RDF database. LUBM[10]is a 
famous test in them. It has fourteen queries. You can get the 
test set from its data generator, then to use the test queries to 
test the performance of the RDF database. If you have done it, 
2013 10th Web Information System and Application Conference
 978-0-7695-5134-0/13 $26.00 © 2013 IEEE
 DOI 10.1109/WISA.2013.10
 11978-1-4799-3219-1/13 $31.00 © 2013 IEE
you maybe find something: some queries spend much time to 
get result. For instance, the second query and the sixth query 
cost much time to run. The reason of it is the query is too 
complicated or the query result is too large. 
AllegroGraph is high-performance commercial RDF 
database. Its LUBM8000 test result is shown in TableB. 
TABLE I. ALLEGROGRAPH LUBM8000 TEST RESULT
 INFO\LUBM Query Query 2 Query 6
 Result Triples 2,528 83,557,706
 Time (s) 278.321 389.062
 Query Content
 PREFIX rdf: 
<http://www.w3.org/19
 99/02/22-rdf-syntax-
 ns#>
 PREFIX ub: 
<http://www.lehigh.ed
 u/~zhp2/2004/0401/uni
 v-bench.owl#>
 SELECT ?X,?Y, ?Z
 WHERE
 {
 ?Xrdf:typeub:Gradu
 ateStudent .
 ?Yrdf:typeub:Universit
 y .
 ?Zrdf:typeub:Departme
 nt .
 ?Xub:memberOf ?Z .
 ?Zub:subOrganization
 Of ?Y .
 ?X 
ub:undergraduateDegre
 eFrom ?Y
 }
 PREFIX rdf: 
<http://www.w3.org/19
 99/02/22-rdf-syntax-
 ns#>
 PREFIX ub: 
<http://www.lehigh.ed
 u/~zhp2/2004/0401/uni
 v-bench.owl#>
 SELECT ?X WHERE 
{?X 
rdf:typeub:Student}
 From the Table B, the runtime of Query2 and Query6 is 
very long, and the result of Query6 is very large. From the 
query’s content, we can know Query2 is a complicated query 
and Query6 is a simple query. 
Now, we find an important problem in RDF database that 
the runtime is very long when the query is very complex or the 
result set is very large. For example, the second query is very 
complicated and the result set of the sixth query is very big in 
LUBM Test. 
III. RC FRAMEWORK
 To improve the query efficiency and alleviate the problems 
caused by the query result set is too large or query is too 
complex of RDF database, the RC is designed and realized. 
The Cache has two layers. The first layer implemented the 
ARC-memory algorithm and realize in memory. The second 
layer realized in Key-Value database. For more information, 
see Figure 1. 
Fig. 1. RC Framework 
The ARC-Memory algorithm of the first layer meets query 
features of user and can get high level of hit ratio. It can help 
database getting better query effect. For more information 
about this algorithm, see Section 4. 
To resolve the problem caused by query too complicated or 
result set too big, the second layer was designed. The data that 
put in the second layer must meet two conditions: 
 The data must be removed by the first layer. 
 The runtime of the query must exceed the limit of time. 
The second layer has two parts: Key-pool, KV. Key-pool 
keeps a fixed-size LRU queue to store the MD5 key of query. 
KV is realized in Key/Value database to store the MD5 key 
and the query result. For more information, see Section 4. 
The detail process flow is in Figure 2. 
Fig. 2. RC Process Flow 
RC<"RDF"database Cache
 First Layer:Memory
 (This layer is using ARC-Algorithm, It meets user's query features and guarantees
 high hit rate)
 Second Layer:Memory + Key/Value Database
 (This layer is using LRU-KV algorithm. It is primarily responsible for storing the
 timeout query result to improve query efficiency.
 When query result is
 removed by first layer
 and its runtime
 exceeds limit time, it
 will be put into second
 layer.
 When hitting in
 second layer, the
 query result will be put
 into first layer.
 Using query string to Generate 
MD5 Key
 In First Floor Cache
 Y
 In Second Floor Cache
 Y
 Generate Insert First 
Floor Cache ThreadY
 First Floor Cache Full
 Generate Insert Second 
Floor Cache Thread
 Second Floor Cache Full
 Insert data in First 
Floor Cache
 Y
 Eliminate data
 Eliminate Data
 Insert data in Second 
Floor Cache N
 Insert data in First 
Floor Cache
 Bigdata
 Get Result from 
Bigdata
 N
 Key/Value database
 Get Rusult From 
Second Floor Cache
 Result
 N
 Begin
 End
 Y
 N
 12
Figure 2 shows the process flow of RC. Because of the query 
string is not a fix-number long, it can be transferred to MD5 
code as the key. 
IV. ARC-MEMORY ALGORITHM
 Adaptive Replacement Cache (ARC)is a page replacement 
algorithm with high performance developed at the IBM 
ALmaden Research Center. Its hit ratio is higher than LRU 
algorithm. This is accomplished by keeping track of both 
frequently and recently used pages plus a recent eviction 
history for both. 
Because of the design of first layer is realized in memory, 
so we change the ARC algorithm into ARC-memory algorithm 
that make the B1 and B2 all in the memory. 
The ARC-memory algorithm: 
INPUT: The MD5 Key x of the Query String, Key-1,Key-2…Key-n 
INITIALIZATION: Set p=0 and set the LRU lists T1,T2,B1 and B2 
to empty. 
Case I: Key-n is in T1 or T2 . 
Move the element of Key-n to MRU position in T2 . 
Case II: Key-n is in B1 . 
If |B1| >=|B2| u=1 Else u=|B2|/|B1|. End If 
Update p = MIN { p + u , c }  
Call ADJUST (Key-n , p).  
Move the element of Key-n from B1 to the MRU position in T2. 
Case III: Key-n is in B2 . 
If |B2|>=|B1| u=1. Else u=|B1|/|B2|. End If 
Update p=MAX { p - u , 0 } 
ADJUST (Key-n , p).  
Move the element of Key-n from B1 to the MRU position in T2. 
Case IV: Key-n is not in T1]T2]B1]B2. 
Case A: |T1|+|B1| >= c . 
If (|T1| <c ) 
Delete LRU page in B1 . 
ADJUST( Key-n , p ). 
Else 
Delete LRU page in T1.  
End If 
Case B: |T1+|B1| <c . 
s = |T1|+|T2|+|B1|+|B2|. 
If(s>=c) 
        If(s==2c) 
            Delete LRU page in B2. 
        End If. 
ADJUST( Key-n , p ). 
End If 
Move the element of Key-n to MRU position in T1. 
Subroutine ADJUST(Key-n , p ) 
If ( (T1 is not empty) and (( |T1| > p) or (Key-n is in B2 and 
|T1|=p)) 
Move the LRU page in T1 to MRU position in B1. 
Else 
Move the LRU page in T2 to MRU position in B2. 
End If 
ARC-Memory algorithm has get high level hit ratio, we will 
test the hit ratio of it and other algorithms in Section 5. 
V. PERFORMANCE TEST
 To show RC performance result, two tests will be done. The 
first test will prove the high hit ratio of ARC-memory 
algorithm in first layer of RC. Then, the second test will put 
the RC into Bigdata. 
A. Cache Hit Ratio Test 
To compare hit ratio in the test, the LRU algorithm and FIFO 
algorithm also be realized in memory. 
The OLTP[11]trace will be as the test set. Due to all 
algorithms realized in memory, the second field (logical block 
address) of OLTP trace will be used. The logical block address 
will be as the query. For more information about this test, see 
TableC and Figure 4. 
TABLE II. THE RESULT OF CACHE HIT RATIO
 Cache 
size\Algorithm 
FIFO LRU ARCC
 200 0.26265 0.27584 0.29442
 400 0.31671 0.33767 0.35618
 600 0.35272 0.37641 0.39546
 800 0.38054 0.40618 0.4253
 1000 0.40443 0.43134 0.44938
 1200 0.42459 0.45271 0.46967
 1400 0.44204 0.47148 0.48694
 1600 0.45714 0.48746 0.5025
 1800 0.47056 0.50158 0.5174
 2000 0.48298 0.51458 0.5304
 2200 0.49416 0.52713 0.54182
 2400 0.50445 0.5386 0.55271
 2600 0.51453 0.54895 0.56232
 2800 0.52428 0.55892 0.57136
 3000 0.53362 0.56888 0.58015
 3200 0.54152 0.57815 0.58831
 3400 0.54901 0.58666 0.59684
 3600 0.55681 0.59443 0.60389
 3800 0.56363 0.6017 0.61099
 4000 0.57139 0.60876 0.61743
 In TableC, ARCC is the ARC-memory algorithm. The hit 
ratio of every replacement algorithm grows with the increase 
of the cache size. The improve ARC algorithm is the best of 
three replacement algorithm. For detail trends, see Figure 3. 
13
Fig. 3. Hit Ratio Test Result 
The test can prove the improve ARC algorithm has ability to 
maintain high hit ratio and it is better than LRU algorithm and 
FIFO algorithm. 
B. RC Performance Test on Bigdata Cluster 
To further illustrate the effect of RC, The second test will put 
the RC into Bigdata Cluster. 
The test set also use the second field (logical block address) 
in OLTP trace. The logical block address of OLTP trace will 
be as SPARQL[12] query. The trend of the test set is equal to 
the trend of logical block address in OLTP. 
Every SPARQL query would be generated by DBpedia 
Random SRARQL Query Generator. It will be used to 
generate the query randomly for DBpedia English repository. 
There are 241,605,993 triples of DBpedia in 
BigdataCluster[13][14]. 
The test will execute 10,000 queries for different cache size. 
In last, it will get the runtime (millisecond) for different cache 
size and query set size. The detail test result is shown in Table 
D.
 TABLE III. THE RESULT OFRC TEST ON BIGDATA
 Cache 
size(1
 04)\Qu
 ery set
 1 2 3 4 5 6 7 8 9 10
 0 52
 77
 39
 100
 419
 7
 148
 338
 4
 195
 738
 8
 242
 527
 9
 289
 560
 6
 334
 972
 2
 381
 135
 1
 426
 164
 6
 471
 349
 5
 100 35
 34
 00
 668
 759
 981
 922
 129
 856
 7
 162
 196
 7
 194
 952
 9
 225
 329
 8
 253
 420
 1
 286
 945
 3
 324
 210
 7
 300 32
 05
 03
 607
 330
 903
 888
 120
 271
 5
 148
 936
 5
 179
 175
 1
 206
 321
 9
 230
 767
 2
 255
 217
 7
 290
 048
 3
 500 30
 63
 79
 586
 099
 875
 624
 117
 469
 9
 145
 513
 3
 175
 668
 1
 202
 751
 6
 227
 643
 6
 252
 169
 5
 288
 255
 7
 700 28
 44
 32
 568
 505
 863
 378
 115
 188
 3
 142
 804
 1
 171
 427
 0
 196
 958
 1
 221
 200
 0
 246
 799
 6
 282
 558
 8
 900 28
 87
 17
 563
 142
 846
 516
 112
 995
 0
 139
 840
 3
 168
 381
 2
 193
 944
 6
 217
 973
 0
 241
 629
 2
 276
 848
 6
 The situation when cache size is 0 is no-cache cluster. To be 
seen with the caching mechanism, the query efficiency 
improved significantly. And with the increase of the cache 
size, the runtime is less and less. When no-cache in cluster, a 
query would consume 47.1ms. After to add cache into cluster 
and set cache size is 100 queries, a query would consume 
32.4ms under the same conditions. When setting cache size 
with 900, the runtime just needs 27.7ms. For detail trend, see 
Figure 4. 
Fig. 4. RC Test Result on Bigdata 
It can be seen by the results of the above two tests that the 
RC can ensure high hit ratio and improve query efficiency 
significantly. 
ACKNOWLEDGMENT 
Thanks for the support of Beijing"Key" Laboratory of"
 Trusted Computing, Beijing University of Technology. 
REFERENCES
 [1] Berners-Lee, Tim, James Hendler and OraLassila (May 17, 2001). "The 
Semantic Web". Scientific American Magazine. Retrieved March 26, 
2008 
[2] W3C. http://www.w3.org/RDF/
 [3] Apache. http://jena.apache.org/
 [4] Openrdf. http://www.openrdf.org/
 [5] Bigdata. http://www.bigdata.com
 [6] Florian Stegmaier, UdoGrobner, Mario Doller, HaraldKosch and 
GeroBaese. “Evaluation of Current RDF Database Solutions”. 
[7] Kurt Rohlo. “An evaluation of triple-store technologies for large data 
stores”. Lecture Notes in Computer Science,2007,4806(1105-1114). 
[8] Nimrod Megiddo, Dharmendra S. Modha. “ARC: A SELF-TUNING, 
LOWOVERHEAD REPLACEMENT CACHE”. 2nd USENIX 
Conference on File and Storage Technologies,2003:115-130 
[9] Franz. http://www.franz.com/agraph/allegrograph/
 [10] http://swat.cse.lehigh.edu/projects/lubm/
 [11] FUJISU.WHITE PAPER:Bechmark Overview OLTP. 2003. 
[12] W3C. http://www.w3.org/TR/rdf-sparql-query/
 [13] Mohamed Morsey, Jens Lehmann, Sören Auer, and Axel-
 CyrilleNgongaNgomo. “DBpedia SPARQL Benchmark-Performance 
Assessment with Real Queries on Real Data”.
 [14] Soren Auer, Christian Bizer, GeorgiKobilarov, Jens Lehmann, Richard 
Cyganiak, and Zachary Ives. “DBpedia: A Nucleus for a Web of Open 
Data”.
 14
