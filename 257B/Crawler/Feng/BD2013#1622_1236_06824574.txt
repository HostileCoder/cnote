Human activity recognition model based on Decision tree 
Lin Fan, Zhongmin Wang 
School of Computer Science & Technology,  
Xi’an University of Posts & Telecommunications 
Xi’an, China 
fanlin@xupt.edu.cn, zmwang@xupt.edu.cn 
Hai Wang 
Department of Information Science and Technology, 
Northwest University 
Xi’an, China 
hwang@nwu.edu.cn 
 
 
Abstract—In daily life, people carry smartphones every 
where. The sensors included in smartphones can tell us 
much information. Activity recognition by smartphone can 
be used for healthcare and sports management. People 
carry smartphones in different positions, such as the 
pocket of the trousers, hands or bags. We use 
accelerometer embedded in the smartphones to classify 
five activities, such as staying still, walking, running, and 
going upstairs and downstairs. This work analysis 
behavior data from accelerometer, extract various features, 
choose highly correlated features, and construct an 
activity recognition model based on location-independent 
smartphone. We construct models based on (behavior, 
position) vector, position and behavior. Compare all these 
models, behavior based recognition model gain the 
highest accuracy and lest time-consuming, which can 
effectively identify human behavior. 
Keywords—Activity recognition model; Position-
 independent; Decision tree 
I.    INTRODUCTION 
People carry smartphones every day. Smartphones 
have many sensors included, which can tell us much 
information. Using sensors, computing ability and 
appropriate algorithm, smarphones can provide more 
powerful service than phones used be. Healthcare 
system and sports management system can help users 
keep healthy life style. These system can urge users to 
take proper exercise every day  also provide the user's 
heart rate, blood pressure and other healthy information. 
Specialized medical equipment or wearable sensors can 
be used for human activity recognition, but it requires the 
user to deliberately put on some devices. With smart 
phones, more and more researchers advocate to do 
activity recognition without being detected. While people 
carrying smartphones, their behavior are recognized and 
recorded. 
Accelerometer information is useful in recognition 
user’s behavior. In this paper we first describe the 
current work in the field of activity recognition and the 
decision tree method. In section III we analysis behavior 
data form accelerometer, contain five activities and three 
smartphone positions. While extract various features, 
choose highly correlated features, we construct three 
decision trees based on (behavior, position) vector, 
position and behavior. Compare all these models to find 
the best model to classify user’s activity. 
II.    RELATED WORKS 
Many researches have been done in activity 
recognition. Previous studies is  Wearable Computing, 
people wear sensors at specified position to identify 
activity and gesture. In 2004, MIT’s Media Lab used five 
accelerometers worn simultaneously on different parts of 
the body to identify 20 kinds of everyday common 
behaviors. Mean, energy, frequency-domain entropy, 
and correlation of acceleration data was calculated and 
several classifiers using these features were tested. 
Decision tree classifiers showed the best performance [1] . 
With smart phones, more and more researchers 
started to do activity recognition by smart phones. 
Gerald Bieber’ team from Germany fixed the smart 
phone in user’s pocket of the trousers. Microphone was 
used to capture the sound of friction to identify user 
behavior severity. They fused sound and acceleration 
data to identify user’s activity[2]. Lenny Grokop’s team 
achieve comparable activity recognition performance 
using smartphones placed in unknown onbody positions 
including pocket, holster and hand. Results obtained 
from a diverse data set show that motion state and 
device position are classified with macro-averaged f-
 scores 92.6% and 66.8% respectively, over six activities 
and seven device positions[3]. Yiqiang Chen’s team[4-7] 
fused accelerometer and GPS information to recognition 
traffic patterns[4]. Paper [7] divided people's everyday 
behavior to: still, walking, running up and down stairs, 
falls, etc., Smartphone gather six kinds of behavior data 
to recognize behavior. Paper [5] considered different 
wear position of phone, different body parts move in 
different ways. 
III. POSITION-INDEPENDENT ACTIVITY RECOGNITION 
MODEL  
This paper first collect data from smartphone, then 
calculate the resultant acceleration. After analysis on 
time and frequency domain, ten features are calculated. 
Three models are brought up and compared. 
A. Data collection and analysis 
Our experiment carried on smartphones with ARM 
processors, Android2.3 system. We developed a 
lightweight behavioral data collection system. 
Experimental designed as follows: 
This work was financially supported by the National Natural Science 
Foundation of China (61373116), Youth Foundation of Xi’an University of 
Posts & Telecommunications (103-0458), Nature Science Foundation of 
Shaanxi Province under Grand ( 2012JQ8047).  
2013 International Conference on Advanced Cloud and Big Data
 978-1-4799-3261-0/14 $31.00  2014 IEEE
 DOI 10.1109/CBD.2013.19
 64
1. User information: we collected 15 user behavior 
data, the age distribution was: 20 to 30 years old 
5 people, 30 to 40 years and 8 people, 2 
persons 40 to 50 years old, basically covering 
smartphone user base; 
2. Activity: behavior information collected is divided 
into five kinds: stationary, walking, running, 
upstairs, downstairs; 
3. Phone position: for each behavior, the user's 
mobile phone wearing position subdivided into 
three kinds, namely, bag, trouser pocket, hands; 
4. Each user behavior and location for each 
movement collected 10 times the acceleration 
information acquisition time 10 sec. 
The following is time domain curve and frequency 
domain curve of resultant acceleration. 
(1) Stay still 
When users are stay still, the resultant acceleration 
value stable at 10, is the gravitational acceleration. 
Operate the smartphone brings a small amount of jitter. 
When the smartphone is carried in hands, trousers 
pocket or bags, the curve of time and frequency is 
almost the same. Fig 1 shows the time and  frequency 
domain curve of resultant acceleration when the user is 
staying still. 
Fig. 1. The time and frequency domain curve of “stay” 
 
 (2) Walking 
User behavior data cyclical when the phone is in 
trouser pocket, so the best cell phone behavior 
recognition placement should be trouser pocket. Fig 2 
shows the time and  frequency domain curve of resultant 
acceleration when the user is walking. 
 (3) Running 
Users running data showed a periodicity, the 
frequency and peak acceleration is higher than walking 
data, energy is mainly concentrated in 2 Hz, peak or 
energy can be used to distinguish between running and 
other activities. Fig 3 shows the time and  frequency 
domain curve of resultant acceleration when the user is 
running. 
Fig. 2.  The time and frequency domain curve of “walking” 
 
 
 
Fig. 3. The time and frequency domain curve of “running” 
"
 65
"
 "(4) Upstairs 
Behavioral data of going upstairs is very similar to 
walking, so here is a high incidence of false positives. 
Fig 4 shows the time and  frequency domain curve of 
resultant acceleration when the user is going upstairs. 
Fig. 4. The time and frequency domain curve of “upstairs” 
 
 
 (5) Downstairs 
The acceleration curve of  going downstairs is 
similar to running, but the cycle is longer, the 
amplitude is smaller, and therefore easy to distinguish. 
Fig 5 shows the time and  frequency domain curve of 
resultant acceleration when the user is going downstairs. 
Fig. 5. The time and frequency domain curve of “downstairs” 
 
 
 
We extract features from all 2250 samples, including 
10 kinds: mean, median, variance, standard deviation, 
maximum, minimum, range, RMS (Root Mean Square), 
Fourier transform coefficients and spectral energy. 
66
B. The model based on the vector (activity, position) 
Fig. 6. The model based on the vector (activity, position) 
 
 
People wear cellphones in different positions. 
According to the foregoing analysis, acceleration data 
are different when cellphones is carried in different 
places. To make position-independent behavior 
recognition, we mix all of the positions and activities of 
the classification. In determining user behavior, while the 
placement of smartphone also identified. We build 
(behavior, location) vector, a total of 15 species, ID3 
decision tree is used as classification algorithm to 
construct a model to  assigned all sample data to 15 
classes. 
Using all of the features to build a decision tree, 
which  shows in Fig 6. We calculate all the features 
information gain  by formula(1-1), and find that the mean 
is the best feature to do the first classification. After 
seven level classification, we get 15 classes. When test 
on the sample set, the rate of miss classification is 
26.28% . Then we take cross-validation, which randomly 
divides the training set into 10 disjoint subsets. Each 
subset has roughly equal size and roughly the same 
class proportions as in the training set. Remove one 
subset, train the classification model using the other nine 
subsets, and use the trained model to classify the 
removed subset. The rate of miss classification is 
48.18%. 
C. The model based on position 
Build a decision tree to classify the position of 
smartphone. Of all the features, the best feature to 
classify the position is the Fourier transform coefficients. 
The tree shows in Fig 7. When test on the sample set, 
the miss classification rate is 20.44%. When take cross-
 validation, the miss classification rate is 38.69%. 
D. The model based on action 
Classify activity directly without considering the 
postion of smart phone. Using all of the features to build 
the tree, which  shows in Fig 8. After pruning, the tree is 
compact.  
The best feature is the maximum value, followed by 
the variance and range. Sample space of the tree model 
validation, if the sample set as a test set, then the error 
rate of 11.68%, if carried out 10 cross-validation, then 
the error rate of 19.71%. 
Fig. 7. The model based on position 
 
Fig. 8. The model based on activity 
 
E. Comparison of three models 
TABLE I.  ACCURACY AND TIME CONSUMING OF THREE MODELS 
Tree species 
Accuracy Time 
consuming Test on the 
sample set 
10 fold cross-
 validation 
Tree based on 
(activity, position) 73.72% 51.82% 0.8813 
Tree based on 
position 79.56% 61.31% 0.8675 
Tree based on 
activity 88.32% 80.29% 0.7869 
 
To sum up, the decision tree model based on activity is 
more accurate than the model based on position. Both of therm 
is more accurate than decision tree model based on (activity, 
position) vector. When making position-independent activity 
recognition, the same activity in different position cannot be 
67
differentiated very clearly. Judge activity and position 
simutaniously seems difficult. Due to the lowest complexity of 
the decision tree based on activity, it has the minimum time 
consuming and the highest efficiency. The comparison shows 
in TABLE I. 
IV. CONCLUSION 
In this paper, phones were placed in three different 
positions. Five daily behavior information has been 
collected based on the synthetic acceleration, ten kinds 
of user activity features are extracted. The decision tree 
based on the features has been established. This paper 
studies the three kinds of modeling method, vector 
(activity, position) based modeling, position based 
modeling and activity based modeling respectively. 
Compare all these models, behavior based recognition 
model gain the highest accuracy and lest time-
 consuming, which can effectively identify human 
behavior.  
REFERENCES 
[1] Bao L. and Intille S., Activity recognition from user 
annotated acceleration data[J]. Pervasive Computing. 
LNCS vol 3001. pages: 1–17. Springer, 2004. 
[2] Gerald Bieber1, André Luthardt, Christian Peter, Bodo 
Urban. The Hearing Trousers Pocket-Activity Recognition 
by Alternative Sensors. PETRA'11, May 25 - 27, 2011, 
Crete, Greece.ACM. 
[3] Lenny Grokop, Anthony Sarah, Chris Brunner, Vidya 
Narayanan, Sanjiv Nanda. Activity and Device Position 
Recognition In Mobile Devices[C]. Copyright is held by the 
author/owner(s). ate and device position estimates. 
UbiComp’11, September 17–21, 2011, Beijing, China. 
ACM. 
[4] Yiqiang Chen, Juan Qi, Zhuo Sun, and Qiong Ning. Mining 
user goals for indoor location based services with low 
energy and high qos[C]. Computational Intelligence, 
26(3):318–336, 2010. 
[5] Zhongtang Zhao, Yiqiang Chen, Junfa Liu, Zhiqi Shen, 
Mingjie Liu: Cross-People Mobile-Phone Based Activity 
Recognition[C]. IJCAI 2011. Vol 3. Pages: 2545-2550. 
2011. 
[6] Yiqiang Chen, Zhongtang Zhao, Shuangquan Wang and 
Zhenyu Chen, Extreme Learning Machine based device 
displacement free activity recognition model[J], Soft 
Computing. Volume 16, Issue 9 , pp 1617-1625. Springer-
 verlag 2012. 
[7] Shuangquan Wang and Yiqiang Chen, Recognizing 
transportation mode on mobile phone using probability 
fusion of extreme learning machines[C] , International 
Symposium on Extreme Learning Machines (ELM2012). 
 
68
