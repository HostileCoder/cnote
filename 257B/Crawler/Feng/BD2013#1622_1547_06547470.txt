User-Oriented Modelling of Scientific Workflows 
for High Frequency Event Data Analysis 
Aarthi Natarajan 
University of New South Wales 
Sydney, New South Wales, Australia 
aarthin@cse.unsw.edu.au 
Abstract— Whether it is research scientists in computational 
physics, astronomy, genomics or financial services, all these 
varying disciplines have been challenged by the analysis of Big 
Data.  They are all required to perform multi-step analysis tasks 
to turn this data into actionable insight, from which critical 
decisions can be made.   Two data processing models that have 
rapidly evolved in the past decade to support data analysts are 
Complex Event Processing and Scientific Workflows.  Our 
research proposes a hybrid approach, which extends scientific 
workflows, to incorporate the handling of event-streams.  This 
model not only aims to provide a more efficient approach to 
analysing high frequency event streams, but also facilitates 
conceptual modelling of processes - to enable domain experts to 
build abstract, exploratory analysis processes in a user-friendly 
manner without the concerns of underlying technology, and 
transparently maps them to concrete solutions at run-time.  
I. INTRODUCTION 
Today, many areas of sciences are dealing with massive 
information streams or “Big Data”.  Big Data is characterised 
by several dimensions – Volume (exponential growth rate),  
Velocity (increasing frequency of data generation),  Variety 
(complexity and diversity of  data types).  These 
characteristics pose varying challenges to domain scientists 
conducting data analysis.  Our research focuses on handling of 
temporal events, a subset of Big Data characterised by high 
frequency event streams.  The industry has increasingly 
adopted Complex Event Processing (CEP) as a solution to fast 
and efficient processing of these event streams in real-time.  
CEP focuses on detecting patterns of interest on event streams 
that are correlated in a causal, spatial or time dimension 
process, analysing their impact and acting upon them.   
 
However, CEP solutions have several drawbacks.  Lack of 
useability, inadequate provenance support and difficulty in 
reproducibility of analysis results make CEP models 
unsuitable to model complex scientific analyses and domain 
scientists often use scientific workflows to represent complex 
sets of computations.  Our research explores a hybrid 
approach, called as Scientific Event Processing (SEP) that 
extends scientific workflows to incorporate the handling of 
high frequency event streams, that is aimed at providing data 
analysts a more efficient way of conducting event analysis.   
 
This paper is organized as follows:  Section II draws a 
comparison of existing data processing techniques and 
establishes the motivation for our work. Section III provides 
an architectural overview of our proposed system.  Section IV 
discusses on how our proposed system can be validated.  
Section V concludes this paper. 
II. BACKGROUND 
This section explores the relative merits and demerits of 
both data analysis models and looks at how an integrated 
approach that unifies the two models would be beneficial.     
A. Complex Event Processing (CEP)  
CEP [1] has emerged as a model to respond to high 
frequency data streams.  CEP engines look for patterns and 
relationships between unrelated events that signal new 
opportunities or critical threats and trigger a reaction in 
response to the detected pattern.  For example, high-frequency 
financial data is increasingly becoming more available to both 
market participants and researchers.  Several types of events 
relevant to the financial market have been identified such as 
an OrderEvent (a market participant submitting an order to the 
market),   TradeEvent ( a timed action that relates to exchange 
of products between two market participants), which have 
been used to study market behaviour [15].   
 
Despite its wide adoption in the industry, CEP solutions are 
not without their limitations.  Currently, a wider platform that 
is able to integrate diverse technologies to support variety of 
functional and non-functional requirements is still a subject of 
research, as CEP technologies today are stand-alone, 
proprietary solutions [18].  Different CEP engines all have 
different characteristics, significantly varying in the manner 
they react to event patterns and applying decisions. CEP 
engines rely on an Event Pattern Language (EPL) to allow 
domain users to define event patterns that are matched against 
event data.  Again, different language styles have been 
adopted by different CEP products as summarised in Table 1. 
TABLE I 
SUMMARY OF EVENT PATTERN LANGUAGE STYLES 
Programming 
Language Style 
Technology 
Stream-Oriented (SQL 
Extensions) 
ESPER [3],  Oracle CEP [4] 
Rules-Oriented Drools [4], Tibco Business Events [5] 
Agent-Oriented Spade [6] 
Imperative-Script Style Apama [7] 
supervised by Fethi A. Rabhi 
978-1-4673-5304-5/13/$31.00 ? 2013 IEEE ICDE Workshops 2013306
Current CEP solutions are only semi-automated. Data 
analysed by event processing systems is still required to 
channel through several pre-processing and post-processing 
tasks.  What we need is to build an infrastructure that allows 
the entire spectrum of processing phases from data acquisition, 
filtering, assimilation to high-end computation tasks to be 
captured into a single Event Processing Network (EPN), a 
model that allows different components of the event 
processing architecture implemented with different 
technologies to be plugged in with minimal effort. 
B. Scientific Workflows 
Scientific Workflows have emerged as a paradigm to 
represent and manage complex distributed scientific 
computations [2].  Scientific data analysis constitutes a 
pipeline of several analytical tasks such as querying single or 
multiple data sources, transforming data (e.g. cleaning, 
enriching, aggregating, summarizing), analysing correlations, 
detecting patterns and testing or discovering models.    Each 
step in the analysis process is a process or computation to be 
executed, which is typically achieved by end-users through a 
software program or statistical tool such as SPSS, SAS, and 
MATLAB or Business Intelligence (BI) tool.  Currently 
several workflow projects such as Taverna [8], Wings [9], 
Kepler [10] have been demonstrated in a variety of scientific 
applications.  A complete survey describing the state-of-the-
 art in workflow technologies is discussed in [11]. 
 
Scientific workflows promise acceleration of scientific 
discovery through automation of computation tasks and 
providing support for provenance information, ensuring 
reproducibility of analysis processes and consistent results and 
sharing of analyses.  However, current workflow projects 
focus only on orchestration and execution of a sequence of 
tasks to process large data sets, and are not suited to process 
complex entities like event.  The article in [12] further 
distinguishes between event-based and work-flow based 
processes.  An event-based approach is seen as a more 
dynamic solution, as it allows domain users to respond to 
situations in the context of each specific event and respond 
appropriately to each.  The context of a specific transaction 
determines the route chosen for that specific transaction.  
While a workflow based approach is seen as being more 
restrictive to domain users because of its prescriptive nature.  
It starts with a flow in mind and activities that happen are only 
secondary to the flow.     
 
A challenge inherent across both CEP and scientific 
workflows including notable open-source projects Esper, 
Taverna, is that the technologies are not tailored to be user-
 friendly.  Domain users would benefit from a more graphical 
based abstract event processing model, rather than a 
programmer based model, that would allow them to tailor 
their own event processing networks.   
 
We look at a motivating case-study that involves a fictional 
analyst interested in detecting unusual price movements in 
trade data for Telstra exchange on the Australian Stock 
Exchange (ASX) in the year 2011 and explore possible 
reasons behind the price jumps [15].   From a user’s 
perspective, the conceptual model is fairly simple - select an 
event source, detect abnormal price jumps, visualise the price 
jumps.  Realisation of this conceptual model however 
involves the use of complex price detection algorithms and 
comprises multiples steps: (1) Acquisition of stock data (2) 
Transformation of data to a format compatible to underlying 
CEP engine (3) Price Jump Detection (4) Visualisation.    
Detection of price jumps can be realised using a CEP engine, 
but other pre-processing and post-processing tasks requires 
manual coordination, using a variety of tools.  CEP alone 
cannot achieve complete automation of the above process. 
Switching between different CEP engines or configuration of 
different price jump algorithms makes the analysis task more 
time-consuming. Reproducibility of analysis results also 
presents a challenge.  Use of scientific workflows might seem 
a better solution to solve reproducibility and automation, but 
domain users are again confronted with multiple tools and 
technologies that require tremendous human effort.  To 
orchestrate the multiple steps of analysis into a workflow 
requires bridging the data flow between the different 
components in a seamless manner.   
 
The wide spectrum of technologies available across both 
CEP and workflow engines has itself become an obstacle to 
domain-experts from purely focusing on the science.   As non-
 technical domain experts are the real participants of the data 
analysis process, a data analysis framework from a user’s 
perspective must be designed.  Domain experts are not 
technical, but they know their data.  They should have the 
flexibility to freely design an abstract, conceptual model of 
their analysis process, which is purely tied to the functional 
behaviour of the process and captures user’s view point 
without specifying the underlying resources that actually 
implement the process.  They should be able to seamlessly 
interoperate with diverse tools and use existing functions and 
packages.  They should be able to build their process in an 
incremental and iterative fashion. They need to perform 
analysis in a collaborative manner.    
 
What we need are “hybrid processes” that have work-flow 
like structures extended to incorporate event processing.  Such 
an integrated solution can capitalise on the merits of both 
paradigms.  It would preserve the reproducibility, automation 
and transparency of scientific workflows and also benefit from 
the non-prescriptive and powerful expressive nature of event-
 based approaches.  It is also imperative that the “hybrid 
processes” be defined at a layer of abstraction, where domain 
experts can conceptually orchestrate a network of event 
processing components into a process model, that is stable and 
sustainable over a rapidly changing technology.   
 
Our research realises this vision through a framework 
called as Scientific Event Processing (SEP).  SEP is a novel 
approach that adds a new dimension to current scientific 
workflow practices through the incorporation of event 
307
processing.  By adopting the principles of Service Oriented 
Architecture (SOA) [13], SEP also allows users to build 
conceptual models of their analysis process that can be easily 
mapped to a variety of technology solutions.  SOA is an 
architectural approach that organises software components 
into interoperable, standards-based services (service-enabled 
technologies) that can be assembled together to create a 
solution to meet a particular business need. The next section 
presents an architectural overview of our proposed system.  
III. OUR PROPOSED APPROACH 
Scientific Event Processing (SEP) is a proposed hybrid 
solution that extends scientific workflows to include the 
processing of temporal event-streams, in a way that preserves 
the current principles of the scientific workflow model.  
A. Event and Event Pattern Concepts  
An Event Instance is “anything that happens or is 
contemplated as happening” [1].  An event instance belongs to 
an Event Type. All similar event instances are grouped under 
the same event type, for example the stream of event instances 
from a blood pressure monitor sensor.  A Temporal Event 
Stream is a set of event instances that are ordered for example, 
on a timestamp.  An Event Pattern is an abstract template that 
matches Event Instances based on their content.  An event 
processing engine applies an Event Pattern on an event stream 
to detect and generate Event Pattern Instances (EPI).  
B. Design Overview 
The following key design principles are proposed in 
support of this solution.  
(1) Creation of abstract service components 
Users should be able to build an abstract model of their 
event analysis process.  This is accomplished by defining 
abstract service components (ASC).  These components are 
purely functional entities from a user’s viewpoint and can be 
easily mapped to a choice of suitable service-enabled 
technologies.  Based on the model described in [15], three 
types of abstract service components are defined as shown in 
Table II, depending on the type of function carried out on the 
event stream. 
TABLE II 
TYPES OF ABSTRACT SERVICE COMPONENTS (ASC) 
ASC Role of abstract service component 
Event Import 
Service 
Extract Event Instances (EI) from event sources 
Event Source å EI 
Event 
Processing 
Service  
Filter : Produces a subset of events, based on 
some filtering critieria,  eg:- first 100 instances 
EI + Filter Expression å EI 
Transformation (Tx) : Takes input event 
instances and outputs event instances that are 
function of the input event  instances, eg:- 
translation, aggregation, merging 
EI +Tx  Function å EI 
Pattern Detection:   
EI + Pattern Template å Matched EPI 
Event Export 
Service  
EPI  or EI å Event Consumer 
(2) Composition of abstract service components into an 
abstract event processing network 
Domain scientists will be able to build a conceptual model 
of their event analysis process from the set of abstract service 
components defined earlier as shown in Figure 1.  This model 
depicts an abstract event processing network (EPN) and the 
nodes represent abstract service components.   
 
Fig. 1  Conceptual Modelling of Analysis Process 
Composition rules will be defined to ensure that only 
meaningful event processing processes can be constructed. 
Examples of valid rules are shown in Table III.   
TABLE IIII 
EXAMPLES OF VALID COMPOSITION RULES 
Composition Rule Validity 
Import å Filter åPattern 
Matchå Export 
Valid 
Import1 å Merge åExport Invalid – Merge must have two 
input sources 
Import1, Import 2 å Merge å 
Transform å Export 
Valid 
 
The abstract EPN is a crucial element in our design, as it 
facilitates modelling the event processing at a layer of 
abstraction independent of underlying technology.  The 
abstract EPN will be captured in a template that is based on 
SCA (Service Component Architecture) Assembly Model 
specifications [14].  SCA provides a model for composing 
applications that follow the principles of SOA and provides a 
set of specifications that describe how components 
implemented with different technologies can be composed 
together in a standard way.   Concrete service definitions will 
be added to this abstract template to generate a concrete 
workflow during the mapping phase.  These process templates 
are persisted to allow them to be re-used.  As domain experts 
examine event sources to engineer new workflows, pre-
 existing templates will be suggested to end-users.  Users will 
have the flexibility to re-run the pre-existing models or 
customise components in the template to explore new models.  
These process templates will assist in both consistent 
reproducibility of analysis results and also accelerate the pace 
of scientific discovery. 
   
(3) Mapping of abstract event processing network to a 
concrete workflow 
Abstract service components defined in a process template 
will be mapped to service-enabled technology solutions.  
308
Mapping is accomplished by maintaining a catalogue of 
services in a service repository.   To select candidate services, 
each service in the catalogue will be associated with a service 
type (as defined in Table II) that will be matched against the 
type of the abstract service component.  The service 
definitions of the selected concrete services are added to the 
abstract process template to generate a concrete SCA 
composite workflow model.  This SCA composite can now be 
executed on any application server that supports a SCA run-
 time.       
 
Event streams flowing between the abstract service 
components are based on a common Canonical Data Model.  
Software components called adapters are created where 
appropriate to transform data to and from the canonical model.  
Three types of adapters will be defined – (1) input adapters (2) 
output adapters (3) bridge adapters. The system architecture 
for our proposed system is shown below. 
 
Fig. 2 SEP System Architecture 
C. Validation 
Using our proposed framework, the case-study presented in 
Section II is modelled as shown in figure 3.   
 
Fig. 3 An event analysis process to detect price jump events in Telstra stock 
IV. CONCLUSIONS 
Currently, no research has successfully unified event 
processing and scientific workflows, and provided the ability 
to model workflow processes in a user-oriented manner.  
Siddhi [16], a stream-oriented CEP engine, represents the 
closest work to our research, but user-oriented modelling is 
not dealt with in Siddhi.  Categorisation of abstract services in 
this paper is inspired by the work in ADAGE [14].   ADAGE 
is an architectural pattern to allow non-IT domain experts to 
effectively express analysis processes.  This paper extends 
ADAGE by formalising the concept of ADAGE abstract 
services using SCA specifications and their mapping to 
concrete services and also introduces the idea of reusable, 
flexible processes from a user’s perspective through use of 
process templates. 
 
In summary, this research proposes a novel approach to 
integrating handling of temporal event streams, using 
scientific workflows that is intended to not only provide 
domain users a more efficient approach to analyzing event 
streams, but also enable domain expert users to build flexible, 
abstract models of their event analysis process and 
transparently maps them to concrete solutions.  The next 
phase in our research is to build an initial prototype and 
validate the prototype using case-study discussed in Section II.   
REFERENCES 
[1] D.Luckham and R. Schulte, Event Processing glossary-version 1.1, 
Event Processing Technical Society, July 2008. 
[2] Y.Gil, E.Deelman, M. Ellisman, T. Fahringer, G.Fox, D.Gannon, 
C.Goble, M.Livny, L.Moreau and J.Myers, “Examining the challenges 
of Scientific Workflow”, IEEE Computer, 40, (12), 26-34, 2007. 
[3] (2006) The ESPER website. [Online]. Available: 
http://esper.codehaus.org/ 
[4] (2009) The ORACLE CEP website. [Online]. Available: 
http://www.oracle.com/technetwork/middleware/complex-event-
 processing/overview/index.html 
[5] (2012) The TIBCO Business Events website. [Online]. Available: 
http://www.tibco.com.au/products/event-processing/complex-event-
 processing/businessevents/ 
[6] M.Hirzel, H.Andrade, H.Gedik, B.Kumar, V.Losa, G.Soule', R.Wu and 
K.-L: “SPADE Language Specification”, IBM Technical Report 
RC24760, (2009)  
[7] (2012) The APAMA website. [Online]. Available: 
http://www.progress.com/en/apama/event-processing-platform.html 
[8] (2009) The TAVERNA website. [Online]. Available: 
http://www.taverna.org.uk/ 
[9] (2009) The WINGS website. [Online]. Available: http://www.wings-
 workflows.org/ 
[10] (2009) The KEPLER website. [Online]. Available: https://kepler-
 project.org/ 
[11] A. Barker and J.V.Hermet, “Scientific Workflow: A Survey and 
Research Directions”, Lecture Notes in Computer Science, Springer, 
Volume 4967, p.746—753, 2008.   
[12] P.E. Schalkwyk,”Difference between Event-based and Workflow-based 
processes”, XMPro Inc 2012. [Online]. Available: http:// 
http://xmpro.com/the-difference-between-event-based-and-workflow-
 based-processes/ 
[13] The ServiceOrientation.com website. [Online]. Available: 
http://serviceorientation.com/index.php/whatissoa/p10 
[14] (2007) The OASIS SCA specification website. [Online]. Available: 
http://www.oasis-opencsa.org/specifications / 
[15] Rabhi, Fethi A., Lawrence Yao, and Adnene Guabtni. "ADAGE: a 
framework for supporting user-driven ad-hoc data analysis 
processes." Computing 94.6 (2012): 489-519.  
[16] S.Suhothayan, I.L. Narangoda, S.Chaturanga, K. Gajasinghe, S.Perera 
and V.Vishaka Nanayakkara, “Siddhi: A Second Look At Complex 
Event Processing Architectures”, Gateway Computing Environments 
Workshop (GCE), Seattle, 2011. 
[17] Opher Etzion, “Event Processing – past, present and future”, 
Proceedings of the 36th International Conference on Very Large Data 
Bases, September 13-17, 2010, Singapore, Vol. 3, No. 2 
[18] O.Etzion and P.Niblett, Event Processing in Action, 1st ed., August, 
2010. 
309
