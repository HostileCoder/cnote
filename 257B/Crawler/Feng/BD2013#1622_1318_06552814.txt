Leveraging Applied Materials TechEdge Prizm™ for Advanced 
Lithography Process Control 
 
Paul Llanos, Roger Cornell 
Advanced Software Services 
Applied Materials 
Hopewell Junction, NY 
Paul_Llanos@amat.com 
 
 
Abstract— Presently the CDSEM metrology tool continues to 
be the “ruler of the fab” providing metrology at over 100 steps 
along the way to building a modern semiconductor product. We 
explore the history of data volume generated with Fab CDSEM 
fleets. As we quantify the size of the fleet dataset, it becomes clear 
why historically only a subset of the rich dataset is ever utilized. 
We review what the treatment of the data using modern “big 
data” analytics and enterprise level server hardware does to 
accelerate development learning, increase engineering turns per 
day and raise the velocity of accurate manufacturing feedback. 
This paper further explores ways to leverage TechEdge Prizm to 
extract more value out of metrology for Lithography process 
control.  The paper will describe some of the challenges facing 
the changing Lithography metrology landscape and how Prizm 
delivers tailored analysis for these challenges.  Results at a 
customer site demonstrate that various types of analysis of 
CDSEM images and data are 10 times more efficient and 
thorough than traditional methods. 
Keywords— CDSEM, Metrology, Data mining, Lithography 
 
I. INTRODUCTION 
Circa late 1980s CDSEM data were printed or written into 
logbooks. At the time digital imaging was new and images 
were not stored to a disk. Each tool was an “island” and 
comparing tool results and matching tools was labor intensive 
and not well characterized. Tools had to be dedicated to 
specific measurement use cases. Host control through the 
SECS/GEM interface was becoming common around 1995 and 
allowed automated collection of data from the CDSEM tool 
fleet.   Real-time data collection led to closed loop feedback 
control of the exposure tool based on CDSEM metrology. This 
development placed intense pressure on the quality of the 
CDSEM data. Incorrect placement of the measurement on the 
wrong structure or incorrect analysis of the measurement signal 
would drive an incorrect exposure at lithography steps on the 
next product lot. Early innovators deployed this automated 
closed loop control scheme by the late 1990s. 
Many CDSEM measurement issues would be identified and 
improved over the next ten years. Quality metrics were added 
to the basic Bottom CD data. A Macro CD measurement 
capability was developed allowing averaging over many 
features, optionally reporting results for the average and each 
individual feature. Total Measurement Precision, Fleet 
Measurement Precision and Total Measurement Uncertainty 
metrics were developed [1]. Improved and increasingly 
powerful signal analysis algorithms would be developed in 
order to meet required measurement precisions. 
SEM images overlaid with measurement results and 
capturing the subtlety of process variation became more 
valuable. A re-measurable lossless image could also be saved 
driving the need for more storage on and off the tool. This 
image or waveform contained the raw numeric data needed for 
the algorithm to measure. The waveform allowed for re-
 measurement without a new SEM scan for cases of low 
precision, failed or incorrect measurements. Powerful off-line 
utilities were developed to optimize measurement strategies 
based on waveforms.  As the variety and complexity of 
measured features grew through shrinking technology nodes 
capturing waveform data at scale became more valuable.  The 
volume of the data set however was often too large for the 
system to save continuously.  If there is a measurement issue a 
lot is placed on hold or a subsequent lot is stopped. If the 
waveforms are available and saved in real-time costly tooltime 
might be avoided.  It is not good practice to store this data on 
the tool for longer than a few days.  A full tool hard drive will 
make a tool unstable and ultimately crash.  Such incidents 
serve well as a detractor to deploying the full-on continuous 
saving of the waveform dataset locally. 
II. NEW TECHNOLOGY STEADILY DEPLOYED 
Eventually CDSEM toolsets were connected to fab 
networks allowing enhanced capability to collect data. 
Furthermore tool event logs containing information about tool 
and recipe flow were collected and analysis tools created for 
fleet management.  FTP clients to tools opened access to the 
image dataset in a limited but distributed way. Prior to remote 
access users had to use costly tool time to collect data.  
Additional parameters were then added to the measurement 
analyses.  Parameters such as edge width measurement, contact 
hole major and minor axes, pattern recognition scores, standard 
deviations, and roughness could now be used to complement 
the measurement and widen the process control palette. Most 
of these additional metrics were captured only locally on the 
tool in the form of report files.  Simple dis-positioning did not 
require these metrics so the additional parameters were 
typically not sent to the host. The SECS/GEM interface was 
not equipped to handle image data or keep up with the rapidly 
256978-1-4673-5007-5/13/$31.00 ©2013 IEEE ASMC 2013
changing capability of what CDSEMs could output. While the 
CDSEM capability grew it became more difficult to effectively 
make use of the data.  Users were mired in finding, transferring 
and preparing of the data for detailed analysis. The labor 
intensive aspect often meant that data was not reviewed, new 
metrics were undiscovered or underutilized and often 
metrology quality languished unnecessarily. 
Over the last two decades the cost of ownership of CDSEMs 
has gone down mainly due to increased throughput.  This 
increase in measurement capacity has been consumed by 
increased sampling and the number of metrology steps per 
technology node due to increased complexity of processes. Fig 
1 shows the increase in percentage of steps taken up by 
metrology over 4 technology nodes. [2] 
 
Fig. 1. Percentage of steps in route taken by metrology/defect and process as 
a function of IBM technology nodes. 
As the density of the features has doubled every two years [4] 
it is common to see more structures are being measured for 
better sampling.  As the number of measurements increases we 
also increase the number of images we save.  In parallel the 
number of entries in event or error logs and trace files also 
accumulates. All of the data collected in a medium sized fab 
across a fleet of 20 tools in one year amounts to around 84TB 
as shown in Fig. 3. This is Big Data.                         
III. DATA VOLUME 
The chosen approach to sizing of the CDSEM dataset is to  
include all user oriented data useful to the fab engineering 
staff.  Fig. 2 shows size calculations of data volume of a 
medium size fab. [5] 
 
 
 
 
 
Fab Size # CDSEMs DataVolume (TB/Yr) 
Small 10 42 
Medium 20 84 
Large 60 253 
Fig. 2. Data Volume Estimates for different sized fabs assuming a mixed 
fleet of older and newer CDSEM generations. 
Data is reported by the tool on a per wafer basis. This includes 
the critical feature measurements and associated quality 
metrics.  Additionally recipe and target build descriptors and 
statistical analysis output data are all captured in a file with 260 
columns of data for each measurement. 
On a per measurement level the data set would include one or 
more images.  The stored size varies depending on pixel 
density, scan area, and compression options. The re-
 measurable waveform image is included as one of the optional 
images to save.  In the sizing we include three images by 
priority; waveform, measurement display and pattern 
recognition field-of-view. 
Medium Fab Annual Data Volume per CDSEM 
Generation (GB) 
Data Type Prior Gen Current Next Gen 
Wafers per hour 18 30 50 
Images 50244 83740 139567 
PR FOV 2115 3524 5874 
Meas Display 5836 9727 16212 
Waveform 42293 70488 117481 
Report Files 56 680 1460 
Events 2 33 49 
Configuration 2 8 9 
Totals (GB) 50305 84461 141085 
Fig. 3. CDSEM Data volume estimated annually comparing different tool 
generations of a medium sized fab or 20 tools.  Assuming 20 sites per wafer, 
90% Tool Utilization and 80% Fab Capacity. 
Additional data to be included is event log data which provides 
contextual detail in and around all measurements. This data set 
has been shown to reveal insight into tool issues, recipe errors, 
alignment problems, software issues, calibration matching and 
other scenarios. The data allows temporal granularity to the 
second around a given tool event and also shows telling trends 
when rolled up over time.  The final data type captured is tool 
global configurations.  These contain parameters which vary 
regularly such as fine adjustments of column alignment 
settings and those which are open to user configuration 
preferences.  
Figure 3 summarizes the data types and volume estimates for 
different generations of CDSEM. The summary captures the 
increase in data volumes due to tool generational throughput 
differences.  The annual data volume estimates for a small, 
medium and large sized modern semiconductor fab are shown 
257 ASMC 2013
in Figure 3. These estimates assume a given throughput, 
utilization and fab capacity.  The volume is dominated by the 
image dataset. 
Reduction of this dataset with a long time horizon is possible 
by deploying a modern enterprise scale big data solution. We 
now describe a system and a set of analysis capabilities turning 
a large rich dataset into actionable insights. 
 
IV. TECHEDGE PRIZM AND BIG DATA 
“Big data is all about better analytics on a broader spectrum of 
data.” [3] 
 
Applied Materials TechEdge Prizm is a web based CDSEM 
data mining application released in Fall 2012.  It provides 
advanced data mining capability of CDSEM metrology at 
scale.  This approach of leveraging the vast differentiated data 
in Prizm gives customers the ability to tease out tool, recipe 
and process excursions from the noise of production and attain 
new levels of Lithography process control.  The upcoming 
challenges of shrinking design rules, 3D, EUV and other new 
process techniques prompted the development of Prizm.  Fabs 
rely more than ever on the images and deeper analysis than 
legacy host systems can provide.  For example at IBM with 
each technology node the number of CDSEM steps has 
increased by 40%. [1] Today’s 22nm node requires CDSEM 
measurement at over twice the number of process steps 
required for the 65nm process. 
 
CDSEM accounts for the largest number of metrology steps 
and is the workhorse for high volume manufacturing process 
control.  What keeps this measurement technique the go-to 
solution is its ability to capture high resolution images of in-
 chip device features.  With the increasing complexity of 
measurement strategies and the growing number of products 
running in foundries and IDMs the need to audit recipes and 
ensure metrology integrity is critical.  The goal of Prizm with 
respect to Lithography process control is to better utilize the 
full data and high resolution images to provide new analysis 
modalities in order to streamline the workflow of process 
engineering stakeholders.  Streamlining workflow is critical in 
order to accelerate learning and shorten development cycle 
time. 
 
Fig. 4. Workflow improvements seen with Prizm over traditional methods 
Where there are issues with metrology integrity Prizm provides 
the tools to distinguish between tool, recipe or process issues.  
Outlined here are several key innovations in Prizm that reduce 
the friction of data post processing for Lithography process 
engineers to answer questions like these and finally exploit 
CDSEM Big Data. See Fig. 4.  Prizm productivity 
improvements and insights are illustrated for each case below. 
V. CDSEM METROLOGY CHALLENGES 
The following are workflow challenges that Lithography 
process stakeholders face and the different modalities that 
Prizm provides to meet these needs.   
Meas Errors Root Cause:  A critical lithography activity is to 
investigate a CDSEM recipe that is reported to have low 
Cp/Cpk.  These are the steps required to find a solution: 
1. Confirm issue - Pull Wafer-to-Wafer Report 
2. Troubleshoot - Identify root cause, use quality metrics 
3. Action - Fix Recipe 
4. Verify - Report and Track 
Confirm Issue:  Using a Wafer-to-Wafer report an engineer can 
quickly understand that this recipe is running poorly with 
respect to other layers at the 32nm process.  In order to do this 
a live search query is made that identifies all targets at the same 
level across the process and then a comparison can be made. 
 
Fig. 5. Live search for all similar targets. 
258 ASMC 2013
 
 
Fig. 6. Wafer-to-Wafer chart showing flyers and missed measurements 
The engineer can troubleshoot using all targets and all wafers 
in context reviewing bottom CD and many other quality 
metrics, in this case pattern recognition score (Pr Score).  Pr 
Score, measured charge, focus offset, fit quality, and other 
metrics are all examples of data which is not sent to the fab 
host but put at the fingertips of the Prizm user. 
Troubleshoot: Subsequently the engineer clicks on the 
interactive chart to pull the wafer map and images. 
 
Fig. 7. Wafer map and image review in Prizm 
Upon review of wafer map and images the pattern recognition 
step is found to be non-unique resulting in flyers and missed 
measurements.  This detailed query on Prizm took only 
seconds to make ~100 wafers and associated images available.  
If the same data and images were to be gathered manually from 
a tool set or repository, the time to find and collect the data 
could take hours. 
Take Action:  A recipe writer selects a unique feature for 
pattern recognition based on the knowledge of the root cause. 
 
Fig. 8. Selecting a unique pattern on the CDSEM tool 
Verify - Report and Track:  The engineer can generate a Roll 
Up report to verify the initial recipe correction and regularly 
thereafter to track continuing performance of ALL 32nm target 
measurements.  This report aggregates thousands of wafer 
statistics in seconds, again saving multiple hours compared to 
traditional methods. 
 
Fig. 9. Rollup report showing all 32nm target performance 
After the target has been fixed the data looks much better with 
tight sigma, no flyers and no missed measurements. See Fig. 
10. 
 
Fig. 10. Another Wafer-to-Wafer pull is done showing clean data 
 
Fig. 11. Metrology integrity root causes 
Process Centering:  The following example shows the wafer-
 to-wafer mean chart with an FEM wafer running in context of 
production.  The process centering is confirmed rapidly as the 
data and all images are at hand after dose correction.  No need 
to find the tool the data was run on or manually collect and 
259 ASMC 2013
chart the results. The process can be back under control with 
improved Cpk 2 hours sooner. 
 
Fig. 12. FEM wafer in-line with production measurements 
Rework Verification:  Fig. 13 illustrates the ability to 
visualize through-lot history on one chart.  The data points are 
colored by Layer showing reworked lots or flyer data at a 
glance. 
 
Fig. 13. Through lot History 
Furthermore Fig. 14 demonstrates the unique ability of the 
Verity4i tool to report localized wafer charge.  In this instance 
Prizm can provide crucial early learning about the impact of 
new resist materials or track  recipe changes driving rework. 
 
Fig. 14. Wafer-toWafer chart of measured charge across multiple wafers 
 
Raw Files Search:  Prizm provides a way for users to quickly 
find and download all the native files that are generated from 
the tools for use in excel or other offline utility.  Traditionally 
users access the measurements and images via the native files. 
(Fig. 15).  The identification of specific data takes only seconds 
while downloads are 10 times faster by compressing all the 
data into one file prior to sending. 
 
Fig. 15. Raw Files download 
Development Images Review: Directly from the Wafer-to-
 Wafer chart a link is provided allowing the engineer to review 
the entire set of images captured from the wafer in a single 
click. Included are all measurement target images as well as 
images captured during wafer alignment. This makes the job 
of looking at a full wafer run a simple scan of thumbnails. 
Figure 16 depicts the flow from wafer-to-wafer chart to full 
images gallery. 
260 ASMC 2013
 
 
Fig. 16. Development Images Review in a Gallery by single mouse click 
including wafer alignment images, pattern recognition images and 
measurement display images across the wafer. 
 
VI. RESULTS 
Utilizing the capability in Prizm the efficiency across several 
workflow categories captured in Fig. 4 has improved by 10x 
or more in many cases.  In cases where metrology engineers 
were manually gathering data from tools in unorganized 
folders the process of finding, transferring and preparing data 
for detailed analyses is done in minutes rather than hours. The 
speed with which data can be reviewed and the resulting 
improvements in metrology integrity are seen. Better and 
more utilization of the big dataset generated by a fleet of 
CDSEM tools by automatically collecting, organizing, 
visualizing and cross linking through state of the art analytics 
are demonstrated. 
VII. CONCLUSIONS 
The introduction of Prizm in 2012 has demonstrated new 
ways to extract value from the ever growing metrology data 
set.  Prizm proves to be far simpler and effective than 
traditional solutions.  It is accessible on any browser enabled 
device as opposed to rigid platform dependent client 
applications.  Traditionally tools stored data and images for 
less than a month.  Users are drawn to the Prizm web 
application since it stores data for up to 7 years making it the 
go to solution to review long term historical data.  The ease of 
use of the wafer-to-wafer chart engages Lithography 
stakeholders with images and trends of their process flow.  
Prizm exploits an underutilized dataset to enhance the Verity4i 
CDSEM tool offering and Applied fab software services to 
enable the next generation of advanced Lithography process 
control.  At a customer location productivity improvements 
have been shown to accelerate troubleshooting and time to 
corrective action. 
REFERENCES 
[1] Eric Solecky ; Chas Archie ; Bill Banke; New comprehensive metrics 
and methodology for metrology tool fleet matching. Proc. SPIE 5752, 
Metrology, Inspection, and Process Control for Microlithography XIX, 
248 (June 21, 2005); doi:10.1117/12.602330.P. Zikopoulos, et al, 
 
[2] E. Solecky, et al, In-line E-beam Wafer Metrology and Defect 
Inspection: The End of an Era for Image-based Critical Dimensional 
Metrology?  New life for Defect Inspection, Phil. Trans. Roy. Soc. 
London, vol. A247, pp. 529–551, April 1955. (references) 
[3]  “Harness the Power of Big Data: The IBM Big Data Platform”, Mcgraw 
Hill Professional 2013 
[4] Kurzweil, R “The Singularity is Near: When Humans Transcend 
Biology”, Penguin books,  2005 
[5] Christian Gregor Dieseldorff (2013)  
SEMI World Fab Forecast. SEMI Industry Research and Statistics 
261 ASMC 2013
