A Method of Data Distribution for Distributed
 Cross Join
 Ping Lu?†, Shengmei Luo†, Zhiping Wang†,Wenwu Qu†
 {lu.ping, luo.shengmei, wang.zhiping1,qu.wenwu} @zte.com.cn
 ?Southeast University
 †ZTE Corporation
 Abstract—One of the major challenges in big data processing
 is the efficiency of cross join, such as the similarity calculation in
 business intelligence. In this paper we introduce an optimal data
 distribution algorithm for distributed cross join which combine
 each row from the first table with each row from the second
 table, which can reduce the network traffic and guarantee the
 computation balance of the distributed system.
 I. INTRODUCTION
 Big data has emerged as one of the most visible topics
 in technology today. As with other trends such as mobile,
 social and cloud computing, big data represents both business
 opportunities and technical challenges. Organizations of all
 types are extracting increased value from large data sets that
 come from real-time data streams, video, mobile Internet, and
 many other sources.
 However, handling this data is not easy. Big data must not
 only be stored, it also be transmitted, processed and reused by
 a variety of applications. This means big data impacts every-
 thing in the entire IT stack, including servers, storage[1][2],
 computation middleware[3][4][5] and applications[6][8][7].
 One of the major challenges in big data processing is the
 computation of joins, which have been studies in recent years
 [9][10][11].
 Although different joins are optimized by different methods,
 cross join which is also called broadcast join, as one kind
 of joins which returns the Cartesian product of rows from
 tables , is only support that one of the two tables is small
 enough to be stored in the memory. At ZTE the application
 of recommendation system, which has users more than tens
 of millions, needs to calculate the similarity between users.
 The storage of user information is close to 1T, so it can not
 be stored in the memory. It will lead to network traffic if the
 computation is realized using the method. Usually, a big table
 is stored in the storage system using the form of sub-tables
 with the same size, which is called block in hadoop system.
 The implementation of the cross join between two big tables
 is to cross join each sub-table of the first table with all sub-
 tables of the second table. The method needs to duplicate all
 the sub-tables of the smaller table on each node, which usually
 tends to cause a bottleneck of network traffic.
 In this paper, we propose a sub-table distribution algorithm
 for distributed cross join which can reduce the network traffic
 on the basis of the computation balance of the distributed
 system. In the implementation of cross join, we only copy
 a part of sub-tables of the two tables on each node just to
 meet the demand of the computation. In the experiments we
 will show that the algorithm can reduce the network traffic
 effectively for cross join of two big table.
 The paper is organized as follows. In the next section, we
 introduce the data distribution model of cross join. Next, we
 present the algorithm of data distribution and the optimization
 in Section 3. We then continue with a presentation of the
 experiment of our algorithm in Section 4, and the conclusion
 in Section 5.
 II. DATA DISTRIBUTION MODEL
 Assume there are two big tables of TableA and TableB with
 the sub-tables of NumTa and NumTb, respectively. There is
 a cluster consists of same physical nodes with the number
 of NumNode. Without loss of generality, we assume all the
 sub-tables have the same size, and NumTa is not smaller than
 NumTb. Consider the cross join of TableA and TableB, which
 means that each sub-table of TableA need to cross join with
 all sub-tables of TableB.
 In traditional solution, the larger table’s sub-tables are
 evenly in the cluster and the smaller table’s sub-tables are
 duplicated on each node. Then the network traffic will be Num-
 Ta+ NumTb* NumNode. Each node has (NumTa /NumNode)
 TableA’s sub-tables and (NumTb) TableB’s sub-tables, so the
 computing capacity of a node is (NumTa /NumNode)* NumTb.
 On the condition of not reduce each node’s computing
 capacity, we propose a new solution of sub-table distribution in
 the cluster. We make the number of sub-tables of both tables on
 each node similar to
 √
 NumTa ?NumTb/NumNode.Then
 the network traffic is 2
 √(NumTa ?NumTb ?NumNode.
 However, the solution brings a new problem that we must
 ensure in the cluster each sub-table of TableA needs cross
 join with each sub-table of TableB. We solve the problem by
 transmitting the sub-tables of both Tables on the appropriate
 nodes which is described in the algorithm 1 and 2.
 Assume k= NumTa/NumTb, then we can get the ra-
 tio of the network traffic with the traditional solution,
 2
 √
 k ?NumNode/(k +NumNode). We can see that if the
 values of k and NumNode are close, the network traffic of
 the two solutions are similar. Otherwise, the larger of the
 difference between k and NumNode, the traditional solution
 will consume more network traffic. For example, when k is
 2013 International Conference on Advanced Cloud and Big Data
 978-1-4799-3261-0/14 $31.00 © 2014 IEEE
 DOI 10.1109/CBD.2013.5
 105
Fig. 1. A coverage solution of a 4*4 rectangle with 4 nodes
 TABLE I
 SUB-TABLE DISTRIBUTION FOR FIG.1
 Node ID sub-tabls on the node
 Node1 Ta1 Ta2 Tb1 Tb2
 Node2 Ta1 Ta2 Tb3 Tb4
 Node3 Ta3 Ta4 Tb1 Tb2
 Node4 Ta3 Ta4 Tb3 Tb4
 close to 1 and NumNode is 100, then the network traffic of
 our solution can reduce 80% than traditional solution.
 III. ALGORITHM
 In this section, we will describe how to distribute the sub-
 tables in the cluster. We regard the computing capacity of
 TableA cross join TableB as a rectangle, whose length and
 width are the number of sub-tables of the two tables. The
 computation that a node can complete can be regarded as a
 cover on the rectangle. We begin with a simple example. We
 then introduce the details and optimizations of the algorithm.
 A. Example
 Consider the cross join between TableA and TableB in the
 cluster consists of four nodes, where TableA and TableB have
 four sub-tables respectively. Each sub-table has a unique name,
 for example Ta1, Tb4. Each node has also a unique name, for
 example Node2. Then the rectangle consists of 16 grid cells as
 illustrated in Fig 1. Each cell represents a cross join between
 two sub-tables of Tai and Tbj. When a cross join of two sub-
 tables can be completed on a node, the cell can be covered by
 the node, for example the cell of sub-tables of Ta1 and Tb1 is
 covered by Node1.
 The coverage solution shown in the Fig 1 is one of the
 optimal solutions whose data distribution is illustrated in the
 following table. The four nodes have the same computing
 capacity and the network traffic is minimal. We can see that,
 when all the nodes completes its computation, the cross join
 of the two tables can be completed.
 B. Algorithm Description
 In the following, we introduce the approach to construct the
 coverage solution on the rectangle of NumTa*NumTb using
 NumNode nodes.The pseudo-code of approach is illustrated in
 Algorithm 2. First, we estimate the replications of two tables,
 and the replications means the average sub-tables of the two
 tables on a node. Basically, we should ensure the computation
 balance among the cluster,where each node should complete
 at least the computing capacity of NumTa* NumTb/NumNode.
 In order to reduce the network traffic, the number of sub-tables
 of TableA and TableB should be similar. So we can estimate
 the replications of TableA and TableB using the following
 expressions:
 Repa =
 √(NumTa ?NumTb/NumNode)
 ?NumNode/NumTa
 =
 √(NumNode ?NumTb/NumTa)
 Repb =
 √(NumTa ?NumTb/NumNode)
 ?NumNode/NumTb
 =
 √(NumNode ?NumTa/NumTb)
 Second, we construct the coverage solution using the repli-
 cations. However, Repa and Repb are usually not integers, so
 they can not used to divide the rectangle directly. We divide the
 rectangle into two sub-rectangles, and on each sub-rectangle
 we use different replications. Through an appropriate division,
 we make that the average replications are similar to Repa and
 Repb. The division of the rectangles is constructed using the
 following expressions:
 Xa1 = Int(Repa) (1)
 Xa2 = Xa1 + 1 (2)
 Xa1 ?Xb1 +Xa2 ?Xb2 = NumNode (3)
 Xb1 +Xb2 = Repb (4)
 where Xa1 and Xb1 are used to divide the first sub-rectangle
 and Xa2 and Xb2 are used to divide the second sub-rectangle.
 Only one of the last two expressions will be valid, which is
 decided by the NumNode. As illustrated in Algorithm 1, if
 NumNode is smaller than middle, then the former expression
 is valid, otherwise the later is valid. Through these expres-
 sions, we can compute the coverage solution of the two sub-
 rectangles.
 106
Algorithm 1 construct the coverage solution
 Input:
 NumTa /*the number of sub-tables of TableA*/
 NumTb
 NumNode /*the number of nodes in the cluster*/
 void SolutionConstruct( NumTa, NumTb, NumNode)
 {
 k = NumTa / NumTb
 repa = Int(
 √
 NumNode/k)
 repb = Int(√NumNode ? k)
 min = repa*repb
 max = (repa+1)*(repb+1)
 middle = (repa+1)*repb
 if NumNode == min then
 Xa1= repa,Xa2= 0,Xb1= repb,Xb2= 0
 if NumNode == max then
 Xa1=0, Xa2= repa +1,Xb1=0,Xb2= repb +1
 if min < NumNode <= middle then
 Xa1 = repa, Xa2= repa +1
 Xb1 = repb +repa* repb -Nn
 Xb2= Nn- repa* repb
 if middle < NumNode < max then
 Xa1 = repa, Xa2= repa +1
 Xb1 = repb +repa* repb -Nn+ repa+1
 Xb2= Nn- repa* repb- repa
 }
 Algorithm 2 division of the rectangle
 void Construct(Nn,Na,Nb,Xa1,Xa2,Xb1,Xb2)
 {
 NodeStart = 0
 PartionA1=
 Int((Na*(Xa1*Xb1)/((Xa1*Xb1)+(Xa2*Xb2))))
 //Using Xa1*Xb1 divides the rectangle of
 //PartionA1*Nb into small rectangles.
 //Each small rectangle represents a node.
 //The sub-tables of the two tables related
 //with small rectangle are distributed the node
 BlockDistribution(1, PartionA1, 1,
 Nb, Xa1, Xb1, NodeStart)
 //Using Xa2*Xb2 divides the rectangle of
 //(Na-PartionA1)*Nb into small rectangles.
 BlockDistribution(PartionA1+1, Na, 1,
 Nb, Xa2, Xb2, NodeStart)
 }
 Third, we distribute the sub-tables in the cluster based on
 the coverage solution. In the data distribution process, we first
 estimate the split point of TableA. Then we can compute the
 division point in each sub-rectangle to construct the area for
 different node, and distribute the sub-tables related with the
 area to related nodes.
 C. Optimization
 In the data distribution process of a sub-rectangle, the edge
 of TableA is divided using Xa1( or Xa2) and the edge of
 TableB is divided using Xb1( or Xb2) , that the network traffic
 Fig. 2. A coverage solution of a 5*5 rectangle with 5 nodes
 Fig. 3. An optimal coverage solution of a 5*5 rectangle with 5 nodes
 maybe not optimal enough . For example, the number of nodes
 is 5, and the sub-table numbers of TableA and TableB are both
 5. According to algorithm 1, the values of Xa1, Xa2, Xb1,
 Xb2 are 2, 3, 1, 1. The coverage solution is shown in Fig 2.
 The rectangle is first divided into two parts, where one part is
 divided with 2*1, and the other divided with 3*1. We can see
 that the shorter edge is divided into more segments, which will
 lead to more network traffic. So we update the data distributed
 algorithm, as illustrated in Algorithm 3, that the longer edge
 will be divided into more segments, shown in Fig 3.
 107
Fig. 4. Another optimal coverage solution of a 5*5 rectangle with 5 nodes
 Algorithm 3 an optimization of rectangle’s division
 void OptimalConstruct(Nn,Na,Nb,Xa1,Xa2,Xb1,Xb2)
 {
 NodeStart = 0
 PartionA1=
 Int((Na*(Xa1*Xb1)/((Xa1*Xb1)+(Xa2*Xb2))))
 //the first sub-rectangle
 MaxX1 = maxXa1,Xb1
 MinX1 = minXa1,Xb1
 If (PartionA1 >= Nb) then
 BlockDistribution(1, PartionA1,
 1, Nb, MaxX1, MinX1, NodeStart)
 Else
 BlockDistribution(1, PartionA1, 1,
 Nb, MinX1, MaxX1, NodeStart)
 //the second sub-rectangle
 MaxX2 = maxXa2,Xb2
 MinX2 = minXa2,Xb2
 If (Na-PartionA1 >= Nb) then
 BlockDistribution(PartionA1+1, Na, 1,
 Nb, MaxX2, MinX2, NodeStart )
 Else
 BlockDistribution(PartionA1+1, Na, 1,
 Nb, MinX1, MaxX1, NodeStart)
 }
 The data distributed algorithm ensures that there is no
 intersection between the coverage areas of any two nodes.
 Although it brings less network traffic, it maybe lead to the
 unbalanced computation among the nodes. The solution is
 to update the function OptimalBlockDistribution(), which will
 ensure that each node can complete the same computation. The
 coverage solution is shown in Fig 4, each node can complete
 6 sub-table’s cross joins. There are two coincident grid cells
 in the areas of Node1 and node2, and 3 grid cells between
 Node4 and Node5.
 IV. OTHER WORK
 In current distributed storage system, the sub-tables usually
 have been replicated in the cluster. We also design and test a
 greedy algorithm as illustrated in Algorithm 4. We first record
 the computation and the sub-tables of each node, and the cross
 joins of the sub-tables which can be complete already. For each
 cross join of Tai and Tbj which has not been completed, we
 select the node with minimal computation among the nodes
 where the Tai located. We then transmit Tbj to this node and
 update related information. The process is repeated until all
 cross joins of the sub-tables can be completed.
 Algorithm 4 a greedy algorithm for data distribution
 void GreeydySelection(Na,Nb,Nn)
 {
 Bool CrossJoinChecking[Na, Nb] //records the
 //computation of TableA cross join TableB
 Initial (CrossJoinChecking)
 For(i = 1; i <= Na; i++){
 for(j= 1; j <= Nb; j++){
 if (CrossJoinChecking [i,j] == false){
 Nodei = {nodes| Ai is on this node,
 and the computation is minimal}
 Add Bj to Nodei;
 For each Ak on Nodei
 If CrossJoinChecking [k,j] == false
 then{
 CrossJoinChecking [k,j] =true;
 Nodei.computation ++;
 }
 }
 }
 }
 }
 V. NETWORK TRAFFIC EVALUATION
 We have implemented simulations to evaluate the network
 traffic of algorithm 3. In our simulations the number of nodes
 in the cluster is 10, 50, 100, 500 nodes respectively. The
 NumTb , the number of TableB’s sub-tables, is 100, 100, 200,
 1000 respectively. The ratio of k= NumTa/NumTb is 1, 2,
 5, 10 respectively. Table 2 shows the network traffics of the
 algorithm 3 and the traditional solution when there are no
 initial replications of sub-tables. When k is equal with the
 number of nodes, the network traffic of the algorithm 3 is the
 same with traditional solution. Otherwise, the network traffic
 of the algorithm 3 is less than traditional solution. The effect
 is better with the increase of the number of nodes and the k
 is close to 1.
 Tables 3-6 show the network traffics of the algorithm 3,
 the algorithm 4 and the traditional solution when there are
 initial replications of sub-tables. The network traffics are the
 average results of 10 runs. In the simulations, we set the initial
 replications of TableA and TableB are both 3, and the sub-
 tables are evenly distributed in the cluster where are no same
 sub-tables on a node.
 When NumNode is small, the network traffics of the al-
 gorithm 3 increase quickly with the increase of k, and the
 effect becomes worse than the algorithm 4 and the traditional
 method. So the algorithm 4 is a better choice when NumNode
 is small. When NumNode is large and k is smaller than
 NumNode, the network traffic of the algorithm 3 is less than
 the algorithm 4 and the traditional method. The effect is better
 108
TABLE II
 EXPERIMENT RESULT FOR ALGORITHM 3
 k NumNode NumTa NumTb Network traffic Network traffic
 of in traditional
 Algorithm 3 solution
 1 10 100 100 602 1100
 2 10 200 100 802 1200
 5 10 500 100 1301 1500
 10 10 1000 100 2000 2000
 1 50 100 100 1406 5100
 2 50 200 100 2000 5200
 5 50 500 100 3103 5500
 10 50 1000 100 4202 6000
 1 100 200 200 4000 20200
 2 100 400 200 5607 20400
 5 100 1000 200 8004 21000
 10 100 2000 200 12403 22000
 1 500 1000 1000 44006 501000
 2 500 2000 1000 55012 502000
 5 500 5000 1000 100000 505000
 10 500 10000 1000 141007 510000
 TABLE III
 NUMNODE IS 10 AND NUMTB IS 100
 k Network traffic Network traffic Network traffic
 of of in traditional
 Algorithm 3 Algorithm 4 solution
 1 419.9 422.9 700
 2 559.6 472 700
 5 909.3 498 700
 10 1403.5 500 700
 TABLE IV
 NUMNODE IS 50 AND NUMTB IS 100
 k Network traffic Network traffic Network traffic
 of of in traditional
 Algorithm 3 Algorithm 4 solution
 1 1324 2524 4700
 2 1879.2 3014 4700
 5 2907.4 3551.8 4700
 10 3948.1 3849.8 4700
 TABLE V
 NUMNODE IS 100 AND NUMTB IS 200
 k Network traffic Network traffic Network traffic
 of of in traditional
 Algorithm 3 Algorithm 4 solution
 1 3877.5 10639.2 19400
 2 5445.2 12667.2 19400
 5 7760.8 14945.5 19400
 10 12021 16151.4 19400
 TABLE VI
 NUMNODE IS 500 AND NUMTB IS 1000
 k Network traffic Network traffic Network traffic
 of of in traditional
 Algorithm 3 Algorithm 4 solution
 1 43735.8 278036.1 497000
 2 54681.1 330022.9 497000
 5 99389.5 386474.6 497000
 10 140153.2 417496.5 497000
 with the increase of the number of nodes and the k is close
 to 1.
 VI. CONCLUSION
 The main contribution of this paper is present a method
 of data distribution for distributed cross join. The simulations
 we implement demonstrate that our solution can reduce the
 network traffic effectively when the size of the two tables is
 close and the number of nodes is large.
 REFERENCES
 [1] S.Ghemawat, H. Gobioff,and Shun-Tak Leung. The google ?le system. In
 19th ACM Symposium on Operating Systems Principles, 2003.
 [2] Apache. Hadoop. http://hadoop.apache.org/, 2006.
 [3] J. Dean and S. Ghemawat. MapReduce: Simpli?ed data processing on
 large clusters. Communications of the ACM, 51(1):107C113, 2008.
 [4] Grzegorz Malewicz, Matthew H. Austern, Aart J. C. Bik, James C.
 Dehnert, Ilan Horn, Naty Leiser, Grzegorz Czajkowski. Pregel: a system
 for large-scale graph processing. SIGMOD Conference 2010: 135-146.
 [5] Sangwon Seo, Edward J. Yoon, Jae-Hong Kim, Seongwook Jin, Jin-Soo
 Kim, Seungryoul Maeng. HAMA: An Efficient Matrix Computation with
 the MapReduce Framework. 2010, CloudCom, pp.721 726
 [6] C. Olston, B. Reed, U. Srivastava, R. Kumar, and A. Tomkins. Pig Latin:
 a not-so-foreign language for data processing. In Proceedings of the 2008
 ACM SIGMOD international conference on Management of data, pages
 1099C1110. ACM, 2008.
 [7] A. Thusoo, J.S. Sarma, N. Jain, Z. Shao, P. Chakka,S. Anthony, H.
 Liu, P. Wycko?, and R. Murthy. Hive: a warehousing solution over
 a Map-Reduce framework. Proceedings of the VLDB Endowment,
 2(2):1626C1629, 2009.
 [8] Biswapesh Chattopadhyay, Liang Lin, Weiran Liu, Sagar Mittal,
 Prathyusha Aragonda, Vera Lychagina, Younghee Kwon, Michael Wong.
 Tenzing A SQL Implementation On The MapReduce Framework. PVLDB
 4(12): 1318-1327 (2011)
 [9] F.N. Afrati and J.D. Ullman. Optimizing joins in a Map-Reduce environ-
 ment. In Proceedings of the 13th International Conference on Extending
 Database Technology, pages 99C110. ACM, 2010.
 [10] S. Blanas, J.M. Patel, V. Ercegovac, J. Rao, E.J. Shekita, and Y. Tian.
 A comparison of join algorithms for log processing in MapReduce. In
 Proceedings of the 2010 international conference on Management of data,
 pages 975C986. ACM, 2010.
 [11] H. Yang, A. Dasdan, R.L. Hsiao, and D.S. Parker. Map-Reduce-Merge:
 simplified relational data processing on large clusters. In Proceedings of
 the 2007 ACM SIGMOD international conference on Management of
 data, pages 1029C1040. ACM, 2007.
 109
