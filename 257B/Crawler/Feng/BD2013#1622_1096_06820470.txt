Proceedings of ICCT2013
 Implementation of K-Means Based on Improved Storm Model
 Jingling Zhao, Zhaohua Sun, Qing Liao 
Beijing University of Posts and Telecommunications, Beijing 100876, China 
zhaojingling@bupt.edu.cn, szh1124@163.com, liaoqing@bupt.edu.cn
 Abstract: In recent years, big data processing has been a 
trend. Hadoop and some other cloud computing 
technologies make batch processing possible to process 
big data. Storm is like a real-time Hadoop. Storm model 
is easy, but it’s difficult to deal with complex Topology 
due to the increasing inter-dependences between 
components. This paper proposes a novel method which  
simplifies the Storm Topology programming model by 
combining Spring with Storm. It provide a modular 
approach and a unified configuration model to build 
topologies and easy to use API for using Storm.
 Meanwhile, this paper propose a system to process data 
and realize the K-Means clustering algorithm in Storm.
 The practice results is shown and analyzed to prove the 
effectiveness of the system and model, at the same time 
it proves that Storm can improve the clustering 
algorithm processing speed.
 Keywords: Stream processing; Storm; Spring; K-Means;
 GPS; Kafka
 1  Introduction
 As the amount of data increases, big data processing 
technologies are also developing. Hadoop [1] is a 
representative distributed data processing technology for 
cloud computing. While people have high demand on 
real-time response now so that Storm [2][3] appears. 
Storm is an open-source distributed realtime 
computation system. It is especially designed for 
processing endless stream data, which makes stream 
processing easier and reliable. The biggest difference 
between Storm and Hadoop is Storm never stop unless 
you kill it explicitly. 
The GPS data is generated constantly over time and 
space from cars, which is large but reflect the temporal 
and spatial characteristics of urban traffic network, 
making it necessary to manage this dynamic data. 
Through the cluster analysis based on cars' location 
information by time, we can not only learn traffic 
information in real-time but provide a reasonable basis 
for road planning of the city. 
Therefore, the GPS data requires effective analysis 
technology for meaningful information search to mirror 
traffic condition. However, the traditional database 
based real time analysis methods cannot meet the 
requirements because their limited performance on the 
speed of response for solving large scale data. As an 
alternative solution, realtime big data processing 
analysis methods is required. Storm is very simple in 
this challenge which processes data seems like a water 
treatment system. Spout [4] reads data from external 
data source and then emits the data to Bolt [4] to process 
until the whole Topology [4] is completed. And Storm is 
not an expensive solution to solve problems with large 
streaming data sets at all. However, as the Topology 
logic becomes complex, the coupling and the 
dependences among components will increase. 
Thus, this paper aims to propose structure and 
computing environment needed for analysis of 
large-scale GPS data which was collected. The proposed 
system consists of three parts: data gathering, data 
analysis, and data storage. Our focus is on data import
 and data analysis module. The data gathering module 
simulates stream status by Kafka [5][6], and there are  
related introduction about Kafka and Storm in 
[8][9][10][11]. The K-Means is used for the GPS data 
analysis, which is the most important for this paper. 
Data storage module save the results through files. In 
fact, files, relational databases or NoSQL databases are 
all acceptable data sources and result storage. 
Meanwhile, this paper improved the traditional 
programming model of Storm by combining Spring with 
Storm which realized the definition of Topology based 
on XML configuration files. In github, mykidong realize 
the Storm-spring-example, but each Spout/Bolt need its 
own ApplicationContext.xml [7]. This paper realized all 
of the components defined in one 
ApplicationContext.xml file. Finally, the paper 
implemented the GPS data analysis module using new 
Storm Topology programming model. In addition, the 
experimental results was shown and analyzed to prove 
the effectiveness of the model. 
The structure of this paper is organized as below: In 
section 2, related technology used in the analysis system  
will be introduced. In section 3, proposed the system 
architecture, and process the K-Means algorithm based 
on Storm. How to implement the system in the Storm 
and the evaluation will be proposed in section 4. Lastly 
this paper will be concluded with the suggestions for 
future research. 
2  Related work
 2.1 Storm Model 
Storm is similar to Hadoop. Storm’s task is called 
Topology which is submitted to the master node to 
execute. Topology is a programming model which 
contains processing logic to process large-scale data in 
parallel. There are two kinds of components in a 
Topology: Spout and Bolt. How to transmit messages 
____________________________________
 978-1-4799-0077-0/13/$31.00 ©2013 IEEE  
  
94:
Proceedings of ICCT2013 
 
among components is decided by streaming grouping [4]. 
The Spouts, Bolts and the stream between components 
compose Topology. Figure 1 shows the structure of the 
Topology used in the analysis system in this paper. 
"""Kprwv
 """Qwvrwv
 Vqrqnqi{"
 Mchmc
 Urqwv
 Mogcpu
 Urqwv
 Ytkvg
 Dqnv
 Kpkv
 Dqnv
 Urnkv
 Dqnv
 Mchmc
 Oguucig"
 Swgwg
 Hkng
  
Figure 1 The Storm Topology 
The above illustration shows how a simple Topology 
would look like in this paper. There are five components 
in the Topologys: KafkaSpout, SplitBolt, InitBolt, 
KmeansBolt and WriteBolt. At the KafkaSpout, it reads 
stream data from Kafka and emits its output in parallel 
to SplitBolt. At all kinds of Bolt, the tuple created at the 
last stage is passed to the next Bolt by processing 
according to user’s definition. In this process, the Storm 
implements Topology program model and framework so 
that we only focus on the implement of the Spout and 
Bolt function, and the rest process including distribution 
and parallel processing is automatically done by the 
Storm framework.  
2.2 K-Means Algorithm 
A GPS terminal can track where you are in real time 
according to the time, the longitude and the latitude 
information. The data of this paper comes from a 
northern city in China. Through analyzing these data 
you can learn the traffic conditions of the city and also 
provide a reasonable basis for road and urban planning. 
As a classical partition clustering algorithm, K-Means 
partitions the samples into clusters according to Nearest 
Neighbor Principle between the samples and the 
centroid of the clusters. Because of its easy to describe 
and implement, and its efficient to handle large data sets, 
the algorithm has been widely used in natural language 
processing and text clustering and many other fields, etc. 
Nowadays, with the development of distributed 
technology, distributed technology combines with the 
cluster algorithm has become a research hotspot. 
Currently, the traditional and improved clustering 
algorithms are rewritten into the parallel MapReduce 
computation model to execute, but on Storm related 
algorithms are not implemented, so this paper realize the 
K-Means algorithm based on Storm. 
2.3 Spring  
Spring Framework is an open source, lightweight, 
inversion of control, and aspect oriented container 
framework. Its architecture is based on the dependency 
injection design pattern. The key benefit of this 
approach is that it enables the developers to build 
loosely coupled applications. Flexible dependency 
injection with XML and annotation-based configuration 
styles bring all business bean into Spring container and 
manage all beans. This minimizes the dependency of 
application code on the container, which in turn 
improves productivity, maximizes the opportunity for 
code reuse, and improves testability. Storm Spring 
provides a unified configuration model to build Storm 
topologies in a Spring XML configuration. The Storm 
topology can be assembled freely by Storm developers 
based on the Spring Framework. 
2.4 Kafka 
Kafka is a high-throughput distributed messaging system 
developed for collecting and delivering high volumes of 
log data with low latency [6]. Kafka cluster is  totally 
distributed, including consumer, producer and Kafka 
brokers.This paper uses Kafka to transform the files into 
streaming data to realize the real distributed computing. 
3  The System Architecture Based on The 
Storm 
3.1 System Architecture  
The implementation of the K-Means algorithm is 
important for our GPS data analysis in Storm. It decides 
the clustering results. However, the traditional K-Means 
method cannot be used in Storm directly. It need to be 
improved for the parallel execution. Therefore, this 
paper simulates a real-time system to analyze the GPS 
data of a northern city by Storm platform which is 
shown in Figure 2. It mainly includes data collecting 
module and analysis module, and the source data and 
result is stored in files.  
GPS  data    (files)
 Kafka  Cluster
 (transform  files  into  message  queue)
 Tgcn/vkog"rtqeguukpi"oqfwng
 Nimbus
 ZooKeeper
 Bolt
 Spout
 Supervisor
 Uvqto"Enwuvgt
  
Figure 2 The Analysis System 
The collecting module collects data from external and 
push them into Kafka message queue. Each message 
includes time, longitude, latitude and some other related 
information. Then the data is processed by Storm. The 
94;
Proceedings of ICCT2013 
 
difference is the Topology is realized through the XML 
configuration file by combining with Spring. K-Means 
algorithm is used as an analysis engine for the collected 
large-scale GPS data. Based on such framework and 
algorithm, we can get the results easily and efficiently as 
if real time statistics. 
3.2 Data Collecting 
Storm does not define the source of data processing, so 
the data can be logs files, database and message queue, 
etc. As long as Spout implements the corresponding 
interface it can read the data from anywhere.  However, 
there is a problem. Since the data is likely on different 
computers, Spout can not know which machine the data 
is. Even if the data exists on the same machine,  the 
number of tasks that should be assigned to execute this 
Spout can only be one which does not meet the 
distributed features otherwise the data will be read the 
same times as parallelism.This paper presents the 
solutions as follows:  
Gzvgtpcn"Fcvc"Uqwteg
 Rwuj"Fcvc
 Mchmc"Enwuvgt
 Dtqmgt3?vqrke?
 Dtqmgt4?vqrke?
 Uvqto"Enwuvgt
 MchmcUrqwv
 Rwnn"Fcvc
  
Figure 3 Data Collection Module 
Kafka middleware unify disparate data into the message 
queue. Storm as the consumers of message queue makes 
the problem of reading data in parallel solved. Meantime, 
different Topology shared data sources become available 
and it improves the scalability of the system. Through 
messaging middleware layer, it masks external data 
source details and Storm-Kafka plugin for Storm is 
available. However, the introduction of Kafka will 
undoubtedly bring a certain complexity, which increase 
the threshold for application development on the Storm. 
The data collection structure is as above Figure 3. 
3.3 K-Means Algorithm 
The system uses K-means algorithm for data clustering 
to extract meaningful information. As a traditional 
clustering algorithm, the standard processing flow is 
presented as follows. Suppose we want to divide the data 
into k clusters:   
1)Choose k cluster centers randomly as the initial center: 
u18u2,;8uk. 
2)In the kth iteration, for each data, compute the 
distance to the k centers8choose the most closest to and 
assign the data point to this cluster.   
3)Re-compute centers by methods such as average.  
4)If the new set of k cluster centers is the same as those 
calculated in previous, the algorithm would be 
terminated. Otherwise, it should return to step 2. 
The clustering algorithm based on the Storm consists of 
four stages: pre-processing data; init stage; k-means 
stage and write result stage. Figure 1 shows the 
Topology of the GPS data analysis system based on 
Storm. This paper uses the same time data for clustering 
analysis according to the time field because our data is 
ordered in time. 
3.4 Spring For Storm 
The definition of the task in Storm is very easy. Take 
our topology for an example. The definition of Topology 
using TopologyBuilder is as follows Figure 48the Figure 
5 shows the same Topology defined using Spring 
configuration files. 
 
Figure 4 Define Topology Using TopologyBuilder 
 
Figure 5 Define Topology Using Spring Configuration Files 
Notice that the creation and submission of the Topology 
is handled by the IoC container. Topology, Spout and 
Bolt are all seen as beans, then place them in Spring 
container to complete the initialization. By combining 
952
Proceedings of ICCT2013 
 
Spring with Storm, the Storm components configuration 
and task deployment are all unified to Spring bean to 
manage. The Topology is assembled via the 
configuration file so that it reduces the dependency of 
application code on the container. 
How to develop a Topology? The implementation of 
Topology function is mainly dependent on the Spout and 
Bolt. The definition of the Topology using Spring 
Configuration Files is processed in steps as follows? 
Steps 1, define the Spout and Bolt standard interfaces for 
using in Spring XML. Here are a few examples? 
a)Topology Interface: IProcessorTopology 
b)Spout Interface: IRichSpoutDef 
c)Bolt Interface: IRichBoltDef 
Steps 2, using the standard interfaces to develop a 
Topology. 
Steps 3, assemble Topology. 
a)For easy assembly, we give a setter method for class   
Topology’s Spout and Bolt attribute. 
b)Create the implementation class of Spout and Bolt. 
c)Build Storm topology in a Spring XML configuration. 
Steps 4, submit the Topology to Storm cluster to Run. 
4  Implementation  and Evaluation  
This section will describe the system's detail 
implementation, including data import, K-Means 
algorithm's parallelization using the new SpringStorm 
model, and I compared the execution time between 
based on SpringStorm and TopologyBuilder, between 
reading messages form Kafka and file, between based on 
Storm and a standalone Java program. 
The system was developed on a cluster of 3 virtual 
machine. One is as Kafka server and one supervisor, one 
is Storm nimbus and zookeeper, the last one is as Storm 
supervisor. Every server has a 512M RAM and 20G 
dists. The operation system is ubuntu 12.4. The Storm is 
Storm-0.7.4, Kafka is Kafka-0.7.0, Zookeeper is 
Zookeeper-3.4.3. 
4.1 Implementation 
Data is downloaded from the datatang.com, including 
more than twenty thousand taxis8GPS location data of a 
northern city in March, we use some sample data to do 
the experiment. The data is saved as a text file with 
493MB units from 1 PM to 4 PM on March 15. First, the 
program will feed GPS data into Kafka through 
Producer program to simulate that data is the form of 
flow. Then write topology, this article develop the 
Topology using the new model according to the steps 
mentioned above to verify the availability of the model 
this paper presented. Figure 6 shows the main beans of 
the GPS data analysis module based on SpringStorm. 
The whole topology was build through the idea of 
componentization, and it consists of five components. 
The system injects dependencies into its topology using 
the dependency injection service, separating the building 
from using forcibly. 
First, Storm as Kafka’s consumer feeds GPS data 
through Kafka and emits every message as input data of 
the next step. Second, we split the message into multiple 
fields. In this process, the time, longitude and latitude 
fields were emitted to the init step. Third, init the cluster 
state including cluster centers, cluster set and error sum 
of squares, then transfer these information to kmeans 
step. Fourth, the K-Means algorithm is calculated, the 
result value is transfered to the write step. Fifth, the 
result is written into file, because of involving writing 
file operation, this step can not realize parallelization. 
 
Figure 6 The Main Beans Of The Topology Based On 
SpringStorm 
4.2 Evaluation 
Three experiments have been conducted on the test 
set. One is to evaluate the performance of the 
SpringStorm module, and I compared and analyzed the 
execution time between the proposed SpringStorm based 
K-Means algorithm and the traditional Storm based 
algorithm. One is to evaluate the performance of Storm 
based reading messages from Kafka and reading 
messages from file. The other is to evaluate the 
performance based on Storm and simply standalone Java 
program. The results are shown in table I, table II and 
table III.  
953
Proceedings of ICCT2013 
 
TABLE I Comparation of Execution Time Based on 
SpringStorm and TopologyBuilder 
 SpringStorm based TopologyBuilder 
1m16s 1m12s 
TABLE II Comparation of Execution Time Based on Storm 
Reading message form Kafka and file 
Read message form Kafka Read message from file 
1m12s 1m4s 
TABLE III Comparation of Execution Time Based on Storm 
and standalone Java program 
Storm based standalone Java program 
1m12s 2m23s 
 
 
Figure 7 The K-Means Result 
Table I shows the comparation of execution time 
between based on SpringStorm and TopologyBuilder. 
The result shows that the proposed method building 
topology based on Spring XML file has almost the same 
performance with the traditional TopologyBuilder 
model. 
From Table II, we can see that reading data from Kafka 
costs more time than reading data directly from files. It 
was likely to be because the Kafka cluster would loss 
some performance, and our data sets and loads are not 
high so that the result in the performance degradation. 
Meanwhile, we need to control the amount of messages 
having been emitted but not processed to prevent the 
Memory and CPU from becoming a bottleneck.   
As shown in the above Table III, performance improved 
almost double in executing K-Means algorithm based on 
Storm compared with a simply standalone Java program. 
On mass data processing, Storm’s distributed 
environments offer huge advantages over similar 
workloads deployed in a standalone system. Figure 7 
shows the clustering results for a second . 
5  Conclusions and Further Work 
Nowadays how to mining useful information from a 
mass of data almost as quickly as the production of 
information becomes a popular topic. This paper 
presented a massive data processing system based on 
Storm and improved its topology model by combing 
with Spring. Finally, this paper       implemented the 
K-means Clustering algorithm based on improved Storm 
model. 
The system is used by combing Storm with Kafka and 
Spring. Storm reads data from a Kafka cluster. And data 
is processed by topology builded in a Spring XML 
configuration to assemble different components. From 
the experiments we can see that the performance was 
improved effectively based on Storm compared with 
executing a standalone java program. And using Spring 
has little influence on performance. However, there is 
performance degradation while using Kafka cluster. 
In the area of highly-parallel batch processing, there 
have been quite a lot of research. However, less research 
in the fields of real-time stream processing especially 
about Storm. In the future, I will extend research based 
on Storm and further improving the performance of 
Storm, and also research how to combine other 
technologies with Storm. 
References 
[1] http://hadoop.apache.org/  
[2] http://Storm-project.net/ 
[3] https://github.com/nathanmarz/Storm/ 
[4] https://github.com/nathanmarz/Storm/wiki/Tutorial 
[5] http://Kafka.apache.org/ 
[6] Jay Kreps,Neha Narkhede,Jun Rao.Kafka: a Distributed 
Messaging System for Log Processing. 
[7] https://github.com/ebottabi/Storm-spring-example 
[8] https://github.com/nathanmarz/Storm-contrib/tree/master
 /Storm-Kafka 
[9] http://www.michael-noll.com/blog/2012/10/16/understan
 ding-the-parallelism-of-a-Storm-Topology/ 
[10] Kafka + Storm = Realtime Data at GumGum:  
http://blog.gumgum.com/2012/08/23/Kafka-Storm-realti
 me-data-at-gumgum/ 
[11] Storm or Apache Kafka:  
     http://www.ymc.ch/en/Storm-or-apache-Kafka
  
954
