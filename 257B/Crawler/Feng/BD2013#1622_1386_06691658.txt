Efficient Updates in Cross-Object Erasure-Coded
 Storage Systems
 Kyumars Sheykh Esmaili
 School of Computer Engineering
 Nanyang Technological University
 Singapore
 kyumarss@ntu.edu.sg
 Aatish Chiniah
 Computer Science and Engineering Department
 University of Mauritius
 Mauritius
 a.chiniah@uom.ac.mu
 Anwitaman Datta
 School of Computer Engineering
 Nanyang Technological University
 Singapore
 anwitaman@ntu.edu.sg
 Abstract—In the past few years erasure codes have been
 increasingly embraced by distributed storage systems as an
 alternative for replication, since they provide high fault-tolerance
 for low overheads. Erasure codes, however, have few shortcomings
 that need to be addressed to make them a complete solution for
 networked storage systems. Lack of support for efficient data
 repair and data update are the two most notable shortcomings.
 We recently proposed to use a 2-dimensional product code
 –Reed-Solomon coding per object and simple XORing across
 objects– and showed that at a reasonable storage overhead, it
 can greatly reduce the repair cost. In this paper we propose
 an efficient approach to handle data updates in cross-object
 erasure-coded storage systems. Our proposed solution has been
 implemented and experimentally evaluated. Our results show
 that compared to the naive approach (re-encoding the data),
 our proposed scheme can considerably decrease the update cost,
 especially for when the number of updated blocks is small.
 I. INTRODUCTION
 In the past few years erasure codes, most prominently Reed
 Solomon (RS) codes, have been increasingly embraced by
 distributed storage systems as an alternative for replication.
 In the coding scheme of RS(n,k), an object consisting of k
 blocks is encoded into n blocks (k < n) in a way that the
 original object can be recreated from any k subset of the n
 encoded pieces.
 The main advantage of erasure codes compared to repli-
 cation is that they provide higher fault-tolerance for lower
 overheads. However, as erasure codes were originally designed
 for a different environment (error control in transmission of
 one-time messages over an erasure channel), they do not con-
 sider two of the essential constraints/properties of distributed
 storage systems: (i) data is scattered among a large number
 of storage nodes connected through a network with limited
 bandwidth, and (ii) data has a long lifespan, during which its
 content may be updated. These constraints, result in several
 shortcomings that need to be addressed to make erasure codes
 a complete solution for networked storage systems. Two of
 the most notable such shortcomings are lack of support for
 efficient data repair and update.
 The naive approach to address these problems are costly.
 More specifically, to repair one single block in a storage system
 encoded with RS(n,k), k other blocks must be fetched and
 This work was supported by A*Star SERC Grant No: 102 158 0038. Aatish
 Chiniah contributed to this work while he was a student at NTU.
 then decoded. Likewise, upon updating one single block in
 the same system, all the k blocks are fetched and re-encoded
 again. These are clearly inefficient solutions, especially in
 cases where the repair/update size (i.e., number of affected
 data blocks) is small, and the costs are not amortized.
 Recently, we proposed [1] to use cross-object redundancy
 to reduce repair cost by combining simple and mature tech-
 niques – juxtaposing RS codes with RAID-4 like parity. This
 proposal was later realized [2], [3] as CORE storage primitive
 (hereafter CORE) and its benefits in terms of repairability over
 the other alternatives were demonstrated through analytical and
 experimental studies.
 In this paper we aim at addressing the update problem in
 CORE by designing an update scheme that is more efficient
 than re-encoding the whole data. At a very high level, our
 solution belongs to the family of parity update solutions [4],
 [5], [6] in which first data diff-blocks –i.e., the difference
 between the old and the new versions of the updated blocks–
 are computed and then they are used to compute the new
 versions of the affected parity blocks. However, as we argue
 in Section II-C, apart from the general idea, the existing
 proposals on parity update are not applicable to CORE and
 the representation of RS codes that it uses. To address these
 issues we make the following contributions in this paper:
 • we define the theoretical foundations for parity update
 in the generator polynomial representation of RS
 codes,
 • we implement the re-encoding as well the parity
 update approaches and integrate them into the CORE
 system,
 • we study the effectiveness of the aforementioned up-
 date techniques analytically and experimentally.
 We would like to note that the applicability of theoretical
 aspects reported in this paper (particularly, the first contribution
 in the list above) is not limited to the CORE system and
 can in fact be adopted by any system that uses similar
 codes/representations, and specifically this includes the stan-
 dard codes/representations, and specifically this includes the
 standard HDFS-RAID implementation [7].
 The rest of this paper is structured as follows. We first give
 a short overview of the relevant background in Section II. Then
 we explain the details of CORE’s update handling approaches
 4235"KGGG"Kpvgtpcvkqpcn"Eqphgtgpeg"qp"Dki"Fcvc"
 4:978-1-4799-1293-3/13/$31.00 ©2013  IEEE 
a6 a7 a8
 b6 b7 b8
 c6 c7 c8
 p6 p7 p8
 c3 c4 c5c0 c1 c2
 a3 a4 a5
 b3 b4 b5
 a0 a1 a2
 b0 b1 b2
 p3 p4 p5p0 p1 p2
 Three
 Objects in a 
RS(9,6)
 Scheme
 Vertical 
XOR
 Parities
 Fig. 1: Illustration of CORE’s Basic Idea
 in Section III. A brief description of the implementation is
 given in Section IV and the subsequent experimental results
 are presented in Section V. Finally, the paper is concluded in
 Section VI.
 II. BACKGROUND
 This section gives a short overview of the background i.e.,
 the CORE storage primitive (II-A), the two representations of
 RS codes (II-B), and a very brief survey of the related work
 on efficient updates in erasure coded storage systems (II-C).
 A. The CORE Storage Primitive
 CORE builds upon a simple observation [1]: by introducing
 a RAID-4 like parity over t erasure encoded pieces –resulting
 in what’s called CORE matrix of size (n,k,t)– it is possible
 to achieve significant reduction in the expected cost to repair
 missing/corrupt blocks. In fact, in the average case, not only
 fewer blocks are needed to carry out repairs but also the
 required computations are simpler and cheaper (XOR instead
 of RS decoding).
 Figure 1 shows an example of CORE(9,6,3): three distinct
 objects –a, b, and c– each comprising of 6 blocks are first
 individually encoded using an RS(9,6) code. Note that each
 data object’s parity blocks are depicted next to it (in gray
 color). Additionally, a simple XOR parity check is computed
 over each column’s blocks and thereby a new row is added at
 the bottom of the matrix. In this example, repairing any single
 failure would only require XORing 3 blocks.
 It is worth noting that the price paid for CORE’s repair
 efficiency is the extra storage overhead (the last row in Fig-
 ure 1). However, as the detailed analysis and discussions in [2]
 show, in realistic settings this extra overhead is reasonably
 low and comparable with those of the existing repairable code
 alternatives.
 This idea, along with a set of related algorithms (e.g., ef-
 ficient scheduling of multiple repairs) were later implemented
 as the CORE storage primitive [2], [3] and its performance
 was thoroughly evaluated.
 B. Reed-Solomon Representations
 The construction method proposed in the original Reed-
 Solomon code paper [8] is based on Vandermonde matrices,
 and is non-systematic, hence it is seldom used for storage sys-
 tems. However, two other methods –one using a matrix repre-
 sentation and the other one using a polynomial representation–
 were later proposed to construct systematic Reed-Solomon
 codes:
 • Cauchy Generator Matrix [9]: this representation is
 based on a Cauchy matrix Gn?k which contains the
 Identity matrix Ik?k. As shown below, to encode a
 message M of size k, it is multiplied by G, resulting
 in a codeword composed of the original data message
 M and the parity message P of size n ? k:
 ?
 ??????????
 1 . . 0
 . . . .
 . . . .
 0 . . 1
 g0,0 . . g0,k?1
 . . . .
 . . . .
 gn?k?1,0 . . gn?k?1,k?1
 ?
 ??????????
 ?
 ?
 ??
 m0
 .
 .
 mk?1
 ?
 ?? =
 ?
 ??????????
 m0
 .
 .
 mk?1
 p0
 .
 .
 pn?k?1
 ?
 ??????????
 For a detailed example of the process see [10].
 • Generator Polynomial [11]: This approach uses a
 generator polynomial, g(x) which consists of n?k+1
 factors and its roots are consecutive elements of the
 Galois Field (GF):
 g(x) =
 n?k∑
 i=0
 gixi
 Moreover, the message elements are also represented
 as coefficients of a polynomial, m(x). To encode
 m(x), it is first multiplied by xn?k and then divided
 by the generator polynomial, g(x). The coefficients of
 the remainder polynomial r(x) are the output parity
 elements:
 m(x) ? xn?k ? r(x) mod g(x) (1)
 or
 k?1∑
 i=0
 mix
 i+n?k ?
 n?k?1∑
 i=0
 rix
 i mod
 n?k∑
 i=0
 gixi (2)
 A set of numerical example of the process can be
 found in [12].
 Except for few recent instances (including HDFS-RAID [7]
 which the CORE implementation is built upon), the storage
 community has been traditionally using the generator matrix
 representation. On the other hand, as noted in [11], in the
 error control literature the generator polynomial representation
 is more commonly used.
 C. Related Work
 Research on updates in erasure coded storage systems has
 been centered around size-preserving1 block updates [13], [6],
 [14], [5], [15], [16]. The naive approach to handle updates
 in erasure-coded storage system is to re-encode the data
 blocks and generate new parity blocks from scratch. This
 approach is clearly quite expensive, especially when the update
 size (number of updated blocks) is small. Hence, improving
 the efficiency of update handling in erasure-coded storage
 systems is crucial. In storage systems like CORE that maintain
 additional redundancies, the need for efficient update solutions
 in even more crucial.
 1Size-increasing and size-decreasing updates can be handled through adding
 new blocks and zero-padding of the updated blocks, respectively.
 29
a6 a7 a8
 b6 b7 b8
 c6 c7 c8
 p6 p7 p8
 c3 c4 c5c0 c1 c2
 a3 a4 a5
 b3 b4 b5
 a0 a1 a2
 b0 b1 b2
 p3 p4 p5p0 p1 p2
 (a) Re-encoding
 a6 a7 a8
 b6 b7 b8
 c6 c7 c8
 p6 p7 p8
 c3 c4 c5c0 c1 c2
 a3 a4 a5
 b3 b4 b5
 a0 a1 a2
 b0 b1 b2
 p3 p4 p5p0 p1 p2
 (b) Parity Update
 Fig. 2: The Two Update Approaches in CORE
 Apart from few recent proposals [15], [16] that aim at
 designing new and inherently update-efficient erasure codes,
 the majority of previous work [13], [6], [14], [5] on up-
 date in erasure-coded storage systems use the classic Reed-
 Solomon codes and are primarily concerned with the concur-
 rency/consistency tradeoff. There are, nonetheless, a number
 of papers [4], [5], [6] in which the idea of efficient update of
 erasure coded data has been discussed.
 The existing solutions, however, are not directly applicable
 to the CORE system for the following reasons: (i) they all
 target the generator matrix representation of RS code (see [4]
 for detailed explanations and formulas) and not the generator
 polynomial representation which is used in HDFS-RAID and
 consequently in our CORE implementation. In fact, to the best
 of our knowledge, designing parity update schemes for the
 generator polynomial representation of RS codes remains an
 open problem, and (ii) CORE has an extra set of vertical, XOR-
 based parities.
 In this paper, we address these issues and analyze the
 effectiveness our solution through analytical and empirical
 studies.
 III. UPDATE HANDLING IN CORE
 In the following, we first give an overview of both re-
 encoding and parity update approaches in CORE (III-A).
 Then, after presenting the formal foundations of parity update
 approach for horizontal (III-B) and vertical (III-C) parities, we
 analytically compare both approaches (III-D).
 A. Overview
 Figure 2 highlights the differences between the two up-
 date approaches while handling one single update (a1) in
 CORE(n=9,k=6,t=3). The chain of steps taken in each case
 are as follows:
 • re-encoding: (i) fetch a0...a5, the k blocks of the
 updated object, and encode them to generate a6..a8,
 the new n ? k parities, (ii) fetch a1, b1, c1, the t
 data blocks on the updated column and XOR them
 to generate p1, the new vertical parity, (iii) similarly,
 generate p6..p8, the other n ? k vertical parities.
 • parity update: (i) first calculate ∆a1, the diff-block
 of the updated data block, and use it to generate
 ∆a6...∆a8, the diff-blocks of the horizontal parities,
 (ii) combine ∆a6...∆a8 and the old versions of a6..a8
 to compute their new versions, (iii) use ∆a1 and the
 old version of p1 to compute its new version, (iv)
 likewise, update p6...p8, the n ? k vertical parities.
 B. Updating Horizontal Parities
 Let’s assume that the updated message is represented by
 m
 ?(x), meaning:
 m
 ?(x) ? xn?k ? r?(x) mod g(x) (3)
 without the loss of generality, let’s also assume that only the
 first data block of the message m(x) has been updated. More
 precisely:
 m0 = m?0 ; ?i = 0 : mi = m
 ?
 i
 now, by summing up equation (1) and equation (3), we obtain:
 (m(x) + m?(x)) ? xn?k ? (r(x) + r?(x)) mod g(x)
 or in the ? form2:
 k?1∑
 i=0
 (∆mi)xi+n?k ?
 n?k?1∑
 i=0
 (∆ri)xi mod
 n?k∑
 i=0
 gixi
 but since
 ?i = 0 : mi = m?i =? ?i = 0 : ∆mi = 0
 then
 (∆m0)xn?k ?
 n?k?1∑
 i=0
 (∆ri)xi mod
 n?k∑
 i=0
 gixi (4)
 In other words, the parity update mechanism when only the
 first data block (m0) has been updated is as follows: (i)
 compute ∆m0, (ii) encode ∆m0; the outputs are {∆ri}, 0 ≤
 i ≤ n? k ? 1, (iii) for each i, use ∆ri and the old version of
 ri to generate its new version (∆ri + ri = r?i).
 Note that the formula in 4 can easily be generalized:
 ∑
 i:mi =m?i
 (∆mi)xi+n?k ?
 n?k?1∑
 i=0
 (∆ri)xi mod
 n?k∑
 i=0
 gixi (5)
 2Notice that in the GF(2) arithmetic m0 +m?0 = m0 ?m?0 = ∆m0.
 30
C. Updating Vertical Parities
 Due to the simple and commutative nature of the XOR
 operation, updating the vertical parities of the CORE matrix
 is straightforward. If p is the vertical parity of a given column
 of t blocks:
 t?1∑
 j=0
 mj = p
 then it can be immediately inferred that:
 t?1∑
 j=0
 (∆mj) + p = p? (6)
 In other words, the new version of the parity block can be
 obtained by XORing its old version with the diff-blocks of the
 updated data blocks.
 D. Analytical Comparison
 Next, we present a set of cost functions that reflect the
 analytical cost of using the re-encoding and the parity update
 approaches. For the sake of simplicity, we limit our study to
 centralized update managers. Moreover, to measure the update
 cost, we consider the statically-computable read traffic, i.e., the
 amount of data read by the update manager during the process
 (in the centralized case, the write traffics of both approaches
 are identical).
 Re-encoding Parity Update
 Single Column t 2.u + 1
 Single Row k 2.u + (n? k)
 Full Matrix* k + u.t + (n? k).t 2.u + (n? k) + u + (n? k)
 Full Matrix** u.k + t + (n? k).t 2.u + u.(n? k) + 1 + (n? k)
 TABLE I: Amount of Data to Fetch to Perform u Updates
 Table I shows the generalized cost functions of both
 approaches for XOR parities (Single Column), the RS codes
 (Single Row), and the complete CORE matrix (Full Matrix).
 In this table u denotes the update size. Furthermore, since in
 the full matrix, there are many possible distributions for u
 updates, we have considered only two special cases: all in one
 row (denoted by *) and all in one column (denoted by **).
 Finally, it’s worth noting that the coefficient 2 in the parity
 update cost functions represent the fact that to compute each
 diff-block, both the old and the new versions of that particular
 block must be read.
 Let’s again consider the example given in Figure 2, where
 in the CORE matrix of size (n=9,k=6,t=3) one data block has
 been updated (u=1). In this example, the overall cost (read
 traffic) of the re-encoding and the parity update approaches
 are 18 and 9 blocks respectively.
 One important conclusion from these cost functions is that
 the benefits of parity update approach are more visible in case
 of small updates. In fact, as shown in [4] and confirmed
 later in our experiments, for a given object, if the number of
 updated blocks is high (e.g., more than half of its blocks), the
 naive alternative (re-encoding from scratch) can be not only
 competitive but even preferred since the costs are amortized.
 IV. IMPLEMENTATION
 The update approaches explained in Section III, have been
 implemented and integrated into the CORE storage primi-
 tive [17], which itself has been developed on top of Facebook’s
 HDFS-RAID [7]. HDFS-RAID embeds the Apache HDFS [18]
 inside an erasure code-supporting wrapper file system named
 Distributed Raid File System (DRFS). DRFS supports both
 Reed-Solomon coding as well as simple XOR parity files. One
 of the main components of HDFS-RAID is RaidNode which
 is a daemon responsible for the creation and maintenance of
 parity files.
 Since neither Apache HDFS nor HDFS-RAID support data
 updates, we first added a feature to the CORE implementation
 which replaces certain blocks of a file with some other
 pre-defined blocks. Our implementation of the re-encoding
 approach uses extended versions of the CORE functionalities
 to recompute the horizontal and vertical parities of the affected
 rows and columns. The parity update approach first deals with
 the horizontal parities (according to equation 5) and then with
 the vertical parities (according to equation 6). In both cases,
 all the computations are performed in a centralized fashion at
 RaidNode.
 The correctness of our implementation was verified through
 multiple test cases in which the MD5 hash values of the
 updated parity files generated by the re-encoding and the
 parity update approaches were compared against each other.
 The source codes, binary distribution, documentations, and a
 visualized demo based on the actual implementation functions
 are available at http://sands.sce.ntu.edu.sg/StorageCORE.
 V. EXPERIMENTS
 We benchmarked the implementation with experiments
 run on a cluster of 20 nodes which has one powerful PC
 (4?3.2GHz Xeon Processors with 4GB of RAM) hosting the
 NameNode/RaidNode and 19 HP t5745 ThinClients acting as
 DataNodes (each with an Intel Atom N280 Processor 1.66 GHz
 with 1 GB of RAM and a solid state drive of 2 GB). The
 average bandwidth of this cluster is 12MB/s.
 We ran two sets of experiments. In the first set we com-
 pare the performance of the re-encoding versus parity update
 schemes for one block update in the context of one single
 object (row) as well as the full CORE matrix. In the second set
 we study the impact of update size parameter and identify the
 sweet spots of each of the update approaches. In both sets, we
 used two groups of CORE matrix parameters: (n=9,k=6,t=3)
 and (n=14,k=12,t=5), inspired by the code length and storage
 overheads of Google’s GFS and Microsoft Azure, respectively.
 Moreover, the block size used was 64MB (HDFS’s default
 value).
 Finally, although in each experiment we measured both
 completion time and data traffic, but due to space limitation,
 we only present the time results (the data results are in line
 with the cost functions of Section III-D).
 A. Efficiency of the Parity Update Approach
 We first compare the efficiency of the update schemes for
 one block update (u=1). Figure 3 shows the completion time
 of a single update at the level of a row (part 3a) and the whole
 31
0
 20
 40
 60
 80
 100
 1 2 3 4 5 6
 Re?encoding
 Parity"Update
 Ti
 m
 e
 (s
 ec
 on
 ds
 )
 Number"of"Block"Updates
 (a) In RS(9,6)
 0
 20
 40
 60
 80
 100
 120
 140
 1 2 3 4 5 6 7 8 9 10 11 12
 Re?encoding
 Parity"Update
 Ti
 m
 e
 (s
 ec
 on
 ds
 )
 Number"of"Block"Updates
 (b) In RS(14,12)
 Fig. 4: Impact of Update Size on the Performance of the Update Approaches in the Polynomial Representation of RS Codes
 0
 20
 40
 60
 80
 100
 (n=9,k=6,t=3) (n=14,k=12,t=5)
 Re?encoding
 Parity"Update
 Ti
 m
 e
 (s
 ec
 on
 ds
 )
 (a) Within a Row
 0
 50
 100
 150
 200
 250
 (n=9,k=6,t=3) (n=14,k=12,t=5)
 Re?encoding
 Parity"Update
 Ti
 m
 e
 (s
 ec
 on
 ds
 )
 (b) Within the Full Matrix
 Fig. 3: Completion Time of Handling One Block Update
 CORE matrix (part 3b). In accordance with the cost functions
 of Table I, the results show a significant gain in the update
 time, specially in the CORE(14,12,5).
 B. Impact of Update Size
 As highlighted in Section III-D, for large number of
 block updates, the naive data re-encoding approach can be
 competitive. To obtain some insights about the crossover point
 between the two approaches, we ran an experiment in which
 the update size parameter u was varied between 1 (minimum)
 and k (maximum, the full object size).
 A subset of the results (only for the RS parities) are
 depicted in Figure 4 and show that when around more than
 half of the blocks of an object are updated (u ≥ k/2) the
 naive re-encoding approach can outperform the parity update
 approach. These results are similar to those reported in [4],
 where the authors measured the impact of update size in the
 matrix representation of RS codes.
 Based on this observation, we ultimately incorporate in our
 CORE implementation a hybrid approach that can adaptively
 decide between the two schemes based on the values of u and
 k. Such approach can offer the best update performance under
 all circumstances.
 VI. CONCLUSIONS AND FUTURE WORK
 In this paper we addressed the problem of efficient updates
 in the CORE storage primitive, a cross-object erasure-coded
 storage system. We defined and implemented a parity update
 scheme which outperforms the naive approach of data re-
 encoding. The benefits of our solution are especially pro-
 nounced in cases where the number of updated blocks is small.
 Our current implementation of the update manager has a
 centralized design. In future, we plan to further optimize the
 update process by exploiting the computational resources of
 the storage nodes, and in doing so, reduce the update traffic
 over network and further lower the update time.
 REFERENCES
 [1] A. Datta and F. Oggier, “Redundantly Grouped Cross-object Coding
 for Repairable Storage,” in Proceedings of the Asia-Pacific Workshop
 on Systems, 2012, p. 2.
 [2] K. S. Esmaili, L. Pamies-Juarez, and A. Datta, “The CORE Storage
 Primitive: Cross-Object Redundancy for Efficient Data Repair & Access
 in Erasure Coded Storage,” CoRR, vol. abs/1302.5192, 2013.
 [3] K. S. Esmaili, L. Pamies-Juarez, and A. Datta, “CORE: Cross-Object
 Redundancy for Efficient Data Repair in Cloud Storage Systems,” in
 Proceedings of the IEEE International Conference on Big Data, 2013.
 [4] F. Zhang, J. Huang, and C. Xie, “Two Efficient Partial-Updating
 Schemes for Erasure-Coded Storage Clusters,” in Proceedings of the
 2012 IEEE Seventh International Conference on Networking, Architec-
 ture, and Storage, ser. NAS ’12, 2012, pp. 21–30.
 [5] K. Peter and A. Reinefeld, “Consistency and Fault Tolerance for
 Erasure-coded Distributed Storage Systems,” in Proceedings of the 5th
 International Workshop on Data-Intensive Distributed Computing Date,
 2012, pp. 23–32.
 [6] M. K. Aguilera, R. Janakiraman, and L. Xu, “Using Erasure Codes
 Efficiently for Storage in a Distributed System,” in Proceedings of the
 International Conference on Dependable Systems and Networks (DSN),
 2005, pp. 336–345.
 [7] HDFS-RAID, http://wiki.apache.org/hadoop/HDFS-RAID.
 [8] I. S. Reed and G. Solomon, “Polynomial Codes Over Certain Finite
 Fields,” Journal of the Society for Industrial & Applied Mathematics,
 vol. 8, no. 2, pp. 300–304, 1960.
 [9] J. Bloemer, M. Kalfane, R. Karp, M. Karpinski, M. Luby, and
 D. Zuckerman, “An XOR-Based Erasure-Resilient Coding Scheme,”
 International Computer Science Institute, Tech. Rep. TR-95-048, 1995.
 [10] J. S. Plank and C. Huang, “Tutorial: Erasure Coding for Storage Appli-
 cations,” The 11th Usenix Conference on File and Storage Technologies
 (FAST’13), 2013.
 [11] S. B. Wicker and V. K. Bhargava, Reed-Solomon Codes and Their
 Applications. Wiley-IEEE Press, 1999.
 [12] U. of New Brunswick, “EE4253 Digital Communications,”
 http://www.ee.unb.ca/cgi-bin/tervo/rscodes.pl, 2013.
 [13] S. Frolund, A. Merchant, Y. Saito, S. Spence, and A. Veitch, “A De-
 centralized Algorithm for Erasure-coded Virtual Disks,” in Proceedings
 of the International Conference on Dependable Systems and Networks
 (DSN), 2004, pp. 125–134.
 [14] P. Sobe, “A Partial-Distribution-Fault-Aware Protocol for Consistent
 Updates in Distributed Storage Systems,” in Proceedings of the 5th
 IEEE International Workshop on Storage Network Architecture and
 Parallel I/Os, 2008, pp. 54–61.
 [15] A. Rawat, S. Vishwanath, A. Bhowmick, and E. Soljanin, “Update Effi-
 cient Codes for Distributed Storage,” in Information Theory Proceedings
 (ISIT), 2011 IEEE International Symposium on, 2011, pp. 1457–1461.
 [16] Y. Han, H.-T. Pai, R. Zheng, and P. K. Varshney, “Update-Efficient
 Error-Correcting Regenerating Codes,” arXiv preprint arXiv:1301.4620,
 2013.
 [17] CORE, http://sands.sce.ntu.edu.sg/StorageCORE.
 [18] HDFS, http://hadoop.apache.org/hdfs/.
 32
