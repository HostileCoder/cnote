Robot: An Efficient Model For Big Data Storage Systems Based On Erasure Coding 
Chao Yin 1 , Jianzong Wang3, Changsheng Xie 12 , Jiguang Wan 12? , Changlin Long 1 and Wenjuan Bi 1  
1  School of Computer Science and Technology, Huazhong University of Science and Technology, China  
2  Wuhan National Laboratory for Optoelectronics, China  
3 NetEase Inc., Guangzhou, China 
? Corresponding Author: jgwan@mail.hust.edu.cn 
 
 
Abstract—it is well-known that with the explosive growth of 
data, the age of big data has arrived. How to save huge 
amounts of data is of great importance to both industry and 
academia. This paper puts forward a solution based on coding 
technologies in big data system that store a lot of cold data. By 
studying existing coding technologies and big data systems, we 
can not only maintain the system's reliability, but also improve 
the security and the utilization of storage systems. Due to the 
remarkable reliability and space saving rate of coding 
technologies, importing coding schema in to big data systems 
becomes prerequisite. In our presented schema, the storage 
node is divided into several virtual nodes to keep load 
balancing. By setting up different virtual node storage groups 
for different codec server, we can ensure system availability. 
And by utilizing the parallel decoding computing of the node 
and the block of data, we can also reduce the system recovery 
time when data is corrupted. 
Additionally, different users set different coding parameters 
can improve the robustness of big data storage systems. We 
configure various data block m and calibration block k to 
improve the utilization rate in the quantitative experiments. 
The results shows that parallel decoding speed can rise up two 
times than the past serial decoding speed. The encoding 
efficiency with ICRS coding is 34.2% higher than using CRS 
and 56.5% more than using RS coding equally. The decoding 
rate by using ICRS is 18.1% higher than using CRS and 31.1% 
higher than using RS averagely. 
Keywords-distributed file system; erasure coding; big data; 
robustness; availiabilty; cloud storage  
I.  INTRODUCTION 
Along with the development and popularity of internet 
technologies, information is playing a significant role in a 
symbol of digital data. In the perspective of enterprises, loss 
of data could even be destructive; therefore the demand for 
dependability of data storage system rises up. With the rapid 
growing number of data, the storage scale has reached TB, 
PB, even ZB level, shown as tremendous development. Jim 
Gray [1], a Turing award winner, dictates that the new data 
amount from the Internet is expected to quadruple in every 
18 months compared with all the old data existed. Thereby, 
traditional information storage scheme, which keeps the data 
in a centralized server, is no longer a satisfying solution to 
current demand for big data storage. Moreover, local storage 
technology will encounter resistance when the extension. 
Some factors, such as costs, techniques and communication, 
let data storage to be the main bottleneck to prevent the 
development  of information technologies.  
In such situation, distributing data for storage and 
extending from local to remote, for instance cloud storage 
has been an inevitable tendency. Distributed storage takes 
outstanding advantage of both storage and transmission 
technologies, presenting unparalleled superiority in data 
security, storage volume, disaster backup and recovery. 
For the storage of big data [8, 9, and 10], problems that 
remain to be solved are as follow: 
• Capacity?Capacity can reach the scale of PB/ZB 
level. As a result, mass data storage systems should 
have ability for scaling. Meanwhile, the online 
expansion method must be convenient enough and 
decrease the degradation serving time; 
• Delay: Big data applications should be real-time, 
especially involved with online trading or financial 
related applications. Date-intensive computing has 
the SLA (Service Level Agreement) requirements. In 
addition, the popularity of server virtualization has 
led to a stringent demand for the high IOPS; 
• Security and Privacy: Access control for big data is 
also a hot topic for research. Big data applications 
lead to concern about security, especially for private 
data of company or individual? 
• Cost: To save the cost, we need to make every 
device work more efficiently and avoid over-
 provision. Due to the widely implementation of 
coding, data de-duplication and cloud storage 
technologies in storage field, big data storage 
applications can be more effective and valuable? 
This paper is focus on the big data backup systems. 
Currently erasure coding and deduplication technologies are 
used in big data storage frequently. Well known cloud 
storage systems like GFS [2], HDFS [3], Amazon S3 [4] and 
Ceph [5] all use replication to provide data redundancy. 
Comparing the two redundancy technologies, Erasure code is 
more suitable for big data backup system since it requires 
less storage for maintaining reliability. We have developed 
an optimized erasure coding algorithm, called ICRS 
(Improved CRS), to store the backup data. The algorithm is 
improved based on original CRS [6] and Reed-Solomon [7] 
algorithms. By optimizing the determinant of a matrix, the 
number of identity element “1” in CRS matrix is decreased 
dramatically. The performance of the system is also 
improved by increasing the speed of matrix operations. 
The underlying architecture of our system used 
decentralized storage systems because of its target 
2013 IEEE International Conference on Big Data
 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 163
requirements. First of all Robot is targeted mainly at backup 
applications where there are no updates frequently. Secondly, 
Robot is built for latency sensitive applications that require 
at least 99.9% of read and write operations to be performed 
quickly. Different from Pastry [25], Scality Ring [26] and 
Chord [11] which route requests through multiple nodes, 
Robot can be characterized as a zero-hop DHT, where each 
node maintains enough routing information locally to route a 
request to the appropriate node directly. This is because 
multi-hop routing increases variability in response times, 
thereby increasing the latency at higher percentiles. 
We have used consistent hash algorithm to store data in 
distributed system. In comparison to these systems, a key-
 value store is more suitable in this case. First, it is intended 
to store relatively small objects (size < 1M). Second, key-
 value stores are easier to configure on a per-application basis. 
The adoption of Hash not only improves the efficiency of 
looking up, but also guarantees that node addressing will not 
conflict.  
In the current era of big data, the storage of data backup 
should make sure reliability and minimize storage overhead. 
Our aim is to reduce storage consumption and improve the 
system performance.  
The main contributions of ours paper are listed as below: 
• Research and design ring system architecture, an 
extension of symmetry, which should favor 
decentralized techniques over centralized control. 
We imported Peer to Peer systems into big data 
system so that the system will not crash because of 
one or more nodes’ damage. 
• Store data in the mechanism including virtual nodes 
and physical nodes. We built corresponding 
relationship between them to ensure that data can be 
stored after coding and fast recovery when data is 
lost. 
• Presented a coding scheme -ICRS (Improved CRS), 
which is based on CRS that can reduce the encoding 
and system down time. The testing result shows that 
the coding efficiency when using ICRS is 34.2% 
higher on average than using CRS and 56.5% higher 
on average than using RS. The decoding efficiency 
when using ICRS is 18.1% higher on average than 
using CRS and 31.1% higher on average than using 
RS. 
The rest of this paper is organized as follows. The 
architecture and the design of Robot are introduced in 
Section 2. Section 3 gives the experimental evaluation and 
results. Section 4 shows related works. We make conclusions 
in Section 5. 
II. ROBOT 
A. The Design of Robot 
Most existing systems use triple replication methods to 
provide reliability. But cold data are barely used by users, so 
the utilization of space is very slow. Considering the feature 
of cold data, system can use code methods to provide 
reliability to optimize the storage usage. 
Coding is one of the key features in distributed system. 
The common distributed system can provide high reliability 
but the storage space usage is overwhelming waste with 
much money investment. We are aim to import code 
methods by replacing duplication schema and two indexes 
are our optimizing targets in our system: Storage Space 
Utilization and Repair Time. 
 
Figure 1.  The architecture of Robot 
Figure 1 show the architecture of Robot, which consists 
of two components: coding servers and data servers. Coding 
servers is responsible for choosing suitable storage group, 
encode or decode data and store important information such 
as metadata. Date servers are composed by virtual nodes, 
which are located in the ring structure. These virtual nodes 
store original data. The ring structure guarantees loading 
balance and randomly distributed on each virtual node. The 
communication on data servers rely on the message 
exchange between virtual nodes instead of unique metadata.  
The import of ring structure can be advanced compared 
with the traditional duplication situation and address the cold 
data storage problems in the big data environment in order to 
save the space. Due to the low read frequency, the demand of 
response time is lower than regular system. So we deploy 
erasure code method to provide reliability and optimize 
storage usage. Furthermore, by dividing physical nodes into 
virtual nodes, keep the system load balancing and prove 
repair speed up by utilizing parallel computing. After 
receiving the request of users, system will select a virtual 
node to build coding server based on the storage demand of 
users, every virtual node use its own storage group. All data 
of the coding servers will store in this storage group. The 
data on the coding servers will be first encoded and then 
store on data servers. When the physical node fails, system 
will read data from several storage groups concurrently to 
repair it. So our design can provide better performance on 
both security and repair speed. 
B. The Disturbution of  Nodes 
The ring structure and hash method can balance the load 
and promote the I/O speed. In the storage system, the 
164
physical node is divided into several virtual nodes according 
to the computing and storage size. Then these virtual nodes 
are placed on the ring complying with hash method. In Robot, 
each coding server has several virtual nodes, and one virtual 
node can only be placed on one physical nodes, one physical 
node can have multiple virtual nodes, as figure 2 shows. 
 
  
Figure 2.  The relation among nodes 
The number of the virtual nodes on one physical node 
depends on the storage size of the physical node. Physical 
nodes with different size storage will have different number 
of virtual nodes. Every virtual node has it unique number, the 
different virtual nodes on physical node will be hashed 
according to IP address and port number. The result of hash 
operation will act as the ID of the virtual node and decide the 
position of the virtual node in the ring. 
Physical nodes are numbered according to the joining 
order, first as No.1, second as No.2…nth as No. n. Then we 
carry out hash operation to the IPv6 address and port number 
of the physical nodes. Then choose 64 bits as the number of 
the virtual nodes and sort them in order. After sorting, we 
place these virtual nodes on the ring according to their 
number. This method can build a mapping between virtual 
nodes and physical nodes, which has good uniform property. 
The amount of the nodes in the ring is related to the 
number and storage size of physical nodes. If Mi is the 
storage size of the No.i physical node, n is the data size, K is 
the required size of virtual nodes. The amount of the virtual 
nodes nr_vnodes: 
 
1
 _ /
 n
 i
 i
 nr vnodes M K
 =
 =Â  (1) 
C. ICRS Code 
We know that the encode time of CRS code depends on 
the encode matrix. We have developed ICRS code to 
accelerate the rate of encoding and decoding. The 
performance of CRS code directly depends on the number of 
1 in the Cauchy matrix. So we use matrix transform to build 
Cauchy matrix with less 1 in it. 
The optimized Cauchy matrix uses less calculation so it 
has better performance in the repair process. Besides, to the 
situation when m=2, we gives all optimal Cauchy matrix 
when wi32. Here, w  means binary words of a fixed length. 
There are 3 steps: 
(1) Build basic Cauchy matrix M: do matrix transform 
M[i,j] = 1/( i?( m+j) ), the division is calculated in 
finite field and plus is normal plus calculation. 
(2) Set all the number in the first row to 1: To column j, 
divide every number in this column by M [0, j] in 
finite field. 
(3) Optimize the rest row: reduce the amount of 1 in the 
rest line is main goal of this operation. We 
implement it by using enumeration. Divide the row 
by every number in the row and choose the situation 
with least 1. 
Through these steps we can significantly improve the 
performance of encoding/decoding process. Here is an 
example of the optimizing process for situation where k = m 
= w = 3. 
Here is the original Cauchy matrix: 
 
6 7 2
 5 2 7
 1 3 4
 Ã ÔÄ ÕÄ ÕÄ ÕÅ Ö
  (2) 
Optimize the first row: 
 
1 1 1
 4 3 6
 3 7 2
 Ã ÔÄ ÕÄ ÕÄ ÕÅ Ö
  (3) 
Optimize the rest row: enumerate every number in the 
rest row and select the best situation. For the second row, we 
try 4, 3, and 6 and count the number of 1. The results are 12, 
11 and 16. So we choose the 3 to optimize the second row.  
Then we divide the last row by 3. 
 
1 1 1
 5 1 2
 1 4 7
 Ã ÔÄ ÕÄ ÕÄ ÕÅ Ö
  (4) 
This optimized matrix have 34 “1” in it, much less than 
the 46 before optimizing process. Using this method can 
have better encoding/decoding performance than CRS and 
RS code, and the reading and writing speed is much better 
than CRS and RS. 
D. Data Division 
In Figure 3, we can see this part first divide big request 
into several fixed-sizes blocks and put them in the data pool. 
After the data pool is filled up, system encodes the data and 
adds parity data then send encoded data block to virtual 
nodes in related storage group. When user requests the 
original data, decoded data from related virtual node and 
return them to user. 
165
  
Figure 3.  The flowchar of data division. 
The encoded process is as following: 
• Get data requests from the coding server. 
• Divided the data request with certain size and each 
block has its own number BLOCK_ID, consisted 
with request block number and sub-block number. 
At the same time, system will add the information of 
the sub-block into the metadata, such as size, amount, 
BLOCK_ID, version. 
• Send data into buffer pool whose size is k. When the 
pool is filled up, trig the encoded process. 
• Encode data block, use erasure code such as ICRS, 
CRS etc. to encode the data and add parity block. 
Add the code type into metadata. 
• Send the encoded data to virtual nodes. 
If we adopt M as the data size of the coding server, 
block_m as the size of data block, en_data as the amount of 
the data block, en_parity as the amount of parity block, then 
we can get the following equation. 
The encoded times encoder_num is: 
 _ =
 _ * _
 M
 encoder num
 block m en data
  (5) 
Total storage size total_m is? 
 
* _
 _
 _
 M en parity
 total m
 en data
 =  (6) 
Fault-tolerant ability of system Q is? 
 _Q en parity=  (7) 
This method of encoding/decoding data improves the 
discreteness of data. Every sub-block can be accessed 
independently. Furthermore, the repair process can be highly 
paralleled.  
III. EVALUATION METHODOLOGY 
A. Experimental Setup 
In the sections, we mainly discuss about the evaluation 
and analysis of the implementation part. 
All the tests are based on a platform with a CPU (Intel 
Xeon CPU E5606 @ 2.13GHz) and RAM memory (16GB 
DDR3). Test mode of all the tests is data filling and recovery. 
We built a simulation for the performance estimation of all 
the processes in data encoding, decoding and node recovery. 
B. System Encoding and Decoding Time Test 
1) Encoding and Decoding Time of Data Chunks 
After selection of storage group, coding servers could 
encode and coding the user data to selected storage group. If 
the data is corrupted, then decoding and recovery is needed. 
When encoding or decoding, Vandermonde code and 
Cauchy code are suitable in distributed system due to its fine 
fault tolerance and dispensability. Therefore we compare 
these two codes with ICRS in the tests. 
In the encoding process, user data is randomly generated, 
divided into chunks, encoded and stored into virtual nodes. 
The division and size of the chunks, data chunks, parity 
chunks and total encoded data size differ, the time of 
encoding and decoding differ. Figure 4 presents encoding 
and decoding time in different data chunk sizes in two 
encoding methods. (Decoding time here mainly refer to 
recovery time when data is corrupted). 
Figure 4 shows the encoding and decoding time pattern 
in a single encoding group when data chunk number is 5 and 
parity chunk number is 2. Chunks size ranging from 1M to 
10M is the only variable parameter. From the figure we 
could know that encoding time rises as chunk size increases. 
Compared to encoding time, decoding time of a single chunk 
has better efficiency. Meanwhile, because ICRS and CRS 
adopts bitmap to convert multiplication into XOR operation 
and requires lower encoding or decoding time than RS code, 
while decoding time of ICRS is obviously shorter than the 
CRS because of coding optimization. ICRS is more suitable 
to be deployed on distributed system for decoding work. It is 
also obvious from the figure that decoding time is less than 
encoding time, so encoding time in systems need attentions. 
 
Figure 4.  Encoding and decoding time in single encoding group(k=5, 
m=2) 
Figure 5 shows the encoding and decoding time pattern 
in a 5-chunk encoding group when chunk size is 1M and 
parity chunk number ranges from 2 to 8. As the parity 
chunks in an encoding group increase, encoding time rises. 
166
More parity chunks can tolerate more faults, which means if 
higher fault tolerance level is needed more encoding time is 
required. However, the decoding time is more stable. 
Decoding time in RS, CRS and ICRS has no noticeable 
fluctuation, which indicates that increase in parity chunks 
numbers will not lead to decoding time increase of a single 
chunk. We could also indicated that ICRS performs better 
than RS and CRS in both encoding and decoding time, 
suggesting ICRS is more adaptive to efficient and time-
 demanding system than the others. 
 
Figure 5.  Encoding and decoding time (size=1M, k=5) 
Figure 6 shows the encoding and decoding time pattern 
in an encoding group when chunk size is 4M; parity chunk 
number is 2 and data chunk number ranges from 3 to 9. As 
the data chunks increase, order of magnitudes of the 
encoding time rises from 10 seconds to 100 seconds. ICRS 
code still has a lower encoding time than RS and CRS. 
Unlike encoding time, decoding time presents a smaller 
fluctuation. That indicates encoding process has larger 
overhead than decoding and encoding time is more 
susceptible by data chunk number k. ICRS remain relatively 
stable and high efficiency than RS, when k changes. 
 
Figure 6.  Encoding and Decoding Time(m=2, size=4M) 
Figure 4, 5, 6 show different result of encoding and 
decoding time in an encoding group when data chunk 
number, parity chunk number and chunk size change. 
Through these comparison tests, it can be clear seen that 
encoding time changes when data chunk number, parity 
chunk number and chunk size change. The relation between 
recovery time of a data chunk and chunk size is the most 
obvious. Bigger chunk size needs more decoding time. When 
data chunk number in an encoding group increases, decoding 
recovery time increases, while the increment is less than the 
case when chunk size increases. In these factors, parity 
chunk number is the least influential one. Decoding time is 
less than encoding time and it fluctuates less. Besides, ICRS 
has a higher overall encoding and decoding efficiency in 
distributed system than CRS and RS. From Figure 4, 5, 6, we 
can see that the coding efficiency when using ICRS is 34.2% 
higher on average than using CRS and 56.5% higher on 
average than using RS. The decoding efficiency when using 
ICRS is 18.1% higher on average than using CRS and 31.1% 
higher on average than using RS. 
2) Encoding and Decoding Time of Nodes 
Encoded data chunks are stored on virtual nodes and if 
any data chunk is corrupted the chunk will be decoded, as 
Section II describes. Node tests of encoding and decoding 
includes encoding time test of massive data and test on 
failure of physical nodes. 
Figure 7 is an encoding time chart when size is 1M, 
numbers are 600. Data chunk number in an encoding group 
ranges from 3 to 9 and the time for generating random data is 
included. Encoding time of both codes does not fluctuate 
very much as data chunk number increases. It is because that 
more data chunks in an encoding group lead to fewer 
encoding groups. Although encoding time of each group 
increases, there are fewer groups. Therefore, no significant 
growth appears. Apart from that, ICRS code has a better 
encoding performance than CRS and RS code. 
 
Figure 7.  Encoding time(size=1M, num=600) 
IV. RELATED WORK 
Erasure code has been widely used in present distributed 
backup storage system.  
It has been applied in many large-scale distributed 
storage systems, including storage systems at Facebook and 
Google.  The updated Google File Systems- GFS2 (Colossus) 
[14]?has imported the Reed-Solomon encoding in action. 
Lots of works on designing efficient erasure codes or 
improving performance from certain aspects have 
mushroomed all around the world.  Compare to ICRS in this 
paper, the performance of RS is much lower. 
167
LRC [15], used in Windows Azure Storage, reduces the 
number of erasure coding fragments that need to be read 
when reconstructing data fragments that are offline, while 
still keeping the storage overhead low. The basic of LRC is 
using extra fragments to construct more parity. As a result, 
fragments in a calibration chain are less than ICRS.  
RS Codes, including ICRS, are Maximum Distance 
Separable- MDS Codes [16], which require minimum 
storage overhead for given, fault tolerance. There are also 
other erasure codes, such as Hover codes [17]; Weaver codes 
[18] and X-code [19], belonging to MDS codes but these 
codes are suitable for disk arrays. Jianzong Wang presented a 
quantitative evaluation model for different redundancy 
schemes from eight aspects: Availability, Reliability, Storage 
Overhead, Performance, Network Bandwidth, Energy 
Consumption and Dollar Cost in order to help the coding 
selection. [22, 13]. Another schema [12] showed that erasure 
coding used appropriately can improve system performance 
and save energy.  
V. CONCLUSIONS 
Big Data has become a challenge for many companies 
around the world. Many enterprises are looking for better 
ways to organize, manage and store their machine, 
application and user generated data that is quickly expanding 
to petabytes and Exabyte in size. This paper has studied the 
situation of present big data backup system and a solution to 
improving the storage utilization based on erasure code. We 
put forward a distributed backup system mechanism based 
on coding. This mechanism applies coding technique to 
distributed system in which large amounts of cold data are 
included to protect data and realize load balance. The ICRS 
(Improved CRS) method can improve performance by taking 
advantage of its high speed of CODEC. By using parallel 
recovery method, the repair time of system has been reduced. 
The system's load balance is improved by using virtual node. 
Results show that it is very fast to complete CODEC by 
using ICRS. 
There is still much work to do in the future which mainly 
contains two directions. First, to reduce the decoding time 
further, we can optimize the present ICRS. Second, as is 
shown in related work?data deduplication is of great value 
in storage of big data. How to combine coding technique 
with data deduplication in Robot is a research direction.  
ACKNOWLEDGMENT 
This Project supported by the National Basic Research 
Program (973) of China (No. 2011CB302303),the National 
High-Tech R&D Program (863) of 
China(No.2009AA01A402), the National Natural Science 
Foundation of China (No. 60933002) and 2011QN032), the 
Fundamental Research Funds for the Central Universities. 
REFERENCES 
[1] R. J. T. Morris, B. J. Truskowski. The evolution of storage systems. 
IBM Systems Journal, 2003, 42(2): 205~217. 
[2] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. The 
Google File System. SOSP '03 Proceedings of the nineteenth ACM 
symposium on Operating systems principles, 2003, pp. 29-43. 
[3] K.  Shvachko, H.  Kuang,  S.  Radia,  R.  Chansler. The  Hadoop 
Distributed File System,  Proceedings of IEEE MSST 2010, Incline 
Village, NV, USA, May 2010.. 
[4] Amazon simple storage service (S3), http://www.amazon.com/s3.. 
[5] Sage Weil, Scott A. Brandt, Ethan L. Miller, Darrell D. E. Long, 
Carlos Maltzahn, “Ceph: A Scalable, High-Performance Distributed 
File System,” In Proceedings of the 7th Conference on Operating 
Systems Design and Implementation, 2006. 
[6] J. Blomer, M. Kalfane, M. Karpinski, R. Karp, M. Luby, and D. 
Zuckerman. An XOR-based erasure-resilient coding scheme. 
Technical Report TR-95-048, International Computer Science 
Institute, August 1995. 
[7] J. S. Plank, “A tutorial on Reed-Solomon coding for fault-tolerance in 
RAID-like systems”. Software –Practice & Experience, 27(9):995–
 1012, September1997. 
[8] Yang Wang, Manos Kapritsos, Zuocheng Ren, Prince Mahajan, 
Jeevitha Kirubanandam,Lorenzo Alvisi, and Mike Dahlin. Robustness 
in the Salus scalable block store. The 10th USENIX Symposium on 
Networked Systems Design and Implementation (NSDI ’13), pp. 357-
 370. 
[9] Yan Li, Nakul Sanjay Dhotre, Yasuhiro Ohara,Thomas M. Kroeger, 
Ethan L. Miller, Darrell D. E. Long. Horus Fine-Grained Encryption-
 Based Security for Large-Scale Storage. The 11th USENIX 
Conference on File and Storage Technologies, pp. 147-160. 
[10] Devesh Tiwari, Simona Boboila, Sudharshan S. Vazhkudai, Youngjae 
Kim ,Xiaosong Ma , Peter J. Desnoyers  and Yan Solihin. Active 
Flash Towards Energy-Efficient, In-Situ Data Analytics on Extreme-
 Scale Machines. The 11th USENIX Conference on File and Storage 
Technologies, pp. 119-132. 
[11] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, et al. Chord: A 
scalable peer-to-peer lookup service for internet applications. in Proc. 
of the ACM SIGCOMM Conference, 2001, pp. 149–160. 
[12] Jiguang Wan, Chao Yin, Jun Wang and Chagnsheng Xie. A New 
High-performance, Energy-efficient Replication Storage System with 
Reliability Guarantee. The 28th IEEE Conference on Massive Data 
Storage (2012). 
[13] Wang J, Gong W, Varman P, et al. Reducing Storage Overhead with 
Small Write Bottleneck Avoiding in Cloud RAID System. In: Grid 
Computing (GRID), 2012 ACM/IEEE 13th International Conference 
on. IEEE, 2012: 174-183. 
[14] Google-GFS2 Colossus, “http://www.quora.com/Colossus-Google- 
GFS2” Google, 2012 
[15] C. Huang, H. Simitci, Y. Xu, A. Ogus, B. Calder, P. Gopalan, J. Li, 
and S. Yekhanin. Erasure coding in windows azure storage. In 
Proceedings of the USENIX Annual Technical Conference (ATC), 
2012. 
[16] G. Feng, R. Deng, F. Bao and J. Shen. New efficient MDS array 
codes for RAID part I: Reed-Solomon-like codes for tolerating three 
disk failures. IEEE Trans. Comp., 54(9):1071–1080, 2005. 
[17] J. L. Hafner. WEAVER Codes: Highly fault tolerant erasure codes for 
storage systems. FAST-2005: 4th Usenix Conf. on File and Storage 
Tech., San Francisco, 2005, pp. 211–224. 
[18] J. L. Hafner. HoVer erasure codes for disk arrays. DSN-06: Int. Conf. 
on Dependable Sys. and Networks, Philadelphia, 2006. 
[19] L. Xu and J. Bruck. X-Code: MDS array codes with optimal encoding. 
IEEE Trans. Inf. Thy, 45(1):272–276, 1999. 
[20] Rowstron, A., and Druschel, P. Pastry: Scalable, decentralized object 
location and routing for large-scale peer to peer systems. Proceedings 
of Middleware, pages 329-350, November, 2001. 
[21] Scality's Ring Organic Storage. http://www.scality.com. 
[22] Jianzong Wang, Weijiao Gong, Changsheng Xie. A Quantitative 
Evaluation Model for Choosing Efficient Redundancy Strategies over 
Clouds. In: Networking, Architecture and Storage (NAS), 2012 IEEE 
7th International Conference on. IEEE, 2012. 
 
168
