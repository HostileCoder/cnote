Safer@Home Analytics: a Big Data Analytical 
Solution for Smart Homes 
Antorweep Chakravorty, Tomasz Wlodarczyk, Chunming Rong 
Department of Computer and Electrical Engineering 
University of Stavanger 
Stavanger, Norway 
{antorweep.chakravorty, tomasz.w.wlodarczyk, chunming.rong}@uis.no 
Abstract—The vast amounts of data generated from sensors 
in smart homes, can give valuable insights about social and 
behavioral patters on households and their residents. The goal of
 the project is investigation & implementation of mechanisms to 
capture/store vast continuous streams of time-series data from 
optical movement sensors, analyze & mine for anomalies/changes 
enabling preventive care with mechanisms for 
presentation/visualization of meaningful information to target 
user groups (next of kin, care providers, professional services), 
while ensuring that the privacy of participants are preserved. 
Keywords—big data; data analysis; data mining; aging-in-
 place; smart homes 
I. INTRODUCTION
 The demographic trend across the world is moving towards 
an increasing pool of older population and is expected to 
double in coming years. The concept of aging-in-place (AIP) is 
creating an environment using modern ICT technologies, to 
enable elderly individuals lead an autonomous life in the 
comforts of their homes, reducing cost involvement, resource 
requirements and maintaining self-esteem, independence, care. 
In order to maintain, improve the standard of healthcare 
services and quality of help, such technologies [1]–[5] would 
play a crucial role. Traditional healthcare services to residential 
homes could be extended using sensor networks supported by 
data analytics to deliver assistive services. One specific 
initiative being, the Safer@Home [6] project at the University 
of Stavanger, that aims at creating such an environment to 
preserve personal control, dignity and quality of life, through 
development of smart integrated systems offering AIP services.  
The smart home concept developed through the 
Safer@Home project includes twenty model homes for 
participating elderly, furnished with a network of sensors. In 
order to provide appropriate services through data analytics, 
sensor data has to be collected centrally to effectively perform 
knowledge discovery algorithms. The need of real time as well 
as historical analysis leads to special infrastructure/processing 
requirements of volume, velocity and variety beyond the scope 
of existing data management solutions [7]–[9]. Big Data
 solutions like Hadoop [10], provides a distributed scalable 
storage and processing framework for handling frequent and 
large amounts of unstructured data. Also the nature of data, 
being extremely personal & sensitive could disclose the 
complete living behavior of individuals. It is necessary that the 
privacy of the individuals be protected while providing the 
needed care. 
Our Contribution: The aim of this project is to establish an 
analytical solution focusing on decision-making towards life-
 style/health of elderly people, with need of being highly 
responsive, available, scalable, secure and data intensive. A 
framework for securely, scalability collecting and storing data 
from smart homes, a statistical analytical platform for data 
intensive processing and a model for preserving privacy of 
shared results is to be established. Through a prototype case 
study, the capacity of the solution for preventive care would be 
demonstrated based on non-invasive movement sensor data. 
Paper Structure: An overview of related works is given in 
section II. Background of different technical solutions used for 
our framework is provided in section III. The research 
methodology is discussed in section IV. The research areas and 
expected contributions are in section V. Section VI concludes 
the paper. 
II. RELATED WORKS
 Smart home systems provides unique data analysis and 
mining opportunities to identify regular user activities and 
patterns to help maintain independence and quality of life for 
an aging population. There have been numerous general 
research in this area along with their benefits [1], [2]. In this 
section, the focus is upon some of the projects that analyses 
data gathered from different sensors (context aware) and/or 
similar past activities (case based reasoning) to provide 
intelligent services.  
Georgia Tech through their Aware House [3] introduced a 
“track-stitching” algorithm for measuring activities in an 
environment based on data collected from RFID tags, optical 
and pressure sensors. They extended upon behavior 
recognition, through inferences drawn from information about 
various activities, interaction with objects and locations. The 
Independent Lifestyle Assisting (ILSA) and the MavHome 
project introduced a behavior-learning model based on 
sequential patterns [1], [4], to predict activities of residents of a 
smart home. The CASAS Smart Home Project [11] as well as 
the Smart Hospital Project [12] used hidden Markov 
probabilistic models, to recognize activities in complex 
situation where multiple individuals within the same 
environment were performing parallel activities. The 
University of Washington Assistive Cognition [13] (ACCESS) 
2013 IEEE International Conference on Cloud Computing Technology and Science
 978-0-7695-5095-4/13 $31.00 © 2013 IEEE
 DOI 10.1109/CloudCom.2013.129
 705
project investigated machine learning and ubiquitous 
computing algorithms to support intelligent way finding 
systems based on travel patterns. It included modules to create 
user profiles, transportation plan learner and significant place 
identifier to predict likely destinations and detect unusual 
variations. MIT Intelligent Home [14] presented a predictive 
framework for location-aware resource optimization in smart 
homes. The Neural Network House [5] from the University of 
Colorado based on neural nets, focused upon providing 
adaptive control of home environments to anticipate needs of 
its inhabitants.  
Although there have been major contributions towards 
analyzing data from smart homes, they remain a lab-based 
initiative. The use of traditional RDBMS solutions for storage 
and processing, constrains their practical applicability and 
scalability. In a real world scenario, sensor data from smart 
homes would generate enormous and continuous streams of 
data beyond the capabilities of existing data management 
solutions. Further the research focus was more towards 
improvement of services offered through smart homes, rather 
than about preventive care where data from sensors can 
provide insights about health/lifestyle anomalies. Our work 
addresses a complete different dimension of establishing 
preventive care through a data intensive solution. The goal is to 
create an analytical solution for privacy preserving data 
analytics. We propose a framework for securely collecting and 
storing sensor time-series data and a platform for statistical 
analysis. Analyzing movement data of a household to 
recognize behavioral patterns, detect incidents and realize 
syndromes at early stages can enable preventive care. In this 
respect, our work is novel and different from existing research, 
where opportunities for preventive care through smart homes 
utilizing new No-SQL based solutions is validated.
 III. TECHNOLOGY OVERVIEW
 The various technologies that would facilitate creation of 
our big data analytics solution are provided in the following 
subsections. 
A. Hadoop 
Hadoop is an open source framework for distributed storage 
and data-intensive processing first developed by Yahoo [15]. It 
has two core projects: Hadoop Distributed File System (HDFS) 
and MapReduce programming model. HDFS is a distributed 
file systems that splits and stores data on nodes throughout a 
cluster, with a number of replicas. It provides an extremely 
reliable, fault tolerant, consistent, efficient and cost effective 
way to store large amounts data. The MapReduce model 
consists of two key functions: Mapper and Reducer. The 
Mapper processes input data splits in parallel through different 
map tasks and sends sorted, shuffled outputs to the Reducers 
that in turn groups and processes them using reduce tasks for 
each group. 
B. HBase 
HBase is a distributed column-oriented and NoSQL 
database built on top of HDFS and modeled after Google's 
BigTable [16]. HBase provides real-time read/write random-
 access to very large datasets [17] In HBase, a table is 
physically divided into many regions, which are in turn served 
by different Regional Servers. One of its biggest utility is of 
combining real-time HBase queries with batch MapReduce 
jobs, using HDFS as a shared storage platform. 
C. OpenTSDB 
OpenTSDB [18] is an open source distributed and scalable 
time-series database, developed by StumbleUpon. It supports 
real time collection of data points from various sources. It 
stores, indexes and serve metrics at a large scale in HBase. 
D. R and RHIPE 
R [19] is a language and environment from the open source 
community widely used among statisticians and data scientists. 
It provides a wide range of libraries for analysis and 
visualization. R Hadoop Integrated Processing Environment 
(RHIPE) is a library for R integrating with the Hadoop DFS. 
Using MapReduce programming model it computes massive 
data sets across different nodes in a cluster. It works from the R 
environment using standard R programming idioms [20]. 
IV. RESEARCH METHODOLOGY
 The key research focus of this project is creating an 
analytical solution to support assisted decision making 
enabling preventive care from analysis of behavior pattern 
based on movement data. A design science [21] research 
method reflects strive to solve practical problems [22].
 Activities in design science follow an iteration of build and 
evaluate [23]. This is particularly helpful if the desired target 
state of a system is not known a priori. First of all, 
requirements for a novel analytical engine to recognize 
arbitrary movement patterns and bring meaning to behavior, 
needs to be compiled. After implementing an initial prototype 
based on the requirements, it could be evaluated and refined 
[24] in subsequent steps. This enables a process of “learning 
via making” [25]. In other words: with each iteration more 
profound understanding of the problem can be gained, leading 
to improved prototypes that would help to further track down 
design issues.  
Design science is particularly suited for designing 
healthcare/lifestyle related systems. In most cases, no technical 
breakthroughs are needed. Rather, existing technology has to 
be adopted, reconfigured, and recombined in creative ways to 
target yet unsolved problems. This helps to focus on the 
research objective - improving the quality of life of elderly 
using modern technology as an enabler. 
Requirements Engineering (RE) needs adherence to well-
 established practices [26]. In particular, requirements for 
movement data analysis has to be derived through literature 
review as well as working closely with domain experts for the 
care of elderly such as municipality and health-care 
professional. Designing and implementing the prototype will 
follow common procedures from Software Engineering (SE) 
[27]. All phases will have an incremental character. Progress 
will be checked with the domain experts with feedback 
incorporated along the new requirements for the next iteration 
cycle. 
706
Fig. 1. Research Areas 
V. RESEARCH AREAS & CONTRIBUTIONS
 The key research of our work would be focused towards 
data analysis and mining. An end-to-end evaluation of the 
complete project leads to classification of the research 
questions into three categories. As represented in Fig. 1, the 
categories are data privacy & security, data collection and data 
analysis & mining. The following subsection provides an 
overview of proposed contributions in creating our analytical 
solution. As mentioned earlier, a scalable framework for 
securely collecting and processing data from smart homes is 
needed. In the due course of our work, we worked on a smart 
home data analysis framework for collecting vast amounts of 
sensor data, storing them into a distributed Hadoop cluster 
while maintaining data security. As continuation of the 
framework we propose a k-anonymization based privacy model
 for preserving privacy of shared results and a data intensive 
platform to enable distributed statistical analysis. Our future 
work would focus more towards establishing preventive care 
mechanisms demonstrated mainly through analysis of 
movement sensor data. 
A. Smart Home Data Analysis Framework 
The data collection process should be independent of the 
source and structure of the data. It should embed the security &
 privacy concepts while extracting data from sensors and 
pushing them into our distributed big data environment. The 
workflow should ensure data consistency, confidentiality and 
integrity. It should be capable of enabling scalability on both 
ends (number of sources and size of cluster). Proven concepts 
for storage and processing of continuous time series data 
without losing their properties in a distributed environment 
should be investigated.  
In an earlier work [28], we had presented a framework for 
securely collecting and storing sensor data from smart homes 
in a distributed cluster using the Hadoop framework. The 
presented approach Fig. 2, maintained the data utility by not 
transforming the stored data. Rather based on cryptographic 
techniques, it replaced the primary and quasi- identifiers1
  of 
collected sensor data with hashed values before storing them 
into a de-identified storage. A separate encrypted identifier 
dictionary storage, with hashed and actual identifier values was 
also maintained as a point of reference for re-introduction of 
identifiers. The identifier dictionary stored only the unique sets 
of primary/quasi- identifiers. The de-identified storage 
contained all data collected from each home, with sizes moving 
upto tera-bytes of information. We proposed using heuristic-
 based k-anonymization algorithms [29] based on the end-users 
privacy level, requirements and authorization on the identifier 
dictionary storage. The hashed identifiers from outputs of any 
data processing job on the de-identified store would be 
replaced with their respective k-anonymized value, thus 
preserving privacy of any presented/shared results. 
Fig. 2. Secure Data Framework Architecture 
B. Data Privacy 
Lifestyle data collected from smart homes are very 
sensitive. Although analysis of such data can enable 
establishing supportive and preventive care, there are major 
privacy regulations that have to be complied in order to share 
results across the value chain. The code of conduct for data 
privacy and security from Helsedirektoratet Norway, 
prescribes guidelines for data from healthcare and social 
sectors. Using k-anonymization, privacy of micro data can be 
preserved depending on actors with whom data is being shared. 
A transformed dataset satisfies k-anonymity if every 
combination of values in personally identifiable columns 
cannot be matched to fewer than k rows. However, heuristic 
based k-anonymization algorithms lack scalability to data 
spread across various nodes in a cluster and are built for 
centralized storages [30]. A novel distributed MapReduce 
based k-anonymization solution is needed to address the 
                                                          
1 Personal and quasi- identifiers describe personally identifiable 
information. These attributes can directly or in-directly reveal personal 
information 
707
requirements of our smart home data analysis framework. K. 
LeFevre, et. al. [31] demonstrates the optimal multi-
 dimensional anonymization is NP-hard and introduce a simple, 
scalable, greedy approximation algorithm for several general-
 purpose quality metrics, having results better than those 
produced by more expensive optimal algorithms [29], [32]–
 [34].  
Our k-anonymization solution realizes the Mondrian 
algorithm in a distributed setting using the MapReduce 
programming paradigm. As illustrated through our privacy 
preserving data analysis framework, sensitive/personal 
information was stored separately in HDFS. The goal is to 
partition the sensitive data set into subsets called equivalence 
classes and recursively further partition them until they satisfy 
the k-condition. The k-condition can be described as the size of 
partitioned equivalence class, greater than equal to the 
specified k or smaller than equal to 2k-1 values. The k value 
represents the number of records that should be 
indistinguishable from each other. The anonymization 
workflow is represented in Fig. 3. The anonymization process 
is carried out iteratively in two phases until the complete 
dataset is anonymized. First data from HDFS is read through 
an initializer mapper. All records consist of a primary identifier 
as key and a set of quasi-identifiers as values. A partitioner
 groups all key-value pairs into the same reducer as a single 
equivalence class. A stat reducer counts the total number of 
records. It also calculates the max, min and cardinalities for 
each quasi-identifier column of type numeric and characters.
 The outputs are stored back into HDFS. Completion of this 
phase initiates the second phase of partitioning the data. A 
partition mapper reads the data from HDFS that is to be 
anonymized. The whole process being performed iteratively,
 data read by the partition mapper is outputs from a previous 
phase. Outputs of the mapper consist of the quasi-identifiers as 
values and a composite key containing the primary identifier 
and a set of equivalence class identifiers of itself and its 
parents. For the first iteration the input data set is the raw data 
set with the same equivalence class identifier as keys for all 
records. Next a comparator sorts inputs for the reducer on a 
quasi-identifier chosen based on the statistics from the earlier 
phase. It uses median partitioning rules as used in kd-trees [35] 
to determine the most suitable sorting/partitioning attribute. 
The partition reducer loads the statistics from previous phase 
as local distributed cache and partitions the output data set into 
two equivalence classes based on values on left hand side (lhs)
 and right hand side (rhs) of its median row. Depending on the 
partitioning rules it either includes all rows after the median 
row for the most suitable sorting/partitioning attribute with the 
same value as itself into the lhs equivalence class and the rest 
to the rhs equivalence class (strict partitioning) or partitions 
records until the median record into lhs and remaining to rhs 
(relaxed partitioning). If an equivalence class satisfies the k-
 condition it is anonymized based on specified recording rules 
[35], else the equivalence classes are stored as intermediate 
results back into the HDFS. The equivalence classes that do not 
satisfy the k-condition are read using a stat mapper and a
 respective stat reducer processes each group. The process is 
continued until all the remaining rows are partitioned into 
equivalence classes satisfying the k-condition. 
Fig. 3. Distributed K-Anonymization Workflow 
C. Data Intensive Processing 
To interpret, analyse and visualize large time-series data, it 
is essential to store them while preserving their properties of 
time dependence, quantity, frequency and speed. HBase 
provides a multi-dimensional storage through usage of unique 
composite keys. OpenTSDB an open source distributed and 
scalable time-series database that use such keys consisting of 
timestamps, metrics and tags for storing and indexing time-
 series metrics in HBase. R is an environment for statistical 
explorations and data visualization with a wide variety of 
analytical functionalities including time-series analysis. RHIPE 
enables the extension of R functionalities through MapReduce 
on data in HDFS & HBase, but remains incompatible in 
processing composite keys used by OpenTSDB. We propose a 
framework called R2Time to fill this gap, integrating these 
solutions together enabling distributed processing of large 
time-series data across a Hadoop cluster. It provides methods 
for distributed handling of composite keys, allowing analysis 
of massive amount of time-series data in an effective and 
scalable manner. The platform enables statistical and data 
mining operations using the MapReduce programming model, 
708
through user defined map and reduce tasks for different 
analytical requirements. 
D. Data Analysis & Mining 
The subsections earlier, described a solution to securely 
collect, store and share data from smart homes. It also enabled 
a platform for distributed statistical analysis. In this section, we 
propose establishing preventive care, demonstrated through 
analysis of movement sensor data.  
Each smart home comprises of a network of optical sensors 
detecting movement of residents within a household. Using 
wristbands with embedded identifiers, multiple individuals 
within a household can be recognized. Profiles for each 
household could be established, through daily movement 
patters. Behavioral anomaly can be detected from significant 
variation in their patterns or co-relation with other households 
with similar behavior, leading to heath risks in the future. An 
example would be behavior of using the toilet, wherein unusual 
patterns could be detected and care be furnished. This is 
especially essential for elderly residents, where it is critical to 
provide right care at the right time. A generic analytical model 
can provide opportunities for ad-hoc analytics along with 
knowledge discovery and data mining methods to detect 
behavioral anomalies. Investigation of various data mining 
methods and techniques [36] has to be carried out for 
identifying, evaluating, and choosing correct algorithms to 
recognize movement patterns, create profiles, establish 
behavior knowledge bases and perform co-relation on time-
 series data. Focus would be towards implementation of 
scalable data mining algorithms to work on a distributed 
environment and to create knowledge in an accurate &
 meaningful way. 
VI. CONCLUSION
 Through this paper the motivation and a prototype towards 
creation of a data analytical solution for the Safer@Home 
project is presented. Majority of research in analyzing data 
from smart homes are much of a lab-based initiative and lack 
adaptation in the real world. Unlike other projects, our focus is 
on establishing preventive care based on analysis of movement 
sensor data to contribute in the welfare of the elderly. Using 
modern Big Data solutions and proper statistical tools the aim 
is providing real-time as well as historical analysis of 
continuous stream of time series data. The key area of research 
through this project is data analysis and mining. Data security, 
privacy, collection and visualization are other areas that are 
also investigated, in order to create and develop a 
comprehensive & complete solution with real-world 
applications.  
REFERENCES
 [1] D. J. Cook, M. Youngblood, E. O. Heierman III, K. Gopalratnam, S. Rao, 
A. Litvin, and F. Khawaja, “MavHome: An agent-based smart home,” in 
Pervasive Computing and Communications, 2003.(PerCom 2003). 
Proceedings of the First IEEE International Conference on, 2003, pp. 521–
 524. 
[2] E. Dishman, “Inventing wellness systems for aging in place,” Computer,
 vol. 37, no. 5, pp. 34–41, 2004. 
[3] G. D. Abowd, A. F. Bobick, I. A. Essa, E. D. Mynatt, and W. A. Rogers, 
“The aware home: A living laboratory for technologies for successful aging,” 
in Proceedings of the AAAI-02 Workshop “Automation as Caregiver, 2002, 
pp. 1–7.
 [4] K. Z. Haigh, L. M. Kiff, J. Myers, and K. Krichbaum, “The independent 
lifestyle assistantTM (ILSA): Deployment lessons learned,” in The AAAI 
2004 Workshop on Fielding Applications of AI, 2004, vol. 25, pp. 11–6.
 [5] M. C. Mozer, “The neural network house: An environment hat adapts to its
 inhabitants,” in Proc. AAAI Spring Symp. Intelligent Environments, 1998, pp. 
110–114. 
[6] W. W. T. Rong C, “Smart system to support safer independent living and 
social interaction for elderly at home.”
 [7] A. Zaslavsky, C. Perera, and D. Georgakopoulos, “Sensing as a service 
and big data,” ArXiv Prepr. ArXiv13010159, 2013. 
[8] N. Braden, The Hadoop Framework. 2012. 
[9] A. Pavlo, E. Paulson, A. Rasin, D. J. Abadi, D. J. DeWitt, S. Madden, and 
M. Stonebraker, “A comparison of approaches to large-scale data analysis,” in 
Proceedings of the 2009 ACM SIGMOD International Conference on 
Management of data, 2009, pp. 165–178. 
[10] T. White, Hadoop: the definitive guide. O’Reilly, 2012.
 [11] D. Cook, M. Schmitter-Edgecombe, A. Crandall, C. Sanders, and B. 
Thomas, “Collecting and disseminating smart home sensor data in the 
CASAS project,” in Proceedings of the CHI Workshop on Developing Shared 
Home Behavior Datasets to Advance HCI and Ubiquitous Computing 
Research, 2009. 
[12] D. Sánchez, M. Tentori, and J. Favela, “Activity recognition for the smart 
hospital,” Intell. Syst. IEEE, vol. 23, no. 2, pp. 50–57, 2008. 
[13] K. Johnson and G. Borriello, “Assisted cognition in community, 
employment and support settings,” 2009.
 [14] S. S. Intille, “Designing a home of the future,” Pervasive Comput. IEEE,
 vol. 1, no. 2, pp. 76–82, 2002. 
[15] Yahoo, Hadoop at Yahoo! . 
[16] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M. 
Burrows, T. Chandra, A. Fikes, and R. E. Gruber, “Bigtable: A distributed 
storage system for structured data,” ACM Trans. Comput. Syst. TOCS, vol. 26, 
no. 2, p. 4, 2008. 
[17] L. George, HBase: The Definitive Guide. pub-ORA:adr: pub-ORA, 2011. 
[18] T.Suna, OpenTSDB. .
 [19] R. Kabacoff, R in action, 1st ed. Manning; [Pearson Education 
[distributor], 2010. 
[20] D. S. Guha, RHIPE. . 
[21] H. A. Simon, The sciences of the artificial. MIT press, 1996. 
[22] S. T. March and G. F. Smith, “Design and natural science research on 
information technology,” Decis. Support Syst., vol. 15, no. 4, pp. 251–266, 
1995. 
[23] A. R. Hevner, S. T. March, J. Park, and S. Ram, “Design science in 
information systems research,” MIS Q., vol. 28, no. 1, pp. 75–105, 2004. 
[24] S. Chatterjee, Design research in information systems: theory and 
practice, vol. 22. Springer, 2010. 
[25] B. J. Oates, Researching information systems and computing. Sage, 2005. 
[26] I. Sommerville and G. Kotonya, Requirements engineering: processes 
and techniques. John Wiley & Sons, Inc., 1998. 
[27] I. Sommerville, Software Engineering (7th Edition). Pearson Addison 
Wesley, 2004. 
[28] A. Chakravorty, T. Wlodarczyk, and C. Rong, “Privacy Preserving Data 
Analytics for Smart Homes,” 2013.
 [29] L. Sweeney, “Guaranteeing anonymity when sharing medical data, the 
Datafly System.,” in Proceedings of the AMIA Annual Fall Symposium, 1997, 
p. 51. 
[30] B. Fung, K. Wang, R. Chen, and P. S. Yu, “Privacy-preserving data 
publishing: A survey of recent developments,” ACM Comput. Surv. CSUR,
 vol. 42, no. 4, p. 14, 2010. 
[31] K. LeFevre, D. J. DeWitt, and R. Ramakrishnan, “Mondrian 
multidimensional k-anonymity,” in Data Engineering, 2006. ICDE’06. 
Proceedings of the 22nd International Conference on, 2006, pp. 25–25. 
709
[32] R. J. Bayardo and R. Agrawal, “Data privacy through optimal k-
 anonymization,” in Data Engineering, 2005. ICDE 2005. Proceedings. 21st 
International Conference on, 2005, pp. 217–228. 
[33] A. Hundepool and L. Willenborg, “?-and ?-argus: Software for statistical 
disclosure control,” in Third International Seminar on Statistical 
Confidentiality, 1996. 
[34] V. S. Iyengar, “Transforming data to satisfy privacy constraints,” in 
Proceedings of the eighth ACM SIGKDD international conference on 
Knowledge discovery and data mining, 2002, pp. 279–288. 
[35] J. H. Friedman, J. L. Bentley, and R. A. Finkel, “An algorithm for finding 
best matches in logarithmic expected time,” ACM Trans. Math. Softw. TOMS, 
vol. 3, no. 3, pp. 209–226, 1977. 
[36] M.-S. Chen, J. Han, and P. S. Yu, “Data mining: an overview from a 
database perspective,” Knowl. Data Eng. IEEE Trans., vol. 8, no. 6, pp. 866–
 883, 1996. 
710
