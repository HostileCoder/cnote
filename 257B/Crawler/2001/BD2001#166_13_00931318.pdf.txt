Assessment of Data and Knowledge Fusion Strategies for 
Prognostics and Health Management’ 
Michael J. Roemer 
Gregory J. Kacpnyaski 
RolfF. Orsagh 
Impact Technologies, U C  
125 Tech Park Drive 
Rochester, NY 14623 
mike.roemer@impact-tek.com 
(716) 424-1990 
Abstract-Various data, feature and knowledge fusion strategies 
and architectures have been developed over the last several years 
for improving upon the accuracy, robustness and overall 
effectiveness of anomaly, diagnostic and prognostic technologies. 
Fusion of relevant sensor data, maintenance database information, 
and outputs fkom various diagnostic and prognostic technologies 
has proven effective in reducing false alarm rates, increasing 
confidence levels in early fault detection, and predicting time to 
failure or degraded condition requiring maintenance action. 
The data fusion strategies discussed in th is  paper are principally 
probabilistic in nature and are used to aid in directly i d e n w g  
confidence bounds associated with specific component fault 
identifications and predictions. Dempster-Shafkr fusion, Bayesian 
inference, fuzzy-logic inference, neural network fusion and simple 
weightinghoting are the algorithmic approaches that are discussed 
in this paper. Data h i o n  architectures such as centralized fusion, 
autonomous fusion, and hybrid fusion are described in terms of 
their applicability to fault diagnosis and prognosis. The final goal 
is to find the optimal combiition of measured system data, data 
fusion algorithms, and associated architectures for obtaining the 
highest overall predictiddetection confidence levels associated 
with a sp&c application. To achieve this goal, a set of metrics 
has been developed for gauging the performance and effectiveness 
of a Fusion strategy. Specifically, this paper will demonstrate how 
various metrics are used for assessing individual and fused 
vibration-based diagnostic algoritbms. Evaluation of the 
diagnostic stmtegies was performed using gearbox seeded-fault 
and accelerated failure data taken with the MDTB (Mechanical 
Diagnostic Test Bed) at the ARL Lab at Penn State University. 
1. blTRODUCTION 
2. FUSION APPLICATION AREAS 
3. FUSIONAR~CTURES 
4. FUSIONTFCHNIQUES 
5. ASSESSINGTHEBENEFITS OFFUSION- M.ETRICS 
6. CONCLUSION 
7. REFERENCES 
1. INTRODUCTION 
Once sensor signals have been validated, the objective of data 
fusion is to combine their respective information in the most 
diagnostically efficient method possible. Multi-sensor data fusion 
refers to intelligent processing of an array of 2 or more sensors that 
have cooperative, complimentary and competitive qualities. As 
long as the sensor m y  does not contain independent sensors, 
arrays usually contain various levels of these three qualities. 
Cooperative sensors are those that work together to create a new 
piece of diagnostic information, while a complimentary array 
creates a more complete picture of a problem. Finally, a 
competitive array provides unrelated measurements of the same 
physical phenomena for improved reliability (Brooks, 97). 
2. FUSION APPLICATION AREAS 
Within a health management systeq there are three main areas 
where h i o n  technologies play a contributing role. These areas 
are shown in Figure 1. At the lowest level, data fusion can be used 
to combine information kom a multi-sensor data array to validate 
signals and create features. One example of data fusion is 
combining a speed signal and a vibration signal to achieve time 
synchronous averaged vibration features. 
CL7803-5599-201/$10.00 Q 2001 IEEE 
6 - 2 9 7 9  
Centralized Fusion 
Detection 
Figure 1 - Fusion Application Areas 
At a higher level (area 2), fusion may be used to combine features 
in intelligent ways so as to obtain the best possible diagnostic 
information. This would be the case if a feature related to particle 
count and sue in a bearing's lubrication oil were fused with a 
vibration feature such as kurtosis. The combined result would 
yield an improved level of confidence about the bearing's health. 
Finally, Knowledge Fusion (area 3) is used to incorporate 
experienced-based i n f o d o n  such as legacy failure rates or 
physical model predictions with signal-based infomation. 
One of the main concerns in any fusion technique is the danger of 
producing a fused system result that is actually performing worse 
than the best individual tool. This is because poor estimates can 
drag down the better estimates. The solution to this concern is to 
weigh the tools according to their capability and performance, 
which must be realized a priori. The degree of a priori knowledge 
is a function of the inherent understanding of the physical system 
and practical experience with the system. The ideal knowledge 
fusion process for a given application should be selected based on 
the characteristics of the a priori system information. 
Figure 2 - Centralized Fusion Architeture 
The autonomous fusion architecture shown in Figure 3 quells most 
of the data management problems by placing feature extraction 
before the fusion process. The creation of features prior to the 
actual fusion process provides the sigmiicant advantage of 
reducing the dimensionality of the information to be processed 
The main undesirable effect of a pure autonomous fusion 
architecture is that the feature fusion may not be as accurate as in 
the case of raw data fusion because a signilkant portion of the raw 
signalhasbeeneliminated. 
Autonomous Fusion 
... 
... 
3. FUSION AR-CTURES 
Identifying the optimal fusion architecture and approach at each 
level is a vital factor in assuring that the realized system truly 
enhances health monitoring capabilities. A brief explanation of 
fusion architectures will be provided here. 
The centralized fusion architecture fuses multi-sensor data while it 
is still in its raw form as shown in Figure 2. In the fusion center of 
this architecture, the data is aligned and correlated during the first 
stage. This means that the competitive or collaborative nature of 
the data is evaluated and acted upon immediately. Theoretically, 
this is the most accurate way to fuse data, however, it has the 
disadvantage of forcing the fusion processor to manipulate a large 
amount of data This is often impractical for real-time systems 
with a relatively large sensor network (€W 97). 
Figure 3 - Autonomous Fusion Architecture 
A hybrid fusion architecture takes the best of both and is often 
considered the most practical because raw data and extracted 
features can be fused in addition to the ability to "tap" into the raw 
data ifrequired by the fusion center (Figure 4). 
6-2980 
Hvbrid Fusion 
... 
... 
I ... 
i l  
Validation 
Figure 4 - Hybrid Fusion Architecture 
4. FUSION TJ3CHNIQUES 
There are probably hundreds of techniques for performing data, 
feature or knowledge fusion Because of this fact, sorting through 
which technique is best can be a daunting and involved task. In 
addition, there are no hard and fast rules about what fusion 
techniques or architectures work best for any particular 
application. The proceeding sections will describe some common 
fusion approaches such as Baysian Jnference, Dempster-Shafer 
combination, WeightingNoting, Neural Network Fusion and 
Fuzzy Logic Inference. In addition, a set of m d c s  will be 
discussed for independently judging the performance and 
effectiveness of the h i o n  techniques within a diagnostic system 
Bayesian Infwence 
Bayesian Inference can be used to detamine the probability that a 
dtagnosis is correct, given a piece of a priori information 
Analytically this process is described as follows: 
where: 
p ( f , l q  = The probability of fault (f) given a diagnostic output 
(0), p(o,I~;)= The probability that a diagnostic output (0) is 
associated with a fault (f), and p ( ~  ) = The probability of the fault 
( f )  occurring. 
Bayes’ theorem is only able to d y e  discrete values of 
confidence fiom a diagnostic classifier (i.e. it observes it or it 
doesn’t). Hence, a modified method has been implemented that 
uses three different sources of information. A-priori probability of 
failure at time t, (PF~t)) , the probability of failure as determined 
fiom the diagnostic classifier (Cwktl) data, and feature reliability 
which is independent of time (&,,). Care must be taken to 
prevent division by zero. 
i d  
The Bayesian process is a common and well established fusion 
technique, but also has some disadvantages. The knowledge 
required to generate the a priori probability distributions may not 
always be available, and instabilities in the process can occur if 
conflicting data is presented or the number of unknown 
propositions is large compared to the know propositions. 
Dempster-Shajm Method 
The Dempster-Shafer method addresses some of the problems 
discussed above and specifically tackles the a priori probability 
issue by keeping track of an explicit probabilistic measure of the 
lack of infomtior~ The disadvantage of this method is that the 
process can become impractical for time critical operations in 
large fusion problems. Hence, the proper choice of method should 
be based on the specific diagnostic/prognostic issues that are to be 
addressed 
In the Dempster-Shafer approach, uncertainty in the conditional 
probability is considered. The Dempster-Shafer methodology 
hinges on the COIlSLSUCtion of a set, called the frame of 
discernment, which Contains every possible hypothesis. Every 
hypothesis has a belief denoted by a mass probabiity (m). Beliefs 
are combined in the following m e r .  
Beli t f (H,  ) = AnB=Hn 
1- C m , ( A ) - m j ( B )  
The technique can be best explained through the use of the 
following example. 
Given: 
A diagnostic classifier detects Fault A with the following 
probability and associated uncertainty: 
P~=0.80+/-0.15 
The a priori probability of Fault A Occurring (based on current 
conditions and a priori information) is the following: 
Pg= 0.30 +/- 0.10 
6-2981 
Therefore: m(A) = 0.65 
m(A,A’) = 0.30 
m(B) = 0.20 
m(B,B’) = 0.20 
m(A’) = 0.05 
mQ3’) = 0.60 
I B I  B’ I B,B’ 
A I 0.13 I 0.39 I 0.13 
A,A’ 
And m(A) + m(B) {True) = (0.13 + 0.13 +0.06)/(1-(0.01 
+0.39)) = 0.53 
This result is called the ‘‘belief’ and it is the fused probability 
lower bound. The uncertainty in this result is the following: 
(4) 
m(A,A’) + m(B,B’) = 0.06 / (140.01 + 0.39)) = 
0.10 or +/- 0.05 
Hence, the probability of Fault A having actually occurred given 
the diagnostic output and in-field experience is 0.58 +/- 0.05. 
WeightingNoting Fusion 
Both the Bayesian and Dempster-Shafer techniques can be 
computationally intensive for real-time applications. A simple 
weighted average or voting technique is another approach that can 
be utilized. In both these approaches, weights are assigned based 
on a prior knowledge of the accuracy of diagnostic/prognostic 
techniques being used. The only condition is that the sum of the 
weights must be equal to one. Each confidence value is then 
multiplied by its respective weight and the results are summed for 
each moment in time. Weights can also change as a function of 
time. 
n=l 
Where i is the number of features, C is the confidence value, and 
W is the weight value for that feature. Although simple in 
implementation, choosing proper weights is of critical importance 
to highlighting the proper features under various operating modes. 
Fuzzy Logic Infwence 
Fuzzy Logic Inference is a fusion technique that utilizes the 
membership hc t ion  approach to scale and combine specilic input 
quantities to yield a fused output. The basis for the combined 
output comes fiom scaling the developed membership functions 
based on a set of rules developed in a rulebase. Once this scaling 
is accomplished, the scaled membership functions are combined 
by one of various methodologies such as sur“& ‘on, maximum or 
“single best” techniques. Finally, the scaled and combined 
membership functions are used to calculate the fused output by 
either taking the centroid, max height or midpoint of the combined 
h C t i 0 n .  
An example of a feature fusion process utilizing fuzzy logic is 
shovm below in Figure 5 .  In this example, features f“ an image 
are being combined to help determine if a “foreign” object is 
present in an original image. Image features such as tonal mean, 
midtones, kurtosis and many others are combined to give a single 
output that ranks the probability of an anomalous feature being 
present in the image. 
% Shadows, YO Midtones YO Highlights -
Tonal Mean Standard Dev. 
# of modes Kurtosis 
Modified Outputs 
Figure 5 - Example of Fuzzy Logic Inference 
Neural Nelwork Fusion 
A well accepted application of artificial neural networks (ANNs) 
is data and feature fusion. For the purposes of fusion, a networks 
ability to combine information in real-time with the added 
capability of autonomous relearning (if necessary) makes it very 
attractive for many fusion applications. 
Artificial neural networks (ANN) utilize a network of simple 
processing units, each having a small amount of local memory. 
These units are connected by “communication” links, which carry 
numerical data. The units operate only on their local data, which is 
received as input to the units via the connections. Most ANN’S 
have some sort of training rule by which the weights of 
connections are adjusted based on some optimization criterion. 
Hence, ANN’s learn fiom examples and exhibit certain capability 
for generalization beyond the braining data (examples). ANN’S 
represent a branch of the artificial intelligence techniques that have 
been increasingly accepted for data fusion and automated 
diagnostics in a wide range of aerospace applications. Their 
abilities to fuse features, recognize patterns, and to leam fiom 
samples have made ANN’S attractive for fitsing large data sets 
kom complex systems. 
6-2982  
The ANN structure is called its architecture, which is an 
expression of the number of processing units and of the 
connections among these units. Most processing units are 
arranged in lqers (a layer is a collection of the units aligned for 
the same computational sequence), and the ANN is often 
referenced by the number of layers and the number of units in each 
layer. 
-+ 
+ ._._...I 
4 ._..I_...._” 
Input Hidden Output 
layer layer layer 
Figure 6 - Simple Neural Network Fusion 
Architecture 
Each &d connection line in Figure 6 represents a numerical 
value called the weight, representjng the connecting strength 
between the two inter-connected units. Each circle is a unit and it 
performs three sequential computations: the first is to multiply the 
weight by the output of the unit on the other end of the connection; 
the second is to sum the weighted outputs fiom all mnnections; 
and the third is to apply the weighted sum to a function (usually 
nonlinear and bounded) called an activation function. One of the 
most common activation functions is called the sigmoid function 
and the b w f ( x )  (0 to 1 input) and bipolar g(x) (-1 to 1 input) 
versions are given below. They are useful because the simple 
form of the derivative reduces the compuhtiod burden during 
training. 
The functional value of the weighted sum is called the output (or 
threshold) of the unit This sequence of computation is carried out 
for each unit and for each layer until the outputs layer of the ANN 
is reached. 
Training a neural network for a fusion application involves the 
process of adjusting the weights and evaluating the activations of 
the numerous interconnections between the input and output 
layers. There are two fundamental types of leaming methods used 
for feature h i m  applications: Zmrupemked and supervised. In the 
unsupervised method, learning is autonomous; networks discover 
properties of the data set and learn to reflect these properties in its 
output, ie., it is used to group similar input patterns to facilitate 
processing of a large number of training patterns. In the 
supervised methd a ‘’teacher” is present during the training phase 
who tells the network how well it is performing or what the correct 
behavior should be, i.e., it is used for specifying what target 
outputs should result from an input pattern. 
A representative application of neural network fusion would be to 
combine individual features from different feature extraction 
algorithms to give a single representative feature. An example of 
this type of neural network fusion will be given in the following 
section 
Results 
The fusion techniques previously described have been 
implemented on various vibration features extracted from a data 
set developed during a series of transitional run-to-faihu-e tests on 
an industrial gearbox at Penn State ARL. In these tests, the torque 
was cycled from 100% to 300% load starling at approximately 93 
hours. The drivegear experienced multiple broken teeth and the 
test was stopped at approximately 114 hours. The data collected 
during the test was processed by many feature extraction 
algorithm techniques that resulted in 26 vibration features 
calculated from a single accelerometer attached to the gearbox 
housing. The features ranged in complexity &om a simple RMS 
level to a measure of the residual signal (gearmesh and sidebands 
removed) from the time synchronous averaged waveform. More 
information on these vibmtion features may be found in 
Byington, 19971. Figures 7 and 8 show plots of two of these 
features, Kurtosis and NA4, respectively. The green, smoother 
line in each of these plots is the ‘‘puud truth severity” or the 
probabiltity of failure as determined ikom visual inspections 
discussed next. 
105 110 
Figure 7 - Kurtosis Feature 
5 
6-2983 
0.5 
0.4 - 
0.3 ~ 
0.2 - 
0.1 - 
-1 ___ 1 
95 100 105 110 115 
Time (Hours) 
Figure 8 - NA4 Feature 
Borescopic inspections of the pinion and drivegear for this 
particuler test run were performed to bound the time period in 
which the gear had experienced no damage and when a single 
tooth had failed. These inspection results, coupled with the 
evidence of which features were best at detecting tooth cracking 
prior to failure features (as determined €tom the diagmotic metrics 
discussed later), was the a-priori information used to implement 
the Bayesian Inference, Weightinfloting, Neural Network, and 
Dempster Shafer lsion processes. 
The seven best vibration feature as determined by a consistent set 
of metrics described in the next section, were assigned weights of 
0.9, average performing features were weighted 0.7, and low 
performers 0.5 for use in the voting scheme. These weights are 
directly related to the feature reliability jn the Baysian Inference 
fusion. Similarly, the best features were assigned the uncertainty 
values of (0.05), average performm (0.10) and low performers 
(0.15), for the Dempster Shafer combinatioa The prior 
probability of Mure required for the Neural Network, Bayesian 
Inference and Dempster Shafer fusion were built upon the 
experiental evidence that a drive gear crack will form in a mean 
time of 108 hours with a variance of 2 hours. 
Seven of the 26 total vibration features calculated are shown in 
Figure 9. Note that some of the features have little correlation to 
the actual tooth failure as de&ed by the ground tmth inspection 
data. The results of the Dempster-Shafer, Bayesain and Weighted 
fusion techniques on all 26 features is shown in Figure 10. All 
three approaches increase in their probability of failure estimates at 
around 108 hours (index 269). Clearly, the voting fusion is most 
succeptible to false alarms, the Baysian Inference suggests a 
probability of failure increase early on but isn't capable of 
producing a high d d e n c e  level. Finally, the Dempster-Shafer 
combination provides the same early detection, achieves a higher 
confidence level, but is more sensitive tbroughout the failure 
transition region overall. 
300 350 
Figure 9 - Top Seven Vibration Features 
0 50 100 150 MO 250 300 360 
Figure 10 - Fusion of all Features 
Next, the same fusion algorithms were applied to just the best 
seven features as defined by the metrics. As one can see, the 
fusion of these seven features produces more accurate and stable 
results, which are shown in Figure 11. Note that the Dempster- 
Shafer combination can now retaiu a high con6dence level with 
more robustness throughout the critical failure transition region. 
6-2984 
I 
0.8 O . ) i  
0.6 '71 
Uempster Schaefer 
Bavesian -- 
" I I I h 
50 100 150 200 250 300 393 
Figure 11 - Fusion of 7 best features 
Finally, a simple back propagation neural network was trained on 
four of the top seven features previously fused (RMS, Kurtosis, 
NA4, and MSA). In order to train this supervised neural network, 
the probability of failure as defined by the ''ground truth" was 
required as a-priori information as described earlier. The network 
aukmatically adjusts its weights and thresholds (not to be 
conhsed with the feature weights) based on the relationships it 
sees between the probability of failure curve and the correlated 
feature maguitudes. Figure 12 shows the results of the neural 
network after being trained by these data sets. The difference 
between the n e d  network output and the "ground truth" 
probability of failure curve is due to error that still exists after the 
network parameters have optimized to minimize this error. Once 
trained, the neural network fusion architecture can be used to 
intelligently fuse these same features for a di€€ixent test under 
similar operating conditions. 
1 
0 8  
0 6  
04 
0 2  
0 
250 I 300 I 340 
150 I 200 50 100 
Cycling Load Crack Failure Formed 
Figure 12 - Fusion with a Neural Network 
5.  ASSESSING THE BENEFITS OF FUSION - METRICS 
Based on the technical results fiom the vibration feature fusion 
demonstrated in the previous section, it is now worthwhile to 
assess the benefits of these fusion processes utilizing a consistent 
set of mathematical ground rules (i.e. metrics). Through 
implementation of fusion techniques at difFerent points in the 
health management intiormation flow (data - features - 
knowledge), as was show in Figure 1, we expect to obtain some 
technical and economic benefits. To illustrate a measure of the 
magnitude of these benefits, some performance metrics associated 
with an algorithm fault detection and diagnostic capabilities were 
developed, along with effectiveness metrics to capture system 
implementation and cost issues. The metrics developed are 
shown in Figure 13 and are briefly discussed next. 
In this paper, we will present only a few results of an exhaustive 
study that was performed on the benefits of combining individual 
vibration features to aid in the detection of cracked gear teetk 
Specifm regarding the individual vibration features that were 
fused for improved fault detection can be found in [Orsagh and 
Roemer, 20001. This paper also provides the detail on how the 
pe r fomce  and effectiveness metric scores were developed and 
calculated The results fiom this paper show how the detection 
ability of different algorithm af€ect the total ownership cost of 
implementing a particular fusion technology. 
Figure 13 - Technology Performance Metrics 
The benefits achieved through accurate detection and fault 
isolation by implementing fusion techniques are weighed 
against the costs associated with false alarms, inaccurate 
diagnoses, licensing, and resource requirements of 
implementing and operating specific fusion techniques. The 
simplified cost function shown below states the Technical 
Value provided by a diagnostic or detection technology for a 
particular failure mode. The value of a fusion-based diagnostic 
tool in a particular application is the summation of the benefits 
it provides over all the failure modes that it can diagnose less 
the implementation cost, operation and maintenance cost, and 
6-2985 
consequential cost of incorrect assessments as stated in “Total 
Value” equation layout as savings-costs. 
(7) 
Technicalvalue= P,*(D*a + I * B ) - ( l -  P,) 
* (P, *(#I - 4 *e> 
where: 
Pf= Probability (time-based) of Occurrence for a failure mode 
D = Overall Detection Confidence metric score 
a = Savings realized by detecting a fault prior to failure 
I = Overall isolation confidence metric score 
p = Savings realized through automated isolation of a fault 
PD = False positive detection metric score 
Q = Cost associated with a false positive detection 
PI =False positive isolation metric score 
6 = Cost associated with a false positive isolation 
TotalVulue= CTechnicuIVulue, - A - 0 - ( 1 - % ) * 6  
FmIumW&a 
where: 
A = Acquisition and Implementation Cost 
0 = Life Cycle Operation and Maintenance Cost 
P, = Computer Resource Requirement score 
6 = Cost of a standard computer system 
Table 1 shows the resulting scores for each of the individual 
diagnostic algorithm evaluated as well as for the Dempster-Shafer 
fusion technique. For all of the metrics, a low score indicates an 
undesirable result, and a high score indicates a desirable result. For 
example, a high Computer resource requirement score is awarded 
to algorithms that use a small portion of the computer’s resources. 
A brief discussion of the metric developed is given next for 
completeness, but refer to [Orsagh and Roemer, 20001 for details 
on the exact calculation. 
The Detection Threshold Metric measures an algorithms ability to 
identify anondous operation associated with incipient f d t s  with 
a specified confidence level. Confidence levels of 67% and 95%, 
corresponding to one and two standard deviations, are used to 
calculate the detection threshold metric. An assessment of the 
detection cdidence level over the entire severity range for 0 to 1 
is achieved with an Overall Detection Confidence metric. An 
algorithm that detects an incipient fault with high confidence will 
receive a high Overall Confidence score, while an algorithm that 
does not report a fault until it becomes very severe would receive a 
low score. 
A confidence level that fluctuates Wildly is diflicult to interpret 
and therefore undesirable. For example, a diagnostic tool that 
produces a Boolean result of either no fault or fault may flicker as 
the fault severity approaches the detection level. The Stability 
w c  measures the range of confidence values that occur over the 
fault transition by integrating the peak to peak difference at each 
point in the transition. In addition, diagnostic systems should 
detect anomalies over the full range of operating (duty) conditions 
such as loads, speeds, etc. The Detection Oun, Sensitivitv Metric 
measures the difference between the outputs of a diagnostic tool 
under various duty conditions. 
A diagnostic tool that incorrectly reports anomalies is 
unacceptable because it reduces availability and increases 
maintenance costs for the equipment. The Fake Positive 
Confidence Metric measures the frequency and upper confidence 
limit associated with false anomaly detection by a diagnostic tool. 
Calculation of the false confidence metric is based on the fdse 
positive function as defined in reference [Orsagh and Roemer, 
20001. In an operational environment, sensor data is sometimes 
contaminated with noise that may interfere with the operation of 
diagnostic algorithms. The robustness of an algorithm to noisy 
data is measured by the Noise Sensitivitv Mm’c. 
Acquisition and implementation costs of the diagnostic 
algorithm may have a significant effect on the overall system’s 
cost effectiveness. The Implementation Cost Metric simply 
measures the cost of acquiring and implementing a diagnostic 
system on a single application. If the diagnostic system is 
applied to several pieces of equipment, any shared costs are 
divided among them. Operation and maintenance costs may 
also play a significant role in determining whether a diagnostic 
system is cost effective. The O&M Cost Metric measures the 
annual cost incurred to keep the diagnostic system running. 
These costs may include manual data collection, inspections, 
laboratory testing, data archival, re-licensing fees and repairs. 
The ability of the diagnostic algorithms or system to be run w i t h  
specified time requirements and on traditional computer platforms 
with common operating systems is important when considering 
implementation on multiple platforms. Therefore, a metric that 
takes into account computational effort as well as static and 
dyllarmc memory allocation requirements is necessary. The 
C ~ n ~ ~ u t e r  R source Mehic computes a score based on the 
normalized addition of CPU time to run (in terms of floating point 
operations), static and dynamic memory requirements for RAM 
and static source code space, and static and dynamic hard disk 
storage requirements. Computer requirements may be a s@cant 
issue in some applications such as aircraft. 
Complex systems are generally more susceptible to unexpected 
behavior due to unforeseen events. The System Complaitv Metric 
measures the complexity of diagnostic systems in terms of the 
number of source lines of code (SLOCs) and the number of inputs 
required 
6-2986 
6. CONCLUSION 
Benefit of Detection 
Cost of Std. Computer 
Calculation of the Detection Technical Value, Overall 
Performance and Overall Effectiveness are based on weighting 
factors described in Tables 2 and 3. These factors were used 
to calculate the results shown in Table 1. 
$50000 
$2000 
The net result of this feature performance and effectiveness study 
was an analytical and relatively unbiased evaluation of different 
feature diagnostic approaches. For this particular study, the 
Dempster-Shafer combination yielded the highest overall technical 
score and value because of its robustness and sensitivity; however, 
it was penalized for its complexity in the final effectiveness score. 
In other words, due to the fact that the Dempster-Shafer fusion 
process needs input from several different feature extraction 
algorithms makes it more complex to implement and therefore 
reduces its overall costlbenefit of implementation. 
This paper provides an in-depth discussion about many aspects of 
fusion including where fusion should exist within a health 
management system the Herent types of fusion architectures, 
and a number of different fusion techniques. These fusion 
techniques were applied to vibration features extracted during a 
transitional failure test associated with an industrial gearbox The 
results yielded conclusive evidence that fusion can be very 
valuable in the dmgnostic process if chosen judiciously. Finally, 
an approach was presented for assessing the performance and 
effectiveness of the vibration feature extraction algorithms and the 
fusion techniques themselves. 
[l] Hall, D., and Llinas, J., “An Introduction to Multisensor Data 
Fusion”, Proceecllngs of the IEEE, January 1997. 
[2] Leferve, E., and Colot, O., “A classification method based on 
the Dempster-Shafer’s theory and information criteria” Proceeding 
of the 2”d International Conference on Infomation Fusion, July 6- 
8,1999. 
[3] Orsagh RF., Roemer MJ., et al “Development of Mettics for 
Mechanical Diagnostic Technique Qualification and Validation”, 
COMADEM Conference, Houston Tx, December 2000. 
[4] Agosta, J. M, and Weiss, J. W., “Active Fusion for Diagnosis 
Guided by Mutual Information Measures”, Proceedmg of the 2nd 
International Conference on Information Fusion, July 68,1999 
[SI Brooks, R R, and Iyengar, S. S, Multi-Sensor Fusion, 
Copyright 1998 by Rentice Hall, Inc., Upper Saddle River, New 
Jersey 07458 
6-2987 
[6] Roemer, M. J. and Kacprzynski, G.J., “Advanced 
Diagnostics and Prognostics for Gas Turbine Engine Risk 
Assessment,” Paper 2000-GT-30, ASME and IGTI Turbo Expo 
2000, Munich, Germany, May 2000. 
[7] Roemer, M. J., and Ghiocel, D. M., “A Probabilistic Approach 
to the Diagnosis of Gas Turbine Engine Faults” Paper 99-GT-363, 
ASME and IGTI Turbo Expo 1999, Indianapolis, Indiana, June 
1999. 
[8] Roemer, M. J., and Atkinson, B., “Real-Time Engine Health 
Monitoring and Diagnostics for Gas Turbine Engines,” Paper 
June 1997. 
97-GT-30, ASME and IGTI Turbo EXPO 1997, Orlando, Florida, 
[9] Byingtoq C.S., Kozlows.ki, J.D., “Transitional Data for 
Estimation of Gearbox Remaining Life”, Proceedings of the 51“ 
Meeting of the MFPT, April 1997. 
Dr. Michael J.  Roemer is the Director of 
Engineering at Impact Technologies in 
Rochester, Ny and Adjunct Professor of 
Mechanical Engineering at the 
Rochester Institute of Technology. He 
was formerly a Vice President of 
Engineering at STI Technologies prior to 
joining Impact Technologies. Mike has a 
Ph.D. in Mechanical Enginewing, MS. 
in Systems Engineering and B.S. in 
Electkal Engineering, all from the State University of New York 
at Bu$alo. He has over 14 y e m  acpen‘ence developing real-time, 
automated health management technologies for complex systems, 
including large steam and gas turbines, gas turbine engines, 
rotary/fied-wing aircrq? subsystems and naval propulsion 
systems. He has developed several diagnostic and prognostic 
capabilities for complex system utilizing probabilistic methodr 
that are directly linked to maintenance planning and system 
operation. He is the author or co-author of more than 50 
technical pqers in these subject areas. He is current& the 
Chairman of the Machinery Failure Prevention Technology 
(MFPT) Society, a Divirion of the Vibration Institute, and 
Prognostics Lead for the sAE-E32 Engine Condition Monitoring 
Committee. 
Gregory J .  Kacptqvnski 
is a Project Manager at Impact 
Technologies with 5-y. exp’ence in 
the development and testing of 
diagnostic&ognostic systems for 
compressom, pumps, trmmksions, 
gas and steam turbinas. He has been 
involved in developing real-time, 
intelligent health monitoring systems 
generation condition-based mmntenance systems, aircraft 
prognostics, and health management design for the Nay and 
USAF. Greg has publishedpapers and developed technologies in 
the area of maintenance optimization, FMECA, Lge Cycle cost 
assessment, model-bared prognostim and data &ion 
technologks. Greg has his MS and BS in Mechanical 
Engineeringfrom Rochester Institute of Technology. 
for gas turbine engines for on-wing 
and test cell applicah*om as well as for other air vehicle 
subsystems. He has managed mdtiple SBIRs dealing with next 
6-2988 
