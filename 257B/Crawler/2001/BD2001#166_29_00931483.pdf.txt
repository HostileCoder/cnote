Synthetic Aperture Sonar - The Modern Method of 
Underwater Remote Sensing1 
Angela Putney, Enson Chang, Ralph Chatham, David Marx, Matt Nelson, L. Kieffer Warman 
Dynamics Technology, Inc. 
2131 1 Hawthorne Blvd., Suite 300 
Torrance, CA 90503-5691 
aputney@dynatec.com 
310-543-5433 
Abstract-Synthetic aperture processing - the coherent 
combination of data from multiple returns - has 
revolutionized radar imaging over the past 35 years. Sonar is 
in the early stages of the same revolution. Synthetic aperture 
sonar (SAS) data can be processed into images with 
resolution independent of range. Additionally, within 
difhction limits, the resolution is frequency independent. 
Such characteristics make SAS a usel l  tool for applications 
such as bottom searching and mapping, mine hunting, or 
submarine detection, for near ranges (- 50 m), mid-ranges 
(several hundreds of meters), and far ranges (several tens of 
kilometers) respectively. 
Over the past ten years, we have shown to be false the long- 
held notion that medium-induced signal fluctuations render 
SAS unfeasible. Through a careful importation and 
extension of key synthetic aperture radar (SAR) 
technologies, such as “autofocusing,” we are successfully 
able to process SAS data. SAS is by no means the same as 
SAR, but is very similar. Among the differences are the 
types of medium-induced signal fluctuations, e.g., the 
velocity of sound changes with temperature, and the 
amplitude of the motions to which the vehicle is subject. 
Autofocusing and other data driven compensation 
techniques are the key to overcoming these problems. For 
instance, our algorithms have routinely estimated and 
compensated for 40,000 degrees of phase error that arose 
from uncompensated vehicle motion and medium induced 
fluctuations. 
We have SAS-processed data collected by eleven different 
hardware suites at frequencies ranging from 240 kHz down 
to 600 Hz; physical array sizes ranging from half a meter to 
256 meters; and with range-independent azimuthal 
resolutions ranging from 2.5 cm at 50 m for the high 
frequency systems to - 6 m  resolution at 26km for the 
lowest frequency system. Our results demonstrate that phase 
coherence can be maintained in spite of severe vehicle 
motion, medium fluctuations, and multipath propagation. 
For instance, we imaged the interior structure of a sunken 
airplane at 350 m and at 1,000 m with similar cross-range 
resolution, despite the rays having suffered a bottom bounce 
on both the transmit and return paths for the 1,000 m range 
. 
data. The same imaging technology is applicable to cross- 
track interferometry (for resolving vertical features), bottom 
penetrating sonar, and wideband waveforms. 
TABLE OF C0N”TS 
1. INTRODUCTION 
2. SAS VERSUS S A R  
4. EXPERIMENTAL @ZWLTS 
3. SAS PROCESSING 
5. CONCLUSIONS 
1. INTRODUCTION 
Synthetic aperture sonar (SAS) is a high resolution acoustic 
imaging technique which coherently combines returns from 
multiple pings to synthesize a large acoustic aperture. It is 
the acoustic analog of synthetic aperture radar (SAR). 
Unlike standard sonar, SAS yields range independent cross- 
range (azimuth) resolution (equal to one half the lateral size 
of the receiver element) as well as frequency independent 
range resolution. High area coverage rate is achieved by use 
of a multiple element receive array in a mode akin to the 
SAR stripmap mode. Synthetic aperture processing is 
scalable, and it has been applied to both mine hunting and 
anti-submarine warfare (ASW) scenarios. 
In spite of the maturity of SAR technology, the acoustics 
community has been strongly skeptical about the 
fundamental feasibility of SAS. The main concerns are the 
medium’s spatial and temporal coherence limitations. These 
problems are exacerbated by significant towbody 
(transmittedreceiver vehicle) motion during integration. In 
the recent years, however, we have seen the emergence of 
highly adaptive motion compensation (MOCOMP) and 
“autofocus” techniques for overcoming the medium and 
motion-induced limitations [l]. These techniques use the 
acoustic data itself to infer motion and medium-induced 
phase errors. A good analogy is nighttime photography of 
moving automobiles. The streaks left by the headlights are a 
record of the cars’ motion during the exposure. Similarly, 
deviations of the acoustic returns from their ideal behavior 
0-7803-6599-2/01/$10.00  2001 lEEE 
(e.g., the hyperbolic range history from each point scatterer) 
is a record of the phase errors introduced by the medium and 
towbody motion. Once these deviations are corrected, their 
former characteristic spatial scale, i.e., the coherence length 
of the medium, becomes immaterial to the integration 
aperture. 
Using the adaptive compensation techniques. we have 
produced SAS images fkom a number of high-frequency 
sonars. These typically required an integration aperture on 
the order of several thousand wavelengths, which is much 
larger thm the natural coherence length of sound in the 
ocean (typically several hundred wavelengths [ 2 ] )  and thus 
thought to be impossible to focus. A question of practical 
interest is whether similar performance can be expected at 
low to mid-frequencies (several hundred to several thousand 
hertz). With the longer propagation range at these 
fkequencies, the successful operation of SAS may lead to 
orders of magnitude improvement in area coverage rate for 
bottom mapping applications. 
The nexl section compares the basics of the well known 
S A R  to not-so-well known SAS. Section 3 presents the basic 
SAS techniques and Section 4 shows examples from a 
variety of systems. 
2. SAS VERSUS SAR 
There are many differences between SAS and S A R ,  
including the methods of taking data, the distances and 
speeds involved, and the analysis of the data. The main 
differences will be touched upon in this section. 
The data taking methods of SAS and SAR are not identical. 
In general for SAR, the antenna, which transmits and 
receives, is mounted on the steered vehicle (usually an 
airplane or satellite). Typically in SAS, there is a transmitter 
and several separate individual receivers which are mounted 
as a linear array on a vehicle (towbody or towfish) that is 
towed behind a larger steered vehicle (boat). The towed 
vehicle does not always have the capability of being steered. 
This SAS configuration is not quite the same as either the 
S A R  monostatic or bistatic configurations since the 
transmitting and receiving elements are not the same 
element, but they are mounted on the same vehicle or, at 
least, tow line. 
There are similarities between the two that may not be 
obvious at first thought. SAS, like SAR, transmits a 
fiequency modulated (FM) pulse or a continuous-wave 
(CW) of energy (ping for SAS; chirp for S A R  if FM pulse). 
The ping is pulse compressed if need be. Like land imaging 
SAR, SAS assumes that the targets and surrounding terrain 
are motionless, thus the only doppler shifts seen are assumed 
to be due to vehicle motion and could be used to determine 
target location. 
When adapting SAR algorithms to SAS systems, several 
important differences between the two technologies come to 
light. Table 1 lists some of them, although the most stressing 
is probably ( V / C ) ~ ~  >> ( V / C ) ~ ~ .  While wavelengths are 
similar for the two systems, SAS systems typically use 
radiating elements smaller, relative to wavelength, than SAR 
systems. As a result, radiation beampattems for SAS 
systems have a greater angular extent than those for S A R  
systems. The effect on synthetic aperture processing is that 
range migration (the shifting of a target’s return through 
range resolution cells as the platform flies past) is quite 
significant and pronounced for SAS systems. 
Table 1. Comparison of typical SAR and SAS key 
parameters. The S A R  parameters range from airborne to 
c W S I  3 x lo8 1.5 x io3 
Wavelength [m] 0.01 - 0.3 0.01 - 1.5 
Resolution: 
range -1 - 30 m 0.025 - 6 m 
azimuth -1-30m 0.025 - 6 m 
Synthetic aperture few seconds minutes - hours 
time 
Synthetic aperture 100s m - few km 30 m - 5 km 
length 
PRI I-lmS 0.1 s- 1 min. 
Platfomi speed 
Range stand-off tens - hundreds h a  few meters - km 
Medium induced 0.4 - 0.7 rms deg 150 mu deg” 
phase fluctuations 
Medium coherence days minutes 
See [ 11 and reference therein. 
- 100 - -7800 d . 3  1 - several d s  
-
Because of the long propagation delays and the desire to 
minimize the synthetic aperture integration time, SAS 
systems generally use an array of receiver elements. 
Aperture sampling requirements, dong with the slow 
propagation, imply an interdependence: between array length 
(L) ,  ping (or pulse) repetition interval (PIU), maximum 
platform velocity ( VsAs) such that, 
Perhaps the most signifkant difference between SAS and 
S A R  systems is the medium coherence. Along with medium 
fluctuations, platform stability can also affect the signal 
phase history. Since integration times for SAS are an order 
of magnitude greater thad those for SAR, the phase 
corruption due to these effects can be much more severe for 
SAS. 
Through an adept application of a combination of S A R  
motion compensation and autofocusing techniques, it is 
possible to correct these large phase errors. The next two 
sections explain how we make the corrections and what the 
outcome is for a couple of systems 
3. SAS PROCESSING 
Synthetic aperture sonar produces high-resolution imagery 
by coherently combining data from multiple sonar pings (see 
Figure 1). To produce high-quality SAS results, these data 
must be referenced to a straight platform track with sub- 
wavelength accuracy. The motion of even well-behaved 
platforms, and phase distortions fiom the complicated 
underwater environment conspire to make this a challenging 
requirement, and much of our SAS processor is devoted to 
overcoming platform motion and phase errors. 
In general, our synthetic aperture processing can be divided 
into three, usually distinct, operations. In the first step, the 
data are adjusted to compensate for initial estimates of 
platform motion, using inputs from both the hardware 
mocomp suite, if one exists, and from information extracted 
from the sonar data itself. The second component is the 
image formation algorithm that performs azimuthal 
compression on the motion-compensated raw data and 
generates an image from the raw data. The third operation 
involves correction of phase errors due to uncompensated 
platform motion and medium instabilities, which is usually 
accomplished by application of some form of autofocus 
algorithm. 
Motion Compensation 
When available, platform motion estimates derived fiom 
specialized motion compensation hardware are applied to 
the sonar data to remove many of the effects of platform 
motion. Unfortunately, such estimates are often not 
available, due to hardware failures or simply the absence of 
these costly instruments. To process data with this 
limitation, we estimate phase error through the analysis of 
the sonar returns only. One technique we employ to estimate 
towbody motion from sonar data is a Prominent Point 
Processor (PPP) [3], which relies upon the existence of a 
dominant scatterer in the scene. An alternative method for 
estimating platform motion from sonar scene data is 
displaced phase center (DPC), sometimes called redundant 
phase center (RPC) processing. RPC estimates towbody 
motion by performing range-wise correlations on data from 
overlapping segments of the hydrophone array on successive 
pings of the sonar. RPC is based on techniques widely used 
in S A R  [4], such as in along track interferometry for 
mapping ocean currents [5]. 
Prominent Point Processing - After manually selecting a 
prominent point and locating its point of closest approach 
from a scene, its echo history is compared to the theoretical 
form it would have were there no platform motion. i.e., a 
hyperbola. The deviations fiom the perfect hyperbola are a 
measure of the phase errors induced by transmitterlreceiver 
motion and medium sound velocity variations. The PPP 
method measures the deviations and compensates for them 
by range and phase shifting the data accordingly, i.e., 
forcing the prominent point returns back onto the perfect 
hyperbola. Note that the PPP method does not alter the 
magnitude of the returns. 
Though robust, this technique requires the existence of 
strong, point-like scatterers throughout the area being 
imaged as well as an operator’s judgement of the prominent 
point’s location. Moreover, the returns fiom those prominent 
points must be distinguishable from other echoes throughout 
I I I DTI-Raytheon SAS .?‘a 
@a! ’ I 
Figure 1. Synthetic aperture sonar works by creating a virtual aperture out of multiple pings. The coherently 
summed extra ‘looks’ at more distant targets compensate for the linear degradation of resolution with range that is 
inherent in real-aperture sonar. The example, from the DARPA program, shows DTI’s SAS-processed images of 
data collected by Raytheon’s 50 Id% sonar in 1996. The targets were hollow 10 cm (-35 dB) and 20 cm spheres at 
180-m range. 
the whole integration length that it takes to develop a 
synthetic aperture. 
System 
css 
css 
Redundant Phase Center Processing - RPC is derived from 
the S A R  technique of along-track interferometry. Our RPC 
implementation for SAS requires neither a prominent point 
nor critical decisions and input fi-om the analyst. Since the 
received signal varies as elmt, where o is the carrier 
frequency, the complex correlation between the two repeated 
looks is sensitive to phase ehors on the order of a fiaction of 
a cycle. 
Frequency Cross-Range Maximum Range 
Resolution 
180 kHz 2.5 cm 50 m 
20 kHz 7.5 cm 50 m 
Although either of these algorithms could fail if the sonar 
data is of poor quality, they do have advantages over 
hardware-based motion measurement approaches. By its 
nature, motion measurement hardware can provide 
information about platform motion only. Unfortunately, 
there are many other sources of phase corruption in the 
underwater environment, such as medium instabilities and 
medium inhomogeneities. Phase errors derived from 
analysis of sonar echoes include the effects of all of these 
sources of phase corruption, and can therefore correct all 
phase errors simultaneously. 
Boeing 1 2 4 0 m  1 6 cm 
CEROS I 12.5kHz I 10 cm 
RMA Image Formation 
Several SAR image formation algorithms exist in the 
literature. Examples are direct matched filtering, chirp 
scaling algorithm, and the range migration algorithm (RMA) 
[3][6]. Because of its speed and full 2-dimensional treatment 
of the problem, we have chosen RMA for the image 
formatioii stage of our SAS processor, and the images shown 
in the next section were all focused using RMA. Developed 
for work in the geophysics community, RMA implements a 
solution of the synthetic aperture problem using fast Fourier 
transform to efficiently apply the matched filter in the 
wavenumber-frequency domain. With this technique, both 
speed and theoretical performance are achieved. 
100 m 
10 m (bottom penetrating) I 2 arrays of 3.5 m 
The Rh4A formalism explicitly treats only single-element 
systems, i.e., where the transmitter and receiver use the same 
antenna. However, a typical SAS system uses a single 
transmitter with an array of receivers, and in addition, the 
transmitter may be physically separated fiom the receiver 
DARPA 
DARPA 
SWAC 
array by a s i g ” t  distance. Therefore, pre-processing, in 
the form of a phase correction, is required to correct for the 
physical separation between each receiver and the 
transmitter. After this correction, the receiver data is 
equivalent to samples along the synthetic aperture 
corresponding to a single transmitterheceiver antenna. 
50kHz 5.5 cm 300 m 
- 6,000h 1 ;:h; I 50kHz 11 cm 1000 m 10,   
600 Hz 6 m  25 km 4.000 h 256 m 
Phase Gradient Autofocus 
To remove residual uncompensated motion from the focused 
images, we employ the phase gradient autofocus (PGA) 
algorithm [7][8]. The PGA algorithm selects candidate 
point-like targets in the synthetic aperture image, estimates 
the residual phase error at those points, and combines them 
into an optimal estimate of the phase error. This phase error 
is removed from the image and the process iterated until 
convergence is obtained. 
To estimate the phase error, only strong scatterers are used. 
Once detected, they are windowed and shifted to occupy 
same location in the synthetic aperture (Doppler history). 
The phase gradient is estimated by, 
where G:(u) is the signal along the synthetic aperture, U .  
Other phase gradient estimators e,&, but the above 
estimator is the linear unbiased minimum variance estimator. 
Integrating the phase gradient is then an estimate of the 
phase enror. After correcting the data for the estimated phase 
error, the algorithm can be iterated. 
4. EXPERIMENTAL RENJLTS 
We have processed data from eleven different hardware 
systems. Table 2 lists some key parameters of several of 
these systems. Examples from a few SAS systems are shown 
here. Fca these cases, only limited, if any, motion sensor 
data weire available, thus requiring us to rely entirely upon 
PPP or IWC for motion estimation. 
DARPA SAS System 
The DARPA SAS system (Figure 2), built and operated by 
Raytheon (formerly Alliant Techsystems), is a heavy-tow 
body with a one-sided, keel-mounted hydrophone array 
consisting of 32 elements. The contiguous tarray elements 
each have a width of 10.9 cm, and were originally 
configured with half of the elements forming a 16-element 
array, allowing for a final cross-range resolution of 5.5 cm. 
Later, they were wired in pairs to produce a 16-element 
array of 21.8 cm elements, supporting a resolution of just 
under 11 cm. The projector array is located on an adjustable 
"wing" approximately 0.8 m above the receiving array. This 
design makes it possible to transmit a narrow vertical beam 
to reduce the effects of multipath and concentrate 
transmitted power on long-range targets. The, projector 
operates on a center frequency of 50 kHz, and can transmit 
in either of two modes: a coherent burst consisting of 
6cycles of the carrier frequency, or a linear FM (LFM) 
chirp of programmable duration and bandwidth. With a 
bandwidth of 10 kHz, the LFM mode yields a theoretical 
range resolution of 7.5 cm; the 6-cycle tone achieves 9 cm. 
Figure 2. Raytheon-DARPA SAS towbody. Keel-mounted 
hydrophone array is 3.2 m long. Projector array is located in 
adjustable wing and provides narrow vertical beam for long- 
range operation. 
A PVC frame supporting a variety of known scientific 
targets was deployed during several sea tests (Figure3). 
Once installed, the rectangular frame lies flat on the sea 
bottom, and has a series of posts protruding upward to 
support targets. Posts running down the center of the frame 
supported two groups of five air-filled steel spheres: one 
group consisted of 10-cm diameter spheres, the other 20-cm. 
In each group, the targets were separated by 1, 2, 4, and 8 
diameters. The spheres should behave as ideal, but low 
cross-section, point scatterers and thus test the resolution of 
the SAS system. Two posts along the farthest edge of the 
fiame supported triplane corner reflectors (30- and 60-cm 
diameter), while two posts on the closest edge were empty. 
Figure 3 shows the final SAS image obtained fiom data 
collected at a range of about 190 m in Lake Washington, 
with the array configured with 10.9 cm receiver elements. 
This image was generated using RPC, RMA, and PGA, as 
described in the last section. Visible in the center of the SAS 
image are the spheres (20 cm on the right, 10 cm on the 
left), as well as a corner of the support frame at the extreme 
right. The artifacts appearing as double-images in range of 
the spheres are consistent with what would be expected from 
a single multipath bounce off the bottom of the lake. At the 
far edge (bottom), the two strong corner reflectors are 
evident, as is another comer of the frame. The empty posts 
along the near edge (top) are also visible. The support frame 
itself is visible as a faint line connecting the target images. 
The 3-dB down-point resolution achieved in this image, 
evaluated by taking a series of intensity cuts through the 
images of the 10- and 20-cm spheres, varies slightly within 
the image, with the best cross-range resolution being 
approximately 7 cm, compared to 5 cm theoretical. Also 
shown is what a conventional sonar beamforming would 
have produced for these data. 
186 
187 
I 8 8  
E l a 9  
' 190  
1 9 2  
191 
194 
191 
I96 
- 
5 I91 
3 1  3 3  35 37 3 9  4 1  4 1  
Azimuth (ml 
1 
Figure 3. Target frame (top) with 10- and 20-cm spherical 
targets centrally mounted. Conventional beamformed image 
(lower left) shows much less detail than SAS image (lower 
right). 
A popular sonar target in Lake Washington is a sunken 
PB4Y-2 navy patrol aircraft resting in 50 m of water. A SAS 
image of this target obtained from a range of 350m and 
processed with prominent point motion estimation is shown 
in Figure 4. The most striking feature compared with other 
published sonar images of this target is that the aircraft has a 
ghostly appearance, as if its skin has been removed. 
Subsequent analysis has determined that the thin aluminum 
skin, immersed in water on both sides, is nearly transparent 
to the 50 kHz sonar signals used by this sonar, with less than 
2 dB of transmission loss through the skin decreasing to 
virtually no loss at grazing incidence. Comparisons to 
published plans of the PB4Y-2 con€i i  that the periodic 
features seen along the fuselage in the SAS image are 
interior structural elements of the airplane. The wing and tail 
spars are visible, as are some of the ribs that support the aft 
4-1753 
fuselage. The locations of highlights in the tail portion of the 
image agree with the blueprints showing the locations of 
frames in the PB4Y-2 to within 3%, thus supporting the 
conclusion that the 50 kHz sonar is imaging the interior of 
the water-filled target. 
Figure 4. Sunken PB4Y-2 airplane from a range of 
approximately 350 m. The SAS image shows details of the 
planes internal structure, resolved to approximately 15 cm. 
A second run past the airplane collected data from a range of 
980 m. A. SAS image produced from this data is shown in 
Figure 5. Although the long-rage image is not illuminated as 
well as the airplane seen from closer range, the resolution is 
approximiately the same in the two images. Sound velocity 
profiles in the lake indicated that medium was downward- 
refracting, and ray tracing codes indicated that there were no 
direct acoustic paths past ranges of about 500 m, where the 
last ray hit the bottom. The airplane was therefore imaged 
with sound that had suffered two bottom bounces (one in 
each direction). In fact, the airplane is :situated such that the 
illuminating ray apparently came from a side-lobe of our 
narrow-vertical-beam-width transmitter and even then it 
almost missed the aircraft. 
Sound 
A 5 f i 7  
I 
25 
Q 35 n 
0 0.2 0.4 0.6 0.8 1 1.2 
Ray angles: -5’ to +5’ Range ( km ) 
Velocity (mls) 
35 
45 
55 
Figure 5. SAS image of PB4Y-2 airplane at 980 m (above). Sound velocity profile and ra.y 
trace results for Lake Washington. 
4-1 754 
CSS High and Low Frequency SAS Results 
Coastal Systems Station (CSS) in Panama City, Florida 
collected SAS data using an array built by Northrop- 
Grumman. This array contained 11 high frequency (180 
kHz) elements and 14 low frequency (20 kHz) elements. 
The length of the high frequency elements was 5.08 cm, 
giving a theoretical cross-range resolution of 2.54 cm, and 
the low frequency elements were 3.81 cm. However, the 
cross-range resolution for the low frequency is limited by 
the wavelength (7.5 cm) rather than the element length. For 
these experiments, a series of objects, such as a large 
cylinder, a ladder, and a truncated cone, were placed on a 
sandy bottom. Figure 6 shows the focused image for the high 
frequency data and Figure7 shows the same image after 
conventional beamforming - note the resolution degradation 
with range. Figure 8 is the resulting image for the low 
frequency. In the case of the high frequency data, the image 
was formed using RPC and RMA, but an autofocus step was 
not required. The low frequency image was formed using all 
three steps. 
Some interesting differences between the two images 
indicate how target response is frequency dependent. For 
example, the cylinder object (upper right corner) in the high 
frequency image is bright along its whole length, and a 
distinct shadow is visible. However, only its ends are bright 
in the low frequency image, and no shadow is present. 
Similarly, the long shadow behind the truncated cone (just 
below the cylinder) also disappears for the low frequency 
image. 
 35m 
Figure 7. High frequency (180 kHz) conventionally 
beamformed image (same scene as in Figure 6). Note that 
the resolution degrades rapidly with increasing range. 
35m- 
Figure 8. Low frequency (20 kHz) SAS image. Objects and 
background reverberation have different image 
characteristics at 20 lcHz than at 180 kHz. 
t------------- 35m _________, 
Figure 6. High frequency (180 kHz) SAS image. 
A cylinder in the upper right gives a clear shadow. 
5.  CONCLUSIONS 
We have shown that synthetic aperture imaging is viable 
with sonar and capable of providing order-of-magnitude 
improvements in cross-range at long ranges resolution over 
conventional sonar beamfoming techniques. SAS 
4-1755 
techniques are applicable to sonar systems of widely varying 
characteristics, and appear to be robust in the face of a 
multipath acoustic environment. Despite poor or non- 
existent motion data, we are able to estimate motion errors 
and correct the,data for such motion. 
SAS is a technique with clear uses in bottom mapping, 
whether for military uses, commercial uses, such as for the 
oil industry, or general research, such as for geology and 
archaeology. Currently all SAS systems are mounted on a 
towbody and therefore must operate in waters with depths of 
tens of meters or greater. However, at time of writing we are 
preparing for a sea test with a SAS system mounted upon a 
bottom crawling robot built by Foster-Miller, Inc. and 
funded by DARPA. This system will function in very 
shallow water and, we hope, in the surf zone. The motions of 
this vehicle are expected to be quick and jerk4 and will 
greatly test our ability to estimate and correct motion. The 
environmental effects of shallow water and surf, e.g., 
multiple top and bottom bounces and air bubbles, will also 
present challenging processing problems. 
REFERENCES 
[l] Bart D. Huxtable and E. Michael Geyer, ”Motion 
Compensation Feasibility for High Resolution Synthetic 
Aperture Sonar,” IEEE Oceans ’93 Proceedings, October 
18-21, 1993. 
[2] W.M. Carey, “The Determination of Signal Coherence 
Length Based on Signal Coherence and Gain Measurements 
in Deep and Shallow Water, I’ IEEE Oceans ’97 Conference 
Proceedings, 6-9 October 1997, Halifax, Nova Scotia, pp. 
462 - 470. 
[3] W. Carrara, R Goodman, and R. Majewski, Spotlight 
Synthetic Aperture Radar. Boston, MA: Artech House, 
1995. 
[4] RM. Goldstein, T.P. Barnett, and H.A. Zebker, “Remote 
Sensing of Ocean Currents,” Science 246, pp. 1282-1285, 
1989. 
[5] W.B. Goggins, “Adaptive Clutter Cancellation for 
Syntheic Aperture AMTI Radar,” U.S. patent no. 3,993,994, 
1976. 
[6] C. CaEorio, C. Prati, and E. Rocca, “SAR Data Focusing 
using Seismic Migration Techniques”. IEEE Trans. on 
Aerospace and Electronic Systems 27, pp. 194-206, 1991. 
[7] P. Eichel, D. Ghiglia, and C. Jakowatz, “Speckle 
Processing Method for Synthetic Aperture Radar Phase 
Correction”. Optics Letters 14, pp. 1-3, 1989. 
High Resolution SAR Phase Correction” IEEE Transactions 
on Aerospace and Electronic Systems, .30, No. 3, pp. 827- 
835, 1994. 
Angela Putney is a research scie,r?tist for Dynamics 
Technology, Inc. She is project manager for two SAS 
programs including building and testing a bottom crawling 
SAS system. She has been processing SAS data over the past 
year an,d a half: Before DTI, she was a Physics 
Management Fellow at the American Institute of Physics 
and a temporary astronomy lecturer at the University of 
Southern California. Until recently, her main interest was in 
magnetic white dwarf stars. She has an S.B. in physics fiom 
MIT and a Ph.D. in Astronomy +om Coltech. 
[SI D. E. Wahl, P.H. Eichel, D.C. Ghiglia, and C.V. 
Jakowatz, “Phase Gradient Autofocus-A Robust Tool for 
4-1756 
