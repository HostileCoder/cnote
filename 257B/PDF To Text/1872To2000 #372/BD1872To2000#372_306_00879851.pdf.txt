Advanced Technologies High Resolution Fourier 
Transform Spectrometer for Atmospheric Studies 
N. S. Pougatchevl, J. F. Campbell’, C. R. Regan’, 
M. C. Abrams3, J. W. Brault4, C. B. Farmer, and D. E. Hinton* 
khristopher Newport University, Newport News, VA, n.s.pougatchev@larc.nasa.gov 
’NASA Langley Research Center, Hampton, VA, j.f.Campbell@larc.nasa.gov, 
c.r.regan@larc.nasa.gov d.e.hinton@larc.nasa.gov 
31TT Industries, Fort Wayne, IN, mcabrams@itt.com 
4brault @ noao.edu 
Abstract-A new high resolution Fourier transform 
spectrometer (FTS) suitable for spacebome and airborne 
applications has been designed and built at the NASA 
Langley Research Center. Applications of advanced 
technologies, e.g., lightweight materials, solid state drive 
mechanism, new data processing approaches, etc., reduce 
significantly mass, volume, and power requirements [ 11. 
The combination of precision elements and optical 
symmetry of a double-passed design make the 
interferometer ‘aligned by design’, i.e., once the 
interferometer is assembled it need never be aligned again. 
Results of the instrument laboratory tests and atmospheric 
solar measurements are presented. 
TABLE OF CONTENTS 
1. INTRODUCTION 
2. INTERFEROMETER 
3. INSTRUMENT CONTROL , DATA ACQUISITION AND 
PROCESSING 
4. TESTRESULTS 
5. CONCLUSIONS 
1. INTRODUCTION 
After four decades of development, FTS has become the 
premiere high resolution, broadband passive spectrometer 
for remote sensing applications. Four flights of the 
Atmospheric Trace Molecule Spectroscopy (ATMOS) 
instrument onboard the Space Shuttle returned important 
geophysical results [2]. Excellent quality of the ATMOS 
spectra was attained, in particular, because of its tilt and 
0-7803-5846-5/00/$10.00 0 2000 IEEE. 
shear compensated optical design, double sided 
interferogram, etc. However, its mass (-250 kg), size 
(-lxlxl  m3), and power consumption (- 200 W), make it a 
less than ideal candidate for future spacebome missions. 
Therefore, a new concept for a high resolution FTS suitable 
for various atmospheric studies is required. Modem 
advanced technologies and new approaches to data 
acquisition and processing enable a small lightweight 
instrument [I]. In the present paper we present a design 
and test results of a compact FTS suitable for spacebome 
and airborne applications which has been designed and built 
at the NASA Langley Research Center. 
2.  INTERFEROMETER 
Figure 1 shows the optical diagram of the iterferometer. In 
the design, both retroreflecting Big Cube-Comers (BCC) are 
moved as one assembly to produce interference. The 
resulting interferogram from the full BCC motion is fully 
doublesided, minimizing difficulties in phase correction. 
The presented optical layout is an eightfold design, i.e., 
1 cm of mechanical displacement of the BCC assembly 
results in 8 cm of Optical Path Difference (OPD). For the 
particular dimensions maximum OPD attainable is 
approximately 25 cm, which translates into -0.02 cm-l 
resolution. Beam diameter is -25 mm, limited by an 
aperture of stationary small Cube-Comers (sCC). To control 
the OPD a single frequency He-Ne reference laser is used. 
In the current configuration the beamsplitter and 
compensator are made out of CaF2 substrate. The 
combination of precision elements and optical symmetry of 
a double passed design make the interferometer tilt 
compensated. An additional attribute of the optical 
configuration is that, since it is ‘aligned by design’, once the 
interferometer is assembled it need never be aligned again. 
237 
au f 
Figure 1 Optical layout of the interferometer. All dimensions are in millimeters. BCC - Big Cube-Comer assembly; sCC 
small Cube-Comers, BS - beamsplitter; C - compensator; FM -folding mirrors. 
3. INSTRUMENT CONTROL, DATA ACQUISITION 
AND PROCESSING 
ms instruments require precision control of the OPD scan 
velocity (-0.1%) to insure the quality of a spectrum [3]. The 
eight fold optical layout of our FTS imposes tough 
requirements on a scanning mechanism and data acquisition 
system. Implementation of an interferogram sampling and 
processing algorithm developed by J. W. Brault [3] resolves 
this issue. This algorithm is based on oversampling of an 
interferogram with subsequent processing using an adaptive 
digital filter [3]. In the following sections a detailed 
description of the instrument control and data acquisition 
systems, along with data processing algorithms are 
presented. 
3.1. Instrument control 
In our instrument a voice coil linear motor is used for 
scanning. The BCC assembly is mounted on a linear 
translation stage that is driven by the voice coil. To attain 
maximum stability of scan velocity, a closed loop control is 
implemented. The feedback signal is generated by the linear 
quadrature encoder with 50 lineslmm resolution and is 
connected to a lox interpolation board. There is another 4x 
interpolation at the controller. The controller is an in-house 
design consisting of an Intel 8751 microcontroller which is 
used as a command interpreter to a National LM628 motion 
controller. The LM628 motion controller was originally 
designed as a DC motor controller. However, it is a standard 
PID (position integral derivative) controller and works well 
with other actuators. It has a built-in quadrature decoder 
with 4x interpolation. It also has a 32-bit counter and 16-bit 
filter coefficients. We currently use the system in a PID 
mode where control is based on position error and uses 
position error rate as stabilization. For any particular 
position error feedback, an optimal position error rate 
feedback to provide critical damping must be found. The 
power drive is provided by a National LM12 power 
amplifier. With this control mechanism, velocity 
nonuniformity is -3% (rms) at average speed 0.2 cdsec .  
3.2. Data acquisition system 
The data acquisition system has been designed at National 
Institute of Standards and Testing (NIST). It consists of a 
24-bit analog-to-digit converter (Crystal CS5396), a fringe 
counter capable of measuring time intervals between fringes 
of a reference laser interferogram, and a PC computer 
interface board. Fringe timings are measured by a 40 MHz, 
high precision quartz clock. The infrared interferogram is 
sampled at a constant frequency of 78.125 KHz. A built-in 
anti-aliasing filter suppresses all signals with frequencies 
higher than half of the sampling frequency. An interface 
board with intermediate buffers transfers data from 
sampling and timing boards into a computer memory. 
3.3. Data processing 
Since the data is taken linearly with time, as opposed to 
OPD, the data must be resampled linearly with OPD. The 
processing is very similar to that developed by Brault [3]. 
238 
Similarly, we use adaptive digital filtering, polynomial 
interpolation, phase correction, etc. The details of how this 
is done are somewhat different, however. 
3.3.1. Correction for scanning noiiuniformity-The 
information gathered from the data acquisition system is 
amplitude-vs-time and time intervals between reference 
laser fringes. The fringe times are not aligned to the 
amplitude data: therefore, a time delay constant must be 
found. The first thing that is done is to find the total time as 
a function of fringe number. This is determined by, 
N 
TN =xtn , 
n =O 
where T is the total time, N is the fringe number and t, is 
the nth fringe time interval. We use this information to 
resample the amplitude. Through interpolation we have the 
time-vs-fringe number and amplitude-vs-time. The 
resampled amplitude is then, 
A~ = A(T, +s), 
where 6 is the system delay. The above assumes a 
resampling at 1 sample/fringe. If some other sampling is 
required, it is a simple matter to find the total time for some 
other fringe sampling, and our software does just that. 
However, there is a great advantage to sampling at 1 
sample/fringe, because only one interpolation needs to be 
done in this case. 
The type of interpolation used is based on a variation of 
Aitkins algorithm [4.5] . This gives the same result as 
Lagrange interpolating polynomials, but is faster and has the 
flexibility of not having to specify a particular interpolating 
polynomial for a particular order of interpolation. We have 
found that gfh order interpolation gives the best results. 
3.3.2. Adaptive Digital Filtering-Another point that has not 
been discussed is digital filtering. Since the data are 
oversampled, we may use this to filter out high frequency 
noise and other artifacts. Time based filters are most 
commonly used by way of convolution. The technique 
developed by Brault [3] is a very efficient implementation 
of this approach. He uses what amounts to a sliding 
window. However, time based filters have their 
shortcomings. Because they are typically based on a short 
convolution, frequencies of interest are filtered along with 
everything else. In addition, some unwanted frequencies 
may leak in, and there will always be a phase dispersion 
associated with the filter. The situation is improved if one 
uses a complicated (long) convolution based on one of the 
standard filters [6].  One reaches a point where it is more 
efficient to take the FFT and filter in the frequency domain, 
since a convolution of the same length of the data set is an 
N2, process whereas an FlT is an Nlog2N process. The 
choice of which method to use depends completely on the 
quality of the filtering desired and the time allowed to do it. 
An FFT filter is very flexible and produces the highest 
quality results when compared with short time based 
convolutions. We use an ideal filter constructed from a 
Fourier transform. Although slower than many time based 
filters, the quality of the filter is much better. The process is 
simple - take the FFT and zero out the unwanted 
frequencies and take the inverse FFT. In order for this to 
work correctly one must understand how the FFT works. An 
FFT of a signal will consist of positive frequencies from 
n=l to n=N/2- 1 and wrapped negative frequencies from 
n=N to n=N/2+1. The value at n=N/2 is mixed. In order to 
construct an FFT filter, one must apply the filtering 
symmetrically. For every positive frequency taken out one 
must take out the same negative frequency. The result is a 
filter that only filters out the unwanted frequencies and 
leaves the others untouched. This filter could be improved 
by applying a taper at the edges of the filter, however, we 
have not found this necessary for our work. 
3.3.3. Preprocessing-Preprocessing amounts to making 
ZPD at N/2, making the number of points the same on either 
side of ZPD, subtracting the slope and tapering the edges. 
The process of subtracting the slope is at first sight a trivial 
matter. However, there are many ways to do this. A method 
which has been developed for the current work is fast and 
relatively immune to round off error. The derivation of this 
method is based on a standard least squares technique. If f 
(n) is the signal we wish to subtract a slope from then we 
minimize, 
-1 
with respect to a and b. The resulting equations are, 
N N N 
a x n 2 + b x n  = x n f ( n )  
n= 1 n=l n =I 
N N 
a x n  + bN = f ( n )  
n= 1 n= 1 
Using the identities, 
239 
1 
=I 6 
N 
n2 = - N ( N  + 1) ( 2 N  +l). 
Then 
The first thing to notice is that this result contains only 2 
sums. If we were to solve the original equations numerically 
we would have to compute up to 6 sums. Potentially this is 
3 times faster to compute. The second thing to notice is that 
these sums involve the sum of small differences. This means 
the potential for round off error is very much reduced. In 
fact, solving the original equations directly would involve 
the sum and difference of terms as large as N4. The potential 
for round off error is high. In fact, if the slope is small 
enough and the length of the array is large the potential for 
doing more harm than good is a real possibility. This, on the 
other hand, may be computed even in single precision with 
reasonable results. 
We taper the edges by taking N/256 points on either edge 
and apply a partial Hanning window. Since this involves 
only N/128 of the data points, the effect on the spectral 
resolution is very slight. 
3.3.4. Phase Correction-The main contributor to the phase 
shift is the electronics, misalignments, etc. This results in a 
frequency dependent phase shift. The ideal interferogram is 
symmetric about ZPD. The phase shifted interferogram, on 
the other hand, has an asymmetric component, which results 
in an imaginary component to the complex FFT. The 
process of correcting the phase is based on the assumption 
that the phase shift is a slowly changing function that may 
be measured. One simply calculates the phase shift from the 
measured data and then fits it to a smooth function, such as 
a polynomial. This polynomial is used then to take the phase 
shift out. The result is a complex spectrum with a mostly 
real component. What is left in the imaginary component is 
noise; therefore, this imaginary component may be 
discarded. 
Our phase correction is done in a manner that is different 
than is customary [7]. The usual method for subtracting the 
phase involves taking the complex FFT of a few hundred 
points about ZPD, and then computing the phase from the 
real and imaginary parts, fitting it to a high order 
polynomial, and using this to subtract the phase out. There 
are potential pitfalls to this method, however. If there is a 
strong absorption and the phase is measured at that 
absorption, then there is a strong possibility that the signal 
to noise ratio (SNR) at that point will be bad enough to 
throw the phase calculation off. The main reason a few 
hundred points about ZPD are used is that, if one were to 
calculate the phase from this short data set, the resulting 
phase curve would be much smoother than if the entire data 
set was used. However, the same problems are there - 
wherever there is a strong absorption line the SNR is not 
good enough to measure the phase. The advantage in using 
this shortened version is that the resolution is so low that 
one does not see every absorption line. However, some 
very strong lines can still get through which can complicate 
the phase calculation and potentially throw it off. 
In the phase correction method developed for the current 
work, the phase is calculated from the entire data set. 
Instead of shortening the data set to eliminate absorption 
lines, we assume they will always be there and only include 
those spectral points where the SNR is good. First, we 
choose a spectral range of interest. Once this is done, we 
find the maximum of the magnitude of the complex 
transform and use only those points where the magnitude of 
the complex transform is between the maximum and some 
fraction of the maximum. How one chooses this fraction 
depends on the spectrum. The criterion used is to pick the 
minimum fraction that will allow a good sampling of points 
in the widest spectral range. In the present study for phase 
correction we take all spectral points that have an amplitude 
between the maximum and 1/2 the maximum. The 1/2 factor 
is chosen such that we have as many points as possible over 
the widest range possible while maintaining a good SNR. 
Thus, the points used in the calculation are chosen based on 
SNR, as opposed to smoothness. This method is superior in 
the sense that we have many more points to work with, 
which means whatever noise exists will be averaged out 
better. 
The complex spectrum is defined as, 
Here the integral has been approximated as a finite sum with 
a step size h. In order to get this into a form an FFT can 
handle, the ZPD is translated from 0 to N/2. The result is, 
240 
We now make the substitution, k=m/(Nh) and find, 
Except for the (-l)m-l term, this is the complex FFT. We 
take the complex FFT of the entire data set and, within that 
data set, select points used in the phase calculation. Taking 
an FFT on one side of the axis results in an additional phase 
shift of i m z  This means we must multiply each element of 
the FFT by (-l)m-l. The thing one must remember is to only 
use points where the SNR is good. This is then fit to a high 
order polynomial using single value decomposition. The 
advantage to using such a large data set is that the 
polynomial fit is so far over determined that whatever noise 
is in the phase measurement is averaged out. One must be 
very careful how this is done, because any error here will 
ruin the data. For instance, if the SNR is 1: lOO and our 
phase calculation is 5% off, doing a phase correction in that 
situation could do more harm than good when compared to 
just using the magnitude of the complex transform. To 
'13 
12 
11 
IO 
B 
8 
7 
6 
5 
4 
3 
2 
4 
a 
-z 
-2 
minimize round off error the x axis is rescaled so that no 
value is larger than one, and all calculations are performed 
in double precision. This eliminates the problems 
associated with taking a large number to the nth power. The 
x axis is then rescaled back after the calculation is done. 
Good quality fit can be attained with 5" order polynomials. 
Results of practical application of the processing techniques 
described above are presented in the following section. 
4. TESTRESULTS 
To test the instrument performances some infrared (IR) 
absorption spectra of a low pressure ( 90 mbar) CO cell 
have been recorded. A blackbody at a temperature of 1300 
K was used as a light source. The output beam was focused 
on a liquid nitrogen cooled InSb photoconductive detector. 
The instrument line shape (ILS) function was retrieved from 
these spectra using a nonlinear least square fitting algorithm 
[8]. An example of such a retrieval is presented in Figure 2. 
The width of the line in Fig. 2 is -5% greater than the 
theoretical limit for the interferogram with the same OPD. 
Figure 2 Instrument Line Shape function (ILS) derived from an absorption spectrum of carbon monoxide. 
241 
As mentioned above, one of the prospective applications for 
the described FTS is solar spectroscopy. Therefore, some 
solar IR spectra were taken. A long-wavepass filter and an 
InSb detector limit the spectral range to (1.63 - 5.5) p. In 
Figure 3a, an example of a broad band solar spectrum is 
presented. A narrow spectral interval containing the R3 
absorption line of carbon monoxide (at 2158.3 cm-l) 
is shown in Figure 3b. Spectral resolution was set at 
0.055 cm-l(unapodized); the field of view was 4.5 mad.  
The spectrum was transformed from a single-scan double- 
sided interferogram with a scanning time of 13 sec. For 
phase correction all spectral points from the spectral interval 
1900 cm-l - 3500 cm-l with amplitude greater than 7500 
(see section 2.3.4) were used. Results of phase retrieval and 
polynomial fit are displayed in Figure 4. One can see that 
the phase curve is smooth and does not contain high 
frequency features, indicating that the proposed method for 
phase correction works well. 
15000 
10000 
5000 
0 
2000 2500 3000 
Wavenum ber (cm -I) 
Figure 3a Broad band solar spectrum. 
10000 
m 
0 
2158 2159 2160 
Wavenumber (an') 
Figure 3b Solar spectrum containing R3 line of carbon 
monoxide (at 2158.3 cm-l). 
3500 
-".d , I 1 I 
2000 2500 3000 3500 
Wavenumber (cm-') 
Figure 4 Phase retrieved from a solar spectrum. Symbols 
are retrieved data points, solid line indicates a 5-th order 
polynomial fit. 
242 
4. CONCLUSIONS 
The combination of a paradigm shift in the design of FTS's 
and the application of new technologies to these new 
designs have the potential for making the FTS a much 
stronger contender for future remote sensing applications. 
The capability for reducing mass and volume by an order of 
magnitude over past FTS instruments now exists. 
Additionally, the use of algorithms, such as the Brault 
Algorithm, for on-board processinglcompression can offer 
relaxed tolerances on the instrument specifications. Our 
FTS design is a testbed for evaluating the impact of new 
technologies and data handling approaches on instrument 
performance and capability. Near-future plans for our 
instrument include its use in field solar spectroscopic 
measurements and assessment of various techniques and 
hardware, i.e., new types of scanning mechanisms, detector 
arrays, and real-time on-board data processing. 
REFERENCES 
1. Hinton, D. E., I. G. Nolt, J. H. Park, W. L. Smith, and 
M. C. Abrams, Applications of advanced technologies to 
space-based Fourier transform spectrometers for 
atmospheric remote sensing, in Proceedings of 1998 IEEE 
Aerospace Conference, paper #275,1998. 
2. Farmer C. B., and 0. F. Raper, High-resolution infrared 
spectroscopy from space: A preliminary report on the results 
of the Atmospheric Trace Molecule Spectroscopy 
(ATMOS) experiment on Spacelab 3, NASA Con$ Proc., 
NASA CP-2429.1986. 
3. J. W. Brault, New approach to high-precision Fourier 
transform spectrometer design, Appl. Optics, 35, pp .  2891 - 
2896,1996. 
4. Germund Dahlquist and Ake Bjork, Numerical Methods 
Prentice-Hall, 1974. 
5.  Teukolsky, Vetterling, and Flannery, Numerical Recipes, 
Press, Cambridge University Press, 1992 
6. C. Britton Rorabaugh, Digital Filter Designers 
Handbook, McGraw-Hill, 1997. 
7. Forman, M. L., W. H. Steel, and G. A. Vanasse, 
Correction of Asymmetric Interferograms Obtained in 
Fourier Spectroscopy, Journal of the Optical Society of 
America, Vol. 56, 59 - 63, 1966. 
8. Hase, F., T. Blumenstock, and C. Paton-Walsh, Analysis 
of the instrumental line shape of high-resolution Fourier 
transform spectrometers with gas cell measurements and 
new retrival software, Appl. Optics, 98, 341 7-3422, 1999. 
Nikita Pougatchev Scientific research in atmospheric 
physics and atmospheric spectroscopy in application to 
remote sensing of atmospheric trace gases. Development of 
methods for remote sensing including software computer 
codes, spectroscopic apparatus design, laboratory and field 
measurements, and data analysis. He developed retrieval 
techniques for CO, ozone, methane, and CO2 total column 
and vertical distribution from solar infrared spectra. He led 
the work of the international spectroscopic team for 
validation of the MAPS 1994 flights, and he is a principal 
investigator for the validation of the MOPITT instrument 
on the NASA Terra satellite. He has a Ph. D. from the 
Institute of Atmospheric Physics, Russian Academy of 
Science. 
243 
